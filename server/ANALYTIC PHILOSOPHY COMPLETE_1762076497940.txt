Chapter 1
Analytic Philosophy as Logical Analysis
1.0 Philosophy as the analysis of the categories in terms of which understand the world
We understand the world in terms of certain categories (e.g., person, statement, fact, impossibility, existence). Philosophy studies these categories. It delineates their structures. This is its sole function. Thus, philosophy is the discipline that delineates the structures of the categories in terms of which we think about the world.
   We’ve already identified some of these categories. By stating a few of our most basic beliefs, we can identify some more (they’re the ones denoted by the italicized expressions):
The world isn’t homogeneous. It is articulated into events bearing various causal and, more generally, spatiotemporal relations to one another. Many of these events involve more or less persistent things (rocks, trees, etc.). Some of these things have minds. Most animate (mind- having) beings have sense-perceptions; i.e., they see things, hear things, etc. Most percipient (perception-having) creatures have beliefs. Some of these beliefs are true; others are false. Some of the true ones are cases of knowledge. Some percipient creatures communicate with one another through the use of language. Mastery of a language makes it easier for one to communicate one’s beliefs to others, and it also enhances one’s ability to reason. Rational (reason-capable) creatures tend to make value-judgments. They judge one another’s actions, and sometimes their own, to be good or bad. Creatures that make such judgments tend to regulate their behavior towards one another by means of systems of law, the supposed purpose of which is to ensure that such behavior satisfy the requirements of justice.
1.1 Knowledge vs. meta-knowledge
Event, space, time, cause, persistence, thing, mind, perception, belief, knowledge, language, truth, value-judgment, law, justice. Whatever we know, we know it through these categories (and others like them—the list is not complete). But even though we cannot think without them, they are seldom the objects of thought. The result is that, although we’re adept at using them, we know little about them.
   For example, we are excellent at distinguishing linguistic from non-linguistic behavior, which suggests that, at some level, we know what conditions a creature’s behavior must meet if it is to embody knowledge of a language. But when asked to make these conditions explicit, we find we can do so only with great difficulty and only with partial success. So even though we are good at knowing who knows a language and who does not, we don’t know what it is that we know by virtue of knowing this.
   The same thing mutatis mutandis is true of each one of these categories. We’re excellent at distinguishing between moral and immoral behavior. We know that rape is immoral and that donating money to charity (for selfless reasons) is moral. But when asked to identify the principles embodied in these pedestrian and uncontroversial judgments, we have trouble producing theories that don’t distort them.
   In general, it’s hard to identify the principles that guide our thoughts. Self-understanding isn’t the mind’s primary function. Nor could it be. The idea of a mind that thinks about nothing other than itself is an incoherent one. Thus, any case of self-awareness, and therefore of self-understanding, is necessarily derivative of, and for that reason of lesser quality than, some other more fundamental sort of understanding.
   
   Being the discipline whose purpose is to delineate the structures of these categories, philosophy has the very non-trivial job of identifying, in as clear and explicit a manner as possible, the conditions that a given thing must satisfy if it is to fall into a given one of these categories. So far as philosophy succeeds in this endeavor, it makes it clear what it is that we are doing when we are doing anything cognitive, be it making an observation or engaging in an extended piece of abstract reasoning. Philosophy is the analysis of the preconditions of all knowledge. It is the analysis of analysis, the logic of logic, the science of science.
1.2 The relationship of philosophy to other disciplines
The philosopher is interested in the laws governing the laws. He doesn’t want to know what in fact holds. He wants to know what it would even make sense to claim to hold. He wants to know the laws that the laws can’t break.
   Philosophical knowledge is metaknowledge—knowledge about knowledge. The non-philosopher wants to know specifics. What happened? When did it happen? What did it cause? How did it cause it? The philosopher is interested in these questions only to the extent that knowing the answers to them helps him understand the categories (cause, place, time, etc.) underlying such knowledge.
   The stranded motorist wants his car to work. He doesn’t care what will get it to do so. The engineer is interested in this. But the engineer is not entirely innocent of the motorist’s epistemic parochialism. The engineer has no interest in what the laws of physics are except in so far as he must know them to create the right mechanisms. But the physicist wants knowledge of the mechanisms only to the extent it will give him knowledge of the laws embodied therein.
   The philosopher is to the physicist what the physicist is to the engineer and, therefore, what the engineer is to the stranded motorist. The philosopher wants to know what causes what and what mechanisms were involved only to the extent that knowing this helps him understand what it is for one thing to cause another— only, that is to say, in so far as it helps him know what it is that one knows in knowing that one thing made another happen.
1.3 How is analytic philosophy different from non-analytic philosophy?
John Stuart Mill (1806–1873), the great philosopher and economist, said that he was an expert in but one science, that being the science of science. What he meant was obviously similar to what we’ve been saying. And it was similar, therefore, to what Gottlob Frege (1848–1925), the great philosopher and mathematical logician, meant when he said that logic studies not the laws of nature but the “laws of the laws of nature.” Whether Frege was right depends on what exactly one means by “logic.” But if, by “logic,” he meant “philosophy,” then Frege’s dictum was spot-on.
   Frege is often described as the first analytic philosopher. Michael Dummett (1925–), an exceptionally capable contemporary philosopher of language, said that “analytic philosophy is post- Fregean philosophy.” What does Dummett mean?
   With some exceptions, pre-Fregean philosophers thought they were studying the most general features of the actual world. They thought that, like the botanist, they were in the business of saying how the world is, the only difference between their work and the botanist’s being that theirs is concerned with more general features of reality than the botanist’s.
   Frege showed that this is wrong. Any interest that botanists have in plants that might exist, but don’t, is subordinate to their interest in what plants actually exist. Like all scientists, they are interested in what there could be only to the extent that it helps them figure out what there is. But with philosophers, it’s the other way around. Any interest they have in the actual is subordinate to their interest in the possible.
   
   Unlike non-analytic philosophers, analytic philosophers figure out what there could be by analyzing statements. Statements that make sense are those that an be true, and statements that don’t are those that can’t. Therefore, statements that make sense describe possible realities and those that don’t don’t.
But what exactly did Frege do?
2.0 Frege’s key insight: Logical form ≠grammatical form
Frege’s legacy to philosophy can be summed up thus:
(FL) When people have an obviously correct belief that seems to have an absurd consequence, they should ask themselves whether that absurdity really is a consequence of that belief. But they frequently don’t. Instead they accept the absurdity and, in order to make this mistake of theirs work, they develop ad hoc hypotheses as to the nature of reality that undermine the integrity of their own belief system.
    Consider the statement: (SC) nothing is a square circle.
SC is true. Everybody knows this. But what does SC say? Judging by its grammatical similarity to “Smith is a very capable lawyer,” which attributes a certain property (that of being a capable lawyer) to a certain individual (Smith), SC would seem to say that a certain entity has the property of being a square circle. Presumably, the entity in question is some non-entity. If this presumption is correct, SC says that:
(SC*) some non-entity, some featureless un-thing, is a circle.
   But SC* is doubly incoherent. If anything is a square circle, then SC is false—it being irrelevant how much of a cipher the entity in question is. Second, the very idea of a non-entity is an absurd one. But it’s hard to find a layperson or scholar who, when asked what SC means, comes up with anything substantively different from SC*.
   Given what a rank absurdity SC* is, we can’t accept it, even though it seems to be an obvious consequence of SC. But we can’t reject SC, since it’s an obvious truth.
   To get out of this jam, we need only reflect a bit on what our words mean. If you say that nobody likes Larry, you’re not saying that some un-person likes Larry. You’re saying that if you gathered together all the people who liked Larry and put them in an otherwise empty room, that room would remain empty. Which is the same as saying that, if you put all the people in existence in an otherwise empty room, there would be no things that liked Larry in that room.
   Thus, what “nobody likes Larry” means is not that some un-person likes Larry, and is instead that the set of people who like Larry is empty or, alternatively, that the set of people doesn’t overlap with the set of things that like Larry.
   SC is to be understood along similar lines. If you put all the square circles in existence in an otherwise empty room, that room would remain empty. This is another way of saying that, if you put all the square things in an otherwise empty room, there would be no circles in that room. So SC says, not some un-thing is a circle, but that
(i) the set of things that are both circular and square is an empty one or, alternatively, that
(ii) the set of circles doesn’t overlap with the set of squares.

(i) is a way of saying that any given thing lacks the property of being both a circle and a square.
Alternatively, it’s a way of saying this property doesn’t have any instances—that it’s uninstantiated.
(ii) is a way of saying that anything having the property of being a square lacks the property of being a circle. Alternatively, it’s a way of saying that these two properties don’t have any instances in common—that they are not coinstantiated.
   (i) and (ii) thus attribute properties to properties. They say, respectively, that the property of being both a square and a circle is uninstantiated and that the properties of being a square and of being a circle are not coinstantiated.
   Since (i) and (ii) are just different ways of saying what SC says, the latter doesn’t make the absurd statement that some non-entity is a circle, and it instead makes the innocuous statement that the set of squares doesn’t overlap with the set of circles or, alternatively, that the property of being a square circle is uninstantiated.
   What this shows is that, in at least some cases, philosophical insight is acquired, not by doing parascience, but by analyzing meanings—not by positing entities, but by clarifying statements.
Analytic philosophy is philosophy that is driven by accep-tance of FL. Let us now expand on FL
and make it clear why it’s true.
2.1 The wrong way to react to grammatical surface-structure
In respect of its grammatical form,
(JS) “John smokes”
is comparable to
(MS) “Mary smokes.”
JS attributes the property of being a smoker to John; MS attributes that property to Mary.
In respect of its grammatical form, each of JS and MS is comparable to:
(LJ) “Larry juggles”
and also to
(JJ) “Jane jogs.”
   Each of these sentences says of some individual that he or she has a certain property. The obvious inference to make is that any sentence grammatically comparable to any one of those of four sentences says of some individual that he or she (or it) has some property.
   In light of these points, consider the sentence: (SS) Someone smokes.
   Given what we just said, the obvious thing to say about it is that it attributes the property of smoking to some individual. But which individual could that be? Which individual does “someone” pick out?
   “It picks out an ambiguous person,” said one logician. But this answer is no good. Words are ambiguous, not people. “Bank” is ambiguous, since it has two meanings. But I’m not ambiguous, and neither are you. And if per impossibile there did exist some ambiguous person—some blank, featureless shell of a person who was picked out by “someone”—SS would unambiguously say of that person that he or she smoked. But there clearly
   
isn’t any one person to whom SS attributes the property of smoking. This is easily shown. If Smith
smokes, the sentence: “someone smokes but Smith does not”
will be false. But it won’t be self-contradictory; it won’t be like “Smith smokes but Smith does not smoke.” (For a statement to be self-contradictory is for it to bear two mutually opposed meanings.) Of course, there isn’t anything special about the name “Smith,” what we just said could have been said in connection with Jones or Brown or any other expression that refers to some individual. Thus, there is no individual N such that it is self-contradictory to say that someone smokes but N does not. Therefore “someone” doesn’t refer to anyone.
   “But you’ve misunderstood my thesis” it will be said. “The word “someone” doesn’t unambiguously pick out an ambiguous person. It is itself ambiguous. It refers to Fred and Ethel and Mary. It refers to all people indifferently.”
   That’s false. “Someone” isn’t ambiguous; it isn’t like the word “dumb.” SS has one meaning, unlike “John is dumb,” which could mean either “John is unintelligent” or “John is mute.” Also, if “someone” were ambiguous between “John” and “Ethel” and so on, then, depending on the circumstances, it would be synonymous with “John smokes” or “Ethel smokes.” And in that case, “someone smokes, but John does not” would sometimes have the same meaning as “John smokes but John does not smoke,” in which case it would be self-contradictory. But, as we just saw, “someone smokes, but John does not” is not self-contradictory under any circumstances. If John does smoke, it will be false, but it won’t be self-contradictory.
   Also, it isn’t clear what it means to say that “someone” picks out everyone “indifferently.” But if, as is surely the case, picking out everyone indifferently involves picking out everyone, then it’s just wrong to say that “someone” picks out everyone “indifferently” (or in any other way). For if it did, it would have the same meaning as “everyone,” which it doesn’t.
2.2 The right way to react to grammatical surface-structure
   What all this shows is that “someone” isn’t in the same category as “John” and “Ethel.” It doesn’t function in the same way, even though, given its grammatical function, one would expect it to. SS is obviously true. The wrong way to react to that fact is to twist reality to make it conform to our assumption that “someone,” being grammatically comparable to “John,” must refer to something. If we take that path, we must say that it refers to an “ambiguous” or “non-specific” person, or some such, given that it obviously doesn’t refer to anyone specific. But then we’re then stuck with the absurd thesis that there is some non-specific entity in the world— that there exists something that isn’t identical with any particular thing and therefore isn’t identical with anything.
   The right way to react to it is to think more deeply about what SS is really saying. Frege did this, and he solved the puzzle. SS’s logical form diverges from its grammatical form. In terms of what its grammar suggests that it is saying, SS is indistinguishable from sentences that attribute the property of smoking to specific objects. In terms of what it really is saying, it is evidently very different from such sentences.
   What SS is saying, as Frege made clear, is that the characteristic—or as analytic philosophers put it, the property—of being a smoker is instantiated. SS is making a statement, not about some non- specific individual, but about a very specific property, and it’s saying of this property that it’s instantiated. (For a property to be instantiated is for there to be an instance of it. An instance of a property is something that has it. You are an instance of, and therefore instantiate, the property of being human since, being human, you have that property. )
   There are properties that nothing has. Nobody has run a three-minute mile. Given any individual, x, it is false to attribute the property of being a person who has run a three-minute mile. Thus, there are no instances of that property. It is uninstantiated. The grammatical form of (“TM” can be thought of as short for “three minutes”):
(TM) “nobody has run a three-minute mile”
   
is just like that of
(JTM) “John has run a three-minute mile.”
JTM clearly attributes that property to an individual. That isn’t what TM does. TM says of that property that it can’t be attributed to anyone. So TM says that (“UP” is short for “uninstantiated property”):
(UP) the property of being a person who has run a three-minute mile is uninstantiated.
Notice that UP’s grammatical form is the opposite of TM’s. The grammatical subject of TM is “nobody”; the grammatical predicate is “has run a three-minute mile.” By contrast, the grammatical subject of UP is “the property of being a person who has run a three-minute mile,” which corresponds to “has run a three-minute mile,” and the grammatical predicate of UP is uninstantiated, which corresponds to “nobody.”
   If one were to take TM at face value, and were thus to assume that its meaning paralleled that of JTM, one would have to say that it attributed the property of being a person who has run a three- minute mile to some un-person, or some such. But if this is what it said, then in order to be true, somebody—namely, this unperson— would have had to run a three-minute mile, in which case TM would be false. When we align TM’s real meaning with its grammar, we don’t have to swallow this rank absurdity. For UP says of some very much existent property (that of being a person who has run a three-minute mile) that it has a certain very much existent property (that of being uninstantiated). So we get the right result if we do linguistic analysis. We get the wrong result if we do para-science—if, that is, we posit new entities in order to account for the datum that TM is true.
The same thing is true of:
(NS) “nothing smokes.”
Pre-Fregeans said that NS says of some non-thing—some blank entity—that it smokes. So, supposing that in 500 years nobody smokes, and that NS is therefore true, it will be in virtue of the fact that some blank entity is around that is smoking.
But if there is such a thing, and it’s smoking, then NS is false. As long as one thing smokes, NS is
false. It doesn’t matter how blank or otherwise deficient that thing is.
Frege straightened this all out. By obvious extensions of what we just said, NS’s real meaning is:
(NS2) the property of being a smoker is instantiated.
NS2‘s grammatical subject (the italicized expression) corresponds to NS’s grammatical predicate; and NS2’s grammatical predicate (the bold-faced expression) corresponds to NS’s grammatical subject. So when we align NS’s logical form (what it actually says) with its grammatical form (what, given its grammar, it appears to say), we no longer have to say, completely absurdly, that NS attributes to some non-specific individual.
   Similar remarks hold with respect to SC. That statement says of two properties that they aren’t coinstantiated. It doesn’t say of some non-entity that it is both a square and a circle.
   Philosophical puzzles are solved by making it clear what statements mean. This is the basic tenet of analytic philosophy. Philosophy explains by clarifying statements. Science explains by positing entities. Science posits entities that are not themselves directly encountered but that, if assumed to exist, would account for phenomena that are directly encountered.
   It used to be thought that philosophical explanation was to be understood in the same way—that philosophical progress was to be made by positing entities that are not themselves directly known but that, if assumed to exist, explain what is directly known. This is not the case. Philosophy isn’t para- science. Philosophy is conceptual analysis. To make a philosophical discovery is not to discover a new entity; it is to make explicit a previously unrecognized implication of an existing belief. Philosophy is explication; it is the clarification of the statements that we accept but whose depths we haven’t yet fully fathomed.
   
3.0 Analysis vs. ontogenesis
In the works of analytic philosophers, one sometimes comes across the word “ontology,” which, etymologically, means “the study of being” (“ontos”= “being,” “logos”= “study”). These days the word “ontology” is usually used to refer to a given philosopher’s beliefs as to what exists. Some philosophers don’t believe in nonspatiotemporal entities. So such entities don’t belong to their “ontology.” Since I do believe in them, they do belong to my “ontology.”
   Analytic philosophers are, almost by definition, ontologically very conservative. In other words, they don’t want to grant existence to anything whose existence hasn’t been demonstrated beyond a shadow of a doubt.
   Pre-analytic, pre-Fregean philosophers were ontologically very liberal. Consider the statement: (TP) no person is over 20-feet tall.
Pre-Fregean philosophers took TP to say that there existed some non-person who was over 20-feet tall, and they engaged in a great deal of spurious “ontologizing” to validate this analysis. Frege showed that this ontologizing, in addition to being futile, is unnecessary. TP says that a certain property (that of being a person who is over 20-feet tall) has another property (that of not being instantiated). No 20-foot tall (un)person need be postulated. No ontologizing need be done. By contrast, non-analytic (pre-Fregean) philosophers often countenanced bizarre and even logically impossible entities to cover up deficits in their analyses.
3.1 When is it appropriate to ontologize?
As a general rule, analytic philosophers do not try to solve philosophical problems by “ontologizing”—that is, by positing an entity, or class of entities, not previously believed to exist. They try to solve them by clarifying statements. In some cases, the results of a successfully clarified statement do demand that we grant existence to something to which we’d otherwise deny existence. But, whenever this happens, the “entity” being posted is never a denizen of the spatiotemporal world; the thing that’s posited is never a person or a table or a mountain or a monster. It’s always an abstract object of some kind, and it’s posited only because, were it not to exist, it would be impossible to account for the truth of obviously true statements.
   For example, given the premise that Bob and Sally are both humans who are intelligent, it follows that there exist characteristics—or, to use the word preferred by analytic philosophers, properties— that Bob and Sally have in common, and from this it follows that properties exist.
   Given that properties exist, are they identical with spatiotemporal entities (i.e., with things that have locations in space and time)? Obviously, instances of properties at least sometimes exist in space-time. Bob and Sally, both instances of many properties, exist in space and time. But although you may encounter many instances of intelligence, you’ll never encounter intelligence per se and it would make no sense to assign any spatiotemporal location to it. Attempts to rebut this argument are doomed to fail, as we’ll see in Chapter 2. Thus, to validate the rather rudimentary inference from “Bob and Sally are both intelligent and kind,” it is necessary to grant the existence of non- spatiotemporal entities and thus to do a bit of ontologizing.
   So even though analytic philosophers do ontologize, they do it only when there is no other way of demonstrating the legitimacy of some indisputably correct form of inference, and they never posit anything nonspatiotemporal in the process.
3.2 Brentano and Meinong: the non-analytic method epitomized
According to Franz Brentano (1838–1917), the essence of the mental is intentionality. In this context, the word “intentionality” refers, not to the property of being done deliberately, but to the property of being representational. So, in Brentano’s view, for something to be a mental entity is for it to be representational, and for something to fail to be a mental entity is for it to be non-representational.
   
   To be sure, there are non-mental things (e.g., deposits of ink or pain) that are representational. Utterances and ink deposits are representational, even though they aren’t mental. But this isn’t a threat to Brentano’s position. Utterances (etc.) are representational only in a derivative sense. It’s because we endow it with meaning that an utterance of “snow is white” is meaningful; in a world devoid of sentient beings, it would just be another noise. So Brentano’s thesis is that for something to be mental is for it to be non-derivatively representational.
   There is an apparent problem with Brentano’s thesis. To be representational is presumably to represent something. Hallucinations are mental entities. But what does a hallucination of a pink elephant represent? A pink elephant? No—pink elephants don’t exist. More formally, there is nothing x such that x is a pink elephant. A fortiori there is nothing x such that x is a pink elephant that is represented by some hallucination. Still, there is clearly a sense in which hallucinations of pink elephants and other non-entities are representational. How is this to be explained?
   The solution to this problem lies in the fact that perception is description. If you’re looking at an actual elephant, which we’ll call “Larry,” the information encoded in your visual perception isn’t the effect that:
(LP) Larry is standing over there, next to that tree, looking ill [etc.].
When you look at an elephant, or a person, or a rock, you don’t just see that object. Seeing Larry involves seeing a thing having various properties—having a certain color, shape, size, position (relative to you), etc. So seeing Larry involves seeing that various properties are instantiated—that there is an instance, in a certain place, of a certain morphology, color, etc.
Perceptions of things aren’t like sentences about them. In the sentence:
(LS) “Larry is standing over there, next to that tree, looking ill [etc.]”
Larry is represented by a single, semantically simple symbol (namely, “Larry”). But in no sense- perception of Larry is he represented by some simple, homogenous, non-composite cipher. So far as he is perceived, Larry is represented as having these or those properties. This means that seeing him involves seeing that these or those properties are instantiated.
   It’s not as though in addition to seeing an instance of a certain morphology, color, etc., you also, separately from that, see Larry. No, your seeing Larry consists in your seeing those property- instances—in your seeing that such and such properties are instantiated. Thus, the content of your perception of Larry is given by some existence-claim similar to the following:
(LC) there exists, over in that place at the present time, instances of such and such properties.
   An existence-claim is any claim to the effect that some property is instantiated. Thus, “there are prime numbers” is an existence-claim, and sufficient since it says that the property of being a prime number has at least one instance.
   Given any existence claim, anything having the requisite properties is said to satisfy it. So the number seven satisfies the just-mentioned existence-claim. The number two uniquely satisfies “there is an even prime,” since (a) it satisfies it and (b) nothing else does.
   When you look at Larry, your eyes are giving you an existence-claim. Given that Larry, and Larry alone, satisfies that existence-claim, he is the object of your perception. So given that Larry uniquely instantiates the property of being a thing in such and such a place that has such and such a morphology (etc.), Larry is the object (or, more likely, one of the objects) of your current perception. So, yes, your perception does represent Larry. But it represents him by way of encoding an existence- claim that he satisfies.
   Given this, suppose that, the next day, you have a hallucination that is experientially just like the veridical perception we’ve been talking about. (A “veridical” perception is an accurate one. “Veridical” is to perceptions what “true” is to sentences. For some reason, perceptions are described as “veridical,” not as “true.”) So even though neither Larry nor anything that looks like him is in front of you, your visual experience is telling you otherwise. That hallucination thus gives you a false message. The message encoded in it will be similar
   
to LC. That message is to the effect that, in a certain place, there is a thing having such and such morphological, chromatic, kinematic (etc.) properties. On this occasion, the message—the existence- claim—in question is false, the reason being that nothing satisfies it. (Yesterday, the message represented by your visual experience was correct, the reason being that the existence-claim in question was satisfied.) The important point is that, although it was hallucinatory, your visual experience encoded an existence-claim and, in so doing, gave you a message and was therefore representational. It wasn’t representational in the sense that there was some thing that it picked out and, for that reason, represented. It was representational in the sense that it gave you a message, albeit a false one, and thus represented the world as being a certain way.
   Your visual perception of yesterday, unlike your visual perception of today, encoded a true existence-claim. But your visual experience of today no more represents some non-existent entity than your sense-perception yesterday. Your visual experience today has for its content a false proposition to the effect that there is a thing having thus and such properties. But just as the sentence “there does not exist a ten-foot tall man” does not, in order to be true, require the existence of a ten-foot tall man, so your perception doesn’t require the existence of an elephant before you.
   The same thing is true of thoughts about the non-existent. When you think about some non- existent number—for example, an even prime greater than two—there isn’t some mathematically impossible entity that you’re cognitively locking onto. What’s going on is that you’re thinking some false existence-claim along the lines of: there is some number n such that n is both even and prime [etc.].
   Mental entities have propositions for their contents. When correct, those propositions describe existing things. When false, they don’t. But nothing non-existent or quasi-existent can be the object of a thought or perception. When we describe a thought or perception as having a “non-existent object,” what we mean, so far as what we mean is coherent, is that it has for its content an existence-claim that nothing satisfies.
   But Brentano dropped the ball. He realized that hallucinations are, in some significant sense, representational. Wishing to reconcile this with the fact that there are no pink elephants (etc.), he said that a hallucination of a pink elephant has a non-existent pink elephant for its object.
   But that’s absurd, since it’s the same as saying: “there exists some elephant x such that x doesn’t exist and such that what you are hallucinating is x.”
   In a failed to attempt to deal with this, Brentano distinguished different kinds of non-existence, and he used different terms to mark them (“inexistent,” “non-existent,” “un-existent,” etc.) His pupil, Alexius Meinong (1853–1920), added another bogus category to this list—the category of “subsistent” entities. An entity “subsists” if it doesn’t quite fail to exist, but doesn’t quite succeed in existing either.
   This entire approach is misguided. Brentano and Meinong were ontologizing when they should have been analyzing. Properly analyzed, hallucinations no more require the existence of non-existent existents than veridical perceptions. The same is true of thoughts about Bart Simpson, the Fountain of Youth, etc. (This is further discussed in Chapters 6, 8, 9, and 25.)
4.0 Empirical puzzles vs. philosophical puzzles
   Some puzzles result from ignorance of spatiotemporal facts. My valuables start disappearing. I’m puzzled. I learn the relevant facts: Larry has been sneaking into my house and stealing my valuables. I’m no longer puzzled.
   The puzzles that science deals with typically involve a failure to know all the facts. The problem isn’t that anyone is making erroneous inferences. The problem is that not all the facts are in. It isn’t yet known that disease X results from an over-production of antibody Y. The reason it isn’t yet known is that, given the available data, there isn’t yet good reason to believe it. But once the data is in, it will be believed, and a cure will be forthcoming.
   Of course, scientific puzzles seldom result entirely from a failure to have the relevant data. In most cases, scientific breakthroughs involve somebody’s figuring out a new and better way to model already available data.
   The pre-history of relativity theory vividly illustrates this principle. If a train rushes past you at a rate of 100 mph, and I rush past you at a rate of 70 mph, the train is traveling at a rate of 30 mph with respect to
   
me. But if a light beam rushes past you at a rate of 186,000 miles/second, and I rush past you at a rate of 180,000 miles/second, the light beam rushes past me at a rate of 186,000 miles/second. There is thus is no optical test for determining one’s own state of motion. In other words, no matter how quickly you travel, you will not be able to detect any change in your velocity relative to that of a light beam. People and instruments not traveling with you will be able to detect changes in your velocity relative to that of a light beam, and you will be able to detect changes in their velocities relative to that of a light beam. But nobody can detect any changes in his own velocity relative to that of a light beam.
   This deeply puzzling fact was established in 1879. But nobody had any idea how to explain it until, in 1905, Einstein put forth the Special Theory of Relativity. Einstein didn’t cite any data that hadn’t been available to the physics community for decades. Einstein’s great innovation was of a conceptual nature. The facts were in, but he was the first to make sense of them.
   Be all of this as it may, Relativity Theory is an empirical theory. It’s based on observational and experimental data, much of which would be impossible to acquire except through carefully executed experiments. This data wasn’t in until 1879. So even though nobody came up with Relativity Theory before 1879, that fact can’t be chalked up to the fact that nobody drew the right inferences. It is due, at least in part, to the fact that the necessary data simply wasn’t available. (What can be chalked up to a failure to draw the right inferences is the fact that, during the period from 1879 to 1905, nobody came up with Relativity Theory.)
   In general, scientific breakthroughs have two components: (i) a strictly fact-based component (new raw data is acquired), and (ii) a purely conceptual component (already known data is modeled in a new and better way).
4.1 Empirical puzzles vs. philosophical puzzles (continued)
Unlike scientific puzzles, philosophical puzzles are not solved by generating new raw data. Philosophical puzzles are purely conceptual in nature and have no strictly factual component. Philosophical puzzles result, not from a failure to know the facts, but from a failure to draw the right inferences. They result, not from ignorance, but from confusion. In figuring out that:
(NS2) the property of being a smoker is instantiated
is what is meant by
(NS) “nothing smokes,”
Frege solved a number of outstanding philosophical problems. But Frege didn’t make any new empirical discoveries. In fact, his work didn’t involve him having access to any empirical information that wasn’t available to anyone who knows what (NS) (or its German equivalent) means. Einstein’s work, by contrast, had a heavy empirical component: he was modeling facts that a layperson would know nothing about, and the same thing mutatis mutandis is true of any scientific discovery.
4.2. Philosophical analysis ≠	linguistic analysis
Impressed by Frege’s philosophical successes, many came to the conclusion that all philosophical puzzles are of a purely linguistic nature. The most famous, and also the most vehement, advocate of this view was Ludwig Wittgenstein (1889–1951). This thesis was the cornerstone of this work. He urged acceptance of it in practically everything he wrote during his long career. He said it before others said it, and he held onto it long after, for reasons to be described forthwith, most of its erstwhile supporters rejected it. “Philosophical confusion begins when language goes on holiday,” he said. Elsewhere he said that all philosophical confusion “lies in a failure to understand the workings of our own language.”
   
   But this position is incorrect. There are many philosophical puzzles that don’t have anything to do with language, and the solutions to these puzzles cannot be modeled on Frege’s solutions to the puzzles discussed a moment ago.
   Here’s an example from epistemology. You couldn’t see the book in front of you were it not for the disturbances of your eyes brought about by the light-rays bouncing off of it. In general, nothing can sense-perceive anything that doesn’t affect it. All knowledge of what is in space-time is rooted in sense-perception. (If it’s in space-time, it isn’t known unless it’s directly perceived or evidence of it is perceived.) Taking it for granted that nothing that isn’t space-time can possibly be known, many contemporary epistemologists, e.g. Jerry Fodor, hold that one can’t know of anything without being affected by it. Thus, such philosophers hold that:
(JK) John’s being aware of the fact that 1 + 1 = 2 involves his being on the receiving end of some
causal process initiated by that fact.
   I personally regard JK as being absurd in the extreme. The fact that 1 + 1 = 2 isn’t comparable to the fact that there is a book in front of you. Were mass-energy distributed differently, there wouldn’t be a book in front of you. But 1+1 would equal 2 no matter how mass-energy were distributed. Thus, “1 + 1 = 2” says nothing about how mass-energy is distributed, and it therefore says nothing about the spatiotemporal world. The fact it describes must therefore be non-spatiotemporal. Nothing outside of space-time can bear any causal relation to anything. Therefore, JK is wrong.
   In any case, the dispute between those who accept JK and those who reject it has nothing to do with language. It’s agreed what JK means. What isn’t agreed is whether the thing that it’s agreed to mean is true.
   But the controversies surrounding NS do concern language; they concern the semantics of the word “nothing.” Those who see “nothing” as being a referring term, like “Socrates,” see NS as saying that some featureless entity smokes. Those who deny that “nothing” and “Socrates” belong to the same semantic category don’t see NS as saying this. Therein lies the controversy. Nothing comparable to this holds in connection with JK.
   Analytic philosophers do agree that the right way to figure out whether or not JK is correct is by carefully analyzing its meaning. But they also hold (rightly) that it isn’t to be solved through linguistic analysis.
   It must be emphasized that, according to analytic epistemologists, this puzzle is of a logical, not an empirical, nature. It is to be resolved through statement-analysis alone, not through statement- analysis combined with empirical research. They’re clearly right about this. JK says that John’s knowing that 1+1=2 is inconsistent with his not being on the receiving end of a causal process initiated by that fact. For P to be inconsistent with Q is for it to be impossible for both P and Q to be true. What is impossible or the otherwise non-existent cannot be observed. Thus, observation cannot tell you that anything is inconsistent with anything. So there is no way for it to tell you whether JK is correct.
   The philosophy of law provides us with another example of a puzzle that is to be solved through statement-analysis but not through linguistic analysis. It’s agreed that legal systems can be morally good. But it’s fiercely debated whether they have to be. According to some, a legal system can fail to embody any morality at all. Law is about power, not morality. Advocates of this view are known as legal positivists (no relation to logical positivism). According to anti-positivists, anything that doesn’t meet certain minimal standards of morality ipso facto isn’t a legal system. To be sure, legal systems, like all institutions, presuppose the existence of relatively rigid distributions of power. But if an institution qualifies as a bona fide legal system, it is at least partly by virtue of its embodying a certain morality.
Positivists and anti-positivists disagree as to whether:
(LM) “nothing can be a legal system without embodying a certain morality”
   is a true sentence. But this debate has nothing to do with semantics. Positivists and anti-positivists are in agreement as to what LM means. What they disagree about is whether the meaning that they agree that it has is a correct one. What analytic philosophers of law, such as positivist H.L.A. Hart (1907–1992) and anti-positivist Ronald Dworkin (1931–) , do agree about is that LM is to be resolved on the basis of logical analysis.
   
   Echoing what we said a moment ago, analytic philosophers deny that LM makes an empirical statement. They’re right. LM says that x’s being a legal system is inconsistent with x’s failing to embody a certain morality. We’ve already seen why the merits of such a claim cannot possibly be determined on the basis of observation.
   No philosophical assertions are empirical. Philosophy analyzes the categories in terms of which we think about the world. It does this by saying exactly what it is that is ruled out by a given thing’s falling into a given category—by, for example, a given thing’s being an instance of knowledge. Since observation can’t tell one whether one statement is inconsistent with another, philosophical assertions are non-empirical.
4.2.1 Not all philosophical analysis linguistic analysis (continued)
Thus, not all philosophical puzzles are linguistic puzzles; and Wittgenstein was wrong to say otherwise. But didn’t we ourselves say that philosophical analysis is the analysis of statements? Yes we did, and we were right to do so. To see why, Wittgenstein is nonetheless wrong, we must distinguish sentences from propositions. Propositions are the things meant by sentences. “Snow is white,” “schnee is weiss,” and “la neige est blanche” all mean the same thing. There is some one proposition that is the meaning of each of them.
   A sentence is true or false depending on whether it has a true or false proposition for its meaning. Thus, when a sentence is described as “true,” the property being attributed to it isn’t the same as the property that is attributed to a proposition that is so described. For a sentence to be “true” is for it to encode a true proposition. But this isn’t what it is for a proposition to be true, since propositions don’t encode anything. In Chapter 3, we’ll say what exactly it is for a proposition to be true. But the obvious answer, though imprecise, is the right one; namely, for a proposition to be true is for it to fit the facts.
   The term “statement” is ambiguous; it has three distinct meanings. Sometimes it refers to propositions, sometimes it refers to the sentences used to affirm them, and sometimes it refers to the act of using a sentence to affirm a proposition. Wittgenstein didn’t countenance the existence of propositions, and this obviously had a hand in his erroneously believing that philosophy is the analysis of sentences, when the truth is that philosophy is the analysis of propositions. Even Frege’s analyses of sentences such as “someone snores” and “nothing is a square circle” fail to conform to Wittgenstein’s conception of what philosophy is supposed to do, since, as we’ll see in a moment, they’re analyses of propositions that involve analyses of sentences and, therefore, are not themselves analyses of sentences.
One must know at least some English to understand the sentence:
(1) “John knows that 1 + 1 = 2”
But the proposition meant by that sentence can be grasped without speaking English; and one
needn’t know English, or any other given language, to be able to analyze that proposition correctly.
   But analyzing (1)—the sentence, not the corresponding proposition—does involve such knowledge. A sentence is an expression; it consist of nouns, verbs, etc. Analyzing (1) involves knowing the various grammatical nuances involved in its structure. Analyzing the corresponding proposition has nothing to do with anything relating to grammar or any other aspect of language. No such knowledge is needed to analyze the corresponding proposition.
   Even though Frege’s work inspired many to identify philosophy with sentence-analysis, Frege himself always made it very clear that propositions are not sentences and that, although sentences are human creations, their meanings are not.
   The sentence “the moon is less massive than Earth” is a human artifact; it didn’t exist until a few centuries ago. But the truth it expresses is in a different category. That truth exists independently of us. After all, the moon was less massive than the Earth before we came along, and it’ll be that way after we sign out. For the same reason mutatis mutandis, the falsehood expressed by “the Earth is more massive than the moon” exists independently of our thoughts and deeds, even though that sentence itself is a human artifact.
   
4.2.2 Not all philosophical analysis linguistic analysis (continued): the nature of sentence-meanings (as opposed to sentences)
What are propositions? They’re properties. For a proposition to be true is for the world to be a certain way. The proposition that Smith is in Richmond is true if the world is a certain way and it’s false if it isn’t. (If mass-energy is distributed one way, Smith is in Richmond; if it’s distributed some other way, he isn’t.) For a thing to be a certain way is for it to have a certain property. To be round is to be one way; to be square is to be some other way. To be round is to have one property; to be square is to have some other property. Thus, the world’s being a certain way is identical with its having a certain property. Since, therefore, the world’s being a certain way is identical with some proposition’s being true, propositions must be identified with properties and a proposition’s being true must be identified with its being instantiated. Propositions are properties and truth is instantiatedness.
   It’s widely thought that propositions are human creations. This is false. The world was a certain way before we were around; it will be a certain way after we’re gone; and the way it is while we’re around is up to us only to a limited extent. It follows that, independently of our having any beliefs or, indeed, our doing or thinking anything, certain propositions are true; and it follows from this that propositions are not human creations. Sentences, on the other hand, are human creations. They wouldn’t be around if it weren’t for us. So sentential analysis is a very different thing from propositional analysis.
4.2.3 Not all philosophical analysis linguistic analysis (continued): Frege’s
accomplishments reassessed
But didn’t we say that Frege’s great accomplishment lay in his insights concerning sentences—in his seeing that a sentence’s surface structure sometimes pulled part from its deep structure? And didn’t we say that, for this very reason, Frege was the first analytic philosopher—that, as Michael Dummett put it, analytic philosophy is post- Fregean philosophy, the reason being that analytic philosophy is statement-analysis? Yes, we did say all this. And yet we just spent a lot of time saying how analytic philosophy is “statement-analysis” only in the sense of being statement-meaning-analysis; that is, proposition-analysis, as opposed to sentence-analysis. How are we to reconcile those various statements with one another?
   The term “analytic philosophy” can be construed narrowly or broadly. Construed narrowly, analytic philosophy is post-Fregean philosophy in the sense that it directly flows out of Frege’s work. Frege was interested in reference, quantification, the nature of logical truth, the extent to which it’s possible to formalize intuitively valid inferences, etc. (These terms will be defined soon enough, if they haven’t been already.) The term “analytic philosophy” sometimes refers to what is done by those people who write about those very questions and who, in so doing, are taking what Frege had to say about them into account. In other words, “analytic philosophy” sometimes refers to the philosophy of language, along with a related branch of philosophy, known as philosophical logic.
   But Frege’s work had a profound influence on philosophers who were working in areas that have no direct connection to language or logic. Frege showed that, by thinking clearly, systematically, and self-critically, one could make real headway on philosophical problems in which others had yet to make so much as a dent, despite hundreds of years of trying. “The devil is in the details,” as they say. Pre-Fregean philosophers tended to disregard the details. Frege did not. He was a stickler for them. And it was partly, though obviously not entirely, for this reason that he was able to solve problems that his predecessors could not. The word “analytic philosopher” sometimes refers to the sort of philosophy done by people who aspire to approach philosophical problems in the same careful and clear-headed way as Frege.
   Thus, there are analytic philosophers of law, analytic ethicists, analytic philosophers of religion, etc. What makes them analytic philosophers isn’t that they’re talking about language or logic or any of the things that Frege talked about. It’s that they believe the problems they’re concerned with to be solved in the same coolheaded, logical way that Frege solved problems relating to language and logic.
   
   But even when taken in the narrow sense, “analytic philosophy” (i.e., philosophical logic/the philosophy of language) is only misleadingly described as the analysis of sentences. Philosophers of language are interested in the sentence:
(NS) “nothing is a square circle”
   only to the extent that, by understanding it, they will deepen their insight into concepts of a general kind (e.g., meaning, analytic truth, modality). Linguists, on the other hand, are interested in those concepts only to the extent that an understanding of them will help them understand specific sentences, such as NS. Frege did indeed painstakingly analyze specific sentences. But he did so only because he knew that, by so doing, he could identify general logical principles. Thus, for Frege, his insight that logical and grammatical form pull apart was ultimately just a means to an end, the end being the identification of the actual nature of the bearing- relations that propositions have with respect to one another. So, yes, analytic philosophy is statement-analysis; and, yes, it was Frege’s brilliant analyses of sentences that availed philosophers of the principles needed to analyze statements properly. But analytic philosophy, even the narrow sense of the term, is not itself sentential analysis.
4.2.4 Not	all	philosophical	analysis	linguistic	analysis	(continued): Wittgenstein—an introduction
Wittgenstein’s two best-known works are the Tractatus Logico-philosophicus (TLP), which he completed in 1921, and the Philosophical Investigations, which he completed in 1949. In many ways, these works are antithetical to each other. But in both of them, Wittgenstein insists that that philosophical problems arise when, and only when, sentences are misused and are solved when, and only when, it is made clear how they are being misused.
   In the TLP, Wittgenstein contends that all philosophical problems result from a failure to understand the syntactic rules of the languages we use. Sentences that would, if meaningful, express philosophical propositions are in all cases ungrammatical nonsense and thus fail to say anything. All such sentences violate the syntactic rules of the languages to which they belong. (For the time being, “syntactic” may be taken to be synonymous with “grammatical.” See Chapter 4, Section 3.3 for a definition of “syntax.”) Because they violate these rules in subtle, easily overlooked ways, they aren’t always seen for the abject nonsense that they are. But we mustn’t let the appearances deceive us. All such sentences are syntactically ill-formed and therefore devoid of meaning, and there would be no philosophical problems if people fully understood the syntactic rules of the languages they spoke. So far as philosophy has any legitimate function, it is to identify these rules, thereby heading off the syntactic blunders that lead to philosophical puzzlement.
   In the Philosophical Investigations, Wittgenstein says, just as he does in the TLP, that philosophical problems arise when language is misused. But in the Investigations, he denies that such misuses involve violations of hidden syntactic rules, and instead says that such misuses consist exclusively in one’s using words in ways in which they are not ordinarily used. Thus, Wittgenstein’s position in the Investigations is that all philosophical problems can be quickly and definitively solved by looking at how words are actually used and, on the basis of the knowledge thereby obtained, ceasing to use words in deviant ways. What we think of as philosophical puzzles concerning knowledge, logic, and morality are puzzles about the words “knowledge,” “logic”, and “morality.” Those puzzles are created by our using those words in non-standard ways, and they’re solved by our ceasing to do so.
4.2.5 Is meaning identical with use?
In a moment, we’ll evaluate Wittgenstein’s (1922) contention that all philosophical statements are ungrammatical nonsense. Right now, let us consider Wittgenstein’s (1958) contention that philosophical puzzles are dissolved by looking at how words are used.
   
   This contention is incoherent on many levels. Given only the acoustical and morphological properties of its spoken and written occurrences, the word “knowledge” could mean anything. So, supposing that it’s the concept of knowledge that we wish to learn about, we can’t possibly know that the word “knowledge” is the right word to study unless we know that it expresses the right concept. But we can’t possibly know that unless we have some way of grasping that concept that doesn’t involve that word. So we can’t even act on Wittgenstein’s exhortation that we study knowledge by studying how people use the word “knowledge” unless we have some way of grasping the concept of knowledge that doesn’t involve that word. But if we don’t need that word to grasp that concept, we don’t need it to it study it; and if we don’t need it to study it, then Wittgenstein is simply wrong to say that one must study how it is used to understand the concept it expresses. Given any expression E and any concept C, an obvious extension of this argument shows that one can’t learn about C by studying E unless one can grasp C, and can therefore examine it, without E’s help. Thus, Wittgenstein is simply wrong to contend that one learns about concepts by learning about how the corresponding words are used.
   “But you’ve over-stated what Wittgenstein is claiming,” it will be said. “Contrary to what you allege, he wasn’t saying that concepts are to be learned about solely by looking at how the corresponding words are typically used. He was saying only that knowledge of expression-usage would be a useful adjunct to some other, more important way of knowing about concepts.” If that’s what Wittgenstein is saying, then he’s conceding everything said the preceding paragraph. To grant that there is any expression-independent way of grasping concepts is to grant that expression-usage is to be evaluated in light of the very conceptual knowledge that, according to Wittgenstein’s thesis, one is supposed to acquire through the study of expression-usage.
   But there’s a problem with our argument. It assumes that, given a meaningful expression (e.g. “knowledge”), there is some object that is its meaning. Wittgenstein rejects this assumption. He holds that there is no entity that is the meaning of “knowledge.” Wittgenstein’s position is, I quote, that “meaning is use.” In other words, for an expression to have a given meaning is for it to be used in a certain way. An expression’s having a given meaning does not, in Wittgenstein’s view, involve there being some entity that is its meaning.
   Before we evaluate this contention, we must make a few facts about it clear. Wittgenstein isn’t making the uncontroversial point that how expressions are used is a function, in part, of what they mean. Nor is he making the equally innocuous point that how an expression is used may have effects on what it means. (“Probable” used to mean “capable of being definitively established.” Enough people used it to mean “likely, but not certain”; and, for that reason, that’s what it now means.) He is saying that what it is for an expression to have a given meaning is for it to be used in a certain way. Here is his argument:
(WA) According to some philosophers, there is some entity that is the meaning of “snow is white” and some other entity that is the meaning of “grass is green.” These entities are known as propositions. Propositions (if existent) are non-spatiotemporal entities.
   The very idea of such an entity is of doubtful coherence. And even if such entities do exist, they’re nothing to us. We can’t see them or touch them or otherwise have anything to do with them. So, even if they do exist, they have no role in human affairs. At the same time, “snow is white” and “grass is green” differ in meaning. So we must find a way of saying what it is for two expressions to ‘differ in meaning’ that doesn’t involve our positing meanings.
   This can be done. “Snow is white” isn’t used in the same way as “grass is green.” There are situations that prompt utterances of the one that don’t prompt utterances of the other. By the same token, if they were used in the same way—i.e., if there were no situation that prompted utterances of the one that didn’t prompt utterances of the other—then they wouldn’t differ in meaning. If the sensory stimulations that induced people to say “grass is green” coincided with those that prompted people to say “snow is white,” there would be no significant sense in which they “differed in meaning.” Thus, two sentences S1 and S2 coincide in meaning exactly if they are used in the same way. So instead of identifying the meaning of “grass is green” with some non-spatiotemporal entity—with some entity whose existence is in doubt and whose role in human affairs, supposing it to exist, is also in doubt—we can just say that two expressions “have the same meaning” if they’re used in the same way. An obvious
   
corollary is that for an expression to have this as opposed to that “meaning” is for it to be used
in this as opposed to that way.
   Were WA cogent, Wittgenstein would be doing to meanings what Frege did to square circles. Frege got rid of square circles by showing that sentences appearing to require their existence (e.g. “square circles simultaneously have, and lack, uniform curvatures”) are equivalent to sentences that don’t (e.g. “the statement x is a circle entails x has a uniform curvature and the statement x is a square entails x does not have a uniform curvature”). Wittgenstein wishes to get rid of meanings by showing that statements appearing to require the existence of expression-meanings are equivalent to statements (about expression-usage) that don’t.
   This wish of Wittgenstein’s embodies some very wrong views as to what linguistic expressions are. A burst of noise that doesn’t have a meaning is just a burst of noise. A burst of noise is an expression only if it has a meaning. But if it already has a meaning, then how it’s being used isn’t what gives it its meaning.
   Our knowledge of what words mean is what guides our linguistic behavior. Expressions have meanings. We know this. And that’s why we use expressions in the way we do. I know what “hug” means; I also know what “discuss” means. That’s why, when talking to my students, I say “I want to discuss the exam,” and not “I want to hug the exam.” If meaning were use, meaning couldn’t guide use. But it obviously does.
   To the extent that meaning doesn’t guide use, people are misspeaking. Wanting to tell you that you’re an absolute genius, I say “you’re an absolute moron,” since, despite my generally good command of the English language, I wrongly think that “moron” means genius. To the extent that my uttering those words embodied a failure to know the actual meaning of what I was saying—to the extent that meaning failed to guide use, in other words—I misspoke. And to the extent that my uttering those words embodied a knowledge of what they meant—to the extent that meaning did guide use, in other words—I spoke properly. This shows that, to the extent that utterances aren’t simply defective, meaning guides use and, consequently, that use is not constitutive of meaning.
   Bearing these points in mind, let us revisit Wittgenstein’s (1958) contention that it’s a philosopher’s job, not to analyze concepts or meanings or other such alleged phantasms, but merely to take note of when words like “justice,” “knowledge,” and “truth” are used. What would it be to do this? The situations in which the word “justice” is used don’t necessarily have any observable characteristics in common with one another. It’s not as though people utter the word “justice” when, and only when, they’re just been bitten by a cat. This isn’t to say that uses of the word “justice” cannot be correlated in any way with facts about the situations in which those uses occur. Such correlations clearly can be made. People are likely to use that word when they’re in classes concerning ethics or the philosophy of law; they’re likely to use it when they believe that they’ve been wronged; they’re likely to be used by politicians who want people to believe them to be worthy of holding office.
   The boldfaced terms express extremely abstract concepts; and utterances of those words are no more capable than utterances of the word “justice”‘ of being correlated with observable facts about the contexts in which they occur. So, while a person‘s decision to use the word ‘justice’ (or “knowledge” or “law,” etc.) may obviously have a situational basis, there is no way to identify that basis except in terms of the very concepts that, according to Wittgenstein, are to be studied by figuring when those terms are used. In other words, any correct generalization as to when words like “justice,” “logic,” “knowledge” and “morality” are used will itself employ the very concepts that, according to Wittgenstein, knowledge of such generalizations is supposed to yield.
   These reflections bring us face to face with an incoherence inherent in all of the different variants of the contention that philosophy is sentence-analysis. To speak isn’t just to make noises; it’s to make noises for the reason that one believes those noises to have certain meanings. I’m with my friend Larry. All of a sudden he starts convulsing and foaming at the mouth. I call 9-1-1 and say (i) “my friend is foaming at the mouth and convulsing; please send help.” Why did I choose those words? Why didn’t I say (ii) “I like pizza” or (iii) ‘“giraffes are friendly creatures”? Because I know that (i) has the right meaning and that (ii) and (iii) don’t. In general, speaking consists in making noises for the reason that one believes that, given existing semantic rules, those noises have certain meanings. If somebody makes a noise that he does not believe to be assigned a meaning by any semantic rule, he isn’t speaking. If, not believing that the noises I’m about to make are assigned any meaning by any semantic rules, I say “blurga dunga blurbo,” I am not speaking. I’m just making noise. Maybe
   
the semantic rules of some language do assign them a meaning. That doesn’t matter. My making that noise wasn’t guided by my knowledge of such rules. So I wasn’t saying anything. And as we saw earlier, I am misspeaking if I misidentify the meaning assigned by existing semantic rules to the noises I am making. So there is no bona fide speech where there isn’t awareness of semantic rules.
   Thus, the analysis of sentences isn’t the analysis of noises. (In this context, take references to “noises” to be short for references to anything that can constitute the occurrence of an expression— e.g., hand-movements, patterns of light on a monitor, etc.) In and of themselves, noises aren’t speech, as we just saw. It is only when a noise embodies an attempt to follow a semantic rule that it constitutes speech. So the analysis of speech—that is, of spoken sentences—concerns noises only to the extent that they embody attempts to follow such rules; and for the same reason mutatis mutandis, the analysis of sentences per se, as opposed to their spoken (or written) occurrences, necessarily involves, if it doesn’t coincide with, the analysis of those rules.
   Those rules are not themselves sentences. The semantic rule that assigns meaning to “snow is white” is not itself a sentence. Given these points, what might it mean to say that philosophy is sentential analysis? It could mean that philosophy is the empirical study of different languages, i.e., that philosophy is linguistics. But that clearly isn’t what philosophy is. So it must mean that philosophy is the study of semantic rules qua semantic rules—that, in other words, it is the study of the concept of a semantic rule.
   In that case, philosophy is also the study of those concepts that must be understood to understand the concept of a semantic rule. And there are many such concepts. Among them are narrowly semantic concepts such as compositionality, reference, quantification, force, and negation.
   But many of these concepts aren’t only of relevance to semantics. As we’ve seen, no noise constitutes a sentence-utterance unless it embodies an intention of a certain kind; and there is no linguistic behavior of any kind where people aren’t intentionally following what they believe to be existing semantic rules. Some believe that semantic rules are conventions. Others believe that they are functions (in the mathematical sense)— assignments of meanings or truth-conditions to noises or to properties that are instantiated by noises (or inkmarks, etc.). There is no way to figure out what semantic rules are without examining these concepts.
   And even if these questions are side-stepped, and philosophers focus only on narrowly semantic concepts (e.g., reference, compositionality, etc.), philosophy ends up being the analysis, not of sentences, but of concepts. Thus, the thesis that philosophy is the study of sentences either collapses into the obviously false thesis that philosophy is the empirical study of language or into the thesis that philosophy is conceptual analysis (i.e., the analysis of the concepts in terms of which the world is understood). Thus, Wittgenstein’s contention that philosophy is the study of sentences collapses into the very view to which it is meant to be an alternative (viz. that philosophy is the analysis of concepts, as opposed to expressions), and is therefore false.
Let us now turn to Wittgenstein’s (1922) Tractarian contention that philosophical statements are
ungrammatical nonsense.
4.2.6 The Tractarian contention that philosophical statements syntactically ill-formed nonsense
The sentence
(a) “one can be aware of the fact that 1 + 1 = 2 without being causally affected by that fact”
appears meaningful. So does the sentence
(b) “there could in principle be a legal system that failed to embody any morality at all.”
But, in the TLP, Wittgenstein says that that this is an illusion. Here is the viewpoint underlying this bold contention:
   
(TA) All philosophical statements are ungrammatical nonsense, and all philosophical problems would vanish if we spoke grammatically. “All philosophical problems belong to the same class as the question whether the good is more or less identical than the beautiful.” Thus, all philosophical statements belong to the same class as:
(BG) the good is more or less identical than the beautiful.
   BG is obviously meaningless. The reason for this is that it’s syntactically ill-formed. If we produced only syntactically well-formed sentences, we wouldn’t produce nonsense like BG. Since all philosophical statements are in the same class as BG, we’d never produce any sentences whose merits it was the job of philosophy to determine.
   Were the logical forms of (a) and (b) brought into alignment with their logical forms—in other words, were their actual meanings reflected in their grammar—they’d be ungrammatical since they have no meanings.
   Although TA is a paraphrase, not a quotation, the part in quotes is an exact quotation from the TLP.
   What Wittgenstein is saying isn’t confined to the defensible claim that philosophical problems are to be solved by clarifying statements. Wittgenstein is making two additional claims. First, no sentence that appears to make a philosophical statement means anything. Second, it’s only because they’re syntactically ill-formed that such sentences are meaningless—there is no other reason.
Let us evaluate these claims. Though ungrammatical, the sentence:
(MH) “me and Herby play tennis every day, and me always win because Herby not in good shape”
is perfectly meaningful. Ungrammatical statements are often meaningful. Thus, BG’s failure to mean
anything cannot be entirely blamed on its being ungrammatical.
   What’s the real problem with BG? The expression “more identical than” is obviously supposed to function in the same way as relational expressions, like “more important than” or “identical with.” But there is no relation that it picks out. Though it consists of English expressions, the expression “more identical than” is itself no more a part of the English lexicon than “blurga derba gurb.” For that reason, the meaninglessness of BG is to be accounted for in the same way as the meaninglessness of:
(BG#) “the beautiful is blurga derba gurb the good.”
   The problem with BG# is that “blurga derba gurb” doesn’t mean anything. It may be that its meaninglessness is reflected in its syntax. It may be that because “blurga derba gurb” doesn’t mean anything, BG#’s syntax is off. But, if so, its syntactic shortcomings are to be explained in terms of its lack of meaning, not vice versa.
   The same holds of BG. The reason that BG doesn’t mean anything is that “more identical than” doesn’t mean anything. BG’s syntactic shortcomings are to be explained in terms of its lack of meaning, and not vice versa.
   This is easily verified. Given any relation R, if “more identical than” denoted R, BG would be meaningful. If, for example, it denoted the relation that is in fact picked out by the expression ‘a better dancer than,” BG would say that the good is a better dancer than the beautiful; and it would thus have the same meaning as
(BG*) “the property of goodness is a better dancer than the property of being beautiful.”
BG* isn’t meaningless; it’s false. The property of goodness can’t dance; neither can any other property, including the property of being beautiful. Therefore, the former property isn’t a better dancer than the latter. Nothing false is meaningless, since to be false is to bear a false meaning. So BG* is meaningful.
   
   Incidentally, according to Gilbert Ryle (1900–1976), a career-long Wittgenstein-hardliner, it cannot meaningfully be said of properties that they can, or cannot, dance. It can be said of a human being that he can, or cannot, dance. But nothing that can meaningfully be said of non-properties, such as human beings, can be meaningfully said of properties themselves.
   Ryle’s position is false. There are many differences between people and properties. One of them is that people can dance, whereas properties cannot. Ryle’s position is also self-refuting. In saying that it cannot be said that properties cannot dance, Ryle is saying exactly what it is that, according to his theory, cannot be said.
   Ryle is confusing absurdity with meaninglessness. The sentence “triangles have four sides” makes an absurd, but meaningful, statement. Given that triangles have three sides, not four, it’s false. Given that it’s false, it’s meaningful. “Properties can dance” is absurd and, therefore, false and, therefore meaningful.
   There are two kinds of “nonsense.” A sentence can be nonsense by failing to have any meaning. (BG# is nonsense in this sense.) And a sentence can be nonsense by virtue of having of an absurd meaning. (“Properties can dance” is nonsense in this sense.) Ryle doesn’t distinguish between these two kinds of nonsense. Neither does Wittgenstein. And Wittgenstein’s position, like Ryle’s, is self- refuting—and for much the same reason. If Wittgenstein is right to say that all philosophical assertions are ungrammatical nonsense, that very assertion is ungrammatical nonsense and therefore isn’t true.50
   Given how implausible and illogical it is, why on Earth did Wittgenstein hold that philosophical statements are always ungrammatical nonsense? The answer, I believe, is that Wittgenstein thought this view to be the distillation of Frege’s groundbreaking philosophical successes. Frege showed that reparsing sentences sometimes solves philosophical problems. By reparsing
(NS) “nothing is a square circle,”
we show that it doesn’t attribute the property of being a square circle to some non-entity, thereby dissolving an age-old riddle. Wittgenstein seems to have inferred from these successes of Frege’s that all philosophical problems are to be solved by reparsing sentences.
   This inference is fallacious. Given only that some philosophical problems are to be solved by reparsing sentences, it doesn’t follow that they are all to be solved in that way. And we’ve seen that, indeed, many of them are not to be solved in that way.
   Also, there were no cases where Frege’s reparsing of a problematic sentence showed it to be ill- formed. For example, in reparsing NS, Frege showed that its logical syntax differed from its apparent syntax. He didn’t show that there was anything wrong with its logical syntax.
   To be sure, philosophers often produce deeply absurd statements. For example, according to pre- Fregean philosophers, NS entails that:
(NS1) there exists some non-entity that that is a square circle. If NS1 is right,
(NS2) there exists some entity that does not exist that is a square a circle.
NS2 is self-contradictory and therefore absurd. But it’s obviously meaningful.51 If it weren’t, it wouldn’t contradict itself. (For a sentence to contradict itself is for it to bear two opposed meanings. “Smith is a lawyer and Smith is not a lawyer” because the one conjunct52 contradicts the other.) But whereas this sentence is explicitly self-contradictory, the self-contradictory sentences that people actually utter are usually only implicitly so.)
   In any case, even if philosophical statements are meaningless, they’re not meaningless because they’re ungrammatical. Second, they’re not meaningless. The statement that they’re meaningless is itself a philosophical statement. That statement is therefore false if it’s true. Therefore it is false. (Any statement that entails its own negation is false.53)
   
4.3 The Tractarian roots of Logical Positivism
Although one of the TLP’s contentions is that all philosophical statements are ungrammatical
nonsense, this is not its main contention. The main contention of the TLP is that:
(CT54) a sentence is meaningful if, and only if, it is either a tautology or an observation report.
A “tautology” is a definitional truth (e.g., “fathers are male,” “there are three feet in a yard”).
   An “observation report” is a statement that reports what one’s senses have told one (e.g., “I am now seeing a dog,” “there is chocolate syrup (or, in any case, a brown discoloration of some kind or other) on Smith’s ice-cream,” “I can see your house from here”).
CT can be broken down into two claims:
(1) All meaningful non-empirical statements are tautologies
and
(2) All meaningful non-tautologous statements are observation-reports.
   (1) entails that non-empirical disciplines (e.g., philosophy, mathematics) consist of statements that say nothing about anything. (2) entails that anything non-tautologous that cannot be known strictly on the basis of what one’s senses tell is meaningless.
   Wittgenstein’s claim that all philosophical statements are ungrammatical nonsense is a corollary55 of CT. If they’re meaningful, philosophical statements, unlike tautologies, are non-trivial. Consider the statement that:
(KC) “knowing a truth doesn’t necessarily involve one’s being affected by the state affairs described by that truth.”
KC is a philosophical statement; and so its negation. Neither statement is a tautology, and neither statement is empirical. If CT is correct, it immediately follows that both KC and its negation are ungrammatical nonsense. Since philosophical assertions are never tautologous, CT entails, as Wittgenstein knew, that philosophical assertions are categorically meaningless.
   The position that (1) and (2) are both correct is known as logical positivism (LP). During the decade or so following the publication of the TLP, and largely because of it, LP was very popular.56 But (1) and (2) are false. Let us now say why.
4.4. Verificationism and falsificationism
(2) is identical with a doctrine known as verificationism. According to verificationism a non- tautologous statement is meaningful iff it’s capable of being verified strictly on the basis of sensory observation.57
   Verificationism is false. The statement “all metal expands when heated” is meaningful. But it cannot be conclusively verified (i.e., shown to be true) strictly on the basis of observation. No matter how many metal objects you find to expand when heated, it’s a possibility that some metal object that you haven’t yet considered will fail to do so.58
   Even though it cannot be verified “all metal expands when heated” can be falsified (i.e., shown to be false) strictly on the basis of observation. Advocates of LP saw this and, having for this reason rejected verificationism, accepted a doctrine known as falsificationism. According to falsificationism, a non-tautologous statement is meaningful if and only if it’s capable of being falsified strictly on the basis of observation.59
   
   Falsificationism is false. Though obviously meaningful, the statement “there exists a gold ball that weighs exactly 27.13654 lbs” cannot be conclusively falsified, since no matter how many gold balls you consider, it’s possible that some gold ball that you haven’t considered has that weight.
   Falsificationism is really a version of verificationism. According to verificationism, S is meaningful if verifiable. According to falsificationism, S is meaningful if S’s negation is verifiable. So given that verificationism fails, it’s no surprise that falsificationism does as well.
   In light of the failure of falsificationism, advocates of LP decided to soften their views about meaningfulness one more time. This time, they said that a non-tautologous statement is meaningful if possible observations can confirm it. (P confirms Q if, other things being equal, Q is more likely to be true if P is true than if not-P is true. Other things being equal, Smith is more likely to be wealthy if he wears fancy clothes than if he doesn’t wear fancy clothes. Thus, “Smith wears fancy clothes” confirms “Smith is wealthy.”) We’ll refer to this view as “confirmationalism.”
   Confirmationalism is equivalent with the position that all meaningful non-tautologous statements are empirical. An empirical statement is one that, if true, expresses a truth that must be known through observation and that, if false, is the negation of a true empirical statement. “There are trees in Santa Barbara, CA” is a true empirical statement, and “there are no trees in Santa Barbara, CA” is a false one. The negation of an empirical statement is an empirical statement. This is becasue, if it’s an empirical question whether or not S is true, then it’s an empirical question whether or not S is false and, therefore, whether or not not-S is true. (There are, as we will see, very few truths, if any, that can be known strictly through observation. A statement is empirical if the truth or falsity of it is to be decided on grounds that are at least partly observational.)
Henceforth when we refer to “logical positivism” (LP), we will refer to the position that a
statement S is meaningful if and only if (i) S is a tautology (e.g., “sisters are female siblings”) or
(ii) S is an empirical statement (e.g., “there are trees in Santa Barbara”).60
4.5 Logical Positivism Evaluated
Consider the statement:
(1) “triangles are three sided figures.”
(1) is plausibly seen as just being true by convention. The same is true of:
(2) “pentagons have five sides.”
For argument’s sake, we’ll grant that, indeed, (1) and (2) are true by convention—that they’re
definitional truths.61 Given (1) and (2), it follows that:
(3) If x is the number of sides of an arbitrary triangle and y is the number of sides of an arbitrary pentagon, then w is an even prime iff w is one less than x and three less than y.
But (3) clearly isn’t a conventional truth. Though it follows from conventions, (3) is not itself a
convention. (3) is thus a non-tautologous, non-empirical truth. It follows that LP is false.
   It’s possible to have conventions that are inconsistent with one another. If I stipulate that “x” unambiguously refers to the number two, and I also stipulate that “x” refers to the number of sides of a triangle, my definitions are inconsistent with one another. The internal consistency of conventions is not itself a matter of convention. It isn’t an empirical fact that the conventions just described are inconsistent with each other. To say that P is inconsistent with Q is to say that P must be false if Q is true. Observation cannot tell you what must be the case; it can tell you, at most, what is the case. So it cannot tell you that two linguistic conventions are inconsistent with each other.
   
   Since observation cannot tell you whether or not two statements are inconsistent with each other, it cannot tell you whether or not one statement is a necessary consequence of some other. This is because for Q to be a necessary consequence of P is to P to be inconsistent with the negation of Q. (The negation of "snow is white" is "snow is not white." In general, the negation of a Q is not-Q.)
   When evaluating LP, one must be careful to distinguish sentences from their meanings. Two different sentences can have the same meaning (e.g., “snow is white” and “schnee ist weiss”). The meaning of a sentence is a proposition. Propositions are not sentences. The thing meant by “snow is white” is not itself a sentence. Some sentences express propositions that are logically true. A proposition is logically true if the laws of logic prohibit its negation from being true. The proposition meant by
(4) “If a given thing is round, then that thing is not a square”
is logically true, since the laws of logic don’t allow round things to be square. And some authors, for this reason, would describe (4) itself, the sentence, as logically true. But what they mean is that, given what it is that it means, (4) must be true. So what they are in fact describing as logically true is the proposition that (4) couldn’t be false, given what it is that it means.
   Thus, it is always propositions, and never sentences, that are logically true. But no proposition is true by convention. It’s up to us what our symbols mean. But it’s not up to us whether those meanings are correct. It’s up to us what it is that “the moon is not made of cheese” means. But it isn’t up to us whether that meaning is correct. LP identifies logical truth with conventional truth: truths of logic are sentences that are true by convention. But that’s false. Logical truths are never sentences; they’re always propositions, and propositions are never conventionally true.
   Incidentally, (ii) collapses into (i). Linguistic conventions are known empirically. It can be known only through observation that “triangles have three sides” is true. That sentence could mean anything.62 It could mean that penguins are smarter than humans; and it’s only because you’ve had the requisite sense-perceptions that you know it not to mean this.
   It should be pointed out that logical positivists were unanimous in denying the existence of propositions and of meanings generally. Logical positivists didn’t accept the view that for a lecture to concern triangles is for the meaning of that lecture to concern triangles. This is why Rudolph Carnap63 (1890–1970), an LPhardliner for many years, said that for a lecture to concern triangles is for the word “triangle” to occur in the lecture.
   Carnap’s view is false. Many a lecture that doesn’t contain the word “triangle” concerns triangles. (Think of all the mathematics lectures given in Japanese, Swedish, and Arabic. How often does the word “triangle” occur in them?) And a lecture that contains the word “triangle” isn’t necessarily about triangles. Somebody giving a lecture on linguistics may use the word ‘triangle’ to illustrate some point about phonetics; but in so doing, that person isn’t talking about triangles. They’re talking, not about triangles, but about the word “triangle.”
   The distinction between the word “triangle” and the corresponding meaning is one that Carnap couldn’t countenance without ceasing to be a logical positivist. The very essence of logical positivism is the denial of meaning. For argument’s sake, suppose there to exist objects that are the meanings of sentences. (Following convention, we’ll refer to these things as “propositions.”) Given the existence of propositions, whether a given sentence is meaningful is not to be explained in terms of its being either tautologous or confirmable. Rather, a sentence’s being tautologous or confirmable is to be explained in terms of its bearing a proposition of a certain kind. A tautologous sentence would be one that had a logically correct proposition for its meaning, and a confirmable sentence would be one that had a confirmable proposition for its meaning. But if there are logically true propositions, then some truths are ipso facto not empirical.
   We can use words in any way that we like. We can use the words “if Smith has three boats, then Smith has more than one boat” to mean that 1+1=3. But whatever meaning we end up assigning to those words, it’s not up to us whether that meaning is correct. And if, as is actually the case, that meaning is of a logical nature, there is ipso facto non-empirical truth, an immediate consequence being that LP is wrong.
   
   Carnap’s attempt to do away with meanings consisted in his saying (though he did not himself put it this starkly) that the meaning of the word “snow” was that very word, i.e., that words were their own meanings.64 Given how brazenly wrong this view is, Carnap’s attempt to do away with meanings never had many takers.
   A much better received attempt to do away with meanings is to be found in a doctrine known as conceptual role semantics (CRS). According to CRS, two sentences have the same meaning if, and only if, they are used in the same way. So “hace mucho calor” is the Spanish translation of “it’s hot” not because those sentences share a meaning—meanings don’t exist, according to CRS—but because the one sentence is used in the same way as the other.65
   CRS seems to coincide with the Wittgenstein-Grice thesis that “meaning is use.” It’s thus a mystery why CRS is so popular, given that Grice’s coincident position was universally rejected long ago.
   In any case, CRS is indefensible. So far as she isn’t misspeaking or randomly barking out noises, anyone who says “it’s hot out” or “hace much calor,” or any other sentence, does so because she knows that existing semantic rules assign a certain proposition to those words and she wishes to put that proposition into words.
   One immediate consequence of this is that Carnap’s position is false. Another immediate consequence is that what it is for those two sentences to have the same meaning is not for them to be “used in the same way.”
   Also, given any natural language, there are infinitely many sentences belonging to it that have never been used. The thesis that sentences have the same meaning iff they’re used in the same way has the absurd consequence that any two sentences that haven’t been used before have the same meaning. (If two sentences aren’t used at all, they aren’t used differently, and are therefore used in the same way, if only in a vacuous sense.)
4.6 Logical Positivism Evaluated (continued)
Let’s resume our discussion of Logical Positivism (LP). We’ve seen that, contrary to what LP says, there are non-empirical truths that have nothing to do with anyone’s linguistic practices. We’ll now see that, contrary to what LP says, there are facts about the spatiotemporal world that cannot possibly be known strictly on the basis of sense-perception.
   Let NT be the body of assertions jointly constituting Newton’s physics.66 There is no denying that NT is meaningful. But by itself NT doesn’t make any predictions or otherwise have observable consequences. Physical laws are expressed by conditional assertions—that is, by statements of the form ‹if P, then Q.›67 NT doesn’t say anything about how this or that physical object will behave. It says how a given object will behave if certain conditions are met. NT says, for example, how an object will behave if it has a certain mass and is within a certain distance of another body having a certain mass.68 But NT itself obviously doesn’t say that this or that object has this or that mass or is within this or that distance of this or that other specific body. Thus, taken by itself, NT isn’t confirmable. What is confirmable isn’t NT, but NT plus statements describing specific matters of fact. What is confirmable isn’t NT, but some statement of the form t ‹given such and such, NT makes it likely that thus and such.›
   But NT is obviously meaningful. This is a problem for LP. To deal with it, advocates of that doctrine proposed that (ii) be replaced with the position that (ii*) a statement S1 is meaningful if there is some statement S2, such that given S2, S1 is confirmable (i.e., capable of being supported by observation).
   By this standard, “the nothing nothings” qualifies as meaningful and so does every other nonsense sentence one can think of. Given the statement “if grass is green, then the nothing nothings,” anything that confirms “grass is green” confirms “the nothing nothings,” and “the nothing nothings” thus qualifies as meaningful.
   LP replaced (ii*) with other, similar proposals. But they all ended failing for reasons similar to the one just discussed.69
4.7 LP self-defeating
For the reasons just given, it soon became clear that LP was unsalvageable, and soon everybody jumped ship. In fact, it was some of LP’s most staunch proponents who first made it clear what LP’s shortcomings were.
   
We’ll see this in this chapter when we discuss the brilliant criticisms of LP put forth by Carl Hempel
(1905–1997), who was one of LP’s first and most ardent advocates.
   But erstwhile advocates of LP tended not to see the incoherence that lies at the center of that doctrine. When saying why they rejected LP, they usually cited narrow, technical problems of the sort just discussed. What they didn’t do, but what we’re about to do, is to say why LP is at its very core a broken and illogical doctrine.70
   Anything that is true or false is meaningful. Truth implies meaningfulness and so does falsity. Thus, LP is meaningful if it’s correct. LP says that any meaningful statement is either a tautology or is empirical. So if LP is correct, it is itself either a tautology or it is empirical.
   It isn’t a matter of convention that the expression “meaningful sentence” is interchangeable with the expression “sentence that is either a tautology or is empirical.” Therefore, LP isn’t a tautology.71
Since it isn’t a tautology, LP is an empirical truth if it isn’t false.
   But LP isn’t an empirical truth. Any attempt to provide an observational basis for any statement presupposes the meaningfulness of that statement and thus presupposes an answer to the question “what conditions must a statement fulfill to be meaningful?” For this reason, the question “what conditions must a statement satisfy if it is to be meaningful?” isn’t empirical in nature. It follows that one cannot coherently attempt to find empirical grounds for accepting LP, since any attempt to do so itself presupposes the meaningfulness of LP. Thus, LP isn’t an empirical theory.
   Thus, LP is neither an empirical truth nor a tautology. It is thus a counterexample to itself and is therefore false.
   Interestingly, in the TLP, Wittgenstein seems to be aware that one cannot coherently say that there can be non-tautologous meaningful statements. Not a single one of the assertions in the TLP is empirical; and not a single one of them is a tautology. This means that, if the TLP's main thesis is correct, the TLP is nonsense. Wittgenstein acknowledges this. For he ends his book by saying that everything that he says in it is meaningless and that those points ought to be seen, not as truths, but as ladders that one can use to get to the truth but that, once one actually gets there, one must throw away, since they are not themselves truths. Here are the very last words of the TLP:
“My propositions serve as elucidations in the following way: anyone who understands me eventually recognizes them as nonsensical, when he has used them—as steps—to climb up beyond them. (He must, so to speak, throw away the ladder after he has climbed up it.) He must transcend these propositions, and then he will see the world aright. What we cannot speak about we must pass over in silence.”72
   So far as they aren’t trivial, these magisterial words are false. To understand something is to see its meaning. Therefore, anything that is understood has a meaning. So Wittgenstein’s words, if understood, have a meaning, and Wittgenstein is therefore contradicting himself in saying that those who understand his words will see that they’re meaningless. Wittgenstein’s awe-inspiring injunction that we pass over in silence what we can’t speak about involves a similar solecism. To remain silent about something is to pass over it in silence. So Wittgenstein is asking, emptily, that we not say anything about what we can’t possibly say anything about.
4.7.1 Empiricism self-refuting
   These points are easily extended to show that empiricism is false if it’s true and, therefore, that it’s false.
Empiricism isn’t the claim that
(1) whatever we know now, we learned it through sense-perception—but it’s possible that at some time in the future we’ll acquire knowledge in some other way.

Empiricism is the doctrine that everything that can be known must be known through observation, i.e., that
(2) it’s inherent in the nature of knowledge that all knowledge be strictly observation-based.
   But it cannot be known through observation that (2) is correct. According to (2), ‹x is knowledge› is inconsistent with ‹x isn’t known through observation.› But, as we noted on page 24, observation cannot tell you whether one statement is consistent with some other statement. Thus, any body observational data is consistent with the assumption that empiricism is false.
   This means that there cannot be strictly observational grounds for believing empiricism correct. Thus, so far as empiricism is correct, there are no grounds for believing it correct; and so far as there are such grounds, empiricism is false. Thus, the likelihood that empiricism is correct is inversely proportional to the degree of probability that the information at our disposal confers on it. And this means that, if it’s a certainty that empiricism is correct, it’s a certainty that it’s false. Therefore, empiricism, if true, is false; therefore it’s false.
   The final sentence of a famous argument given by Bertrand Russell (1872–1970) ends with a sentence very similar to the last one. (This was deliberate.) The argument in question is to the effect that “naïve realism”—which is a specific, particularly extreme form of empiricism, and is therefore relevant in this context—is false:
   We all start from naïve realism, i.e., the doctrine that things are what they seem. We think that grass is green, that stones are hard, and that snow is cold. But physics assures us that the greenness of grass, the hardness of stones, and coldness of snow are not the greenness, hardness, and coldness that we know in our experience, but something very different. The observer, when he seems to himself to be observing a stone, is really, if physics is to be believed, observing the effects of the stone upon himself. Thus, science seems to be at war upon itself. When it most means to be objective, it finds itself plunged into subjectivity against its will. Naïve realism leads to physics; and physics, if true, shows that naïve realism is false. Therefore, naïve realism, if true, is false; therefore it’s false.73
   Though eloquently stated, this argument consists of spurious reasoning for a false conclusion. In observing the paper-weight on my desk, I’m not observing some effect of the stone upon myself: I’m observing the stone itself. To be sure, my observing the stone is itself an effect of some event involving the stone. (Light bounces off the stone and, in due course, strikes my retinas, precipitating various physiological and psychological responses, among them the aforementioned sense- perception.) But that doesn’t mean that what I’m seeing, in having that sense-perception, is some effect that the stone had on me; and unless we’re perpetually hallucinating, in which case we’re never observing anything external, we very obviously do observe external objects.
   This brings us to the second problem with Russell’s argument. Russell says that the greenness, hardness, and coldness of daily observation are not identical with the counterparts in physics. This is false. Physics has a lot to say about greenness, hardness, and coldness that commonsense does not. But that’s very different from saying that the coldness we feel, the greenness we see, etc., aren’t the greenness, coldness, and hardness of physics. Physics tells us what it is for something to have the properties we know them to have through sight, touch, etc. When you grab and object and feel that it’s cold, you don’t feel or otherwise sense-perceive the micro-events in virtue of which it is cold. It’s the job of the theoretical physicist to tell you about these microevents. This means that the coldness studied by the physicist is identical with the coldness that you feel. Physics tells us that many of our pre-theoretic beliefs as to what that coldness is are wrong; and in order to do that, it has to study the coldness that those pre-theoretic beliefs concern. So Russell’s argument, despite Einstein’s high regard for it, is a failure.74
   
4.7.2 The empiricism-unfriendliness of the concept of confirmation
Confirmationalism, the doctrine that a non-tautology is meaningful iff confirmable, is a form of empiricism. But we’ll now see that the concept of confirmation is an incoherent one unless it’s granted that there is nonempirical knowledge and, therefore, that confirmationalism is incoherent.
An argument due to Nelson Goodman (1954) makes this clear75:
   (GA76) Let’s say that an object is “grue” if it’s green and examined before Jan. 1, 2010, or it’s blue and examined anytime thereafter. All green objects examined before Jan. 1, 2010, are grue. So, supposing that we’ve examined ten million emeralds before Jan. 1, 2010, and found them all to be green, we’ve also found them to be grue. Presumably, the fact that they’ve all been green warrants the inference that they’ll be green after Jan. 1, 2010. But, so far as that data entitles us to infer that they’ll be green, it also entitles us to infer that they’ll be grue and, therefore, blue.
   This line of thought is easily extended to show that anything can confirm anything.77 Let phi, psi, and chi be three properties such that (i) a thing is phi if it’s examined by a human being who knows and therefore truly believes that, at that time, no human being can fly; (ii) a thing is psi if examined by a human who knows that, at that time, all human beings can fly; and (iii) a thing is chi if it’s examined before Jan. 1, 2010, and known to have phi or it’s examined after that time and is known to have psi. Since everything ever examined as of the present time (May 24, 2009) has had phi, it’s also had chi. So given that, thus far, no human has been able to fly, we’re no less entitled to infer that in 2015 they’ll all be able to fly than we are entitled to infer that, at that same time, none of them will.
   GA can be taken to show either that no inductive inference is better than any other or that, since some inductive inferences clearly are better than others, GA must involve an error of some kind. Supposing that the second interpretation is the right one, it’s easy to identify the problem with GA. Contrary to what that argument tacitly assumes, induction does not have strictly observational basis. From a strictly observational standpoint, it’s no less correct to describe an emerald examined in 2009 as “grue” than it is to describe it as “green.” Given any body of data, there are different, but equally observationally legitimate ways of describing it. This means that, if any inductions are better than any others, we must have legitimate but at least partly nonobservational grounds for believing that, when making inductive inferences, certain properties (e.g., green) are relevant and others (e.g., grue) are not. (These grounds are identified in Chapters 12 and 18.)
4.8 The brokenness of the concept of tautological truth
   In this section we'll see that it is utterances of sentences, not sentences per se, that are tautologies. For reasons that will become clear, this entails that, contrary to what LP alleges, non-empirical truth cannot be identified with conventional truth.
   Whether a given utterance is tautologous very much depends on the manner in which the person hearing that utterance learned the meanings of the expressions composing it. A story may help make this clear. You don’t know to what length the word “yard” refers, and you ask your friend Smith to give you this information. In response, he points to some object L and says: “the length of that object is one yard.” L is in fact three-feet long. But you can’t tell this just from looking at it. You can tell roughly, but not exactly, how long L is. You don’t bother to measure L. This all happens on Monday.
   The next day, you see some object M. You measure it and find that its length is three feet. You tell your (still present) friend Smith that M is exactly three-feet long. You know, of course, that M’s length is more or less comparable to L’s—that neither length is, for example, ten times as great as the other. But you don’t have precise knowledge of their comparative lengths; you don’t know, for example, whether L’s length is within six inches of M’s. Because you have a passion for knowing the comparative lengths of objects, you find this upsetting, and you tell Smith that you wish you knew how L’s length compared to M’s. Smith says: “I don’t know
   
why you’re upset. You’ve measured M and found that it’s three-feet long. Since, as you know, L is a yard long, it’s patently obvious what M’s length is.” You don’t quite know what he means, and you tell him this. Somewhat irritated, he says:
(i) “there are three feet in a yard.”
Under these circumstances, (i) is not trivial and, therefore, is not a tautology. It would be tautologous if you had learned the meaning of the word “yard” by being told that “yards are lengths of three feet.” But this isn’t how you were told it. You were shown a yard-long object and told that the word “yard” refers to its length. Obviously that visual perception did apprise you of that object’s length. But the way it described that length to you was different from the way that this same information would be conveyed to you by an utterance of: “the lenght of that object is one yard.”
   And given the information embodied in your visual perception’s of L and M, it wouldn’t be a trivial matter to know that the length described by the contents of your L-perceptions coincided with that described by your M-perceptions. Therefore, (i) would not, under those circumstances, express a tautology, at least not from your perspective. But it would express a tautology from the perspective of somebody to whom “yard” had initially been defined as “distance of three feet.”
   So even though it’s standard practice among philosophers to describe sentences as “tautologies,” this practice embodies a serious confusion. A given sentence may or may not be tautology, depending on the manner in which the auditor learned the meanings of its constituent expressions and depending, therefore, on the information on the basis of which the auditor knows those meanings.
   It might be thought that, so far as (i) is non-trivial to you, it’s only because you don’t really understand it. This isn’t true. To somebody who doesn’t speak Albanian, a sentence of Albanian isn’t trivial or non-trivial. It doesn’t mean anything to you and is, from your perspective, just so much noise and is no more “trivial” or “non-trivial” than the sound of wind chimes. But, in our story, you do know what is meant by (i). It’s not as though you’re hearing a sentence of Albanian (or, if you happen to speak Albanian, a sentence of some language that you don’t know). Therefore, it is only because you understand Smith’s utterance of (i) that it is nontrivial for you. Therefore, tautologousness, and non-tautologousness, are properties, not of sentences, but of the information on the basis of which auditors figure out the meanings of sentences. And it’s wrong to say that sentences per se are, or are not, tautologies.78
   This story illustrates some deeply important facts that are in the philosophy of language. First, one knows the meanings of expressions descriptively. It is through sight and hearing (and, possibly, other sensory modalities; e.g., touch) that you learn what words mean. Your perceptions apprise you of facts about the world by describing them to you—by apprising you of their colors, shapes, etc. Two very different descriptions can pick out some one thing (cf. “the third U.S. President” and “the President responsible for the Louisiana Purchase”). Therefore, the perceptually encoded descriptions through which one learns what two expressions mean may differ enormously, even if those expressions mean the same thing. A consequence is that what utterances tell you is as much a function of the information through which you learn their meanings as it is of the those meanings themselves. Thus, a given sentence may convey very different propositions to different people, all of whom know what it means, the reason being that those people access that meaning through different descriptions.
4.9 An alternative to the logical positivist conception of meaningfulness
The logical positivist’s analysis of meaningfulness was a complete failure. I’d like to propose an
alternative to it.
   First of all, when asked to give examples of meaningless statements, the logical positivists tended to cite sentences that nobody ever uses; for example, “the nothing nothings”1, “the all is one,” “the absolute is perfect.” This is deeply suspicious: a theory that only takes on straw men can’t be much of a theory.
   
   And LP can’t even prevail against these straw men. For, contrary to what its advocates said, the problem with these so-called statements is not that they’re incapable of empirical corroboration. Consider the sentence:
(i) “the universe is a perfect unity.”
Much loved by many a freshman narco-intellectual, this is a meaningless sentence if ever there was one; and it is just the sort of sentence that logical positivists had in mind.
   But if it were said what exactly it means to describe something as a “perfect unity,” (i) would be meaningful, as it would then be true or false. If, by a “perfect unity”, one means an object that consists of events bearing a specified causal or logical relationship to one another, then (i) is either true or false, depending on the identity of that relationship. For example, if a “perfect unity” is an object such that, given any two nonsimultaneous events composing it, there is a possible causal process connecting the first of those two events with the second, then (i) is true.1 (In contemporary physics, ‹x precedes y› is defined as: ‹there is a possible causal process, e.g. a light-signal, beginning with x and ending with y.› ) On the other hand, if, by a “perfect unity,” one means an object such that, if x and y are any two of its parts, the very idea of x’s existing in the absence of y is an incoherent one, then (i) is meaningful—and false. (One can coherently imagine a universe in which Cheney exists but Biden does not.)
   In any case, the term “perfect unity” is clearly intended to refer to some sort of causal or logical integratedness, and once that mode of integration is pinpointed, (i) speedily becomes a true or false claim.
   “Statements” such as “the universe is a perfect unity,” “the nothing nothings,” and so on, aren’t really statements at all. They’re statement-forms. (i) is obviously supposed to attribute some property to the universe. But since this property isn’t identified, (i) contains an undefined term and therefore says nothing. Once that term is defined, a meaningful statement results.
   It’s true that (i) is neither tautologous nor confirmable. But that’s a consequence of the real problem, viz. that “perfect unity” is undefined. (i) is comparable to “x is tall.” The reason “x is tall” says nothing is that “x” is undefined—it hasn’t been assigned a referent. And no sooner is a referent assigned to “x” than “x is tall” becomes meaningful. (“x is tall” comes to have the same meaning as “Bob Dole is tall” the moment Bob Dole is assigned to “x.”)
   Before “x” is assigned a referent, “x is tall” is neither confirmable nor tautologous. But that’s only a symptom of the real problem, viz. that “x” doesn’t have a referent. The same thing mutatis mutandis is true of (i).
   Let’s move onto the next phase of our argument. If S is a meaningful sentence, there is some object x and some property phi such that S says that x has phi. In other words, any given sentence is equivalent to one that has the form: ‹x has phi.› Let us now say why this is so.
   Any non-compound sentence (i.e., any sentence that doesn’t consist of other sentences) either says of some individual that it has some property or it says that two more individuals are interrelated in a certain way. Thus, “Smith is tall” says of some individual (Smith) that he has a certain property (tallness), and “Bob loves Sally” says that one individual (Bob) bears a certain relation (that of loving) with respect to some other individual (Sally).
   “Smith is tall,” “Jerry snores,” and all other non-relational, non-compound sentences obviously have the form ‹x has phi.› And, though it isn’t obvious, the same is true of “Bob loves Sally,” “Wilma detests Linda,” and all other non-compound sentences that affirm the existence of relations between two or more objects. Let “R” be defined as follows: for any objects x and y, ‹ <x,y> has R› is true iff x loves y. (So for any objects x and y, the ordered pair <x,y> has R exactly if x loves y.) Thus, “Bob loves Sally” is equivalent with “<Bob, Sally> has R,” which has the form ‹x has phi.›
   A similar procedure can be performed on sentences (such as “Bob is standing in between Sally and Larry”) that affirm the existence of relations involving three or more objects. Let “R*” be defined as follows: for any objects x, y, and z, ‹<x,y,z> has R*› is true iff x is standing in between y and z. Thus, “Bob is standing in between Sally and Larry” is equivalent with “<Bob, Sally, Larry> has R*,” which has the form ‹x has phi.› Other non-compound relational sentences are to be dealt with similarly.
   
   What about compound sentences? Not a problem. Let “K” be defined as follows: for any sentences S1 and S2, ‹ <S1, S2> has K› is true iff the state of affairs described by S1 is a consequence (of some kind or other) of the state of affairs described by S2. Thus, “Smith broke his leg because he fell out of the a tree” is equivalent with “<Smith broke his leg, Smith fell out of the a tree.> has K,” which has the form ‹x has phi.› Other compound sentences are to be dealt with similarly.
   Negative sentences are particularly easy to deal with. “Smith doesn’t smoke” is equivalent with “the proposition that Smith smokes is false,” which clearly has the form: ‹x has phi.› Other negative sentences are to be dealt with similarly.
   There is only one kind of sentence that we haven’t yet considered, namely, quantified generalizations. A “quantified generalization” is any statement that says how many members one class of objects has in common with some other class of objects. Examples are: (a) “some person smokes,” (b) “no giraffes fly,” and (c) “all mice read Tolstoy.” (a) says that the class of people has at least one member in common with the class of smokers. (b) says that the class of giraffes has no members in common with the class of things that fly. And (c) says that the class of mice has no members in common with the class of things that don’t read Tolstoy.
Bearing this in mind, let “E” be defined as follows: for any properties P and Q, ‹ <P, Q> has E› is
true iff the class of things having P has a least one member with the class of things having Q. Thus,
(a) is equivalent with: “<the property of being a person, the property of being a smoker>, has E” which obviously has the form ‹x has phi.› Other quantified generalizations are to be dealt with similarly.
   We have thus established that any given sentence S is equivalent to some sentence having the form ‹x has phi.› Given this fact, there is an obvious answer to the question “what is it for a sentence to be meaningful?” A sentence is meaningful if it attributes some property to some object. A sentence S is meaningful if, for some object x and some property phi, S says that x has phi.1 It’s irrelevant whether it can be perceptually confirmed, let alone verified, that x has phi.
   How could this theory be wrong? If a sentence attributes any property to any thing, it says something about something and is therefore meaningful. And if a sentence doesn’t attribute any property to anything, it doesn’t say anything about anything and is therefore meaningless.
5.0 The picture theory of meaning
   One of the most interesting contentions put forth in the Tractatus Logico-Philosophicus (TLP) is the so-called “picture theory of meaning.” In the TLP, Wittgenstein says that sentences are “pictures” of the facts they describe.
   What does he mean? Maybe he means that sentences are picture-like in that they, like pictures, represent facts. But in that case what Wittgenstein is saying is completely and utterly trivial.
   Thus, so far as what Wittgenstein is saying has substance, it isn’t that sentences are like pictures of the facts they describe; and it must therefore be that they are such pictures.
   But in that case, what Wittgenstein is saying is false. It is only relative to arbitrary conventions that “Smith punched Jones” describes the fact that Smith punched Jones. But it isn’t relative to such conventions that a film or painting of Smith punching Jones describes that fact.
   To be sure, there is a non-conventional component to sentential representation. Let P be the proposition meant by the sentence:
   (1) “Given that Socrates was a philosopher, it follows from the fact that Socrates was bald that there has been at least one bald philosopher.”
   The fact that (1) means P is not itself a convention. It is a logical consequence of our semantic conventions (e.g., that “Socrates” refers to Socrates, etc.). But for that very reason, there is a conventional component to that fact. And since graphic resemblance is a non-conventional method of representation, it follows that, so far as (1)’s relation to the fact it describes is conventional, that relation is fundamentally not like the relation borne by a picture of an event to that event. Thus, the picture-theory is false if taken literally and it’s empty if taken non-literally.
   
   But maybe there’s some way of interpreting that theory that we’ve overlooked. To see whether this is so, let’s consider Wittgenstein’s argument for it:
At first sight a sentence—one set out on the printed page, for example—does not seem to be a picture of the reality with which it is concerned. But neither do written notes seem at first sight to be a picture of a piece of music, nor our phonetic notation (the alphabet) to be a picture of our speech. At yet these sign-languages prove to be pictures, even in the ordinary sense, of what they represent79 . . . There is a general rule by means of which the musician can obtain the symphony from the score, and which makes it possible to derive the symphony from the groove on the gramophone record, and, using the first rule, to drive the score again. That is what constitutes the inner similarity between these things which seem to be constructed in such entirely different ways. And that rule is the law of projection which projects the symphony into the language of musical notation. It is the rule for translating this language into the language of gramophone records.
   The idea seems to be that just as laws of projection coordinate the painting of the bowl of fruit with the bowl of fruit itself, so the semantic rules of a language coordinate its sentences with the realities they describe.80
But this analogy is a shallow one; and when it’s scrutinized, it becomes even more clear than
before how unlike pictures sentences are.
   What if, because of some change in the environment, snow turned black? The English language would not for that reason be impaired. In fact, the English language would, without itself having to change, give us the resources to describe this change. We could describe it by saying “snow is black.” Thus, as far as the English language is concerned, snow can be any color. The semantic rules of English don’t say that snow is white. They say that, if snow is white, one can express that fact by saying “snow is white.” And those rules are to the effect that if snow is black, one can express that fact by saying “snow is black.” So the semantic rules of English assigns sentences not to the fact that snow is white—for as far those semantic rules know, it isn’t a fact that snow is white—but to the proposition that, when true, gives rise to that fact.81 Thus, sentences depict facts by way of having propositions for their meanings. But this isn’t how photographs work. A photograph doesn’t go through the corresponding proposition. It goes straight to the fact (when there is one). No picture goes through a proposition. Pictures, unlike sentences, go straight to the facts, if any there be, that they represent. This shows how fundamentally unlike pictures sentences are.82
   A related point is that pictures have structures that are radically different from those of any sentences. Sentences are digital structures.83 They have a unique decomposition into a finite number of discrete parts. (“The cat is on the mat” decomposes into “cat,” “mat,” etc.) Pictures aren’t like this. A picture of a cat on the mat doesn’t have one, minimal unit of significance corresponding to the cat, another to the mat, etc. The part of the picture corresponding to the cat may also contain a part corresponding to the cat’s ear and to the cat’s leg, etc.
   The fact that sentences, unlike graphic representations, are digital structures is a consequence of the fact that the former, unlike the latter, have a conventional component. The reason for this is a subtle one. But it’s worth stating, since it shows how deeply wrong the picture-theory is and since, in so doing, it reveals a lot about language.
   Let D1 be some random photograph of a person smiling. D1 isn’t a symbol of a language. But that could easily change. For this to happen, some convention would have to arise whereby it had a fixed a meaning— whereby it meant, for example, that people are sometimes are happy, and the same thing mutatis mutandis happens in connection with each of several other photographs. So for example, there is some photograph D2 of a person who is crying, and some convention is created whereby D2 means that people are sometimes unhappy; and so on. Let L be the language defined by the totality of these conventions.
Even though D1 is an image, it isn’t functioning as an image so far it’s functioning as an expression of
L. The fact that D1 is a picture of a smiling person may obviously make it easier for people to remember that, in L, D1 means that people are sometimes happy. But it won’t be what it is for D1 to bear that meaning, or any other, in L. The character “0” is an unfilled hole and can thus be taken as graphic representation of emptiness.
   
But so far as, “0” is such a representation, that isn’t what it is for it to denote the integer preceding the number one. The same point mutatis mutandis holds of D1.
   Also, D1 doesn’t graphically represent the fact that people are sometimes happy; it graphically represents the tenuously related fact that, on some one occasion, some one individual was happy, along with various other specific facts about that person’s appearance that have nothing to do with anyone’s being happy. So isn’t by virtue of graphically representing the fact that people are sometimes happy that, when functioning as a sentence of L, D1 describes that fact.84
So far as D1 is a sentence of a language, what it actually picks out is irrelevant; the various
nuances of the smiling gentleman’s face are irrelevant. In general, its internal structure is irrelevant. Considered as an expression of L, it has no internal structure. (It is what philosophers of language call a semantic primitive. A semantic primitive,” or primitive symbol,” is one that doesn’t consist of other symbols and that, so far as it is an expression of a language, thus has no internal structure.) For exactly similar reasons, each of the other photographs composing L is, when considered as an expression of L, devoid of internal structure and thus, in the most extreme way possible, not like a graphic representation.
   We must make one more point before we can close the argument. Let N be a photograph of a bolt of lightning, and suppose that N is the L-translation of the English expression “it is not the case that.” So if S is the L-translation of “grass is green,” NS is the L-translation of “grass is not green.” (NS is formed by putting N to the left of S.) Even though NS consists of pictures, it is not itself a picture. Putting two pictures together isn’t one picture; it’s just two pictures that are next to each other. For exactly similar reasons, if conventions were created whereby the sentences of L could be conjoined, disjoined85, or otherwise combined, the resulting compound sentences would not be pictures.
   Let us take stock. Not a single one of the simple symbols belonging to L is a graphic representation of the fact that it depicts, and not a single one of the complex symbols belonging to L is a graphic representation of the fact depicted by any one of its components. In general, to the extent that a given thing is functioning as a linguistic expression, it is not functioning as a picture. Things that happen to be pictures cannot function as pictures so far as they are functioning as linguistic expressions or, therefore, as sentences. Thus, Wittgenstein's contention that sentences are pictures of the facts they describe is the antithesis of the truth. In addition to showing that Wittgenstein’s picture- theory is false, this shows that any conventional assignment of meaning to any collection of symbols—any language, in other words—necessarily yields symbols that have a unique decomposition into discrete parts. This is obviously, almost tautologically, true of compound symbols; and it’s vacuously true86 of non-compound symbols, since no such symbol has any internal structure at all.
5.1 The picture theory of meaning (continued)
It’s not entirely clear why Wittgenstein said that sentences are pictures. But it is clear that this
contention of his is consistent with this empiricism.
   Empiricism says that all knowledge is observation based. Thus, if you know it, you either (i) sense-perceived it or (ii) you inferred it from what you saw, provided that the inference rule you used is one that is known through sense-perception. (So far as knowledge is obtained with the help of inference rule whose legitimacy can’t be authenticated by sense-perception, some knowledge is not perception-based.)
   Our sense-perceptions give us pictures. Not all sensory modalities give us visual pictures, of course. Hearing gives us auditory pictures, touch gives us tactile pictures, etc. But perceptual representation is pictorial representation. (In what follows, when I say “see,” I mean “see or hear or touch [etc.].”)
   But much of what we know can’t be embodied in images of any kind. (In this context, I’ll use the word ‘image’ not just to still-images, but to moving pictures.) I know that:
(1) the moon is not made of cheese.
What would an image of this fact be? An image of a cheesy moon with a big X on it? No. The big X wouldn’t be an image at all. Like the word “not,” it would be a conventional sign of negation. Whereas a picture of a
   
cheesy moon would indeed resemble a cheesy moon, a big X doesn’t resemble the operation of negation. Nothing could physically resemble that operation, since it isn’t something that could possibly be seen or otherwise sense-perceived.
   Also, a picture of a cheesy moon corresponds to a lot of different propositions.87 Any such picture will also depict an object having a certain color, shape, etc. Since (1) doesn’t anything about the moon’s shape or color, it isn’t identical with such an image. No proposition is identical with any image, since any image will contain information not contained in the image.
   Thus, there are at least some cases where one’s knowing of some fact doesn’t consist in there being an image in one’s mind of that fact. How is the strict empiricist to deal with this? First of all, it’s hard to see how sense-perception, which gives us nothing but one image after another, could apprise us of truths that are incapable of being expressed in a strictly imagistic form. For argument’s sake, let’s concede to the empiricist that it’s strictly through perception that I know that the Moon is made of XYZ. How are we to deal with my subsequent knowledge that the Moon is not made of cheese? Obviously that knowledge is largely based on my knowledge that it’s made of XYZ. But it can’t be entirely based on it. What my senses tell me, at most, is what the moon is made of, not what it isn’t made of. So some kind of non-perceptual knowledge is involved in my making the leap from the moon is made of XYZ to the moon is not made of cheese.
   Here is a related, if not quite coincident, argument. Even if image-resistant facts (e.g., those expressed by negative statements) are learned in a strictly perceptual manner, the mental states that mediate our knowledge of them are not themselves images. The information borne by those mental states must be encoded in some non-iconic form. This means that, at some point, pictorial information was converted into non-pictorial information. But if our post-perceptual mental states are to be knowledge, that conversion process must be a legitimate one. In other words, it can’t, when given pictorial input x, yield some output y that is inconsistent with x. Moreover, we must know that the conversations being made are legitimate. For argument’s sake, suppose that I don’t know that, given my (let us assume) strictly perception-based knowledge that the moon is made of XYZ, it is correct to hold that the moon is not made of cheese. In that case, to the extent that my belief that it isn’t made of cheese is based on my knowledge that it’s made of XYZ, that belief isn’t knowledge. If, on the basis of testimony given by a source of whose reliability I have knowledge, I believe P, I don’t know that P. Uncorroborated testimony, though a helpful initial step on the road towards knowledge, is not itself enough for knowledge. For much the same reason, if I don’t know the rules that permit the derivation of non-perceptual beliefs from strictly perceptual ones, then, even if my post-perceptual beliefs are correct, they aren’t knowledge.
   But there couldn’t possibly be any strictly perceptual way of knowing that those conversions were accurate. Those conversions, by supposition, turn pictures into non-pictures. So our knowledge of their existence, or (a fortiori) of their legitimacy, cannot itself be strictly pictorial. This is the real problem with empiricism. The rules that we use to make inferences from perceptual experience cannot themselves be learned strictly on the basis of sense-perception. This will be discussed at length in Chapters 12 and 13.
5.2 The picture theory of meaning (continued)
Interestingly, Wittgenstein made points at least vaguely like these in the TLP:
   In order to be ale to represent logical form, we should have to be able to station ourselves with sentences outside logic, that is to say outside the world. Sentences cannot represent logical form: it is mirrored in them. What finds its reflection in language, language cannot represent. What expresses itself in language, we cannot express by means of language. Propositions show the logical form of reality. They display it.
   Thus, if one proposition ‘fa’ shows that the object a occurs in its sense, two sentences ‘fa’ and ‘ga’ show that the same object is mentioned in both of them. If two sentences contradict one another, then their structure shows it; the same is true if one of them follows from the other. And so on. What can be shown, cannot be said.90
   
   Wittgenstein seems to be saying that we cannot correctly describe the relationship holding between our words and the facts they describe. But, if correct, that point itself describes that relationship, calling into question its own coherence.91
   In any case, contrary to what Wittgenstein says, we can identify the logical forms of our own utterances. To identify the logical form of a statement is simply to make it clear what it means. We can do this. We do it all the time. We do it whenever we put the meanings of words into words. There are some qualifications to this, as we’ll see in a moment, but none that redound to the credit of Wittgenstein’s point.
   Wittgenstein’s assertion that “what can be shown, cannot be said” is obviously false. I tell you that I can do fifty push-ups. (I say “I can do fifty push-ups.”) You don’t believe me. So I show you that I can do fifty push-ups. (I do fifty push-ups in front of you.) And, as we just saw, that principle holds no less in connection with logical forms than in connection with a person’s ability to do push- ups.
   Echoing what we said earlier, although it isn’t clear why Wittgenstein made these claims or what he meant by them, it is clear that they’re consistent with his view that sentences are pictures of reality. A picture cannot picture itself. If P is a picture of a seagull, P can’t contain a picture of itself, for the simple reason that nothing can be a proper part of itself. Of course, P might be a picture of a big seagull and also of some other, much littler, but otherwise identical seagull. But the big-seagull part of the picture isn’t identical with the little-seagull part. The big part contains two seagull-images; the little part only contains one.
   So if sentences were pictures, then a given sentence S1 couldn’t be a picture of itself. But it doesn’t follow that some other picture S2 couldn’t be a picture of S1. Nor, therefore, does Wittgenstein’s much stronger claim that nothing—no picture, no set of pictures, no sentence—could depict or otherwise represent the rules by which true statements are paired off with the facts they described.
   Wittgenstein’s claim that we cannot state the logical forms of sentences, which collapses into the brazenly false claim that we can never say what our words mean, has two roots. One of them is his just-discussed belief that sentences are pictures of the facts they describe. The other is his not yet discussed belief that, if it’s assumed that we can say what our words mean, we have no way of dealing with paradoxes like the following. If somebody says:
(i) “what I’m saying is false,”
what that person is saying is true if it’s false and false if it’s true. Wittgenstein was keenly interested in this paradox during his pre-Tractarian years.92 His reaction to it, it appears, was to hold that any attempt to articulate semantic rules would self-refer in the same the same paradox-engendering way as
(i) and, therefore, that such rules cannot possibly be put into words.93
   But this is not good reasoning. When I say, while pointing at the person exiting the limo, “that’s Mick Jagger,” I’m stating a semantic rule. There is some individual x such that I am saying (correctly, we may suppose) that it’s a semantic rule that “Mick Jagger” refers to x. The semantic rule I’m expressing doesn’t self-refer and isn’t otherwise defective.
   As we’ll see in a moment, there are reasons to think that some semantic rules cannot be put into words, and Wittgenstein seems to have had at least a vague knowledge of some of them. But given only that some semantic rules can be put into words, it obviously doesn’t follow, contrary to what Wittgenstein seems to have inferred, that no semantic rules can be put into words.
Having spent pages dwelling on the shortcomings of the Tractatus, let’s end this section on a
sunnier and more constructive note.
   It is often said that truth is indefinable. Many people say this without meaning anything by it. Setting such people aside, those who say this seem to mean either (a) that it cannot be said what it is for a proposition to be true or (b) that no language can state all of the semantic rules that belong to it.
(a) is false. (See Chapter 3.) But (b) is true.
   (b) isn’t the absurd claim that no language can state any of its own semantic rules. Every time one uses an English sentence to define an English expression, one is expressing a semantic rule of English in English. But neither the English language, nor any other, can state all of its own semantic rules. Here’s why.

   Given any meaningful expressions, there is a semantic rule r saying what s’s meaning is. (This is trivially true. A meaningful expression is one that has a meaning and is therefore one such that some true proposition identifies that meaning; and any proposition that, like r, says what an expression means is ipso facto a semantic rule.) So, for example, supposing that x is Dick Cheney, there is a semantic rule of English to the effect that “Dick Cheney” refers to x. That rule is not itself a sentence. But it can obviously be expressed by a sentence (as we just saw). In general, semantic rules, though often capable of being expressed by sentences, are not themselves sentences. In light of this fact, suppose for argument’s sake that, for each semantic rule of English, there is a sentence of English that expresses that rule. Let K be the class containing all and only sentences of English that correctly express actual semantic rules of English. Let SRE be the conjunction of all of K’s members. SRE is a true and therefore meaningful sentence of English. SRE is also a member of K. After all, K contains every sentence that correctly says what is meant by at least one expression of English, and SRE obviously satisfies that requirement. But given that SRE is also a conjunction consisting of all of K’s members, it follows that SRE is one of its own conjuncts. No conjunction can be one of its conjuncts. (The conjunction “snow is white and snow is white” is not one of its own conjuncts, since that sentence is a conjunction, whereas “snow is white” is not.) We’re forced to reject this obvious truth if we grant the supposition that the English language can express each of its own semantic rules. Therefore, the English language cannot state all of its own semantic rules. Given any language L, what we just said about English is true of L. Thus, no language can express all of its own semantic rules.94
6.0 (ii) revisited: formal truth ≠ analytic truth
One of the main contentions of the TLP is that all entailment is formal entailment. One statement entails another if, supposing the first is true, the second couldn’t possibly be false. So “Smith is a triangle” entails “Smith has more than one side.” One statement, S1, formally entails another sentence, S2, if the statement “if S1, then S2” is a formal truth. A statement is a formal truth if every statement having the same form as it is true. Thus,
(1) “If Smith is in the barn, then it is not the case that it is not the case Smith is barn”
is a formal truth, since every statement of the form
(2) “if P, then it is not the case that it is not the case that P”
is true.
(1) is also an example of a formal entailment. It’s a formal entailment since it’s a formal truth that is also an entailment. (It’s an entailment since it’s to the effect that that one statement (Smith is in the barn) entails another (it is not the case that it is not the case that Smith is in the barn).
   In the TLP, Wittgenstein asserted that all entailments are of this kind. He was aware that there are apparent counterexamples to this. For example:
(4) “Brown is a bachelor”
entails that
(5) “Brown is unmarried.”
But
(6) “if Brown is a bachelor, then Brown is unmarried”

isn’t formally true, since it has the same form as
(7) “if Brown is a bachelor, then Brown is a cupcake”
which isn’t true at all.
Wittgenstein deals with this by saying, very reasonably, that (4) is synonymous with:

(4F) “Brown is unmarried and Brown is an adult and is male.”
Unlike (4), (4F) does formally entail (5). According to Wittgenstein, all apparent counterexamples to his thesis that all entailment is formal entailment can be dealt with similarly.

But the method used in connection with this particular counterexample fails in connection with others. The sentence:
(8) “Brown is a circle”
entails
(9) “Brown is a two-dimensional figure.”
(8) doesn’t formally entail (9). Wittgenstein must say that (8) is synonymous with something that does
formally entail (9). If there is any sentence that is synonymous with (8) that formally entails (9), it’s:
(10) “Brown is a closed, planar, two-dimensional figure of uniform curvature.”
(10) does indeed formally entail (9). But (10) isn’t synonymous with (8). That’s why:
(11) “Brown is a circle iff Brown is a circle”
is trivial, and says nothing, whereas
(12) “Brown is a circle iff Brown is a closed, planar, two-dimensional figure of uniform curvature”
is non-trivial.
   (12) doesn’t say anything about the spatiotemporal world. (12) is logically true; its truth is guaranteed by the structures of the concepts composing it. Unlike (11), (12) isn’t a tautology. Therefore, it’s a non-tautologous, non-empirical truth. Thus, there are non-formal entailments, and this entails that the Tractarian conception criterion of meaningfulness advocated false. (“Tractarian” is the adjective form of “the Tractatus Logic-Philosophicus.”)
7.0 Why the concept of a logically perfect language is an incoherent one (This section is hard and should be skipped on a first reading.)
Let’s say that a sentence is perspicuous iff its logical and grammatical forms coincide; and let’s say
that a language is logically perfect iff every sentence belonging to it is perspicuous.
   Many non-perspicuous sentences belong to any given natural language (e.g., English, Swedish). One of Wittgenstein’s objectives in the TLP is to identify the conditions that a language must meet if it is to
   
be logically perfect. Wittgenstein takes it for granted that the concept of such a language is a coherent one. Influenced by the TLP, many early analytic philosophers longed for the day when logically perfect languages would replace natural languages.95
   In any case, the concept of a logically perfect language is not a coherent one. It isn’t possible for everything about a sentence’s meaning to be reflected in its grammar. And if per impossibile there did exist a logically perfect language, it would be expressively inferior to English, Arabic, and every other natural language. In other words, there would be much that couldn’t be said in it that could be said in any natural language.
   More precisely, for each analytic truth capable of being expressed by a logically perfect language, there would be infinitely many that it could not express and that English or Spanish or any other natural language could express. At the same time, there would be no truth that could be expressed in a logically perfectly language that couldn’t also be expressed in a logically imperfect language, such as English. Let us now discuss why this is so.
   A sentence belonging to a logically perfect language is analytically true iff it is formally true. Why is this? A sentence is perspicuous only to the extent that its grammatical form makes it clear what it says and, therefore, makes it clear what it entails and what entails it. Bearing this in mind, let S be some arbitrary sentence. To the extent that there are false sentences, or true but non-analytic sentences, that have the same surface-structure as S, S’s grammatical and logical forms don’t coalesce and, consequently, S isn’t perspicuous. So an analytically true sentence is perspicuous only if all other sentences having the same form are true. A sentence is formally true if, and only if, any sentence having the same form is true. Thus, a sentence is perspicuous only if formally true. Therefore, a sentence belonging to a logically perfect language is analytic only if formally true.96
   A consequence is that, for each analytic truth that a logically perfect language can express, there are infinitely many that it cannot express. Given any object x and any property phi, the sentence

(S1) ‹if x has phi, then it is not the case that x does not have phi›
is perspicuous, the reason being that nothing having the same surface structure is false. But the superficially similar sentence

(S2) “given any object x and any property phi, x has phi, then x does not have phi”
is not perspicuous, since it has the same surface structure as:

(S3) “given no object x and no property phi, if x has phi, then x does not have phi,”
which is false. Formally true sentences are instances of informally true universal generalizations. So no sentence capable of expressing such generalizations is logically perfect.
   This point has important and often overlooked consequences. Making a valid deductive inference involves recognizing an entailment. Your deductively inferring Q from P involves your recognizing that P entails Q. The only way to know that some formal entailment is valid is to know that some informal entailment is valid. You know that:
(S4) “Jerry is in Richmond,”
entails that
(S5) “it’s not the case Jerry is not in Richmond”
And that’s why, if you accept S4, you also accept S5.
   But how do you know that S4 entails S5? Is it on the basis of your knowledge that all instances of S1 are true? No. How could you possibly know that all of S ’ s instances were true unless you could
recognize the
   
validity of specific inferences that it licenses (such as the inference from S4 to S5)? If you couldn’t recognize that S4 entailed S5, then you obviously wouldn’t have any idea why all of S1’s instances were correct.
   This is not, at least not merely, a psychological point. It’s a psychological corollary of an epistemological point, which, in its turn, is a corollary of a logical point. The reason why every instance of S1 is true—the reason, in other words, why S2 is true—is that and each of infinitely many specific inferences, of which the inference from S4 entails S5 is but a single instance, is valid. There are, quite literally, infinitely many informally valid inferences for each formally valid one. So Wittgenstein’s allegation that all entailments are formal entailment is not feasible.
7.1 Hempel on the limits of strict empiricism
Carl Hempel (1905–1997) provided the following rigorous proof of the falsity of strict empiricism97:
(HA98) If x’s length is one unit, and y’s length is  2 units, then there is no length L such that
L goes an integral number of times into both x’s length and y’s length.
   Measurement is comparison with respect to some standard. To compare x’s length with y’s—in other words, to establish their comparative lengths—it is necessary to find some third body z that is taken as a standard99; and the relative lengths of x and y are determined by finding out how many z-length segments each of x and y can be divided into. (If one object can be divided into exactly twice as many z-length segments as some other, then the first is twice as long as the second.) Supposing that x’s length is one unit and y’s length is i2 units, it follows that there is no body z such that both x and y can be divided, without remainder, into z-length segments.100 It follows that, if an object’s length is given by an irrational number, that fact cannot be known directly on the basis of measurement. It therefore follows that there is no strictly observation-based way to know that y’s length equals x’s multiplied by n2. In general, for any two objects x and y, there is no strictly observation-based way of establishing that x’s length (or mass, etc.) is incommensurable with y’s. (Two magnitudes M1 and M2 are incommensurable if there is no magnitude M3 that goes an integral number of times into both M1 and M2.)
   The branch of mathematics known as “calculus” is integral to modern physics. Calculus is the study of continuously changing quantities. In order to describe physical phenomena in a way that makes it possible to use the powerful techniques of the calculus to describe them, it must be assumed that they change continuously and, therefore, that the degree to which a given phenomenon has a given property may sometimes be given by an irrational number.101 Thus, it must be assumed that, at certain junctures, the velocities, lengths, masses, etc., of objects are sometimes given by irrational numbers. But there cannot, as we’ve seen, be strictly observational grounds for believing that a given object‘s length is  2 meters (or that its mass is m2 lbs, etc.).102 Since the calculus can’t be applied to observable phenomena unless it’s assumed that things’ weights, velocities, etc., can at least sometimes assume values given by irrational numbers, it follows that modern physics integrally depends on an assumption for which there cannot be possibly a strictly observational basis. This means that strict empiricism is inconsistent with the obvious fact that modern physics is a source of knowledge.
8.0 The sub-disciplines composing philosophy
The main branches of analytic philosophy are: the philosophy of mind, the philosophy of language, the theory of knowledge (also known as “epistemology”), philosophical logic, metaphysics, the philosophy of science, ethics, political philosophy, legal philosophy, the philosophy of religion, and formal logic.
   It should be kept in mind that these sub-disciplines overlap a great deal. So, for example, the question “do we think in words?” belongs to the philosophy of mind and to the philosophy of language.
   
8.1 The philosophy of mind
This discipline studies the concepts in terms of which the mind is to be understood. Among the questions it tries to answer are:
   Must one know a language in order to think? Or, on the contrary, is the ability to think a prerequisite to learning and operating with a language?
Given that knowing a language seems to enhance some kinds of thinking, how does it do so?
   What are beliefs, and what is the difference between believing that Smith is tall and wondering whether he is tall?
How is perception related to thought?
   Can perceptual content (i.e., what our eyes, ears, etc., tell us) be put into words? Or is there a fundamental difference between the kind of information that our sense-perceptions bear, on the one hand, and the kind of information that can be encoded in sentences, on the other?
To what extent is self-knowledge possible? What factors limit our ability to know ourselves? How is mind related to brain? Are they one? If not, what is the relationship between the two? Can there be unconscious mental activity?
8.2 The philosophy of language
This discipline studies the nature of linguistic meaning. Among the questions it tries to answer are:
   What does it mean to say that “Smith” refers to Smith? What, in general, does it mean to say of an expression E that it picks out some object O?
How do the meanings of a sentence’s parts relate to the meaning of the sentence as a whole?
   Do expressions like “some person,” “all people,” and “no people” function in the same way as proper names (e.g., “Smith,” “Jones”)—that is, do they pick out objects? Or do they function in some other way? If so, what is that other way?
   To what extent can the nature of linguistic meaning in general be understood in terms of the relationship that proper names bear to their referents (the things they refer to)?
How is it that statements about non-existent things can be meaningful?
   How is the meaning of a sentence related to the thoughts of those who utter that sentence? Do the thought and the meaning coincide? Or is the relationship more indirect? If so, what exactly is that relationship?
   How well does the grammatical structure of a sentence reveal what it actually says? Does grammar distort meaning or, on the contrary, is grammar a good guide to logical form?
   Are the semantic rules of a language (e.g., the rule that, in English, “snow” refers to a certain crystalline substance) known to speakers of that language? Or are such rules merely idealized descriptions of the behavior of those speakers?
   Assuming, as some authors do, that there is an innately known language-like code in which we think, to what extent does that code resemble the languages (e.g., English, Spanish) that we learn?
How “transparent” is meaning? To what extent do users of a language know what sentences of
that language mean?
   What does it say of a sentence S that its literal meaning is P? What exactly is “literal” meaning? How is it different from communicated meaning? Is literal meaning merely an idealized description of communicated meaning, or is it something else entirely?
8.3 Epistemology
This discipline studies the nature and extent of knowledge. Among the questions it tries to answer are: What is knowledge? What separates those beliefs that are knowledge from those that are not?
   
   What can be known and what cannot be know? (Can it be known what cannot be known? Or is it incoherent to give an affirmative answer to this question?)
Can we know about the future, the past, the possible but not actual, the impossible?
Can we know about the external world, or is knowledge limited to our own mental states? Can there be knowledge of things that are not in space or time (e.g., numbers) and, if so, how?
   Are there any self-evident or self-justifying beliefs? Or must all justified beliefs be justified by beliefs other than themselves?
   What is the structure of the totality of our knowledge? Are there some pieces of knowledge from which all the rest are derived or are all pieces of knowledge interdependent?
   Is there a fundamental difference between knowledge of spatiotemporal fact (e.g., knowledge that there is a dog over there) and knowledge of purely conceptual truths (e.g., that there are laws only where there is government)? Or is the one kind of knowledge to be reduced to, or modeled on, the other?
8.4 Philosophical logic
This discipline studies bearing-relations holding among sentences and propositions (sentence- meanings). Among the questions it tries to answer are:
   What is it for one statement to entail another? (P “entails” Q if there is no way that Q can be false if P is true.) Are there different kinds of entailment? If so, are some more central to reasoning than others?
   Are inferences concerning the non-existent (e.g., “if Zeus is tall, then at least one god is tall”) to be modeled on inferences concerning the existent (e.g. , “if Bush is tall, then at least one president is tall”)? Are the same principles involved? Or is the non-existent logically sui generis?
To what extent can reasoning be “mechanized”? In other words, to what extent is it possible to
produce rules that can be applied without any thought that will do the work of a rational being?
   How are statements about what might have been, but is not, to be understood? Are they similar, logically, to statements about what is? Or do they have an altogether different logical form?
   Are all statements either true or false? Or are some “indeterminate”—that is, is there a “gray zone”? And are there “degrees” of truth?
8.5 Metaphysics
This discipline studies the nature of possibility and necessity, of causal relations between objects. It also studies the nature of identity and the conditions that something must meet in order to exist. Among the questions it tries to answer are:
   Under what circumstances are two distinct objects (e.g., my heart and my liver) both parts of some one thing?
What is it for an inanimate object to endure in time?
What is it for an animate object (e.g., a person) to endure in time?
   Is there a sense in which fictional objects (e.g., Fred Flintstone) exist? Or is there no need to assume the existence of such things to account for the facts of experience?
   What is it for something to be possible but not actual? What is it for something to be actual not necessary? What is it for something to be necessary?
Are necessity and possibility properties of objects (e.g., rocks, trees, people) or of statements? Are there things that are not in space or time?
Must things have causal properties in order to exist?
   
8.6 The philosophy of science
This discipline studies the logical structure of scientific endeavor and of its results. Among the questions it tries to answer are:
What is the difference between statements that are scientific and those that are not? What are explanations? What is it to explain an event?
Is there a sharp distinction between theoretical and non-theoretical claims? Or, as some claim, are
all statements (even basic ones; e.g., “that’s a rock”) “theory-infected”?
   Given two rival theories, how is it to be determined which, if either, is the more accurate one? And supposing that one of them is the more accurate one, does it follow that it is the better one? In other words, is accuracy the only virtue a theory can have or, if not the only such virtue, then the most important one? Are theories to be evaluated (judged correct and, what may or may not be different, judged good) entirely in terms of their degree of agreement with the experimental data? Or are other factors (e.g., simplicity, comprehensiveness) involved?
   What is the nature of measurement? Are there any reasons, other than reasons of convenience, for taking certain objects or events as standards? To use Hempel’s (1952) example, is one wrong to take the Dalai Lama’s heartbeat as a periodic process, or is it simply inconvenient to do so?
   What is the nature of probability? What does it mean to say that there is a 50% chance that the coin will come up heads? Is probability just “a measure of ignorance,” as Laplace (1749–1827) said? Or is it an objective fact about the world?
   Do theoretical entities (e.g., protons, unconscious urges) exist in the same way as non-theoretical entities? Or are theoretical entities merely devices that we use to make sense of non-theoretical entities? Are statements about “protons” just abbreviated statements about meter readings and other macroscopic phenomena?
   Is there a fundamental difference between explanations in the physical sciences and explanation in the psychological sciences?
   Under what circumstances is a hypothesis (a tentative theory) to be rejected? Is a single disconfirmatory result enough? If not, what else is needed?
   Must all theories be “deterministic”? (In other words, must they posit a rigid causal order?) (Einstein said “yes.” Peirce (1839–1914) said “no.”) Others, e.g., Ernest Nagel (1901–1985), say that the question is ill-formed, the reason being that whether a system is deterministic or not depends on how it is described. Determinism is a logical property of statements, in Nagel’s view, not of the events they describe.103 A consequence is that a given domain may be deterministic with respect to one method of describing it, but indeterministic with respect to some other method of describing it. Thus, the sub-atomic realm, Nagel says, is indeterministic with respect to the concepts in terms of which we describe the macroscopic realm; but it doesn't follow, Nagel plausibly alleges, that it is indeterministic tout court.)
   Should science attempt to state how the world actually is? (Karl Popper says “yes.”) Is that even possible? (Kant says “no.”) Or should science confine itself to producing theories that are consistent with the data, while leaving it open whether those models are actually correct or not? (Bas van Fraassen says “yes.”104) (A “model” is a description of a hypothetical structure that, if existent, would account for the relevant data.)
8.7 Ethics
This discipline studies the nature of good and bad, right and wrong. Among the questions it tries to answer are:
What is it for an act to be good and what is it for an act to be bad?
Are there absolute standards of goodness and badness, or do such standards vary from culture to culture?
Are there in fact such things as right and wrong?
   
   Are any of our beliefs about the rightness and wrongness of things correct? Or are all our ethical beliefs illusions of some kind?
   How are ethical statements (e.g., “killing is wrong”) related to non-ethical, purely “descriptive” statements (e.g., “killing tends to undermine social order”)?
To what extent can one have ethical obligations towards oneself?
Does one have ethical obligations towards others, or should one be concerned only for oneself?
To what extent, if any, is it in one’s interest to act morally?
8.8 Political philosophy
This discipline studies the nature of law and government. It tries to identify the conditions under which laws and other political institutions are legitimate. Among the questions it tries to answer are:
What is a law?
What is the difference between a law and, for example, a gunman’s threat?
What is a government? What is the difference between a government and, for example, the Mafia? How are legal rights related to ethical rights?
   Can there be legal systems that are entirely evil, or must something embody at least a minimum of morality to qualify as a legal system?
Under what circumstances, if any, is one ethically entitled to break the law?
   Under what circumstances, if any, does a government have the right to thwart the interests of its subjects?
What is the most just form of government?
Which kinds of freedoms ought a government to protect?
8.9 The philosophy of religion
This discipline studies the nature and existence of God and the conditions under which religious belief is justified. Among the questions it tries to answer are:
If there is a God, why do bad things happen?
   Given that God, being invulnerable, cannot know what it is like to be vulnerable, how can God know everything?
If God knows everything, including what we will do, how can we have free will? If God is responsible for everything, how we can be justly punished for what we do?
Does God have a gender? Does it make sense to say that God is a male as opposed to a female? Is there a God? If so, how is that to be established?
   Is religious knowledge acquired in the same way as non-religious knowledge, or are different cognitive vehicles involved? And, once acquired, is religious knowledge (supposing such a thing to exist) to be justified in the same way as non-religious knowledge, or are different standards involved?
What is the relationship between religion and morality? Can there be valid moral codes in a Godless world?
   Can a genuinely religious person believe that God herself is bound by ethical principles? Or, in holding that God is so bound, is one undermining God’s authority and, therefore, abjuring a religious outlook?
Is acceptance of some kind of religion necessary for a meaningful life?
   If there is an after-life of never-ending bliss, wouldn’t we get bored? Does fulfillment involve adversity? Isn’t struggle what gives life meaning?
   
8.10 Formal logic (a.k.a. mathematical logic, a.k.a. symbolic logic)
(What follows is very compressed and should probably be skipped on a first reading.) This discipline studies formal truth. The concept of “formal truth” is discussed in Chapter 7 and a precise definition of it is given in Chapter 18. But here’s the basic idea.
   S2 formally follows from S1 if the sentence ‹if S1, then S2› is formally true. A sentence is formally true if every sentence of the same form is true. A sentence has the same form as a given sentence if there is some open-sentence of which both sentences are instances. An open sentence is a sentence- like expression that contains a free variable and is thus neither true nor false. Synonyms of “open- sentence” are “statement-form” and “sentence-schema.”105 An open-sentence is formed by taking an actual sentence and replacing one of the expressions in it with a variable. “Two is even” is an actual sentence. If the “two” is replaced with a variable, the result is ‹x is even›, which is an open sentence.
   An instance of a sentence-form is what results when the variables in that sentence-form are replaced with constants. Thus, “two is even” and “five is even” are instances of ‹x is even.› To interpret an open-sentence is to replace the variables in it with constants, and an interpretation of an open-sentence is an assignment of constants to the variables in it. Consider the open-sentence ‹x has property phi.› An interpretation of that open-sentence is simply a proposal to the effect that the variables in it be replaced with constants. Thus, if I propose that the expressions “two” and “even” replace the first and second variables in that open-sentence, I am proposing an interpretation of it. Since the corresponding sentence (“two is even”) is correct, that interpretation validates that open- sentence. In general, an interpretation of an open-sentence validates it if the corresponding sentence is correct.
   Not every interpretation of ‹x has property phi› validates it. For example, the interpretation of it that generates “two is odd” fails to do so.
   If a given open-sentence is validated by every interpretation of it, then each instance of it is formally correct. This coincides with our earlier definition of “formally correct.” If every interpretation of a given open-sentence is correct, that open-sentence is said to be “true under all its interpretations.” It must be kept in mind that this is just a figure of speech, since open-sentences are not, in fact, true.
   Statement-forms fall into three categories: (i) those whose instances are sometimes, but not always, correct (e.g., ‹x is even›); (ii) those whose instances are always false (e.g., ‹x is even but not divisible by two ›): and (iii) those whose instances are always correct (e.g., ‹x is identical with x›. ) An open-sentence falls into (i), (ii), or (iii) depending on whether it is (i*) true under some, but not all, of its interpretations; (ii*) true under none of its interpretations; or (iii*) true under all of its interpretations.
   Formal logic tries to formalize informal analytic truth, so far as that’s possible to do so, and to say when it isn’t possible, so far as it isn’t. An analytic truth is one whose negation is incoherent, and an analytic truth is informal if it has the same form as some false statement. Thus, “triangles have three sides” is analytic, since “triangles don’t have three sides is incoherent,” and it’s informal, since it has the same form as “squares have three sides.” To formalize an informal analytic truth T is to identify an open-sentence S such that every instance of S is true and such that one of S’s instances is equivalent with T.
Consider the sentence:
(1) Bill is self-identical.
(1) is an analytic truth, since its negation is
(2) Bill is not self-identical, which is incoherent.
But (1) isn’t formally correct, since it has the same form as:
   
(3) Bill is green,
which is false, given that Bill is a non-green person. (1) and (3) are both instances of the form sentence-form:
(4) Bill has phi,
Since some of (4)’s instances are false, (1), though analytically true, is not formally so. But (1) is
equivalent with a formal truth, namely:
(5) Bill is identical with Bill.
(5) is an instance of the form:
(6) x is identical with x.
The reason that (5) is formally true is that it’s an instance of (6) and no instances of (6) are false. We just formalized an informal analytic truth and, therefore, did on a very small scale what mathematical logicians do on a very big scale.
   What we believe to be bona fide statements sometimes turn out to be statement-forms; and statement-forms that we believe to have only true instances sometimes turn out to have false ones. 106 Both of these deeply important facts first became apparent when, in the middle of the 19th century, Euclid’s axiomatization of geometry was re-examined. Euclid showed that a great many geometrical truths follow from a small set of assumptions. These assumptions were:
(1) Any two points can be connected by a straight line-segment.
(2) Any line-segment is a part of some line.
(3) Given any point and given any line-segment starting from that point, there is a circle whose radius is the length of that line-segment.
(4) All right-angles are equal to each other.
(5) Given a line L1 and a point P not on L1, there is exactly one line L2 that passes through P and
doesn’t intersect with L1
(5) is known as the “parallel postulate.”
We’ll use the expression “(1)-(5)” to refer to the conjunction of (1) and (2) and (3), etc. Thus, (1)-
(5) is a single open-sentence, and “(1)-(5)” is thus a singular, not a plural, noun. One would think that (1)-(5) is correct. But this turned out not to be so. It turned out that (1)-(5) is a statement-form, not a statement proper, and that (1)-(5) therefore isn’t true or false. It also turned out that some of its instances are false. Let us now describe one such instance.
   Let S be some sphere. Given an arbitrary point on S’s surface, there is a path leading from that point back to that same point that cuts S into two symmetrical halves. If by a “line” we mean such a path, and we make the corresponding changes to the otherwise unchanged meanings of (1)-(4), the propositions thereby assigned to (1)-(4) are true, but the proposition assigned to (5) is false. For, if “space” and “line” are so defined, a line has zero parallels, as opposed to one.
   According to many, this shows that the parallel postulate isn’t true of every possible space. This isn’t what it shows. The parallel postulate isn’t true or false of anything. It’s a statement-form, not a statement, and statement-forms aren’t true or false of anything. The right conclusion to draw is that there are possible spaces that are (partly) described by sentences that are negations of instances of the parallel postulate.
   If “space” and “line” are defined in the conventional, Euclidean way, the sum of the interior angles of a triangle is 180. But if “space” and “line” are defined in the way just proposed, that sum may be anything greater than 180° and less than 360°. The larger the triangle, the greater the sum.
   
   In (1)-(5), the words “line” and ‘space’ are functioning as variables, not as constants. This is an immediate consequence of the just-seen fact that, depending on what specific meanings are assigned to those words, (1)-(5) may come out either true or false. “But a ‘space’ isn’t the surface of a sphere,” one might protest. “And a ‘line’ isn’t a pathway of the sort just described. So all you’ve shown is that by misinterpreting (1)-(5), you can generate some interesting results. But that means that you haven’t really shown anything.” Not true. In saying that “space” and “line” don’t have these non-Euclidean meanings, one is making assumptions as to the nature of space that it is the very purpose of (1)-(5) to establish. In presupposing that ‹x is a space› entails that x isn’t the surface of a sphere, one is in effect presupposing that triangles have interior angles adding up to 180°—one is, indeed, presupposing a great many of the principles that (1)-(5) are supposed to establish. So one cannot, without invalidating one’s attempt to ground geometry in (1)-(5), assume that “line” and “space” are not to be defined in this way.
   In (1)-(5), the words “line” and “space” are functioning as variables, not as constants. We’ve seen that (1)-(5) isn’t true for all values of those variables. That is, some instances of that open-sentence are false. That is, that open-sentence isn’t true under all its interpretations. Formal logicians aspire to identify open-sentences that are true under all their interpretations, since it is only to the extent that they can do this that they can formalize analytic truth, which is their main objective. In the course of this search, they inevitably come across many open-sentences, such as (1)-(5), that they had hoped were true under all their interpretations but turned out not to be. Given an open-sentence S of this kind, they try to say, as precisely as possible, what it is that all those interpretations of S that validate it have in common with one another that they don’t have in common with any interpretation that fails to validate S. In other words, they try to come up with a general characterization of “truth under S.”
   There are some classes of true statements that one would expect to be formalizable but turn out not to be. The class of arithmetical statements (“1 + 2 = 3,” “2 × 9 = 18,” etc.) is an example. In other words, arithmetical truth cannot be formalized.
First of all, arithmetical statements, as they are ordinarily expressed, are not formally true. “2 + 2
= 4” has the same form as “2 + 2 = 5.” They both have the form “x + x = y.” Since “2 + 2 = 5” is false, and has the same form as “2 + 2 = 4,” the latter, though true, isn’t formally so.
   Formalizing arithmetic would involve finding some open-sentence S such that, for some interpretation of S, every true arithmetical statement is a formal consequence of that interpretation and such that no false arithmetical statement is such a consequence.
   It turned out that this is not possible. This means that any formal characterization of arithmetic is either inconsistent (i.e., it entails a contradiction), or incomplete (i.e., there is some arithmetical truth that is not a consequence of it). (The reasons for this are outlined in Chapter 7.) Given a body of truths that might appear to be capable of being formalized, mathematical logicians wish prove whether or not it is so; and, supposing that it can be formalized, they wish to find a model for it.
   
Chapter 2
Properties and Non-Spatiotemporal Existence
1.0 Why we must grant that there are non-spatiotemporal entities
Not everything that exists is in space-time. Everything that is in space-time is an instance of at least one property, and properties are not themselves in space-time. I like to play tennis. I thus have the property of liking to play tennis and am thus an instance of that property. I am obviously in space-time, but that property is not. No matter how thoroughly one searches the universe, one will never encounter the property of liking to play tennis. One will, at most, encounter its instances.
   Many hold that, although property-instances exist, properties per se either don’t exist or exist but only because they’re identical with spatiotemporal entities of some kind (e.g., aggregates of their own instances, ideas in people’s minds). In this chapter, we’ll discuss why this seemingly reasonable viewpoint cannot be sustained. We’ll also see why the negation of this viewpoint is, contrary to initial appearances, utterly consonant with commonsense.
   Properties themselves have properties. The property of being a square circle has the property of being uninstantiated. Properties of properties are higher-order properties. Properties that are not higher-order properties are first-order properties. The instances of higher-properties, being properties themselves, are not in space-time. The instances of first-order properties are in space-time.
   Everything that exists is either a property or is in space-time. Non-spatiotemporal entities that seem not to be properties always turn out to be so. For example, propositions are not spatiotemporal and propositions do not initially seem to be identical with properties. (Propositions are sentence-meanings.) But propositions turn out to be properties. (We’ll see why in Chapter 3.) Sets are not spatiotemporal, and sets do not initially appear to be identical with properties. But they too turn out to be properties. (But, contrary to what many a philosopher has said, properties are not identical with the sets that contain their own instances. The property of being a bird is not identical with the set of all birds. It’s identical with a very different set, as we’ll see at the end of the present chapter.)
   The doctrine that spatiotemporal things are instances of non-spatiotemporal things is known as “Platonism.” This is because Plato was the first person to advocate that doctrine. Sometimes Platonism is known as the theory of universals, and we will sometimes refer to it that way. The doctrine that properties don’t exist, or do exist but only because they are identical with spatiotemporal entities, is sometimes referred to as “nominalism.” But we’ll usually refer to it as “anti-Platonism.”
   Incidentally, nominalism is so called because some anti-Platonists held that universals are identical with word. (“Nomen” being the Latin word for “name” or “word.”) In Section 3.0, we’ll see that this position, in addition to being false, is incoherent, the reason being that words are themselves universals. 
1.1 Why we must grant that there are non-spatiotemporal
      entities (continued)
Given that:

(1) Sally and Fred are both intelligent

it follows that there is something that they have in common; that is, that

(2) there exists some property P such that Fred is an instance of P and Sally is an instance of P.
   
   Instances of intelligence are in space-time. Einstein was in space-time; so was Keynes. But intelligence itself is not in space-time. “But mightn’t the property of intelligence be nothing other than some sort of aggregate of all its instances?,” one might ask. “Mightn’t there be some way of spatio-temporalizing that entity?”
   No. Consider the property of having a perfectly triangular shape. Nothing has this property. Are we to say that it doesn’t exist? Were we to do so, we’d be saying that, since there are no instances of the property of triangularity, that property doesn’t exist. Which is the same as saying there exists a property, viz. that of triangularity, such that, because nothing has it, it doesn’t exist. Which is absurd.
   Also, a consequence of identifying properties with “aggregates” of their instances is that properties that clearly aren’t identical with each other must be seen as being identical with each other. (In this context, the word “aggregate” can refer to any spatiotemporal entity that is composed, in any sense of the word “compose,” of other spatiotemporal entities.) There are no perfectly spherical objects; nor, as we just pointed out, are there any perfectly triangular objects. So, if we identify properties with aggregates of their instances, the aggregate of all the instances of the one property is identical with the aggregate of all the instances of the other, the reason being that each aggregate is a perfect nullity.
   A story will clarify these points. Max is the world’s greatest harpsichord player. He’s also the only redhaired person who ever has, or ever will, set foot in house X. The property red-haired person who sets foot in X is co-extensive with the property world’s greatest harpsichord player. Given that, for this reason, there is no aggregate of things having either property, it follows that no aggregate of things having the one property is different in any respect from any aggregate having the other property. This means that, anything x that is an aggregate of the one kind will be identical with anything y that is an aggregate of the other. Thus, a consequence of identifying properties with aggregates of their instances is that there cannot be distinct, uninstantiated properties. But that’s absurd. The property of being a perfect husband is obviously distinct from the property of being a perfect soldier, even though neither property is instantiated.
1.2 Logic property-based, not set-based
Consider the clearly correct statement that:

(1) squareness is a form of rectangularity.

On the face of it, (1) seems to make a statement about the property of squareness. So, if (1) ‘s appearance is to be trusted, then there exists a property (viz. that of squareness) that has another property (viz. that of being a form of rectangularity).Many philosophers  have tried to show that, despite its appearance, (1) doesn’t really talk about properties per se and that it instead talks about their instances. They’ve proposed that the real meaning of (1) is:

(2) everything that is square is a rectangle.

And they’ve proposed that other statements that, like (1), seem to refer to properties be treated similarly. (So “green is a color,” they say really just means that everything green has a color.)
   But (1) doesn’t mean the same thing as (2). If there were exactly two square things, x and y, and x and y happened to be green, the statement:
(3) everything that is square is green
would be true, but

(4) squareness is a form of greenness

would be false (and so would other statements of its ilk; e.g., “squareness is a color”).
   Of course, the statement

(5) everything that is square is for that very reason a rectangle

is true, whereas

(6) everything that is square is for that very reason green

is false, even if the only two square things happen to be green.
   What (5) says is that:

(7) a thing’s being a square is responsible for its being a rectangle,

which is obviously correct; and (6) says that:

(8) a thing’s being a square is responsible for its being green,

which is obviously false. But (6) collapses into (1). (6) says that, to the extent that everything square is rectangular, it’s because the property of squareness bears a certain relation (that of being a form of) to the relation of rectangularity. The relationship between a thing’s being a square and its being a rectangle is, (6) rightly says, to be understood in terms of a relationship holding between squareness and rectangularity. But the relationship between a thing’s being square and its being green is not to be understood in such terms.
   A thing is a rectangle in virtue of its being a square, but a thing isn’t green not in virtue of its being a square even if it happens to be a square. Whenever one encounters an expression like “in virtue of,” “ipso facto,” “to the extent that,” or “for that very reason,” one knows that one is dealing with a statement that is primarily about properties and only secondarily about objects. If I say that “copper things are ipso facto good conductors of electricity,” I’m saying that the relationship between a given thing’s being made of copper and its being a good conductor of electricity isn’t fortuitous and is grounded in the natures of those two properties. In other words, to understand why an instance of the first property is an instance of the second, one looks to the natures of those properties. The connection goes from property instance (instance of being made of copper) to property (property of being made of copper) to property (property of being a good conductor of electricity) to property-instance (instance of being a good conductor of electricity). And the reason why “copper things are ipso facto in JMK’s living room” is false is that, even though (so we will suppose for argument’s sake) every copper object happens to be in my living room, the connection between x’s being made of copper and x’s being in my living room isn’t routed in that way through those properties.
   All principles connections are relationships between properties. This means that nomic connections (e.g., the connection between a thing’s being made of copper and its being a good conductor of electricity) and also all logical connections (e.g., the connections between a thing’s having knowledge and its having a mind) are expressed by statements whose subjects are properties. The correct statement that:
(9) For any x, the statement x has knowledge entails x has a mind
is another way of saying that
(10) something that has knowledge for that very reason has a mind of some kind.
And (10) is another way of saying that:

(10) the property of having knowledge is a form of the property of having a mind.

In conclusion, unless it’s conceded that properties exist, there is no way to account for the fact that there are principled relationships of any kind. And in fact those who deny that properties exist tend not to grant that there exist any such relationships. Those who deny the existence of properties tend to be empiricists. Since empiricists cannot grant the existence of things, such as properties, that cannot be seen or otherwise known (more or less) directly on the basis of observation, they end up denying that anything has any bearing on anything. (See Chapter 18.)
1.3 Logic property-based, not set-based (continued)
Let S1 be the set containing the smallest number greater than zero that is divisible by two, and let S2 be Fred’s favorite number, which happens to be the number two. S1 and S2 are the same set, and the statement:

(1) x is a member of S1

is therefore identical with the statement

(2) x is a member of the set that contains the number two and doesn’t contain anything else;

and both statements are identical with

(3) x is a member of S2.

Thus, anything entailed by any one of those statements is entailed by each of the others, and anything that entails any one of those statements entails each of the others. Thus, (1) entails:

(4) x is less than twenty,

and so do (2) and (3). And

(5) x is a whole number greater than one but less than three

entails (1), and it also entails each of (2) and (3).
   But the statement:

(6) x has the property of being Fred’s favorite number

entails

(7) x has the property that Fred is aware of its existence,

but (1) doesn’t entail this, and neither do (2) or (3). And

(8) x has the property that it is a number that is preferred by Fred to every other number that Fred has considered

entails (6), but it doesn’t entail (1) or (2) or (3). It follows that properties cannot be identified with sets of their instances without mutilating the most basic principles of logic.
   “But surely that’s wrong,” one will say. “(1) is the statement that x is a member of the set that contains the smallest number divisible by two (and nothing else),” and (2) is the statement that x is a member of the

set containing Fred’s favorite number (and nothing else). So I don’t see how (1) and (2) could entail, and be entailed by, the same things; nor do I see how (1) and (6) could entail, or be entailed by, different things.”
   If the expression “the set containing Fred’s favorite number” is taken in this way—in other words, if it’s taken in such a way that (1) and (6) are equivalent, whereas (1) and (2) are not—then the word “set” is going proxy for the word “property.” If by “the set containing Fred’s favorite number” you mean, not “the set containing the number two,” but instead “any set, whatever its membership, that comprises Fred’s favorite number,” then what you mean by “the set containing Fred’s favorite number” is: “any set that is generated by the property of being Fred’s favorite number.” But in that case, when you make statements about “sets,” you’re really talking about properties.
1.4 The axiom of extensionality
It may be obvious at this point that properties aren’t identical with sets of their instances. But this now obvious point is easily extended to reveal the futility of attempts to show that properties, if existent, are spatiotemporal. But in order to make the needed extensions, we must take a very quick detour through a bit of set theory.
   Two very different properties can be co-extensive. Two properties are co-extensive if any instance of the one is an instance of the other. But different sets cannot have the same members. This is known as the axiom of extensionality. Since different properties can generate the same set, properties aren’t identical with sets of their instances. We’ll revisit this point later in this chapter. So if S1 is a set and S2 is a set, then S1 is identical with S2 if and only if nothing is a member of the one that isn’t also a member of the other. A set whose members are x, y, and z can’t fail to have those members any more than it can fail to be itself—indeed, for it to fail to have those members would be for it to be fail to be itself. Thus, sets are individuated by their memberships. This principle is sometimes known as the axiom of extensionality.
   A corollary of this axiom is that a set’s membership is frozen—frozen, indeed, in two senses. First, it’s temporally frozen. Sets don’t gain members and they don’t lose them. Second, it’s modally frozen. If a set’s actual members are x1...xn, it couldn’t possibly exist without having exactly those members.
   This may at first seem patently false. “Surely the set of people changes from year to year; people are born; people die.” This is the wrong view. The right view is that some one property—that of being a person—generates different sets at different times. So really there is no such thing as the set of people. There is the set of people at 3:00 P.M. April 28, 2009, the set of people at 3:01 P.M. April 28, 2009, etc.
   And if S is the set of people—in other words, if it’s the set that contains you, me, Barack Obama, etc.—S couldn’t possibly exist in a universe in which one of us three didn’t exist. Of course, there could be people in a world where one of us didn’t exist. And, in that world, the property of being a person would generate a set. But that set wouldn’t be S. It would be some other set.
   “But isn’t the axiom of extensionality just a matter of convention? Couldn’t we stipulate that sets could lose and gain members?” If we used the word “set” in this way, it would become a proxy for the word “property.” To say that the “set” of humans changes every time someone is born or dies is to say that, at any given time, this set’s membership is determined by what it is that, at that time, has the property of being human. So, while there’s nothing wrong with using the word “set” in this way, it isn’t an option for somebody who wishes to replace properties with sets.
   Having taken care of these technical preliminaries, let us move on to matters of substance. If some piece of copper happens, at a given time, to be conducting electricity, it’s because of what is going on right then and there. The fact that there exists some other piece of copper in some remote galaxy is irrelevant. But if S is the set of all pieces of copper, the existence of that other piece of copper is relevant to S’s existence. Sets are individuated by their memberships. (The set consisting of Smith, Larry, and Sally ceases to exist if Smith does.) So if, for some reason, the universe hadn’t begotten that other piece of copper, then S wouldn’t exist. But what difference would that make to the fact that this piece of copper is conducting electricity? None.
   Any given thing belongs to many different sets. What those sets are is only as good an indicator of how that thing is as it is an indicator of what properties that thing has. If S is the set of people who actually exist,

then S doesn’t exist in a world W that where Dick Cheney doesn’t exist but is otherwise exactly like our world. But what difference does that make to my life-path in W? None. So far as you can learn anything about me from the fact that I belong to the set of humans, it’s because, in learning this, you are learning that I have the property of being human.
   Everything just said about sets can be said of any entity that is constituted by property-instances. Suppose, for argument’s sake, that there is a “scattered object” consisting of all and only those human beings in existence. (This is a popular view among philosophers.) Just replace each occurrence of “set” in the argument just given with “scattered object consisting of all and only human beings,” and the resulting argument shows that the property of being a person isn’t identical with that set. (Also, we’ll see in the next section that, setting aside properties that have only one instance, there are no spatiotemporal entities that can be identified with a given property’s instances. There are no “scattered objects.”)
2.0 Arguments against Platonism
It is seldom denied that there are instances of properties, but it has often been denied that there are nonspatiotemporal entities. But it’s hard to see (i) how there could be instances of properties without there being properties themselves, and it is also hard to see (ii) how properties could be given spatiotemporal coordinates.
   Opponents of Platonism respond either by saying that (i) involves some sort of logical or linguistic trickery or by saying that properties can be identified with spatiotemporal entities. Let us now consider how anti-Platonists defend their view.
2.1. Argument #1 against Platonism
   Not every word in a sentence corresponds to some entity in the world. If I say “for the sake of all that is good, make sure you give at least some money to charity” the word “sake” doesn’t denote anything—there aren’t such things as sakes, after all—even though, being a noun, the word “sake” has the same syntactic function as words that do have denotations.
   We can develop this point by taking a brief tour through linguistic theory. It seems fairly clear that not all expressions refer to things. Consider words like “of,” “and,” “the,” “nonetheless.” It’s hard to believe that these words are comparable to “Smith,” “Jones,” and “cow.” The medievals referred to expressions like “Smith” and “Jones” as “categorematic” expressions, and to expressions like “of” and “the” as “syncategorematic” expressions. A syncategorematic expression is one that doesn’t refer to anything and whose linguistic function is strictly syntactical. Contemporary linguists make a similar distinction: they distinguish between “lexical” and “non-lexical” items: the former include “Smith,” “Jones,” “red,” and “cow”; the latter include “the,” “of,” and “nonetheless.” A lexical item is one that has a referent; a non-lexical item is one that does not, and whose purpose is strictly syntactic. (In other words, the purpose of a non-lexical tems is simply to facilitate the unification of lexical items to form larger lexical items.)
   Even though there are many expressions that appear to denote properties, they are really syncategorematicor non-lexical expressions. Words like “red” or “the property of redness” don’t refer to anything. This is not to say that they are not meaningful. “Of” is meaningful, even though it doesn’t denote anything, and the same is true of “the property of redness.”

This argument evaluated: Expressions like “red” and “the property of redness” have very different logical properties from expressions that are known to be syncategorematic. If I know that:

(1) x is red

is true, then I can logically infer

(2) There exists some color or other that x has.

This inference involves affirming the existence of the thing meant by the term “red.” Many inferences have this structure. Given:

(3) Fred is smart but Larry is not,

I can infer that

(4) there exists some property that Fred has that Larry lacks.
   
   Words like “of” don’t behave in a comparable manner. Consider:


(4) There is a picture of Paul on the mantelpiece; nonetheless, I don’t think that the owner of the mantelpiece likes Paul, since the picture is an extremely unflattering one.

I can make many inferences from (4), but not a single one involves affirming the existence of something meant by “of” or “nonetheless.”
   So it is not easy to make a case that words like “smart” and “red”—words that denote properties—lack referents and are really to be thought of on the model of purely syntactic terms like “of.”
   There is another problem with Argument #1.Words are themselves universals. The word “red” isn’t identical with this or that ink mark or burst of noise. Given any inscription or burst of noise—given any spatiotemporal entity—that word can exist even if that spatiotemporal entity is destroyed. When you erase an inscription of the word “red,” you don’t erase the word itself. Inscriptions of words, and spoken utterances of them, are instances of words, not words per se. Words themselves are properties of such physical entities. We’ll pick this up later.
2.2 Argument #2
Although properties exist, they are identical with spatiotemporal entities. The property of being a rock is identical with the set of rocks. And the set of rocks is a spatiotemporal entity. That set, after all, is simply a very spread out object that consists of rocks.

This argument evaluated: (The first two paragraphs of this section repeat many of the points made in Sections 1.0–1.5.) This answer is no good. Sets are abstract objects. They don’t have space-time coordinates. The set of rocks is not some big rock and it isn’t some big object consisting of rocks separated by stretches of empty space. If all the rocks in the world move to some new place, and none are destroyed, the set of rocks hasn’t changed at all: it is the same as it was before. But, under those circumstances, any object consisting of all the rocks in the world has changed: it has acquired a new location (or, in any case, it has undergone an internal structural change).
   A set is a mathematical entity; it has no location and is defined entirely by its formal properties. Where its members are, and what they are doing, is irrelevant (so long as its members don’t cease to exist). But any object that is actually composed of all the rocks in the world is affected by the movements of their members, and thus cannot be identified with sets. (Of course, it is unclear whether there is such an object—an issue we’ll revisit shortly—but what is clear is that if there is, then it is affected by movements of the kind just described.) Thus, sets aren’t spatiotemporal entities. Consequently, they are themselves Platonic entities. So one is conceding the truth of Platonism, not undermining it, by identifying properties with sets.
   Aware that, for the reasons just given, sets cannot be identified with sets, philosophers of an anti-Platonist bent have sometimes chosen to identify properties with what are referred to by contemporary philosophers as scattered objects.
   
What is a scattered object? Ordinary objects are geographically and dynamically cohesive. Consider your back-pack. If you move one of the straps ten feet across the room, you have moved the whole bag across the room (unless, of course, you’ve damaged the bag in some way). And even though (at the microscopic level) the bag consists mostly of empty space, all of its parts occupy one, fairly compact, relatively continuous region of space-time.
   Now consider all the rocks in the universe. Those rocks clearly don’t constitute a dynamically or geographically integrated unit. Supposing that those rocks collectively constitute any object at all, the object they constitute is a “scattered object.” In general, a scattered object is one that lacks the cohesiveness and dynamic integrity of ordinary objects. According to some anti-Platonists, properties are scattered objects. Is this correct?
   No. There are no scattered objects. The very concept of such a thing is an incoherent one. In Chapter 16, we’ll see why. Here’s an outline of what we said. If spatially disjoint entities are to constitute a single spatiotemporal object, their interactions must be characterized by a certain regularity and predictability. Since it cannot be known without doing empirical research whether the various rocks in the world have this property, it cannot be said whether there is some “scattered object” consisting of all the rocks in existence.
   But even if scattered objects do exist, properties aren’t identical with them. Let R be some scattered object composed of all the rocks in the universe. If you destroy half of the rocks in the world, you have changed the just-mentioned scattered object. But you haven’t changed the conditions that a thing must satisfy to be a rock. (To be a rock, a thing must still have a certain microstructure, or whatnot.) Therefore, you haven’t changed what it is to be a rock or, consequently, the property of being a rock. So, by Leibniz’s Law, that scattered object, if it even exists, cannot be identified with the property of being a rock. Given any other property, the same points mutatis mutandis show it not to be a scattered object.
2.3 Argument #3: The third-man argument
According to Platonism, any given spatiotemporal entity is an instance of at least one property, and for two spatiotemporal entities to resemble each other in some respect is for there to be some property of which each is an instance. Presumably, properties must resemble their instances. For example, the property of being triangular must itself be triangular. Bearing this in mind, let T be the property of being triangular, and let x be an arbitrary triangle. If Platonism is correct, it follows that there is some property T1 such that T and x are both instances of T1 and such that it is in virtue of their both being instances of T1 that they are triangular. Given that, according to Platonism, properties resemble their instances, it follows that T1 must resemble each of T and x. In other words, T1 must be a triangle. It follows that, if Platonism is correct, there must be some property T2 such that each of T1 and T and x is an instance of T2 and such that it is in virtue of their being instances of T2 that they are triangular. And so on ad infinitum. Were they to exist, properties would be useless, since the very questions that arise in connection with their instances arise in connection with them.

This argument evaluated: Consider the property of being spatiotemporal. If Platonism is right, that property is not itself spatiotemporal and, in the relevant sense of “resemble,” it doesn’t resemble its instances. Here is another example. To be triangular is to have a certain shape. Only things that are in space have shapes. The property of triangularity is not in space and, therefore, doesn’t have a shape and, therefore, isn’t an instance of itself. TMA succeeds in showing that instantiation isn’t resemblance. This means that it succeeds in proving nothing, given that it’s inherent in Platonism that instantiation not be resemblance.
2.4 Argument #4: the argument from the causal impotence of properties
Properties lack causal powers. For this reason, they can serve no explanatory function. To explain something is to show how it came about. Being causally impotent, properties can’t make anything come about. Therefore, there is no reason to posit them.

This argument evaluated: Properties do indeed lack causal powers. Causes are necessarily in space and time. To be a cause is to induce change. Changes and their causes are ipso facto in space-time.
   But this is no reason to think that properties are explanatory deadwood or, therefore, that there’s no good reason to believe them to exist. Not all explanation is causal explanation. Some explanation is what we call analytic or conceptual. There are as many even numbers as there are whole numbers. (This is a theorem of set-theory.) How is this to be explained? Even though the even numbers are a subset of the whole numbers, it is possible to put the two sets of numbers into a one-one correspondence. Since, whenever two sets can be put into such a correspondence they have the same number of members, it follows that the set of even numbers has as many members as the set of whole numbers.
   This explanation is not causal. It explains a truth not by identifying its causal antecedents, but by delineating the structures of concepts. Many explanations are like this. You ask me: “Why can’t someone know something without having any form of awareness?” I answer (correctly) by saying: “because knowing something involves having a true belief, and a belief is a form of awareness.” This explanation identifies conditions that are conceptually, not causally, necessary conditions for knowledge. Like this explanation, Plato’s theory isn’t a causal theory, and it’s therefore irrelevant that properties aren’t in space-time.
2.5 Argument #5 (a variant of #4): the argument from the causal theory of knowledge (CTK)
For x to know of y, y must have causal effects on x. You can see the dog only because the dog has certain effects on you—light bounces off its fur and hits your eyes. You can know about Socrates only because, long ago, Socrates made various noises, which were transcribed, and copies of those transcripts made their way to. So it is only because there is a causal process linking Socrates to you that you know about him and are able to have thoughts about him.
   Properties don’t have effects on anything. They don’t initiate or otherwise participate in causal processes. So we can’t know about them, even if they exist. So there is no good reason to suppose that they exist.

This argument evaluated: Seeing a dog does indeed involve the dog having effects on you—it involves your eyes being disturbed by photons bouncing off of the dog. But, in and of themselves, those photonic disturbances are lifeless and informationally empty. If they were to hit a rock, vision wouldn’t result. The photons responsible for those disturbances don’t contain little dog images. You have to read such information into them. Your mind must extract such images from them; and to do this, your mind must have some way of interpreting those disturbances. The knowledge needed to interpret these disturbances cannot come from sense-perception, since that knowledge is itself a prerequisite for sense-perception. This entails that, in at least some cases, it isn’t through a causal process that the knower becomes aware of the known. It also entails that a prerequisite for the very existence of sense-perceptions, or indeed of any mental activity that results from causal exchanges with the world, is knowledge of properties. Why does it entail this? Because, were it not for a grasp of what it is for a thing to have the property of having this or that shape, or being this or that distance from one, or having this or that color, one couldn’t interpret the radiation-induced disturbances of one’s sensory receptors in the way needed to generate sense-perceptions.
2.6. Argument #6: Conceptualism
If they exist, properties are identical with mental representations of some kind or other—presumably, with thoughts about rocks or, in any case, with categories created by the mind that help it upload and process sensory information.

This argument evaluated: Since conceptualism is thoroughly evaluated in Chapter 13, I’ll be brief. There were rocks before there people. And, back then, rocks were similar to one another in ways that they weren’t similar to bats and stars and other non-rocks For two things to be similar to one another in a certain respect is for there to be some property that they both have. So for two rocks to resemble each other in some respect is for there to exist some property that they both have. Thus, before there were human minds, there were properties. Therefore, properties are not products of human artifice.
2.7 Argument #7: Resemblance nominalism (RN)
Let x be some red thing. x’s being red consists, not in its being related in some way or other to some non-spatiotemporal entity but in its resembling roses, spots of blood, stop-signs, and other such things. Being red is a relation, not between the spatiotemporal and the non-spatiotemporal but between the spatiotemporal and the spatiotemporal. In general, to have a property phi isn’t to bear some relation to some other spatiotemporal entity.

This argument evaluated: For two otherwise dissimilar square-shaped objects to resemble each other in respect of shape is for there to exist some shape, and therefore some property, that they both have. For two otherwise dissimilar red objects to resemble each other in respect to shape is for there to exist some color, and therefore some property, that they both have. There is no such thing as mere resemblance; there is only resemblance in this or that respect. For two things to resemble each other in a given respect is for there to exist a property that they share, and resemblance nominalism therefore collapses.
2.8 Argument #8: Conventionalism
The only non-empirical truths are linguistic conventions (e.g., “there are three feet in a yard”). Therefore, all non-conventional truths are empirical. Empirical truths register spatiotemporal facts. Conventions, whether linguistic or not, are obviously spatiotemporal entities. Therefore, all truths are spatiotemporal.

This argument evaluated: Since conventionalism is evaluated in Chapters 1, 13, and 18, we can be brief. Not all non-empirical truths are conventions. It’s a non-empirical truth that there are continuous functions that cannot be differentiated at any point. But it’s not a convention. Given the symbolic conventions that govern our usage of the relevant words (“continuous”, “function,” “differentiated”, etc.), it follows that the sentence “there are continuous functions that cannot be differentiated at any point” expresses a truth. But this means that it holds in virtue of convention plus some various non-conventional facts. Those facts are not empirical; they don’t concern the spatiotemporal world. Therefore, the fact described by that sentence is not spatiotemporal. Further, since that fact concerns logical structures of properties (e.g., the property of being differentiable), it follows that there are properties. Since, as we just noted, that fact is non-spatiotemporal, it follows that properties are non-spatiotemporal.
3.0 Nominalism
Many medieval philosophers, and some 20th century philosophers, held that properties are identical with words and, therefore, that properties are not spatiotemporal.
   But this position is incoherent, since words and linguistic expressions generally are themselves universals or properties. How many words are right below this sentence?

 “snow”
“snow”
“snow”

Is it one or three? The answer: there are three instances of one word. To put it another way, there are three s tokens of one word-type. Instances of an expression are called expression-tokens and the expressions themselves are called expression-types.
   No one utterance of the word “snow” is identical with that word. It’s not as though the word-type “snow” will disappear when the inscriptions of it in the line above this one is destroyed. That word-type is a property of certain deposits of ink (e.g., the ones above) and burst of noise, and those ink-deposits and bursts of noise are therefore instances of that property. This shows that, even if the nominalist is right to replace identify the property of being a rock with the word “rock,” he has still conceded the truth of Platonism.
   Plus, that property isn’t identical with that word. The Spanish word for rock is “piedra.” It would be arbitrary to identify that property with the word “rock” but not with the word “piedra.” Since “rock” and “piedra” are obviously different words, the nominalist must say that the property of being a rock is not identical with itself, which is absurd.
   All of these points aside, it makes no sense to identify that property, or any other, with a word. A thing’s being a rock has nothing to do with words; there were rocks before there were words.
4.0 Properties demystified
David Armstrong (1989) says that properties are “ways that things can be.” To be round is to be one way; to be square is another. Armstrong’s conception of what properties are is a fruitful one; and if it is kept in mind that properties are just ways that things can be, the resistances that we have to accepting their existence crumble.
   Nobody denies that there are ways things can be. To say that there are ways things can be is to say that there are possibilities as to how things can be. Not all of those possibilities are actualized. Not everything that could be the case is the case. Now, actualized possibilities are in space-time. But unactualized possibilities— possibilities that never “came true”—are surely not in space-time. So where are they?
   One could say that they don’t exist. But that would be absurd. It’s one thing to say that a possibility wasn’t (or won’t be) actualized; it’s a very different thing to say that the possibility itself doesn’t exist. It’s possible that you will you go to law school. But (let us suppose) you’re not going to go to law school (because you’re going to pharmacy school instead). Does the fact that you won’t go to law school mean that it isn’t an option? Surely not. Your situation is very different from that of somebody (e.g., somebody on death-row) for whom it simply isn’t an option. So the fact that a path isn’t taken doesn’t mean that the path doesn’t exist; and the fact that a possibility isn’t actualized doesn’t mean that the possibility itself doesn’t exist. So, given that possibilities, even unactualized ones, do exist, we must again ask: where are they? They’re not in space-time. The possibility of your going to law school is not in space-time. So that possibility, being outside of space-time and thus being without location, is nowhere.
   At first this may seem alarming, but it ceases to be so if we choose to see possibilities as properties and actualizations of possibilities as property-instances. It thus seems that the presumptive existence of unactualized possibilities provides support for the theory of universals.
   A story may help clarify the nature of properties. You are a meat inspector. You’ve just inspected all the meat in slaughterhouse X. None of it passes inspection. All of it was completely rotten. There is obviously a way something would have to be to be a piece of meat that passed inspection; and there is obviously a way something would have to be to be a piece of meat in slaughterhouse X that passed inspection. So when reporting to your supervisor, you say “none of the pieces of meat in X deserved to pass inspection,” you’re saying: “none of those pieces of meat was the right way.” Which is the same as saying: “there exists a way that something would have to be in order to be a piece of meat in X that deserved to pass inspection; but nothing is that way.” Which is the same as saying: “the property of being a piece of meat in X that deserved to pass inspection is uninstantiated.”
   
Thus, the property of being a piece of meat in X that deserves to pass inspection isn’t a giant piece of meat in the sky. It’s simply a way something would have to be in order to be a piece of meat in X that passed inspection.
   The same is true of the property of being a pink elephant. There are no instances of that property, since there are no pink elephants. But there is a way that something would have to be to be a pink elephant. I know what that way is, and so do you. That’s why we both know that, by going to the zoo and spray-painting one of the elephants there, we could make something be that way; and that’s why we also know that nothing is that way (or, in any case, that nothing we’ve ever heard of is that way—maybe some prankster spray painted an elephant). For something to “instantiate the property of being a pink elephant” is simply for it  to be that way. So that property isn’t some pink elephant in the sky. It’s just a way something would have to be to be a pink elephant. And for there to be no instances of that property is simply for nothing to be that way.
   Properties can be thought of as conditions. The property of being a pink elephant is a condition a thing must fulfill in order to be a pink elephant. Lots of unfulfilled conditions exist. Mary won’t marry someone unless he fulfills the following condition: he’s a genius who is always friendly and never sleeps and always dotes on her and has a billion dollars. That condition isn’t fulfilled by anyone. But the condition exists. Thus, properties that aren’t instantiated are just unfulfilled conditions.
   So given that there are unfulfilled conditions, it follows that there are uninstantiated properties. And given that properties exist, even when they have no instances, it follows that, when they do exist, they aren’t identical with their instances. The property of being a pink elephant exists, but is currently uninstantiated. If there were to come into being a single pink elephant, which promptly died, the property wouldn’t go out of existence. It would still be around. But if it were identical with instances, then it would go out of existence the moment its one instance did.
5.0 Relations and higher-order properties
We pointed out earlier that properties have properties. The property of being a bird has the property that there are more instances of it than the property of being a penguin. Actually, any statement can be interpreted as a statement about higher-order properties. “Smith has a dog” is equivalent to “the property of having a dog has the property of instantiated by Smith.”
   Higher-order properties are indispensable to scientific and ordinary discourse. If you say “true integrity is rare,” you’re saying that the property of having true integrity has the property of being seldom instantiated. If you say that ambition is more important to success than ability, you’re saying that the property of being ambitious has the property of comparing favorably with the property of having ability in respect to whether, in virtue of having it, its instances are likely to succeed.
   Gottlob Frege (1844–1925) discovered that statements about numbers are statements about higher-order properties. “There are zero penguins in the house” means: the property of being a penguin in the house has the property of being uninstantiated. “There are two penguins in the house” says that the property of being a pair of penguins in the house is instantiated. The number two may be defined as what all pairs of objects have in common. For x to be a pair of objects is for it to be a set S such that there are objects O1 and O2, distinct from each other, that belong to S and such that anything O2 that belongs to it is identical to either O1 or O2. The number two is the property of being such a pair. See Chapter 7.
   Relations may be identified with properties of ordered pairs. There is some property P such that x is taller than y exactly if the ordered pair <x, y> has P. This conception of what relations are may seem contrived, but it’s an extremely useful one, since, without it, the logical forms of many inferences couldn’t be identified.
6.0 Sets and propositions identical with properties
We’ve seen that properties are not identical with sets of their instances. The main reason for this, we saw, is properties tend to be modally elastic, whereas sets are modally frozen. In other words, a given property (e.g., the property of being a poet) can generate different instances in different worlds, whereas the set of poets is frozen. If Smith is a member of the set of poets in this world, and S is the set of poets in this world, then S doesn’t exist in any world where Smith does not (or where Smith does exist but isn’t a poet).
   But sets still may be identified with properties. Suppose that Smith, Jones, and Brown are the only three poets in existence. Let S be the set of actual poets—that is, the set containing Smith, Jones, Brown, and nothing else. In that case, the statement:
(1) x is a member of S
is equivalent with
(2) x is identical with Smith or Jones or Brown
and, therefore, with
(3) x has the property of being identical with Smith or Jones or Brown.
   Thus, S may be identified with the property of being identical with Smith or Jones or Brown; and membership in S may be identified with possession of that property.
   Sets are non-spatiotemporal entities. Given that sets are really properties, it follows that, given only that sets are non-spatiotemporal, it doesn’t follow that anything non-spatiotemporal isn’t a property.
   Propositions are non-spatiotemporal entities. But they two are properties. The proposition JM is playing tennis at time t is true just in case certain properties are instantiated at certain times, and we may therefore identify that proposition with the set containing the relevant properties and identify that proposition’s being true with the fact of all of that set’s members’ being instantiated. We’ll work out the details in the next chapter. Since sets can, in the way just described, be identified with properties, it follows that propositions are properties.
   Properties aren’t mind-independent and neither (therefore) are propositions. But, of course, it’s a popular belief, mainly among empiricists, that propositions, if existent, are human creations. Here is a reason, distinct from the one just given, to think otherwise.
   There are infinitely many propositions. (Since there are infinitely many locations, there are, for any given particle x, infinitely propositions of the form x is in place y at time t.)We couldn’t therefore have directly created every proposition there is. So, supposing that propositions are human creations, we must be only indirectly responsible for infinity many of them, and it must therefore be supposed that we created some finite stock of propositions that somehow brought about the rest. But in that case there are true propositions, which we’ll refer to as “intermediary” propositions, that describe how the ones we directly created brought about the others. But since there are infinitely many propositions that we didn’t create, there are infinitely many intermediary propositions: one for each proposition not directly created. (Suppose for argument’s sake that we didn’t directly create the proposition that dinosaurs wore tweed, and also suppose that p1...pn are the propositions that we directly created. In that case, there is a true intermediary proposition to the effect that p1...pn brought about the propositions that dinosaurs wear tweed, another intermediary proposition another to the effect that p1...pn brought about the proposition that either dinosaurs wore tweed or 1 + 1 = 2, and another to the effect that p1...pn brought about the proposition that it’s possible that it’s the case that either dinosaurs wore tweed or 1 + 1 = 2, and so on.) We didn’t create each of these individually many intermediary propositions. (Supposing that we didn’t directly create the propositions that dinosaurs wore tweed; we also didn’t directly create any proposition having it as a proper part—e.g., the proposition that either dinosaurs wore tweed or 1 + 1 = 2.) We must therefore posit a second group of intermediary propositions that will mediate between the first group and the propositions that we directly created. But everything just said about the first group of intermediary propositions will hold of the second, and we’ll be no further along. Thus, it cannot coherently be supposed that we directly create every proposition in existence. This might appear to leave open the possibility that some propositions, but not others, are human artifacts. But such a view would be arbitrary and implausible, like the view that some whole numbers are human creations while others are not. It would also be demonstrably false. We’ve
seen that we don’t directly or indirectly create the propositions describing how those that we do directly create, supposing that there are any, give rise to those we don’t. Those that we don’t directly create demonstrably entail those that we do. Suppose that we didn’t create the proposition that dinosaurs wore tweed but that we did create the proposition that snow is white. In that case, we didn’t create the proposition that dinosaurs wore tweed and snow is white. That proposition entails that snow is white, and thus requires its existence. Therefore the proposition that snow is white doesn’t need us to create it, since its existence follows from one that we didn’t create. Therefore, we couldn’t have created the proposition that snow is white, since one can’t create what already exists.



Chapter 3
What Are Propositions and What Is Truth?
1.0 Propositions as sets of properties, truth as instantiatedness of said properties
By a “proposition,” I mean what is meant by an utterance of a sentence. If I point at Smith and say “that man is a scoundrel,” the meaning of my utterance is is a proposition.
   In this chapter, we’ll provide answers to the questions “what are propositions?” and “what is it for propositions to be true?” Here’s what we’ll see. Propositions are sets of properties; and a proposition is true just in case the properties that are members of it are instantiated—so what it is for a proposition to be true is for the members of the set with which it is identical to be jointly instantiated. Roughly, truth is instantiatedness. Less roughly, truth is identical with the property of being a set (of a certain kind) all of whose members are instantiated. Aside from a few brief remarks, I will leave it open whether all sets of properties qualify as propositions (hence the parenthetical hedge in the last sentence). But a case will be made that only sets of properties are propositions.
2.0 The Argument
Consider the proposition:

1. Tommy is smoking.
   
   Intuitively, this proposition seems to consist of at least three components: first, Tommy (or, in any case, something “individuative” of Tommy: perhaps a property that he uniquely instantiates or a concept under which he and he alone falls); second, the property of smoking; and, third, some kind of “synthesis” of the two—some complex constituent that involves Tommy’s smoking. (We will try to state precisely what this synthesis involves.)
   If 1 is true, then:

A. the property of being identical with Tommy

is instantiated, and so is

B. the property of smoking.

But, of course, those two properties could be instantiated in a world where Tommy is not smoking—in a world where, for example, Larry is smoking and a non-smoking Tommy is playing golf. We thus need a third property—a property such that, if a set S contains that property along with A and B, then 1 will be true just in case all of S’s members are instantiated. That third property is not hard to identify. It is:

C. The property of being identical with something that is smoking and is identical with Tommy.

Before moving on, let’s look at the apparatus that we’ve been developing. Once again, let S be a set that contains all and only A, B, and C; and remember that we have identified S with 1 (the proposition that Tommy is smoking).
   First of all, if C is instantiated, so are B and A. Further, if C, and therefore B and A, are instantiated, then, and only then, is 1 true. It follows that 1 is true if and only if each of A, B, and C is instantiated. This is consistent with, and even corroborates, the thesis that 1 is S and that 1’s being true is S’s members being jointly instantiated.
   Of course, that does not by itself show that 1 can be identified with S or that 1’s being true can be identified with S’s members being jointly instantiated. After all, there are infinitely many distinct sets of properties such that 1 is true just in case their members are instantiated. For example, let Z be the set containing the following properties and nothing besides: the property of being identical with a smoking Tommy; the property of being an even number; the property of being three sided if a triangle. The second two properties are instantiated in every possible world, given that even numbers necessarily exist and given that triangles cannot fail to have three sides. But surely Z cannot be identified with 1, the reason being that Z’s membership cannot, at least not in a sufficiently natural manner, be aligned with what we know about 1’s constituency.
   But S’s membership does so align, as a brief look back makes clear. S’s members are (or at least include) A, B, and C. 1’s constituents are (or at least include):

(i) something individuative of Tommy,

(ii) the property of smoking, and

(iii) something that combines those two things.

Obviously A is individuative of Tommy. (Only Tommy can have that property; and, what is more, he must have it.) So far, so good. (ii) and B are identical. So far, still so good.
   What about C? That property is instantiated exactly if A and B are both instantiated. So, in a very clear sense of the term “combine,” that property combines the property of smoking with (something individuative of) Tommy. (In the relevant sense of the term “combine,” one property “combines” n other properties exactly if the first is instantiated exactly if the other n properties are jointly instantiated.) And we know that, in some way or other, 1 combines (something individuative of) Tommy with the property of smoking. In at least one respect, then, C’s relationship to A and B is suggestively similar to 1’s relationship to its parts. Moreover, C “dominates” each of A and B in a way suggestively similar to the way in which 1 dominates its constituents. A’s being instantiated is necessary but not sufficient for C’s being instantiated, the same being true of B’s being instantiated. Tommy’s existing is necessary but not sufficient for 1’s being true, the same being true of somebody’s being a smoker.
   While none of this demonstrates definitively that 1 is identical with S or that 1’s being true is identical with S’s being instantiated, we have, I believe, found enough of a match between 1/1’s being true and S/S’s members’ being instantiated to warrant looking into the idea that they might be one and the same.
2.1 The unity of the proposition
How does 1 combine Tommy with the property of smoking? According to Frege, Tommy (or some concept thereof) saturates that property (or some concept thereof). (Henceforth, I’ll omit the qualification “or some concept thereof.”) But this doesn’t help at all. For, as Davidson (1967) observed, the term “saturate” is just another label for the operation in question. So while the Fregean statement:
   (FR) “1 is the result of Tommy’s saturating the concept of smoking”
may well be correct, we don’t know what it means.
   
We are in a position to give the meaning of FR and to say what this mysterious “saturating” amounts to. We’ve argued that 1 is a set whose members include the property of being Tommy, the property of smoking, and the property of being a smoking Tommy. 1 is the result of Tommy’s “saturating” the property/concept of smoking in the sense that 1 is identical with a set S that consists of those three properties.
   For any proposition X, to say that X is the result of Y’s “saturating” Z (for some Y and Z) is to say that X is a set whose members are the property of being identical with X, and Z itself, and also the property of being identical with something that is identical with X and also has Z.
2.2 More on the decomposition of propositions
It is indisputable that 1 is true just in case C is instantiated. So why not just identify 1 with C, and 1’s being true with C’s being instantiated? Why go through the rigmarole that we went through? Why bother with A and B and, in general, any other properties other than C? Because if we identify 1 with C, and 1’s being true with C’s being instantiated, our theory won’t accommodate the very reasonable presumption that 1 has discrete parts corresponding to Tommy and to the property of smoking.
   Consider an instance of the property of being a smoking Tommy. Obviously that instance will involve Tommy smoking. But it will not, at least in any obvious way, contain a discrete part corresponding to Tommy or a discrete part corresponding to smoking. And what is true of an instance of that property is, quite possibly, true of the property itself. It cannot be taken for granted that C has a discrete part corresponding to Tommy or to smoking or to anything else. In fact, being a non-spatiotemporal entity, C won’t have discrete parts in any straightforward sense at all.
   The impression that C is part-less, or at least lacking in the right kind of parts, is reinforced when we look at what an instance of C is like. Such an instance is, to adapt Kenneth Taylor’s (1998) apt expression, a dent or ripple in the quantum; it is a shift in the movement of mass-energy. Of course, that mass-energy is (by hypothesis) sufficient for the existence of Tommy and of smoking and, indeed, of a smoking Tommy. But you would have a devil of a time isolating some part of that distribution that corresponded to Tommy, then distinguishing that from some other part corresponding to smoking, and then finding a third that fused those two, otherwise discrete, entities into a discrete instance of a smoking Tommy.
   By contrast, the proposition:

1. Tommy is smoking

is, of its very nature, neatly parsed into Tommy, the property of smoking, and a third constituent that synthesizes the two just mentioned. The neat articulations found in 1 are found, in some form, in S. Those articulations, though found in S’s membership as a whole, are not found in C taken by itself, making S, but not C, a suitable mirror for the decompositional structure of 1.
   States of affairs (or “facts,” as they are sometimes called) do not, as Ian Hacking (1975) long ago put it, have the same kinds of “articulations” as propositions. The quantum-ripples on which the truth of a proposition supervenes don’t have anything like the structure of that proposition. Whereas the proposition Tommy is smoking clearly has a unique, and relatively simple decomposition into Tommy (or some property/concept individuative thereof), the property of smoking, etc., the state of affairs in which Tommy’s smoking consists—the confluence of psychological, physiological, and, ultimately, sub-atomic disturbances—obviously doesn’t uniquely decompose into Tommy, the property of smoking. In fact, it seems a stretch to suppose that it even has one such decomposition.

2.2.1 A corollary
Consider the proposition:

2. Tommy is snoring.

Let D be the property of being a snoring Tommy. It is obvious that:

1. Tommy is smoking

and

2. Tommy is snoring

have much in common. They have in common the constituent Tommy (or, in any case, something corresponding thereto). They have in common the property of being a Tommy who is doing something (in other words, they have in common the property of being identical with a thing x such that x is identical with Tommy and such that, for some y, x is doing y); and they also have in common the property of being a thing that is doing something (in other words, they have in common the property of being a thing x such that, for some y, x is doing y).
   In light of this, consider some instance of D. In other words, consider the kind of property-instance, the kind of mass-energy distribution, on which the truth of 2 supervenes. That instance will, of course, suffice for the existence of Tommy, as will an instance of C. But will those instances, in virtue of that fact, have some discrete part in common? Unlikely. In neither case do we have Tommy simpliciter. We have Tommy smoking (while sweating profusely and worrying about his algebra test and his nascent nicotine addition, all the while talking with his cousin Albert); in the other we have Tommy snoring (while having terrible dreams about his future as a second string pitcher on a mediocre team). There is no such thing, in either case, as Tommy simpliciter. There is only Tommy doing this or that, having this or that property. A corollary is that two situations that comprise Tommy do not, in virtue of that fact, have in common some discrete, isolable entity. So while it is true that C and D both comprise Tommy, the one does not, in comprising him, have a discrete constituent in common with the other.
   But now we must consider what we’ve said about the composition of 1 and also what follows, by obvious extensions of what we’ve said about 1, about 2. 1 is a set S whose members are:

a:	the property of being Tommy
b:	the property of smoking
c:	the property of being a smoking Tommy

And, by similar reasoning, 2 is a set S* whose members are:

a:	the property of being Tommy
b*:	the property of snoring
c:	the property of being a snoring Tommy

S and S* do have well-defined, discrete parts in common. Indeed, they have in common precisely what is had in common by:

1. Tommy is smoking

and

2. Tommy is snoring.
   
   If we were to be really precise about it, we’d say that each of S and S* comprised, not only a–c, but also

d.	the property of being a Tommy that does something (i.e., the property being a Tommy that does something or, in any case, has some property),

and also

e.	the property of being a something that does something (i.e., the property being a something that does something or, in any case, has some property).

   Let’s look at 1 for a second. It immediately and formally implies:

i	Tommy smokes;
ii	something smokes;
iii	Tommy does something;
iv	Tommy exists;
v	something does something.

And 2 immediately implies:

i*	Tommy snores;
ii*	something snores;
iii	Tommy does something;
iv	Tommy exists;
v	something does something.

Now let’s look at S and at S*. The members of S are:

I	The property of being Tommy
II	The property of smoking
III	The property of being a Tommy that smokes
IV	The property of being a Tommy that does something
V	The property of being a something that does something

The members of S* are:

I	The property of being Tommy
II*	The property of snoring
III*	The property of being a Tommy that snores
IV	The property of being a Tommy that does something
V	The property of being a something that does something
   
   Having identified 1 with S and 2 with S*, everything we know about those propositions—about what they entail, about what their components are, and about how their higher-level components are “forged” out of their lower level components—is accounted for.

2.3 Another desideratum satisfied by our analysis
Many semanticists today hold that Plato and Socrates are veritable constituents of the propositions that concern them. So according to Kaplan (1989),who is following and agreeing with Russell (1903), Timmy—the person, not some Fregean concept thereof—is a constituent of both 1 and 2. Other adherents of this view are Scott Soames (2003), Nathan Salmon (2005), and Robert Moore (1995). (Opponents are J. Searle (1983), M. Dummett (1973), and—with some very heavy reservations to be stated later—the present author.)
   There is a rather serious problem with this view. Consider, not 1 or 2, but rather:
3. Plato snores.
At this point in time, Plato doesn’t exist. So if he’s a (necessary) constituent of 3—if, in other words, 3 exists only if Plato does—then 3 doesn’t exist. Salmon and Soames, both of them hard-line direct reference theorists, deal with this by taking a desperate measure, viz. by saying that 3 exists and that its existence constitutively depends on Plato’s existence and that these two positions can be reconciled with each other—that, more specifically, they can be reconciled by saying that 3 exists, albeit as a non-existent proposition.
   This is not necessary or plausible or helpful. 3 exists. Plato does not. But the property of being identical with Plato, whatever it is, does exist. What is it to be Plato? To be Plato is, perhaps, to be a causal sequence that is initiated by the fertilizing of a certain egg by a certain spermatozoa. To be Plato is, perhaps, to have a soul or mind of a certain kind. What we know is that, if something is Plato, its being Plato supervenes on something probably having to do with the mass-energy distribution in the cosmos—on its mode of origination, on the quotient of spiritual energy in the particle-interactions that constitute it, on who knows what. In any case, even though Plato does not exist, the property of being identical with Plato does. That’s why I can meaningfully, not to mention correctly, say “I am not Plato” or, equivalently, “I don’t have the property of being identical with Plato.” And it’s also why we can meaningfully, and presumably correctly, say that Plato does not exist. For, in making such a statement, we aren’t picking out a non-object—which would, having been picked out, ipso facto cease to be a non-object—and then saying of it that it doesn’t exist. We are saying of an existing property, viz. that of being identical with Plato, that it is uninstantiated.
   But our analysis is still consistent with the heart of direct-reference-theory, this being the idea that, for some x such that x is identical with Plato, the proposition meant by “Plato snores” is true just in case x snores, it being completely irrelevant what properties (other than being a snorer) x has. (The Fregean indirectreferentialist holds that for “Plato snores” to be correct is necessary that, for example, a unique great philosopher to die of hemlock-poisoning snore.) It is clear why our analysis is consistent on this matter with the viewpoint of the direct referentialist. According to our analysis, 3 is true exactly if the following properties are instantiated:
a.	the property of being identical with Plato
b.	the property of snoring
c.	the property of being a Plato who snores
d.	the property of being something that snores
e.	the property of being something that does something (or has some property)
It is readily seen that, on our analysis, there is some x, such that x is Plato and such that 3 is true exactly if x snores, it being irrelevant what other properties x has. This is exactly what the direct-referentialist holds. At the same time, our analysis guarantees the existence of the proposition that Plato snores—after all, the property of being Plato exists, even though it is now uninstantiated. So our analysis of that Plato snores gives the direct-reference-theorist the truth conditions that she wants and that (given certain compelling arguments due to Kripke 1980 and Soames 2003, 2004) she probably deserves. At the same time, our analysis doesn’t put the direct-reference-theorist in the awkward, logic-bending position of having to say that the proposition that Plato snores exists despite the failure of existence of entities on whose existence its own existence is constitutively dependent.

3.0 Molecular propositions
(Because this section and the three that follow it are more technical than substantive, I suggest skipping straight to Section 4.0 on a first and probably a second reading.) Our analysis applies to molecular propositions no less than to atomic propositions. But making this transposition go through will involve a certain amount of sensitivity to details and technicalities. A certain amount of “engineering,” as opposed to philosophy “proper,” will be needed.
3.1 Existence-claims
In keeping with tradition, I will treat generalizations as molecular propositions. So:

4. something snores

is an existential generalization. Given what we’ve said, the most obvious analysis of 4 would be to say that 4 is the property of snoring (or a set whose sole member is that property) and that 4’s being true is identical with that property’s being instantiated.
   That would not be the correct analysis. Even though 4 is true just in case the property of snoring is instantiated, 4 is not identical with that property and its truth is not identical with that property’s being instantiated. We know from Frege that 4, unlike the property of snoring, has a rather distinctive decompositional structure, and that 4 thus consists of (at least) three or four constituents. (Note: In this context, by an “instantiated function,” I mean a proposition-form at least one of whose members is correct. Thus x snores is such a function. An “instance” of a function is anything satisfying it. So, supposing that he snores, Smith is an instance of the just-mentioned function. A “propositional form” may be thought of as a class of propositions all of the same form.)We also know from Frege what the first two constituents are:

a.	the property of snoring
b.	the property of being instantiated
   
   In light of what we’ve already said, it is not hard to generate some (if not all) of the remaining constituents of 4, these being:

c.	the property of being an instantiated function each of whose instances snores
d.	the property of an instantiated function each of whose instances has some property or other
     
   Let S be a set containing all and only a–d. 4 will be true iff a–d are instantiated. So, from the viewpoint of truth-conditions, there is no barrier to identifying 4 with S or to identifying 4’s being true with S’s members being instantiated. Further, 4’s structure is easily mapped onto S’s. 4, if true, entails that there exists some property that has some instances; that there exists at least one snorer; that at least one property is instantiated; and that at least one property exists. And all of this is precisely what S’s members’ being instantiated involves.
   Now consider the proposition:

5. Something smokes.

By reasoning similar to that just given, the constituents of this proposition are:

a.*	the property of smoking
b.	the property of being instantiated
c.*	the property of a function each of whose instances smokes
d.	the property of a function each of whose instances has some property or other
   
We know pre-theoretically that 4 and 5 have certain constituents in common (e.g., the property of being instantiated or, in any case, some property expressed by “something”). Our analysis of 4 and 5 validate everything we know, theoretically and pre-theoretically, about the decompositions and logical forms of the propositions.
3.2 Negative non-quantified propositions
Before considering “nothing snores,” I want to consider a negative, but non-quantified, proposition:
6. Timmy is not smoking,
in other words,
6. It is not the case that Timmy is smoking.
   (The reason for the underlining will be clear in a moment.) The two immediate constituents of 6 would appear to be “It is not the case” and “that Timmy is smoking.” But there’s a problem here. We have said that propositions are sets of properties that are true when instantiated. In any case, this is what we have said about atomic propositions and, for uniformity’s sake, this is what we must say about molecular propositions. But if we say that, in 6, the underlined proposition is instantiated—that is, that all its members are instantiated— then that Timmy is smoking will be true and 6 will be false and indeed self-negating.
   Not-P is true just in case P is false. So “not” can be thought of as expressing a function that assigns truth to all and only false propositions or (what, in this context, is scarcely different) as a property of all and only false propositions.
   For the reason given a moment ago, we don’t want to say that that Timmy is smoking is a constituent of 6, and will instead say that the property of being identical with that proposition is such a property. We will also say that the property of being a false proposition is such a constituent. Then we synthesize those two components into the property of being the false proposition that Tommy is smoking. That property, it will be noticed, is instantiated exactly if the proposition that Tommy is smoking is false. So, according to our analysis, the constituents of 6 are:

a.	the property of being a false proposition
b.	the property of being identical with the proposition that Tommy is smoking
c.	the property of being identical with a proposition that is false and that is identical with that Tommy is smoking.

Let S be the set containing all and only a–c. Let us consider what happens when each of S’s members is instantiated. First, suppose that c is instantiated. In that case, there is an instance of a proposition that is false and that is identical with the proposition that Tommy is smoking. So 6 is true just in case c is instantiated. Since, if c is instantiated if the other members of S are instantiated, it follows that 6 is instantiated if and only if each of the members of S is instantiated. Thus, there are, as of yet, no bars to identifying 6 with S and 6’s truth with S’s members’ being instantiated.
   Next, suppose that b is instantiated. In that case, the property Tommy is smoking exists—but it isn’t necessarily true. And if 6 should be true—which, according to our analysis, would mean that all of a–c were instantiated—we’d be stuck with the existence, but not the truth of the proposition that Tommy is smoking. Which is precisely what we want.
   Finally, suppose that a is instantiated. In that case, the property of being a false proposition is instantiated. And, of course, if 6 is true—if, in other words, the members of S are all instantiated—then that property is instantiated. Which, again, is precisely what we want.
   
Thus, our analysis is consistent with most of our pretheoretic intuitions about the decomposition of 6. (The one exception that being that, where our pre-theoretic intuition wants to that Tommy is smoking in 6, our analysis puts the property of being identical with that proposition in its place.) And our analysis is also inconsistent with the logical properties of 6.
3.3 Quantified propositions revisited
Consider:

7. Everything snores.

By reasoning similar to that already given, the main constituents of this are:

a.	the property of snoring
b.	the property of being universally instantiated
c.	the property of being identical with a universally instantiated property that is identical with the property of snoring
   
   Of course, c is a property each of whose instances is an instance both of (a) the property of snoring and (b) of the property of being universally instantiated.
   Let us now consider:

8. Nothing snores
   
   I will treat this is as the negation of 5. I will treat it, in other words, as:

8: It is not the case that something snores.

For reasons now already clear, the constituents of 8 include (but are not confined to):

a.	the property of being a false proposition
b.	the property of being identical with the proposition that something snores
c.	the property of being identical with a false proposition that is identical with the proposition that something snores

Notice that, if c is instantiated, so are b and a. And notice that, if c is instantiated, then the proposition that something snores is false. Finally, notice that c is related to a and b in the usual way—any instance of 6 is an instance both of (a) the property of being a false proposition and (b) the property of being identical with that Tommy smokes.
3.4 Non-quantified molecular propositions
Let’s finish up by considering two non-quantified molecular propositions. Consider the sentence:

9. Tommy is smoking or Tommy is snoring

9 can be seen as saying of a certain pair of propositions (namely, that Tommy is smoking and that Tommy is snoring) that at least one of its members is true. I thus see 9 as consisting of:

a.	the property of disjunction

which in this context we may regard as the property of being a pair of propositions at least one of which is true, and
b.	the property of being identical with a pair of propositions, such that one member of that pair is that Tommy is smoking, the other member being that Tommy is snoring.
   Of course, 9 could be false even if both a and b were instantiated. (This would be the case in any world where both Tommy is smoking and Tommy is snoring were false, but where some disjunction or other was true.) So, for now familiar reasons, we must look for a third constituent, where that constituent must be a property c such that each instance of c is (i) an instance of a pair of propositions at least one of which is true and is also (ii) an instance of a pair of propositions, one them being that Tommy is smoking, the other being that Tommy is snoring. So our final properties are:
a.	the property of being a pair of propositions, at least one of which is true
b.	the property of being a pair of propositions, one of them being that Tommy is smoking, the other being that Tommy is snoring
c.	the property of being a pair of propositions, at least one of which is true, and at least one of which is that Tommy is smoking and at least one of which is that Tommy is snoring

Of course, if c is instantiated, then so are b and c. And if c is instantiated, then either Tommy is snoring or Tommy is smoking. So c, and therefore a–c, are instantiated exactly if 9 is true. So if S is the set containing a–c, then 9 is true iff all of S’s members are instantiated.
   We’ve thus made it clear (i) what it is for something to be a “constituent” of a proposition, (ii) what it is for an argument to “saturate” a function, (iii) more generally what it is for two propositional constituents to “synthesize” into a third constituent, (iv) what it is to be a proposition, and (v) what it is for a proposition to be true. And our analysis is to a non-trivial degree (though not completely) consistent with what pretheoretic intuition and common sense have to tell us about propositions.
4.0 The Russell-Kaplan-Salmon analysis of propositions
According to Russell (1903), Salmon (1986), Kaplan (1989), R. Moore (1995), J. Perry (1996), J. King (1996, 1997), to name but a few, a proposition is some kind of “structure” consisting of “objects and properties.” So, according to this view, the proposition expressed by (tokens of) “Socrates is bald” is some kind of structure consisting of Socrates—the man himself, not some property that he has or some concept that he satisfies—and the property of baldness. It is usually said that the structure in question is an ordered pair. At least part of the reason for is that different propositions seem capable of having the same parts (cf. Brutus killed Caesar and Caesar killed Brutus). And unless the sets with which propositions are identified have some kind of ordinal structure, distinct propositions (e.g., the two mentioned in the last parenthesis) will collapse into one another. Thus Socrates is bald is identified, not with (Socrates, baldness), but instead with <Socrates, baldness> or with the <relation of having <Socrates, baldness>>, or some such.
4.1 Problems with this view
The ordered pair <2,7> isn’t true or false. Neither is the ordered pair <2,7 <less than>>. Given that these ordered pairs aren’t true or false, why is <Socrates, the relation of having <baldness>>rue or false? There’s no denying that we could use the corresponding expression (viz. “<Socrates, the relation of having <baldness>>”) to express the proposition expressed by the sentence “Socrates is bald.” We could obviously invent a code whereby “<the relation of having <Socrates, baldness>>” meant Socrates is bald. But this fact tells us little, if anything, about the structure of the corresponding proposition that we didn’t already know from the fact that it can be expressed by “Socrates is bald.”

4.1.2 Another concern
Obviously the brackets are meant to be symbolic of some kind of order that holds among Socrates and baldness (and the relation of having). But what is that ordinal relation? If that ordinal relation bears no resemblance to the relation that would actually be had by Socrates, in a situation where he was bald, with respect to the property of baldness, then it wouldn’t be clear why what relation was the right one: some kind of reason—the likes of which have never been provided by advocates of this model—would have to be provided why that particular ordinal relation was the right one. So, thus construed, the analysis in question is highly programmatic. On the other hand, if that relation is the very relation that would be had by Socrates, with respect to the property of baldness, in a situation where he was bald, then Socrates’ baldness—his actual baldness—would be built into the very existence of the proposition that he was bald. In other words, the proposition that Socrates is bald would, by virtue of its own configuration, make him bald, and would thus predetermine its own truth. But obviously the truth of Socrates is bald isn’t self-determining. Basically, if a theory requires propositions to model facts too well, then that theory wrongly requires contingent propositions to be true; but a theory runs the risk of arbitrariness if the relations that, according to it, hold among a proposition’s parts are not in any intuitive way counterbalanced by the facts that, if that proposition were true, hold among the components of the corresponding fact. If we turn the proposition Socrates is bald into a model consisting of Socrates standing in the relation of having with respect to baldness, then the proposition itself is the fact of Socrates’ being bald, and no way is left open for the obvious possibility that it might be false. At the same time, it would be easy to render overly tenuous and schematic the relationship between, on the one hand, the fact of Socrates’ being bald and, on the other hand, the relationship that, in the proposition that Socrates is bald, Socrates bears with respect to baldness. This mistake is, I believe committed by the theory according to which that proposition is identical with ordered pair <the relation of having <Socrates, baldness>>. The relation borne that, in that structure, Socrates bears with respect to baldness is, it seems to me, too schematic—too without any counterpart in the fact that, supposing that proposition true, makes it so.
4.1.3 Another problem
Though it is now false, the proposition Socrates is alive obviously exists. What if, unbeknownst to you, your friend Joey died some time during the last five minutes? Surely you wouldn’t want to say that the proposition Joey loves to read suddenly ceased to exist. Apart from an acceptance of a certain version of direct-reference theory, there is no reason to accept that view.
   Some authors (e.g., Salmon (2005)), do say that Joey loves to read does cease to exist when Joey dies (or that it continues to exist, but only in some curious form—that it exists, but only as a non-existent entity, or some such). The reasoning underlying this extraordinary view seems to be as follows. There is some x—namely, Joey—such that “Joey loves to read” is true exactly if x loves to read. It follows, it is said, that the proposition meant by that sentence—namely, Joey loves to read—must have Joey as a constituent. And from this, it is said, it follows that Joey loves to read ceases to exist when Joey does.
   This reasoning is spurious. If only for argument’s sake, let us suppose that, for some x, such that x is Joey, “Joey loves to read” is true iff x loves to read. It doesn’t follow that Joey loves to read ceases to exist when Joey does. For, if anything like the view I am advocating is right, it could be that it is not Joey per se, but the property of being identical with him, that is a constituent of that proposition. Our view is consistent with the idea that “Joey” rigidly designates Joey—that there is some x such that x is Joey such that “Joey loves to read” is true just in case x loves to read, it being irrelevant what properties are had by other things. But, according to our view, it isn’t Joey per se, but some property that is a constituent of Joey loves to read. That property, which is the property of being identical with Joey, is one that nothing other than Joey could possibly instantiate. (It isn’t like the concept bifocal inventor, which could be instantiated by something other than the thing which is its actual instance.) According to our analysis, the proposition that Joey loves to read is true only if that property is instantiated. Thus, there is indeed some x, namely Joey, such that each of Joey loves to read and “Joey loves to read” is true iff x loves to read. But Joey’s existence is a pre-requisite for the truth, not the existence,

of that proposition. So, unless one maintains (implausibly) that the property of being identical with Joey can exist only if it is instantiated, it follows that Joey loves to read doesn’t cease to exist when Joey does.
   Like the present author, Frege held that it wasn’t Socrates per se that was a part of the proposition Socrates is alive but was instead some concept that Socrates uniquely satisfied. (Frege’s analysis is therefore consistent with the fact that “Joey likes to read” holds onto its meaning even if Joey ceases to exist.) But, apart from that, Frege’s view is quite as vague as Russell’s. Frege was extremely opaque about the nature of the structure of this proposition; and what he failed to provide in the way of clear formulations he tried, unsuccessfully, to make up for with unhelpful terms such as “saturate.”
   What is good about the Russell-Frege-Kaplan-King view is that it insists that propositions resemble the sentences that express them. So that view is, at least, consistent with the fact that languages can be learned and used. (For, presumably, learning and using languages involves there being systematic ways of hooking up meanings to sentences.) And, as we’ll now see, other analyses don’t do such a good job of satisfying this requirement.
5.0 Propositions as sets of their own consequences
For a while, it was widely held (by e.g., Clarence Lewis (1946) and Rudolph Carnap (1934)) that the “intension” of a sentence (which, in this context, we may identify with what we would now call the “meaning” of that sentence or the “proposition” expressed by it) was identical with the class of all propositions that could be inferred from that sentence. So (a natural extension of this view would be that) the proposition John knows that corn is yummy is the class of all propositions deducible from that proposition—for example, John believes that corn is yummy, John knows something, John has some kind of attitude towards the proposition that corn is yummy. There are a few problems with this analysis, some minor, some major. A minor problem is that, as it was stated by Lewis and Carnap, analysis is viciously circular, since many propositions can be deduced from John knows that corn is yummy that involve that very proposition—for example, either John knows that corn is yummy or there are square circles. This particular problem is not, I believe, insuperable, since the position can be amended to avoid it. The right emendation would seem to be: a proposition is identical with the class of all propositions—setting aside that proposition itself, and any propositions having it as a component (e.g., disjunctions of which it is a disjunct)—that can be inferred from it.
5.1 Why this view is false
Even so, the position in question isn’t very plausible. Consider the class of all propositions that follow from John knows that corn is yummy. That class doesn’t have a structure corresponding even remotely to the structure that we would expect that proposition to have, given that it almost certainly has a structure non-trivially similar to that of the sentences that express it. Also, in order to figure out whether a given proposition is a consequence of John knows that corn is yummy, one must grasp that proposition itself. Here’s why: The set of propositions that follow from John knows that corn is yummy is infinitely large. One can grasp that set only in the sense that one grasps some rule that generates its members—after all, one obviously cannot grasp them all one by one. And grasping that rule would seem to involve grasping John knows that corn is yummy or some other similar proposition.
6.0 The possible worlds approach
We now turn to what is nowadays probably the most popular analysis of propositions and, indeed, of modality: the possible worlds analysis. According to possible worlds semantics (PWS), a proposition is necessary (possible) if true in all (some) worlds, and a proposition is a function that assigns truths–values to worlds or, alternatively, is a set of worlds (viz. the set of worlds where it is true). So the proposition 

grass is green is a function that assigns truth to all the world where grass is green, falsity to worlds where grass is not green, and either assigns falsity to grass-free worlds or assigns them no truth-value at all.
   In this context, the first question to ask is: what is meant by the term “world”? Oftentimes, advocates of PWS say that “worlds,” as they are using the term, are propositions (or sets of propositions). In that case, as David Lewis (1986) was quick to point out, the PWS slogan that “a proposition is a set of worlds” becomes “a proposition is a set of propositions,” which is not only false but viciously regressive, the same thing mutatis mutandis holding of the statement “a proposition is a function that assigns truth-values to worlds.”
   Aware that treating worlds as propositions (or sets thereof) eviscerates PWS, some advocates of that doctrine say that worlds are just that—worlds: concrete objects like our own, “maximal states of affairs.” Not, it must be emphasized, properties that, if instantiated, would be worlds. But veritable worlds.
6.1 Problems with this approach
Not too many are going to grant the existence of bona fide alternative worlds. Second, even if they do exist, we can’t know anything about them except what we can figure out on the basis of modal knowledge obtained independently of our knowledge of those worlds.
   Lewis (1986) says, correctly, that we don’t know about alternative worlds by taking a tour of them. We know about them by considering materials that are available to us here and “employing a principle of recombination”—by, basically, applying modal principles that we already know to hold and then seeing if those principles square with the proposition whose modal status we wish to know (e.g,. there might be square circles in other worlds). But in that case, the worlds answer to us, not us to them. Our modal knowledge is the tail that wags the dog, the dog being these other worlds; and from the viewpoint of explaining (or validating) our modal knowledge, those extra worlds are useless (though there may be other good reasons for positing them).
6.2 Other problems
The class of worlds where 1 + 1 = 2 is identical with the class of worlds triangles have three sides. But those propositions are obviously distinct, that being why you can think the one without thinking the other. (There’s no intensional fallacy here, since propositions are intensions.) In its most primitive form, PWS can’t distinguish analytically equivalent propositions. Some advocates of PWS deal with this by saying the following:
There are two ways of thinking of what functions are. A function can be thought of as a set of ordered pairs. So, from that viewpoint, the function F(x) = x + 1 just is the set of pairs: <1, 2>, <2, 3>....And from that viewpoint, F(x) = x + 1 is identical with the function F(x) = x + (90 – 89). This is the extensional view of functions: functions just are the pairs they generate—how they generate them is irrelevant. But the extensionalist view of functions isn’t the only one, since there’s also the intensionalist view. The intensionalist says that functions are individuated by how they generate the pairs they generate. So, for the intensionalist, for functions to be identical, it is necessary but not sufficient that they generate the same ordered pairs. To avoid falsely identifying distinct, analytically equivalent propositions, PWS must take an intensionalist view of functions. So propositions are functions, and those functions are individuated by their intensions, not their extensions.
There are two problems here. First, this view still demands that there be other worlds. If those worlds are propositions, then we’re no further along. If those worlds are concrete, then we’re stuck with some useless metaphysical lumber. But leaving those problems aside, the solution just proposed collapses on itself. Propositions are intensions (though not all intensions are propositions—e.g., the propositional function x is a human being is not a proposition, even though it is an intension). This by itself is a problem for PWS since much of its raison d’être is that it replaces intensions, which for various reasons are seen as inimical to scientific thought, with extensions, which are seen as methodologically unimpeachable. So in taking an intensionalist view of

functions, PWS is undermining itself. For, in taking such a view, PWS is letting properties back in—properties are no longer to be identified with sets of their instances. But, by parity of reasoning, propositions needn’t be identified with sets of their instances (i.e., with sets of worlds where they hold). So PWS cannot, without arbitrariness, take an intensionalist view of functions; but it cannot, without failing to distinguish between obviously distinct propositions, take an extensionalist view of them either.
6.2.1 A similar problem
Consider the proposition grass is green. As we know, PWS identifies that proposition with a function (that assigns truth to worlds where grass is green) or with a set of worlds (containing all and only those worlds where grass is green). If it isn’t thought of as a set of ordered pairs, that function must be thought of as a rule of some kind. What kind of rule? One that assigns truth to certain worlds on the basis of their satisfying some condition. What condition is that? The condition that, in those worlds, grass is green. So the function in question, understood intensionally, must be understood in terms of the very proposition in question. So unless the advocate of PWS wants to falsely identify 1 + 1 = 2 with triangles have three sides, he must take an intensionalist view of functions, which means that he must circularly understand the functions with which he aspires to identify propositions with the very propositions with which he aspires to identify them.
7.0 Conclusion
Frege (1918) made it clear that propositions are the contents of psychological entities and are not themselves psychological entities. Since Frege, many attempts have been made to say what propositions are. Those attempts have either been programmatic to the point of near-emptiness or demonstrably false or both.
   But it is possible to identify structures that model the properties that we know, on both theoretical and commonsensical grounds, propositions to have. Given any proposition P, it is clear that there is some set of properties p1...pn that will be instantiated just in case P is true. Supposing that S is the set containing those properties, this suggests that S is P and that P’s being true is S’s members’ being instantiated.
   We found that, taking this approach, we could give non-metaphorical meanings to terms that, though liberally used, have thus far been used in a purely metaphorical way—terms like “constituent” and “synthesize.” A “constituent” of a proposition, we found reason to believe, is a member of the set (or, more accurately, of some set, since there are many of the kind in question) of properties whose joint-instantiatedness is necessary and sufficient for that proposition’s truth. As for the term “synthesize”: since all components of propositions are properties, only properties can, in any relevant sense, be synthesized. And two properties p1 and p2 are “synthesized” into another component when a third property, p3, is identified each of whose instances is ipso facto an instance of both p1 and p2. (Or, to put it in a way that doesn’t have any misleading chronological or psychological overtones: p3 is a synthesis of p1 and p2 just in case any instance of p3 is ipso facto an instance of each of p1 and p2.)


PART II
Language and Thought


Chapter 4
What Is a Language?
1.0 The meaning of “meaning”
There would be no languages if there were no expressions (words, phrases, sentences, etc.). Nothing meaningless is an expression. For this reason, the concept of an expression must be understood in terms of the concept of meaning, the same therefore being true of the concept of language.
   But it isn’t much use to be told that words and sentences “have meanings,” since the word “meaning” has three different meanings, and only one of these directly relates to the nature of language.
Meaning #1: The evidential meaning of “meaning”
In some cases, to say that x “means” y is to say that x is evidence of y—that x and y are causally interrelated in such a way that, given x, it can reasonably be inferred that y. “Smith’s hacking cough means that he has a violent lung infection” means “Smith’s hacking cough is evidence that he has a violent lung infection.” And the latter means that coughs like Smith’s are causally connected to violent lung infections in such a way that it may reasonably be inferred that Smith has a violent lung infection.
   Smith’s violent lung infection is a cause of Smith’s hacking cough. But for x to be evidence to of y, it is neither necessary nor sufficient that y cause x. Why isn’t it necessary? First of all, causes can be evidence of their own effects. (Bill’s current drunkenness is evidence of a poor performance on his upcoming economics exam.) Second, if some event or state of affairs z is a cause of both x and y, then x can be evidence of y without being a cause or an effect of y. (Suppose that Bill is slurring his words. This is evidence that he’ll do poorly on the upcoming test. But his slurring his words is neither a cause, nor an effect, of his substandard test-performance. His drunkenness is a cause of (a) his slurred speech and (b) his imminent, substandard test-performance. And it’s because his slurred speech has a causal ancestor in common with his poor test-performance that the former is evidence of the latter.)Why isn’t it sufficient? Given only that the cause of Bill’s failing was that he was drunk, we can’t infer from the fact that he failed that he was drunk. There are many reasons why a person may fail a test. Supposing that y caused x to occur, x is evidence of y only if it can’t reasonably be supposed that anything other than y was the cause. (Only a violent lung infection could be responsible for Smith’s hacking cough, that being why the latter is evidence of the former.)
Meaning #2: The psychological meaning of “meaning”
When we use sentences, we mean things by them. Meaning in this sense is a psychological notion. You tell me that Sally is the most wonderful, decent person you’ve ever known. I respond by saying “things aren’t always as they seem.” What I mean is that Sally is devious. In other words, my intention in making this statement is to say that Sally is devious. Given that intentions are psychological entities, meaning in this sense is obviously a psychological notion.
Meaning #3: The linguistic meaning of “meaning”
The sentence “snow is white” says something about something; it attributes the property of being white to snow. Therefore, it means that snow is white. This kind of meaning is in a class by itself; it isn’t identical with either of the two kinds mentioned so far; and there isn’t any obvious way to understand it in terms of them. Let us now say why.
   
Meaning in the psychological sense involves, but does not coincide with, meaning in the linguistic sense. Once again suppose that, in response to your telling me that Sally is a wonderful person, I say “things aren’t always as they seem.” My meaning—what I’m trying to get across—is that Sally is devious. But in my attempt to get this across, I’m taking advantage of the fact that “things aren’t always as they seem” has an existing (linguistic) meaning. My meaning that Sally is devious is parasitic on my utterance’s meaning that things aren’t always as they seem. Meaning in the psychological sense is therefore parasitic on meaning in the linguistic sense.
1.2 Why Meaning #3 ≠ Meaning #2
Some philosophers and linguists have held that for:
(1) “snow is white”
to mean that snow is white is for it to be the case that, in uttering “snow is white,” what people mean is that snow is white. This view, duly generalized, is that for a sentence S to have meaning M is for it to be the case that, in uttering S, people to mean M.
   This position is false. There are many sentences that have determinate meanings even though they’ve never been uttered before and, therefore, no one as of yet has ever meant anything by them. The sentence:
(2) “the cube root of three is Sir Lawrence Olivier’s favorite irrational number between one and four”
has a determinate meaning, even though that sentence never probably has been uttered. Thus, meaning in the linguistic sense is not in all cases identical with meaning in the psychological sense.
   But a stronger point is warranted. Let’s say that P1 and P2 are the propositions meant by (1) and (2), respectively. In saying that (1) means P1 and that (2) means P2, we are not using the word “means” equivocally. Both occurrences of “means” in the last sentence denote the same relationship. Thus, the relationship that (1) bears to its meaning is the same as the relationship that (2) bears to its meaning. Given that, as we saw, (2)’s having P2 for its meaning isn’t identical with P2’s being what people mean in uttering (2), it follows that (1)’s having P1 for its meaning isn’t identical with P1’s being what people mean in uttering (1). Of course, what we just said about (1) and (2) can be said of any other sentence. So even if what people mean in uttering a given sentence happens to coincide with its literal meaning, what it is for sentence S to have proposition P for its literal meaning isn’t for people to mean P in uttering S.
   Psychological meaning presupposes linguistic meaning. What a person means when uttering a given sentence is a function of, among other things, his beliefs as to what that sentence already means. You must believe that “snow is white” means snow is white if, intending to speak sincerely and literally, you say “snow is white” with the intention of getting it across that snow is white. If you think that “snow is white” means grass is green, you cannot, if your intention is to speak sincerely and literally, believe that “snow is white” means snow is white.
   Of course, you could know full well what “snow is white” in fact means, but use that sentence to get across something that has nothing to do with the color of snow. Knowing what “snow is white” actually means, you might utter that sentence with the intention of getting it across that the government is controlling our thoughts with alpha waves. And, depending on the circumstances, that could be precisely what an utterance of that sentence would convey.
   But whatever the message is that, in uttering a certain sentence, you wish to convey, you must believe that message to have some kind of relationship to the one meant by that sentence itself. Furthermore, if you are to succeed in saying what it is you wish to say, what you believe to be meant by the sentence you are using must be right. If, intending to speak sincerely and literally, you say “snow is white,” thinking that it means bananas are yellow, you will fail to say what you wanted to say.
   Thus, setting aside defective utterances, one cannot, in uttering a given sentence, mean anything by it unless one knows what it already means. So meaning in the psychological sense is parasitic on meaning in the linguistic sense, and the two kinds of meaning are therefore entirely distinct.

1.3 Why Meaning #3 ≠ Meaning #1
The sense in which “snow is white” means that snow is white isn’t comparable to the sense in which smoke means fire. The fact that smoke means fire has nothing to do with conventions on the part of human beings. But the fact that “snow is white” means what it does is, at least in part, a matter of convention. It’s a matter of convention that “snow” doesn’t refer to grass and, therefore, that “snow is white” doesn’t mean that grass is white; it’s a matter of convention that “white” doesn’t mean green and, therefore, that “snow is white” doesn’t mean that snow is green.
   Although the whiteness of snow sometimes causes people to say “snow is white,” it doesn’t do so in the way that fire causes there to be smoke. Fire happens; smoke happens as a result. The presence of smoke doesn’t embody any judgment about anything. But, when caused by the whiteness of snow, utterances of “snow is white” do embody judgments of various kinds. People see or otherwise come to believe that snow is white; and, since they know the relevant linguistic rules, they know that, were they to say, “snow is white,” they judge that they’d be making a correct statement. Thus, utterances of “snow is white” embody judgments about the color of snow and about how, linguistic conventions being what they are, one can report the color of snow. Also, people don’t say everything that occurs to them. Before deciding to utter a given sentence, people typically make context-based judgments about the appropriateness of uttering that sentence. So various judgments—about snow, about language, and about human psychology—are involved in the causal connection between the whiteness of snow and a given gerson’s saying “snow is white.” There is thus a normative dimension to language use that is absent where purely natural, non-conventional cause-effect relations are concerned.
2.0 Sentences as proposition-isomorphs
The meaning of a true or false sentence is a proposition. Propositions are not themselves sentences. That is why different sentences (e.g., “schnee ist weiss” and “snow is white”) can express the same proposition.
   Propositions, when true, are truths. Thus, propositions have existed as long as there have been truths; which means that they’ve existed as long as there has been anything and, consequently, that propositions are not creations of human creations.
   Though distinct from the sentences that express them, propositions are structurally similar to them. Two otherwise dissimilar sentences can share the word “John.” “John loves Mary” and “Sally punched John” are two such sentences. The meanings of those sentences obviously have something in common corresponding to the fact that they share the word “John.” Since they share no other constituents, the thing meant by “John” must be capable of moving on its own from sentence-meaning to sentence-meaning. This would not be the case if the thing meant by “John” in the proposition meant by “John loves Mary” were incapable of being disengaged from the things meant by “loves” and “Mary.” It follows that propositions consist of discrete parts; it also follows that those discrete parts correspond to discrete parts of the sentences that express them. Taken together, these two points entail that sentences are structurally like the propositions they express.
2.1 Propositions as digital structures
Given that propositions consist of discrete, isolable entities, it follows that, like sentences and unlike visual perceptions and photographs, propositions are digital structures. The sentence “Sally punched Bob” has a unique decomposition into a certain “minimal units of significance,” or “morphemes,” these being “Sally,” “Bob,” etc. Given what we said in Section 2.0, it follows that something similar is true of the corresponding proposition. Sentences and propositions are digital structures, meaning that they have unique breakdowns into minimal significant units.
   A visual perception of Sally punching Bob doesn’t have a structure comparable to that of “Sally punched Bob” or any other sentence. Unlike sentences, perceptions don’t have to decompose into minimal significant units. Visual perceptions, unlike sentences and propositions, therefore have a non-digital or analogue structures. Given that at least some thought involves the processing of perceptual information,  it follows that thought 

at least sometimes has a structure very different from language. (See Section 5.4 for further discussion of this.) The nature of propositions is discussed in Chapter 3.
3.0 The three branches of the philosophy of language: syntax, semantics, and pragmatics
The study of language is typically divided into three sub-disciplines—semantics, syntax, and pragmatics. In addition to denoting a branch of linguistic study, each of these three words denotes dimension of language. So “semantics” refers to a certain discipline and also to a feature of expressions, the same being true of the other two expressions.
3.1. Semantics
The discipline of semantics attempts to make it clear what our utterances literally mean. It has no interest in what is conveyed through suggestion or innuendo.
   If a disappointed boss says to a substandard employee, “it might not be a bad idea for you to start thinking about finding a new position,” the literal meaning of his utterance is quite innocuous. But the message that is being sent is not innocuous—that message is: you’re fired; you’re a disgrace; go away; etc. The utterance’s semantic coincides with its literal (innocuous) meaning.
3.2 Pragmatics
Pragmatics studies the use of language. Sometimes language is used literally. Asked whether I’m over thirty years of age, I say “yes, I’m over thirty years of age.” What I mean coincides with what my utterance literally means.
   Language is often used non-literally. If, while addressing a pan-handler, I say “you’ve made a fine life for yourself,” what I mean is the antitheses of what my utterance means. But usually the propositions literally meant by our utterances are neither opposed to, nor exhaustive of, the propositions we wish to affirm in producing those utterances. Asked whether there’s a place to get food, I say “there’s a McDonalds down the road.” The proposition I’m affirming is: there is a nearby place to get food, the reason being that there’s a McDonalds down the road. Thus, the proposition literally meant by my utterance is a only a part of what it is that I’m saying. Thus, what a sentence literally means is only one of many factors governing what it is used to mean. The discipline of pragmatics tries to identify the remaining factors.
3.3 Syntax
The disciplines of syntax studies the structures of the meanings of complex expressions. A complex expression is one that consists of other expressions. (Thus, “the man who ate my cookie” is a complex expression, since it consists of “man,” “ate,” etc., each of which is meaningful. By contrast, “red” is not a complex expression, since it doesn’t have any meaningful proper parts.) The discipline of syntax tries to make it clear how the meanings of complex expressions depend on those of their parts.
   Thus, the discipline of syntax doesn’t study the meanings of complex expressions per se. It studies the relationships that such meanings have to those of their constituents. Consider the sentence “Sally hates Bob.” The word “hates” occurs in that sentence. If that occurrence is replaced with an occurrence of “loves” or “is amused by,” the resulting sentence has a very different meaning from the first. This shows that what “Sally hates Bob” means depends on what “hates” means.
   Bearing this point in mind, consider the sentence “Larry loves Julie.” Obviously this sentence doesn’t mean the same thing as “Sally hates Bob.” But the relationship borne by the meaning of “Sally hates Bob” to the meaning “hates” is identical with the relationship borne by the meaning of “Larry loves Julie” to that of “loves.” Exactly similar points hold in connection with each of the remaining two constituents of each of those sentences.
   

   The discipline of syntax studies the relation that the meanings of complex expressions bear to the meanings of the simple expressions composing them. Thus, syntax doesn’t study the semantics (meanings) of complex expressions. It studies the structures of the semantics of complex expressions. Syntax studies semantic structure.
4.0 The need for the discipline of semantics
Even though we all know what:
(1) “John wants to catch a 20-pound striped bass”
means, we don’t know what it is that we know in knowing this. Semanticists supply us with the missing metaknowledge. Consider the sentence:
(2) “John wants to punch Bob.”
(2) attributes a certain property to John—that of wanting to punch Bob. Given that (1) and (2) are grammatically isomorphic, it’s natural to assume that there exists some 20-pound striped bass x such that the proposition expressed by (1) is:
(3) John wants to catch x.
   But this isn’t the right analysis. There isn’t some one fish such that, if the desire ascribed to John by (1) is to be gratified, John must catch that very fish. There is thus no fish x such that, if (1) is to be true, John must want to catch x.
   The meaning of (1) is:
(1R) John wants it to be the case that: there exists some fish x such that x is 20-pound striped bass and such that John catches x.
Thus, (1) doesn’t describe a relationship between John and some non-existent or quasi-existent fish. It affirms the existence of a relationship between John and a proposition. The proposition in question is one that, in English, is expressed by the sentence:
(4) “there exists some fish x such that x is a 20-pound striped bass and such that John catches x.”
If John’s fishing-trip is a success, that proposition will be true; otherwise it will be false. But that proposition exists either way.
   But we still haven’t solved the problem. In (4), the expression “some fish” occurs. Grammatically, that expression is a noun-phrase. But, unlike other noun-phrases, it doesn’t refer to anything. (“Some fish” doesn’t refer to some fish. There is no fish x such that “some fish” refers to x. That’s why, given any particular fish F, if you say “some fish is wet, but x is not,” what you are saying isn’t self-contradictory.) So the problem we were trying to solve remains.
But to solve the problem, we need only reword (4). The needed rewording is this:
(5) The property of being a 20-pound striped bass that John catches is instantiated.
The property of being such a fish exists. So (1), which seemed to be about a non-existent fish, is about an existent property. (5) says of that property that it’s instantiated. Thus, a complete analysis of (1) is given by:

(1CA) John wants it to be the case that the property of being a 20-pound striped bass that John catches is instantiated.
   So even though just about every English speaker understands (1), knowing what it is that one knows in understanding it isn’t such a trivial thing.
4.1 Semantics needed to figure out what is literally meant and what is not
Despite everything just said, there is clearly a sense in which every English speaker knows what (1) means. What the semanticist is doing in connection with (1) isn’t comparable to what you (who, we’ll assume, speak Spanish) are doing in connection with it when you tell a monolingual Spanish speaking friend of yours what it means. The semanticist is needed to clarify the structure of the meaning that (1) is already known to have, but he isn’t needed to identify that meaning. The semanticist isn’t a translator. But there are many cases where the semanticist is needed to identify literal meaning. In fact, as paradoxical as it may sound, there are cases where he is needed to identify the meanings of sentences that are perfectly well understood.
   First of all, we must distinguish what is literally meant by an utterance from what it is that the speaker wishes to convey. To give a trivial example: You and I are robbing a bank. I yell: “the cops are coming!” What I wish to convey is that we should hurry up. In this particular case, it’s easy to distinguish what is literally meant from what is non-literally suggested, and semantics would therefore have no interest in it. But in other cases, it’s exceedingly hard to do this, and it’s with these other cases that semantics is concerned.
   A story will help us move forward. Somebody who is wearing a ski-mask, and who I therefore don’t recognize, deftly snatches my pocket from my wallet. As he’s running off, I point at him and yell: “that man is a thief!” Let U1 be this utterance.
   Before moving on, let’s take a moment to make it clear what U1’s literal meaning is. Somebody just stole my wallet. I don’t know who that person is. But whoever it is, I am attributing a certain property to him. If that person has that property, I have spoken truly; if not, not. U1 is correct if, and only if, the person referred to by “that man” has the property expressed by “is a thief.” Thus, there is some individual x such that x has just stolen my wallet and such that what I’ve just said is true exactly if x is a thief. (The underlined part is U1’s literal meaning.)
   The next day, my lovable office-mate Steve eats one of the cupcakes that was on my desk. I jokingly point at him and say: “that man is a thief.” Let U2 be this utterance. There is some x such that x just ate my cupcake and such that U2 is true exactly if: x is a thief.
   Unbeknownst to me, Steve is the pick-pocket, and there is some individual x, namely Steve, such that each of U1 and U2 is true if and only if x is a thief. Thus, U1 and U2 have the very same literal meanings. But I don’t know this, even though I speak English perfectly and, on each occasion, obviously understand perfectly well what it is that I’m saying.
   How this is possible? Our sense-perceptions describe things. My uttering U1 was a response to my being given a visual description of Steve. That description was to the effect that:
(i) there is some man x such that x is wearing a ski-mask and such that x is running off into the distance.
But U1’s literal meaning is not that that effect. There is some man x such that x is a wearing a ski-mask (etc.), such that in uttering U1 I was saying that:
(ii) x is a thief.
The meaning of U1, being identical with (ii), is quite threadbare. But I grasped that threadbare meaning through my descriptively rich visual perception, whose content is given by (i).
   
My uttering U2 was a response to my being given a different description of Steve. That description was to the effect that:
(iii) there is some man x such that x is a portly amicable fellow who is sitting over in that chair.
But U2’s literal meaning is not that that effect. There is some man x such that x is a portly amicable fellow (etc.) such that in uttering U2 I was saying that:
(ii) x is a thief.
Echoing what we said a moment ago, the meaning of U2, being identical with (ii), is quite threadbare. But I grasped that threadbare meaning through my descriptively rich visual perception, whose content is given by (iii).
   Because I grasped (ii) by way of different bodies of perceptual (descriptive) information, I didn’t know, when uttering U2, that what I was affirming was the same thing I was affirming in uttering U1. Oftentimes, literal meaning is cloaked by the pre-semantic information through which it is grasped, and semanticists are needed to uncloak it.
4.2 Semantics needed to figure out what is literally meant and what is not (continued)
Fido is the smartest dog on the planet. I know this well, but some of my friends don’t yet know this. I point to Fido and say: “that dog is very smart.”
   The proposition that it was my intention to affirm and communicate is indeed true. For a dog, Fido is indeed smart. Of course, Fido is vastly less intelligent than a human being, such as my friend Timmy, who is of mediocre intelligence. But if I say “Timmy is very smart,” what I’m saying is false. Judging by the words I’ve used, the property I’ve attributed to Timmy is identical with the property I’ve attributed to Fido. Given that Timmy has that property to a vastly greater degree than Fido, it would seem to follow that, since “Fido is smart” is true, “Timmy is smart” must also be true. And yet “Timmy is smart” is false. How can this be?
   Some deal with this by saying that “smart” is ambiguous, like the word “dumb.” So “Timmy is smart” and “Fido is smart” have different meanings, like “Timmy is dumb [unintelligent]” and “Timmy is dumb [mute].”
   This solution is pretty clearly false. A more plausible one is that the property of being smart for a dog is distinct from the property of being smart for a human. Fido has the first but not the second. And many humans have the second, but almost all of those lack the first.
   A similar, possibly coincident, view is that “smart” is implicitly relational. When, for some object x, you say ‹x is smart›, you are saying that x is smart relative to some benchmark, the identity of which the context makes clear. So “Fido is smart” says that Fido is smarter than most dogs, which is true, and “Timmy is smart” says that Timmy is smarter than most human beings, which is false.
   I published a paper arguing that, for any degree-property phi, ‹x has phi› expresses a proposition of the form: the degree to which x has phi exceeds standard S, where S is some standard that, given the context, is clearly the relevant one. (A “degree property” is one that can be had to varying degrees.) But even if this is right, it doesn’t follow that such judgments are the literal meanings of such sentences. And there is no independent evidence that ‹x is smart› has the syntactic properties of sentences that clearly do have for their literal meanings propositions of the just-described kind. This suggests that, so far as ‹x has phi› communicates such a proposition, it isn’t because it semantically encodes it.
   In any case, it not obvious what ‹x is smart› means or, in general, what ‹x has phi› means, where phi is any degree property. Thus, the literal meanings of such sentences are sufficiently recondite that the intervention of professional semanticists is needed to identify them.

5.0 Semantic rules
The English language assigns a certain meaning to the sound “that dog has rabies”; and given the spectacle of a rabid dog, it furnishes one with a sentence with which to describe what one sees. In general, the English language assigns meanings to sentences and sentences to meanings. This is true of all languages. A language is a systematic way of pairing off sentences with meanings. Any rule that assigns a meaning to an expression is known as a “semantic rule.” Languages are sets of semantic rules.
5.1. An important subtlety
There are a couple of subtle but, in some contexts, important inaccuracies in what I just said. First of all, something isn’t a sentence until a meaning has been assigned to it. In a world where there were no animate beings, but in which the forthcoming parenthetical ink deposit (1 + 1 = 2) was formed out of twigs, that twig deposit wouldn’t be an expression of any kind. That twig deposit would be an expression if and only if it were endowed with meaning. This shows that something has to have meaning in order to be an expression. Thus, expressions aren’t assigned meanings. They already have them and don’t need to be assigned them. Therefore a semantic rule can’t be defined as a rule that assigns a meaning to an expression.
5.2	How meaning is assigned to hitherto meaningless and, therefore non-linguistic, entities
Thus, semantic rules assign meanings to non-expressions. But which non-expressions? A story will give us the answer.
   You and I want to invent a code that only we two know. We both know a guy whose real is name is Larry. We decide that our code name for Larry is to be “Ichabod.” So what’s going on is that we’re creating a semantic rule: one that to the effect that “Ichabod” is to pick out Larry. How exactly is this rule enacted?
   In order to implement this rule, I say: Let’s refer to Larry as “Ichabod.” The burst of noise that I produce is a sentence-token. And what you hear is some token of “Ichabod”—you do not, since one could not, hear the name type itself.
   When you hear this burst of noise, along with my proposal concerning our new name for Larry, you know that what I’m saying is to the effect that any other physical object that is similar in the relevant ways to this burst of noise is itself henceforth to refer to Larry. Thus, I am in effect proposing that all and only those bursts of noise that are similar, in the relevant respect, to this particular burst of noise are to refer to Larry. (By implication, I’m proposing the same thing mutatis mutandis to hold of all and only ink-deposits that, given certain conventions, are paired off with such bursts of noise.) The thing that, according to my proposal, is henceforth to pick out Larry is the thing of which all and only such bursts of noises (etc.) are instances. That thing, like anything else of which there are instances, is a property. It is the property had in common by all and only bursts of noise (etc.) of the relevant type.
   That property doesn’t (yet) have a meaning; it isn’t (yet) an expression. It’s a property that existed, and was instantiated, before either or any instances meant anything. So the semantic rule that I’m proposing we adopt assigns a referent to a property that does not itself have a meaning. The same thing mutatis mutandis holds of any other semantic rule.
   Thus semantic rules assign meanings to properties of physical objects—to morphological or acoustical properties (in other words, to properties that a things has in virtue of having a certain shape or sounding a certain way). A semantic rule is therefore something which assigns a meaning to a property, and language is a set of such rules.
   (Technically, this is only an approximation to the truth. The relevant qualifications are found in Section 7.5.)

5.3 What are semantic rules?
Many believe that linguistic meaning is to be understood in function-theoretic terms—that, in other words, semantic rules are mathematical functions.
   Let us start by defining the word “function.” Given any pair of whole numbers, the expression “+” assigns exactly one whole number to that pair. In general, a function is a rule that, given some class of objects, assigns no more than one object to any given member of that class.
   Although the rule expressed by “plus” assigns the number 8 to the pair <4,4>, it doesn’t assign that number to that pair in the way in which a person assigns a task to an underlying. In the former case, the word “assigns” has a psychological meaning; in the latter, it has a non-psychological, purely logical meaning. A related point is that the rule that assigns 8 to <4,4> isn’t a social rule, and it therefore isn’t something that can be obeyed or disobeyed.
   According to the function-theoretic view, semantic rules are rules in the strictly logical sense; that is, they are mathematical functions. The semantic rule for “Socrates” is a function that assigns a certain individual (Socrates) to that word (or to occurrences thereof). The semantic rule for “snow is white” is a function that assigns truth-conditions to that utterance (or to occurrences thereof). And so on.
5.3.1 Why semantic rules are not functions
The just-described view is false. The rule denoted by “+” has always existed and always will. Of course, the expression “+” hasn’t always existed. But that’s irrelevant, since things pre-exist the expressions we use to denote them. “Socrates” is an Anglicization of the name with which Socrates referred to him. Since Socrates lived well before the English language came into existence, “Socrates” (the name, not the person) didn’t come into existence until well after its referent went out of it.
   The semantic rule that assigns Socrates to ink deposits having certain shapes would exist even if the English language had never come into existence. Like the rule denoted by “+”, that rule has always existed, and always will. So has the rule that assigns Abraham Lincoln to such ink deposits. The mathematical function that assigns the proposition snow is white to ink deposits like the italicized one has always existed, as has the mathematical function that assigns the proposition all horses weigh 18,000 lbs to those same ink deposits.
   But the English language hasn’t always existed. Since the English language is a set of semantic rules, those semantic rules haven’t always existed. Therefore, they haven’t always existed. They came into existence quite recently. Therefore, those rules aren’t mathematical functions.
   Also, if the semantic rules of English were such functions, there would exist a language in which “Socrates” referred to Lincoln and in which “snow is white” meant all horses weigh 18,000 lbs, the reason being that the corresponding mathematical functions exist. But there is no such language. Of course, there could be such a language. And maybe there will be; maybe somebody will invent a code in which those things have those meanings. But right now they don’t. Such a language is merely possible and, therefore, doesn’t exist. Thus, semantic rules are not rules in the mathematical sense.
5.3.2 The Gricean approach
Understandably, many philosophers of language believe that semantic rules must be understood in psychological, not mathematical, terms. There are different versions of this view. I accept one version of it. But the version I accept bears little resemblance to the versions of it that are usually held, each of which is some variant of the view held by H.P. Grice.
   According to Grice (1957), for expression E to have literal meaning M is for it to be the case that, when they utter E, M is what they mean. So “snow is white” has the proposition snow is white for its literal meaning because what people generally mean when they say “snow is white” is that snow is white. People generally mean snow is white in uttering that expression.
   
Literal meaning is to be understood in terms of speaker’s meaning. That’s the main idea. Neo-Griceans hold that, even though literal meaning cannot in all cases be identified with speaker’s meaning, it is always, ultimately, to be understood in terms of it.
   Wittgenstein (1958) advocated a version of this view. “Roughly speaking,” he said, “meaning is use.” Expressions mean what we use them to mean—they mean what we mean by them. Wittgenstein nowhere makes it clear what he means by the words “roughly speaking.”
   But it doesn’t matter, since his statement isn’t even roughly true. Literal meaning is isn’t identical with speaker’s meaning and isn’t to be understood in terms of it. It’s the other way around. We saw why in Section 1.3.
   Also, Grice’s theory fails to deal with the fact that the meaning of a subsentential expression isn’t something that could be possibly be meant. “Of ” has a meaning; so does “skip,” “snorkel,” “or,” “gladly,” etc. But whatever it is that “or” means, it cannot, at least not by itself, be what a person means. Obviously I can say “snorkel” and mean it—but only if I’m using it as an abbreviation for some whole sentence (e.g., “my favorite activity is to snorkel”) and, therefore, to convey something other than its literal meaning.
5.3.3 More problems with the Gricean approach
If Grice were right, the meaning of the sentence:
   (SF) “Smith is now living in France”
would be fixed by the intentions people have in using it.
   But its meaning is not fixed by those intentions. It is fixed by the meanings of its parts (“Smith,” “France,” etc.), together with the way those expressions are ordered in that sentence. The semantic and syntactic rules of English being what they are, SF would have its current meaning even if it had never been used. So whatever the intentions of people using that sentence are, those intentions do nothing in the way of assigning it that meaning. In general, Grice’s view is inherently incapable of accommodating the fact meaning is compositional.
5.3.4 How some Griceans deal with the problem just described
Some Griceans respond by saying that, although speaker-meaning doesn’t directly fix sentence-meaning, it does so indirectly. In their view, it is because of what we mean by sentences of the form ‹....France...› that such sentences are to the effect that...France...and not to the effect that, for example,...Germany....
   In addition to being an abandonment of Grice’s core idea, this move is a failure. Let P be the proposition meant by SF. So far as people utter SF with the intention of affirming P, it’s because they believe (correctly, as it happens) that each of the expressions composing it already has a certain meaning.
   It’s irrelevant that how we use sentences of the form ‹...France...› causally determines what “France” means. There are many ways to cause meaning-shifts—many ways to get a given expression to have a certain meaning. But the question we’re asking isn’t “how did ‘France’ acquire its current meaning?”, and is instead “whatever it is that ‘France’ means, what is it for it to have that meaning?” And it’s no answer to this question to say that it may have acquired that meaning because of what, at some point in time, people meant by sentences of the form ‹...France...›.
5.3.5	Why Grice’s theory is inconsistent with the normative nature of semantic rules
A billiard ball isn’t right to move after being struck; it just does. The relevant scientific laws merely register that fact; they aren’t normative—that is, they don’t characterize it as good or bad. Unlike scientific laws, 

semantic rules are normative. If, intending to affirm that Smith is female, you say “Smith is male,” you’ve done something wrong. If Grice is right, literal meaning is speaker’s meaning. This means that, if Grice were right, speaker’s meaning wouldn’t be accountable to existing semantic rules. Since it is, Grice is wrong.
5.4 The psychological reality of semantic rules
One view as to the nature of semantic rules is that they are idealized descriptions of the activities of speakers. Proponents of this view seldom if ever identify the facts about the speaker-behavior of which semantic rules are supposedly descriptions. The most natural assumption is that they are idealized descriptions of what people mean when they speak and write (etc.). If this assumption is right, then, given the points just made, the view in question is wrong.
   But even if this isn’t what proponents of this view have in mind, their view is very clearly wrong. If semantic rules are just idealizations of speaker-behavior, then speaker-behavior must pre-exist the semantic rules embodied in it. But if that’s the case, then the activity described by semantic rules isn’t guided by them. An awareness of those rules is no part of what leads people to say the things they do. Those rules are psychologically inert. They have no “psychological reality.” This view is held by Nathan Salmon (2007) and also by Scott Soames (2002).
   This view is inconsistent with some obvious facts. I know that Smith is now living in France. Wanting to tell you this, I say: “Smith is now living in France.” Why do I choose this particular sentence? Because, first of all, I know the relevant semantic rules (viz. that “Smith” refers to Smith, that “living” refers to a certain property) and, secondly, because I believe that, given these facts about semantics, the sentence in question is the right one to express my belief. A knowledge of semantics underlies my speech-act and, by obvious extensions of these points, all non-defective speech-acts.
   Another problem with the Salmon-Soames view is that it’s inconsistent with the normative character of semantic rules. If semantic rules merely describe existing semantic activity, then that activity isn’t answerable to semantic norms. It is; so the Salmon-Soames view is wrong.
5.5 Conceptual role semantics
A little while ago, we discussed Wittgenstein’s claim that “meaning is use,” i.e., that for an expression to have a given meaning is for it to be used in a certain way. This doctrine is incoherent in many ways. We’ve already discussed one of those ways; now we’ll discuss some of the others.
   Expressions have meanings. A meaningless burst of noise isn’t an expression. If I cough or guffaw, the burst of noise I’ve produced doesn’t have the sort of meaning had by bona fide expressions. It has, at most, meaning in irrelevant, purely evidential sense, e.g., the sense in which a cough may be evidence of a cold. Since anything that is a linguistic expression ipso facto has a meaning (in the relevant, linguistic sense), there are no expressions to be used before noises, ink-marks, etc., have been assigned meanings. So, since there can be no expression-use until after there is expression-meaning, it makes no sense at all to say that expression-use determines expression-meaning. “Meaningful expression” is a pleonasm. So, contrary to what Wittgenstein said, meaning isn’t use.
   Of course, how a given expression is used may well assign it a new meaning. But there is all the difference in the world between saying:

(1) Expression E’s having meaning M is causally determined by E’s being used in such and such a manner,

and

(2) Expression E’s having meaning M is identical with E’s being used in such and such a manner.
An expression E’s having meaning M cannot possibly be constituted by its being used in such and such a manner, since E isn’t an expression and, therefore, isn’t an expression to be used until it has a meaning.
   
According to a doctrine known as “conceptual role semantics” (CRS), whose exponents include Hartry Field (1977) and Robert Brandom (1994), for an expression to have a given meaning is simply for it to be used in a certain way. But this isn’t correct as we just saw.
   CRS is incoherent for reasons other than the one just given. According to that doctrine, what a sentence means is determined by what people infer from it and what people infer it from. Whereas commonsense holds that one infers “an even number is less five” from “two is less than five” because the latter already has a given meaning, advocates of CRS say that, on the contrary, it’s because people infer “an even number is less than five” and other similar statements from “two is less than five” that the latter has the meaning it has.
   This is not a viable view. If we learn tomorrow that, contrary to what we previously thought, Aristotle wrote several plays, we’ll infer “somebody who wrote several plays wrote the Nichomachean Ethics“ from “Aristotle wrote the Nichomachean Ethics.” But it doesn’t follow that “Aristotle wrote the Nichomachean Ethics” would have undergone some change in its semantic meaning. Changes in what we believe affect what we infer from statements; but they don’t categorically change the meanings of those statements. CRS entails that every inference is an analytic inference. Once it’s learned that Aristotle wrote plays, it becomes, according to CRS, constitutive of the meaning of “Aristotle wrote the Nichomachean Ethics” that one can infer from it that a playwright wrote the Nichomachean Ethics. But surely the inference from “Aristotle wrote the Nichomachean Ethics” to “a playwright wrote the Nichomachean Ethics” isn’t analytic.
   What we may infer from a sentence is answerable to its existing meaning. CRS says that a sentence’s meaning is answerable to what we infer from it. If correct, that would have the consequence that one couldn’t possibly draw a false inference from any sentence. Which, in its turn, would have the consequence that no sentence would mean anything. Which, since nothing meaningless is a sentence, would have the absurd consequence that there neither are, nor could be, sentences.
   Consider the sentence “Bill plagiarized his first novel.” If one knows that sentence to be true, one can make inferences about Bill’s character, his past activities, his ambitions, his values, and so on, that one couldn’t make if, other things being equal, one didn’t know that sentence to be true. But it’s only because of what the sentence already means that one can make those inferences. Given any other sentence, the same thing mutatis mutandis is true of it. CRS says that what a sentence means is determined by what we infer from it. Since it’s the other way around, as we’ve just seen, CRS is false.
6.0 What is literal meaning?
Where complex expressions are concerned, there is no limit to how much literal and understood meaning may diverge from each other. But where simple expressions are concerned, literal and understood meaning must coalesce. It makes no sense to suppose that people could be systematically wrong as to what “red” meant. If people thought that “red” meant what is in fact meant by “blue,” then “red” would have that meaning. Systematic, widespread error is impossible where semantically simple expressions are concerned. This gives us a way of understanding what literal meaning is.
   Even though there can be widespread, systematic misinterpretations of sentences, those misinterpretations do not arise as a result of people failing to know what the simple parts of sentences mean. They arise as a result of people not knowing how to put those meanings together. So to the extent that its meaning is fixed by the fact that it has the form ‹...Socrates...›, people (English speakers) do systematically understand “Socrates was more wise than Plato, but he was less sharp then Aristotle”; and to the extent that its meaning was determined by its having the form ‹...wise...›, people do understand that sentence; and so on. So far as that sentence is systematically misunderstood, it is because people are having trouble putting the meanings of its constituents together—it is because they’re having trouble figuring out how those meanings ought to be put together.
   What a simple expression literally means is determined by what it is that a sentence means by virtue of containing it. Since, where simple expressions are concerned, what people take literal meaning to be coincides with what it really is, a simple expression’s literal meaning coincides with what it is that, in virtue of containing that expression, sentences are taken to mean. So a simple expression’s literal meaning is given by a statement saying what it is that, by virtue of containing it, sentences are taken to mean; and a complex expression’s literal meaning is a function, in the mathematical sense, of the meanings of its parts.
   
Here’s an illustration. “Socrates” is a simple expression. So what people think it means must ultimately coincide with what it actually means. So it refers to Socrates only because people think it refers to Socrates and, therefore, only because people think that “Socrates is intelligent” attributes intelligence to Socrates and, in general, that ‹...Socrates...› attributes...x...to Socrates.
   Of course, people don’t always take utterances of ‹...Socrates... › to be attempts to say that Socrates has...x... It might be clear from the speaker’s tone that what he really meant when in saying “Socrates was wise” was that Socrates was not wise. But to the extent that their belief that “Socrates” refers to Socrates is determinative of what people take the meanings of utterances of the form ‹...Socrates...› to be saying, what they take it to be saying is that Socrates has...x... That is what it is for them to take “Socrates” to refer to Socrates. And their taking “Socrates” to refer to Socrates is for “Socrates” to refer to Socrates, given that “Socrates,” being a simple expression, has the semantics that people think it has. The same thing mutatis mutandis is true of every other simple expression.
   Bearing these points in mind, let CE be any complex expression, and let e1...en be the simple expressions composing it. How people interpret CE may diverge from its literal meaning. But when this happens, it’s because what it is taken to mean diverges from what, given what people believe its simple parts to literally mean, people are disposed to take it to mean.
   Since what people take simple expressions to mean is what they mean, this is the same as saying the following. A divergence between
(i) a sentence’s literal meaning
and
(ii) that sentence’s understood meaning
is the same thing as a divergence between
(a) that sentence’s literal meaning
and
(b) what it is that, given their (correct) beliefs as to what its simple parts literally mean, people are disposed to take that sentence’s literal meaning to be.
   The literal meaning of a complex expression is a function of two things: (i) the meanings of its simple parts, and (ii) the order in which those parts are arranged. To say what literal meaning is in general, we need to say what it is for a simple expression to have a given literal meaning. Given the points just made, we can do this. Where simple expressions are concerned, literal and communicated meaning coincide (ultimately)—in other words, such expressions mean what people take them to mean. And where complex expressions are concerned, literal and communicated meaning may diverge, but literal meaning nonetheless coincides with what, given what the simple components of the expression in question literally mean, people are disposed to take it to mean.
7.0 Tokens vs. types: some preliminary terminological points
No word is identical with any utterance of it. My utterance of the word “snow” lasts for a fraction of a second. But the word “snow” itself endures.
   Utterances and inscriptions of expressions are referred to as “expression-tokens” (or just “tokens”). So there are three tokens of some one word to the right of the upcoming colon: snow, snow, snow. The things being uttered or inscribed are referred to as “expression-types” (or just “types”).

7.1 Two-dimensional semantics
Some expressions appear to have a two-tiered semantic structure. For example, an occurrence of the pronoun “I” has a referent, this being the person who uttered it, and it picks out that referent in a certain way (i.e., by way of a certain concept).
Thus, the semantics of “I” is given by the rule that an utterance of “I” refers to a given person if and only if that person has the property of being the one that produced that utterance.
   So, if I say “I am tired,” the concept through which my utterance of “I” refers to me is the concept person who produced the utterance in question. This, then, is the concept through which reference is secured; it is, as we’ll henceforth put it, the mediating concept. When Smith says “I am tired,” his utterance of “I” refers to himself, not to me. But the mediating concept remains the same.
   If somebody points to me and says “that guy is tall,” the person picked out by “that guy” is me. But in this case, the mediating-concept is different. The semantics rule for “that guy” is given by the rule that, if “that guy” is uttered in a context where there is a unique, salient guy, that utterance refers to that individual.
   “I” and “that guy” are context-sensitive expressions: what such an expression refers to depends in a systematic manner on facts about the context of utterance. (We’ll soon refine this vague statement shortly.) Such expressions are known as “indexicals.” Other examples of indexicals are “you,” “he,” “those animals,” “this monkey,” “tomorrow,” “yesterday.” Some indexicals are single words (e.g., “tomorrow,” “he”); others consist of more than one (e.g., “that tall man”). The latter are known as “complex indexicals.”
7.1.1 Demonstratives vs. indexicals
Some indexicals often cannot be successfully used without an accompanying demonstration on the speaker’s part, the purpose of which is to eliminate any doubt as to what the intended referent is. If Jim and Larry are both equally salient in the context in question, an utterance of “that guy” won’t single anyone out. But it will do so if an act of pointing accompanies it. Indexicals that fall into this category are known as “demonstratives.” Not all indexicals are demonstratives. For example, “tomorrow,” “now,” and “here,” aren’t demonstratives. Given an utterance of “tomorrow,” no gesture is needed to make it clear what the intended referent is. If I say “tomorrow I’m going hiking,” it’s clear what the referent of “tomorrow” is; no demonstrative act is necessary, and none could possibly do any good.
7.1.2 Indexicals (continued)
Indexicals have a “two-dimensional” semantic structure. Consider the expression “today.” If I say it right now, that utterance will refer to April, 27, 2009, since that is today’s date. If I say it tomorrow, that utterance will refer to April 28, 2009. But the rule that assigns April 27, 2009, to the first utterance is identical with the rule that assigns April 28, 2009, to the second utterance. That rule is this: if “today” is uttered on a given day D, that utterance refers to D.
   The meaning of an utterance “today” is the day it picks out. The meaning of the corresponding word-type is the rule just described. Given any indexical, the meaning of a token of that indexical is its referent; the meaning of the corresponding indexical-type is the rule that assigns that referent to that token.
7.2 Definite descriptions
In Chapter 6, reasons are given for thinking that definite descriptions are not devices of reference. But there are also reasons to think that they are devices of reference. (It’s very hard to believe that “the whole number that comes right after one” doesn’t refer to the number two.)And in this section we will suppose them to be just that.
Definite descriptions, like indexicals, have a two-dimensional semantic structure. A given utterance of “the current U.S. President” refers to some individual. Right now such an utterance would refer to Barack Obama. A few years ago, such an utterance referred to Bill Clinton.

But even though an utterance in 2009 of “the U.S. president” doesn’t have the same referent as an utterance in 1999 of that same expression, both utterances are assigned their respective referents by the same semantic rule. The circumstances have changed—hence the change in referent—but the semantic rule has stayed the same.
   That rule is: if, at time t, x uniquely has the property of being a U.S. president, then an utterance at t of “the U.S. President” refers to x.
7.2.1 Incomplete definite descriptions
Some definite descriptions appear to be “incomplete”—that is, they fail to pick out a single object. So, for example, “the bald guy” could pick out any one of many different people. But, like all expressions, definite descriptions are not used in a vacuum; and the context usually supplies the information needed to enrich the mediating concept enough to enable it to single out a single person. So if you and I are in a room and I say “the bald guy is wealthy,” it’s clear that, so far as I making a determinate statement, what I mean is that the contextually salient bald guy is wealthy.
   If phi is a property that obviously has no more than one instance (e.g., the property of being the whole number successor of one or of being the U.S. President), phi’s sole instance is contextually salient by default.
7.3 The expressive limitations of indexical-free languages
Indexical-free languages are expressively impoverished; much of what there is to say can’t be said in them. The reason is that much information is perspectival, and nothing perspectival can be stated in a language that doesn’t contain indexicals. Suppose that I spoke a language that didn’t contain any indexicals, but was otherwise just like English. In order to express what I believe concerning the weather in my area, I’d have to say “it’s 60° in Richmond on Feb. 07, 2009.” (And the “is” couldn’t be taken as the present tense of the verb “to be,” since, thus interpreted, it would be an indexical that picked out the time of utterance. The “is” would have to be stripped of any temporal meaning and, thus, be downgraded to an empty grammatical place-holder, like the “it” in “it’s raining.”) But that utterance wouldn’t necessarily express the belief I wanted to express. My believing it’s 60° in Richmond on Feb. 07, 2009, is different from my thinking it’s now 60° in Richmond, even though I am in fact in Richmond at the time in question. I could have the one thought and not have the other. I could, after all, not know that I was in Richmond. And my believing either of those things is different from my thinking it’s now 60° here. One could have any given one of those beliefs without having any of the others. Further, one could rationally have any given one of those beliefs without having any of the others. A person who is in Richmond at the time in question can rationally believe it’s now 60° here while rejecting it’s 60° in Richmond on Feb. 07, 2009. For the data at one’s disposal may warrant the first judgment, but not the second.
   So nothing perspectival—nothing that embodies any information relating to the speaker’s perspective on the world—can be expressed without using an indexical. Nothing could be said about what’s going on here, at this time; and there would be no me-thoughts (e.g., I’m thirsty) could be expressed; one could only express their third-person counterparts (e.g., “JM is thirsty”). Thus, one could not, in an indexical-free language, express the thought I am JM or I am that guy in the mirror. And such a language would therefore be extremely impoverished.
7.4 Tokens, types, and context-sensitivity
No sentence-type containing a context-sensitive component is either true or false; for no such sentence-type says anything. It is tokens of “I am now tired” that make statements; the corresponding sentence-type does not do so. What a token of “I am tired now” affirms depends on facts about the context of utterance. If Smith’s the one who’s speaking, and it’s 3:00 P.M., such an utterance is true just in case Smith is tired at 3:00 P.M. If Jones is the speaker and it’s 4:00 P.M., such an utterance is true just in case Jones is tired at 4:00 P.M.
   
Thus the semantic rule that assigns a proposition to such a token does so on the basis of the facts about the context of utterance. And the rule in question is clearly this: “If, at time t, person p tokens the sentencetype “I am tired,” then the proposition thereby affirmed is true exactly if p is tired at p.” The same thing mutatis mutandis is true of all context-sensitive expressions. So the rule that assigns a proposition to an utterance of “that man is married to that woman” is: if, in the context of utterance, x is a uniquely salient man and y is a uniquely salient woman, a token of the sentence-type “that man is married to that woman” affirms a proposition that is true if and only if x is married to y.
   So context-sensitive sentence-types aren’t true or false; they don’t, in and of themselves, bear propositions. But they have an important semantic role: the identity of the proposition meant by a token of such a type depends on the identity of the type. A token of “I am tired” means one thing; a token of “you are tired,” uttered by the same person at the same time, means something else; and that difference obviously stems from the fact that, because different sentence-types were tokened, the semantic rule that assigns a proposition to the one token is different from the rule that assigns a proposition to the other. 
   This can all be distilled into the following principle: where context-sensitive sentences are concerned, the meaning of a token is a proposition, and the meaning of type is a rule that assigns a proposition to one of its tokens on the basis of facts about the context in which that token occurred.
   Long story short: the meanings of sentence-tokens are propositions and the meanings of sentence-types are rules that assign propositions to their tokens, usually on the basis of facts about the context of tokening.
7.5 Ambiguity and context-sensitivity (revisited) and the typetoken distinction (revisited)
Consider the sentence-type “that person is a professor.” Is that sentence true or false? No. Some tokens of it are true and some are false. This is because what a given token of that sentence says is a function of the circumstances. If I utter it while pointing at Bob, I’m attributing the property of being a professor to Bob. If I utter it while pointing to Sally, I’m attributing that property to Sally, not Bob. So what it is that I’m affirming in the one case is different from what it is that I’m affirming in the other case. But that isn’t because the sentence “that person is a professor is ambiguous.” That sentence is not ambiguous: it has just one meaning. But that meaning is not a proposition; it isn’t something that is true or false. That meaning is a rule. That rule in its turn assigns meanings to tokens of that sentence. Those meanings are true or false; those meanings are propositions.
   Remember that expression-types are what result when properties per se, as opposed to their instances, are assigned meanings. Of course, the rules that assign meanings to properties are semantic rules, since anything that assigns meaning to anything is ipso facto a semantic rule. So the sentence-type of which the following ink deposit—“that guy is a professor”—is a token is what results when some semantic rule assigns a meaning to some property. Let R1 be the semantic rule in question. Let R2 be the meaning that R1 assigns to the just-mentioned property. R2 is itself a semantic rule. But, whereas R1 assigns a meaning (a rule) to some property, R2 assigns meanings to instances of that property. So R2 assigns meanings to particular instances of the morphology had by the following ink deposit (“that guy is a professor”). The meanings that R2 assigns to those tokens are not themselves rules; they are propositions—they are things that are true or false.
   There are thus very different sorts of semantic rules. There are those that assign meanings to properties, and there are those that assign meanings to instances of those properties. The meaning that was assigned to the property we were just discussing is itself a semantic rule. As we’ll now see, every meaning that is assigned to a property (as opposed to a property-instance) is itself a semantic rule. Consider the following ink deposit: “Barack Obama.” There is a semantic rule that assigns a meaning to the property of having a morphology similar to that ink deposit. The meaning assigned to that property is itself a semantic rule. That rule assigns a meaning to each instance of the property in question. It assigns Barack Obama, the person, to any such instance. Thus, any such instance is an expression that picks out Barack Obama.
   In the previous section, we said that semantic rule is something which assigns a meaning to a property. That’s correct, but incomplete. The right definition is this: a semantic rule is something which assigns a rule to a property that in its turn assigns meanings to instances of that property. Let us now move onto slightly less abstruse material.

7.6 Do any expressions have one-dimensional semantics?
The question arises: What about sentence-types that don’t contain context-sensitive components? Where they are concerned, does token-meaning coincide with type-meaning?
   First of all, in natural languages, there are no such sentence-types. Every sentence contains a tense-marker. And in virtue of containing a tense-marker, a sentence is such that the proposition expressed by any given one of its tokens is a function of (inter alia) when that token occurs. If you say “the U.S. economy is fairly stable,” whether you are speaking the truth or not depends on when you say it.
   There are some apparent counterexamples to this. For all intents and purposes, any two tokens of
(IA) “the interior angles of a Euclidean triangle add up to 180°”
express the same proposition. But, from a strictly semantic perspective, IA is context-sensitive, and tokens of it uttered at different times don’t encode the same proposition. If it were believed that mathematical reality were as volatile as the stock-market, we would without hesitation regard IA as being in the same category as patently context-sensitive sentences such as:
(BH) “Bill’s holdings add up to $180,000,000.”
And we’d have no more temptation to regard the tense-marker in IA as inert than we’d have to regard its counterpart in BH as inert. What this shows is that, to the extent that the tense-marker in tokens of IA are doing nothing, it’s only because, our beliefs about mathematics being what they are, we choose to see such utterances as expressing atemporal propositions.
   Nonetheless, many semanticists hold that, at the level of literal meaning, IA is context-insensitive. They hold, in other words, that IA is what Quine (himself such a semanticist) refers to as an “eternal sentence.” (S is an eternal sentence if there is some one proposition P such that any two of S’s tokens express P.) If only for argument’s sake, let’s suppose that there are eternal sentences.
   It’s tempting to hold that an eternal sentence’s meaning is identical with those of its tokens. After all, the distinction between type-meaning and token-meaning seems quite hollow except where context-sensitive expressions are concerned.
   But this reasoning is spurious. The tense-marker on the occurrence of “add” in (IA) has the same semantics that it does in
(BH) “Bill’s various holdings add up to $180,000,000.”
In BH the tense-marker is obviously doing real work in IA. That’s why utterances of BH are true on Monday (before the market crashed) and false on Wednesday (after the market crashed). Therefore, different tokens of BH express different propositions. Therefore, the meaning of BH—the sentence-type—isn’t some proposition, and is instead the rule:
(BHSR) If t is a token of BH that is uttered at time T, t is true iff, at T, Bill’s various holdings add up to $180,000,000.
   But, of course, for any time t, the meaning of a token of BH that is produced at t is a proposition that is true just in case.
(BHT) At t, Bill’s various holdings add up to $180,000,000.
   Given that occurrence of “add” in any given token of IA has the same literal meaning as its counterpart in any given token of BHT, it follows that, from a narrowly semantic perspective, IA is quite as context-sensitive as BHT. To be sure, there is obviously a sense in which IA is, whereas BHT is not, context-insensitive.

But IA’s context-insensitivity, we must conclude, is a thoroughly pragmatics-based affair. Obvious extensions of this reasoning show that all expression-types have rules that assign meanings (or referents) to their tokens and, therefore, that where any expression is concerned, type-meaning diverges from token-meaning. The meaning of the expression-type “that man” is: a token of “that man,” uttered in context C, refers to x if, in C, x is uniquely a salient man. If, in a given context, Smith is such a man, then a token in that context of “that man” refers to Smith; if instead Jones is such a man, it refers to Jones; etc. The same is true of “the current President.” In one context (the year 1992), tokens of that expression refer to Bill Clinton; in a different context (the year 2009) it refers to Barack Obama.
   Some would be tempted to say that, because they have fixed referents, proper names (e.g., “Bill Clinton”) don’t have a two-dimensional semantic structure. This would be a mistake. Expression-tokens are physical entities—bursts of noise, deposits of ink, etc. Expression-tokens are therefore perceptible entities and are thus capable of transmitting information. Expression-types, on the other hand, are abstract entities and are thus inherently unsuited to be vehicles of communication. Let us develop these points.
   Expression-types are properties. Why are they properties? Tokens of a type are instances of it. Anything of which there are instances is ipso facto a property. So expression-types, unlike expression-tokens, are properties and are therefore non-spatiotemporal entities. And, as we just noted, it makes no sense to suppose a nonspatiotemporal entity could mediate information or, therefore, could in any significant sense be a symbol. Also, given the profound metaphysical differences between tokens and types, it would be theoretical arbitrariness of the worst kind to suppose that types could discharge the same semantic functions as their tokens. We must therefore assume that, whereas tokens of “Bill Clinton” refer to Bill Clinton, the corresponding type does not refer to Bill Clinton; and we must also assume that “Bill Clinton,” the expression-type, has for its meaning a (constant) function that assigns Bill Clinton to any given one of its tokens. In general, proper names, no less than indexicals and definite descriptions have two-dimensional semantics.
   The semantic rule corresponding to a proper name is a constant function, whereas the semantic rule corresponding to an indexical or definite description is not a constant function. All utterances of “Bill Clinton” refer to Bill Clinton, but not every utterance of “the current U.S. president,” or of “that guy over there,” so refer. This has encouraged the erroneous view that “Bill Clinton” itself, the expression-type, refers to Bill Clinton.
7.7 Ambiguity and context-sensitivity (re-revisited) and the type-token distinction (re-revisited)
Remember that expression-types are what result when properties per se, as opposed to their instances, are assigned meanings. Of course, the rules that assign meanings to properties are semantic rules, since anything that assigns meaning to anything is ipso facto a semantic rule. So the sentence-type of which the following ink deposit—“that guy is a professor”—is a token is what results when some semantic rule assigns a meaning to some property. Let R1 be the semantic rule in question. Let R2 be the meaning that R1 assigns to the just mentioned property. R2 is itself a semantic rule. But, whereas R1 assigns a meaning (a rule) to some property, R2 assigns meanings to instances of that property. So R2 assigns meanings to particular instances of the morphology had by the ink deposit (“that guy is a professor”). The meanings that R2 assigns to those tokens are not themselves rules; they are propositions—they are things that are true or false.
   There are thus very different sorts of semantic rules. There are those that assign meanings to properties, and there are those that assign meanings to instances of those properties. Consider the following ink deposit: “Barack Obama.” There is a semantic rule that assigns a meaning to the property of having a morphology similar to that ink deposit. Let PBO be that property. The meaning assigned to PBO is itself a semantic rule. In other words, the meaning of PBO is given by the statement that:

B1: Any given token of PBO refers to to Barack Obama.
   Given some specific token t of “Barack Obama”, the semantic rule for t is:
B2: t refers to Barack Obama.
   B1 and B2 are very different rules. Unlike B2, B1 doesn’t say anything about any specific token of “Barack Obama” or any other expression. The need for a two-dimensionalist approach to semantics is embedded in the very concept of what an expression is.
8.0 Logical form
Some statements that, given their grammatical forms, appear to be about objects are in fact about properties. We saw this in Chapter 1, and we’ll see it again in Chapter 7 when we discuss Frege’s ground-breaking insights into arithmetical statements (e.g. “2 + 3 = 5”). Frege was the first to see clearly that logical and grammatical may diverge—he was the first to grasp the very idea of such a divergence. This insight of his is embodied in his statement that the sentence
(WM) “whales are mammals”
isn’t about whales. As paradoxical as it may seem, he was right. WM says that if an object is a whale, then it’s a mammal. But there is no specific object x such that WM says that x is a mammal. A fortiori there is no specific whale x such that WM says that x is a mammal; and for any number n, no matter how high, there are no whales x1....xn such that WM says that xi (1 ≤ i ≤ n) is a whale. So just as Frege said, WM isn’t about whales.
   WM makes a statement, not about whales, but about the property of being a whale. It says that
(WM*) the property of being a whale has the property of being instantiated only by mammals.
   WM* perspicuously represents WM’s meaning. In other words, WM* represents WM’s logical form. WM*’s grammatical form diverges from WM’s grammatical form.
The reason is that WM’s logical and grammatical forms pull apart is that WM contains a quantifier. (Examples of quantifiers are “all birds,” “no man,” “most whales,” “three birds,” and “some individuals.” We’ll define the term “quantifier” in a moment.) Given any statement of English, or any other non-artificial language, that contains quantifiers, the logical and grammatical forms of that sentence diverge. A quantifier is an expression having the property that, if a sentence contains it, that sentence is ipso facto to the effect that the extension of one property has a certain degree of overlap, ranging anywhere from no overlap to total overlap, with the extension of some other property. “All birds have beaks” says that the extension of the property of being a bird is a subset of the extension of the property of having a beak. “Only birds have beaks” says (falsely) that the extension of the property of having a beak is a subset of the extension of the property of being a bird.
   In virtue of a containing a quantifier, a sentence about properties, not about specific objects. Of course, a quantified (quantifier-containing) statement can also be about individuals. But it isn’t in virtue of containing a quantifier that a sentence concerns individuals; and it is in virtue of containing a quantifier that a sentence concerns properties.
   In natural language, quantified sentences are pseudo-objectual statements. They appear to be about objects, but are really about properties. That is why they must be reparsed if their logical forms are to be exposed. It immediately follows that a statement’s grammatical form may diverge from its logical form. Frege discovered both facts and, therewith, created modern analytic philosophy.

8.1 Contextual definition
The fact that grammatical and logical form sometimes diverge is related to the fact some expressions are to be defined contextually. To define an expression contextually is to how, in virtue of containing it, a sentence’s meaning is affected. So, for example, “someone” doesn’t refer to anyone. It doesn’t refer to John or Sally or Jane. That is why, given any proper name N, the statement
(NS) ‹N doesn’t snore ›
is compatible with
(SS) “someone snores.”
   Thus, the meaning of “someone” isn’t given by some rule that pairs it off with this or that individual. In other words, there is no individual N such that the semantic rule for “someone” is:
(WRS)‹Someone has psi› is true just in case N has psi.
Rather, the meaning of “someone” is given by the statement that:
(RS) ‹Someone has psi› is true just in case the property of being a psi is instantiated.
Thus, the logical form SS is clearly displayed by the sentence:
(PS) “the property of being a snorer is instantiated.”
PS’s logical form therefore coincides with its grammatical form. Since SS has a different grammatical form from PS, it follows that SS’s logical form diverges from its logical form. The divergence between SS’s grammatical and logical forms is obviously a consequence of the fact that “someone” must be defined contextually.
8.2 Contextual definition: its scope and limits
Nonetheless, it would be an overstatement to say that whenever a sentence contains an expression that must be defined contextually, it’s grammatical form pulls apart from its logical form. As we’re about to see, every expression is to be defined contextually. Obviously grammatical form doesn’t always pull apart from logical form. Therefore, it isn’t always the case that, in virtue of containing an expression that must be defined contextually, a sentence’s logical and grammatical forms diverge.
   How can it be said that all definitions are contextual definitions? Aren’t there also denotative definitions? (A denotative definition of an expression E says what E means by saying what it denotes.) Isn’t “Socrates” defined denotatively? Yes, it is. There is some object x such that one says what “Socrates” means if, and only if, one says that “Socrates“ refers to x.
   But in saying of some object x that “Socrates” picks out x, one is saying that, in virtue of having the form ‹Socrates has psi›, a sentence S is to the effect that x has psi. “Socrates” refers to Socrates because, the remaining semantic rules of English being what they are, if you wish to attribute the property of being wise to Socrates, you can do so by saying “Socrates is wise”—because, in general, for any property psi, if you wish to attribute psi to Socrates you can do so saying ‹Socrates has psi.› If, in saying “Socrates was wise,” you were really saying that it was Aristotle, not Socrates, who was wise, then “Socrates” wouldn’t refer to Socrates, at least not in that context. In general, to say that E refers to O is to make a statement about effect a sentence’s containing E has on its truth-conditions. More precisely, it is to say that, in virtue of having the form ‹E has psi›, a sentence attributes psi to O, for any property psi.
   
But the logical forms of sentences of the form ‹E has psi› don’t necessarily pull apart from their logical forms. Since there is some object x (namely, Socrates) such that ‘Socrates is tall’ says that x is tall, and since ‹x is tall› has the same form as “Socrates is tall,” the fact that “Socrates” is to be defined contextually does not entail that logical and grammatical form ever diverge.
   So it is only because certain expressions are to be defined contextually that such divergences occur. But which expressions? Those that cannot also be defined denotatively. Whenever an expression can be defined denotatively, a sentence’s logical form will not, by virtue of that sentence’s containing that expression, diverge from its logical form. (But, of course, that sentence’s logical form may diverge from its logical form for some other reason. Thus, the logical form of “Socrates saw someone” diverges from its grammatical form; but the reason for this is that it contains the word “someone.” The occurrence of “Socrates” in that sentence isn’t what induces that divergence.)
   Let E be an arbitrary expression that can be defined denotatively. In other words, suppose there to be some object x such that E is defined by saying that it refers to x. The logical form of ‹E has psi› is: x has psi. In general, to the extent that the logical form a sentence containing E is determined by its containing that expression, that sentence’s logical and grammatical forms coincide. But, since such a sentence’s logical form isn’t determined only by its containing E, and is also a function of the semantics of the other expressions occurring it, its grammatical form may still diverge from its logical form. After all such a sentence may contain an occurrence of “someone” or “nobody” or some other expression that induces such a divergence.
8.3 Frege’s generalization of the concept of a function
As we’ll see in Chapter 7, what made it possible for Frege to revolutionize logic was his insight that grammatical and logical form diverge; and what made the latter insight possible was his generalization of the concept of a mathematical function.
   A mathematical function is a rule that assigns no more than one object to each object falling in a given class. (So “+1” can be thought of as expressing a function or rule that assigns 2 to 1, 3 to 2, etc.)
   According to Frege, the occurrence of “snores” in
(PS) “Plato snores”
is best represented as the open sentence ‹x snores›; and that open sentence is best thought of as expressing a function that assigns the truth-value true to each snorer and the truth-value false to each thing that doesn’t snore. (For brevity’s sake, I’ll henceforth use the words “truth” and “falsehood” instead of, respectively, “the truth-value true” and “the truth-value false.”)
   Here’s the idea. A true sentence results if the variable in ‹x is even› is replaced with an expression denoting an even number and false if it’s replaced with a number that doesn’t denote such a number. (“2 is even” is true and “3 is even” is false.) So we can think of ‹x is even› as assigning truth to two, four, etc., and falsity to one, three, etc. For similar reasons, we can see ‹x snores› as assigning truth to snorer Bob and falsehood to non-snorer Wilma, and so on.
   Frege sees the occurrence of “is taller than” in
(BTM) “Bill is taller than Mary”
as being identical with the open sentence ‹x is taller than y›, and he sees that open sentences as expressing a function that assigns truth-values to ordered pairs of objects. So ‹x is taller than y› assigns truth to the ordered pair <x, y> if x is taller than y and otherwise assigns falsehood to that pair.
   Frege treats:
(BJMP) “Bill is standing between Mary and John”

as comprising the open-sentence ‹x is standing between y and z›; and he sees that open sentence as expression a function that assigns truth to ordered triples of objects—as assigning that truth value to <Bill, Mary, John> just in case Bill is standing between Mary and John.
   In this way, Frege was able to assign a single form to all atomic sentences. An atomic sentence is one that, unlike “Bill is tall and Sally is smart,” doesn’t consist of other sentences and that, unlike “someone snores,” doesn’t contain quantifiers. Non-atomic sentences are molecular. A molecular sentence is one that either consists of other sentences or contains a quantifier. Frege was able to show that, ultimately, all atomic sentences have the form ‹O has psi. › Contrary to first appearances, BTM has the form: the ordered pair <Bill, Mary> has psi, where psi is the property had by such a pair just in case its first member is taller than its second.
   Pre-Fregean logicians saw each of PS, BTM, and BJMP as having a different form from each of the other two, and this made it impossible for them to do anything meaningful in the way of formalizing inferences involving atomic sentences. But Frege didn’t have this problem, since he, unlike them, wasn’t made blind by grammatical surface structure to the underlying structural similarities.
   
Chapter 5
Do We Think in Words?
1.0	Two different ways that knowledge of a language might enhance intelligence
It is obvious that knowledge of a language makes one more intelligent in at least some respects. Consider the thought that authoritarian governments tend to be less responsive to the needs of their constituents than democratic governments. Could one grasp that thought without knowing some language or other? We have, I think, at least some inclination to say “no.” And, more generally, we are reluctant to regard creatures that cannot interact with reality through a language, or in any case through some sort of symbolic medium or other, as being capable of grasping, let alone delineating the consequences of, abstract principles or therefore of thinking about reality in a discursive manner.
   My own view, as we’ll see shortly, is that this is false—that whatever one can grasp through language, one must be able to grasp independently of language. But this, I grant, is a counterintuitive view; and, speaking personally, it was only after trying to defend the negation of that view, and finding that it was impossible to do so, that I came to accept it. Still, our untutored intuitions do, I think, incline us to hold that, but for knowledge of a language (of some kind or other), a creature would be incapable of thinking discursively about the world.
   But untutored intuitions are not always probative. And sometimes they are inconsistent with one another, this being one of those cases. For, while we are reluctant to impute discursive thought to the language-less, we also strongly feel that we sometimes have thoughts of considerable sophistication that we don’t know how to put into words; and, if that’s right (as I personally have no doubt that it is), then it seems to follow that not all discursive thought is language-dependent.
   The purpose of this chapter is to provide a brisk but relatively rigorous answer to the question: Do we think in language?
2.0	Two different versions of the thesis that we think in language
Do we think in language? No. But, before we can say why, there are two very different versions of the view that we think in language.
   Version #1: English speakers think in English; Albanian speakers think in Albanian; etc. In general, people think in the natural languages that they learn. (A “natural language” is one that organically arises through human interactions. So English, Spanish, Arabic, Chinese, etc. are natural languages. A non-natural or “artificial” language would be one that people invent—for example, computer-programmers invent languages to serve their special needs, and so do mathematicians and philosophers. Philosophers invent special notations because natural languages often obscure important features of the logical structure of the meanings that their sentences express.)
   Version #2: We think in an innately known code, a “language of thought.” So although we think in sentences, those sentences don’t belong to English or Spanish (etc.) but rather to some system of symbolism that is hard-wired into us from birth.

3.0	Why version #1 is wrong
Do English speakers think in English, Spanish speakers in Spanish, etc.? No. (We will find that some of the arguments against Version #1 also apply to Version #2.)
3.1	First reason
We can obviously have thoughts that we are incapable of putting into words. This shows that we grasp those thoughts in some way other than by grasping the English sentences that express them. Also, there are occasions where, although we can put into words what we are thinking, doing so requires great effort: we have to think long and hard about which words to use. This shows that thinking is often a prerequisite to using language, which in turn shows that at least some thinking is non-linguistic.
   Astonishingly, many authors (e.g., Ludwig Wittgenstein, Simon Blackburn, John McDowell) deny that we know anything that we can’t readily articulate. “If you can’t say it, you don’t know it,” they say. This presupposes that what we believe is expressed only in the words we utter. But that’s not the case. A given person’s beliefs can be expressed in many ways, and many of them don’t depend on that person’s being able to use words. A person’s knowledge of the differences between x and y may be expressed in that person’s drawings of x and y; or it may be expressed in that person’s movements while he is in the vicinity of x and y; or it may be expressed in some other non-linguistic manner.
   The way that authors such as Blackburn, McDowell, Wittgenstein respond to this is to say that no bona fide knowledge is involved in my painting things accurately—that what is involved is a kind of pseudo-knowledge. This is obviously false. It also overlooks the fact that, but for this “pseudo-knowledge,” we couldn’t know anything about language, since it is only through our ability to differentiate noises, ink-marks, etc., on the basis of their perceptible properties that we can learn, or use, language.
3.2	Second reason
Some kinds of information (e.g., visual information) seem inherently incapable of being fully expressed by sentences of English or of any other natural language. Also, sentences have very different structures from pictures, even when the sentences and the pictures overlap in content. A visual perception of a man wearing a leather jacket has a very different structure from any sentence that describes that experience. For example, such a sentence decomposes into a finite number of distinct parts (words), whereas the sense-perception does not so decompose. (Sentences are digital structures, meaning that they consist of discrete entities. Sense-perceptions are analogue structures, meaning that they don’t.)
   Also, any sentence must be interpreted to be understood. To understand the sentence “there is a man wearing a leather jacket over there,” you must know the relevant semantic rule (i.e., you must know the rules that assign meaning to that sentence). But you don’t have to interpret a visual perception, at least not in the same way. Perceptions are “self-interpreting” in a way that sentences are not.
3.3	Third reason
In order to learn a language, one must already be able to think. To learn English is to learn that certain sounds have certain meanings; and in order to be able to do this, you already have to be able to synthesize information—to make judgments, on the basis of experience, as to what sounds have what meanings. So knowledge of a language presupposes the ability to think.
3.4	Fourth reason
Different sentences can have the same meaning, and a single sentence can have multiple meanings.
   
What you think when you think that Bob loves Mary is identical with what you think when you think that Mary is loved by Bob. But the sentence “Bob loves Mary” is different from the sentence “Mary is loved by Bob,” even though they mean the same thing. So if you thought in English sentences, then the belief you’d have by virtue of accepting the sentence “Bob loves Mary” would be totally different from the belief you’d have by virtue of accepting the sentence “Mary is loved by Bob.” But the belief you have in virtue of accepting the one sentence is identical with the belief you have in virtue of accepting the other.
   Also, if you thought in language, you couldn’t disambiguate ambiguous sentences. If your thinking Bob is dumb (i.e., unintelligent) were identical with there being an occurrence in your mind of the sentence “Bob is dumb,” then your thinking Bob is dumb (i.e., he can’t speak) would be identical with there being an occurrence in your mind of that same sentence going off in your head, and those thoughts would therefore be identical. But they are not identical. So your thinking Bob is dumb (i.e., unintelligent) is not identical with your thinking “Bob is dumb.”
3.5	Fifth reason (similar to reason #4)
People who speak different languages can have the same thoughts. Monolingual Spanish speakers believe that 1 + 1 = 2, and so do monolingual English speakers. But English and Spanish speakers use different sentences to express that truth, showing that thinking that truth cannot be identical with thinking a sentence of English or Spanish or, by obvious extensions of this line of thought, any other language.
3.6	Sixth reason
Understanding sentences involves thought. You must be able to think to understand what is meant by “if snow is cold, then snow is not hot.” This is because, in order to understand that sentence, you must be able to pair it off with the right meaning, and your pairing that sentence off with the right meaning is obviously different from an image of that sentence flashing through your mind. If I hear a sentence of a language that I don’t understand, it may pass through my mind later (i.e., I’ll remember the sounds later, just as songs that one has heard often flash through one’s consciousness), but I won’t know what it means. So understanding a sentence is different from its flashing through your mind. But if your thinking if snow is cold, then snow is not hot were identical with your thinking “if snow is cold, then snow is not hot,” then your having that thought would be identical with that sentence’s flashing through your mind. Since it isn’t, we don’t think in natural language.
4.0	Why version #2 is false
Do we think in some innate code? No. (Some of the arguments that we used against Version #1 obviously apply to Version #2. So we won’t repeat those.)
4.1	First reason
We often think in images (visual and auditory), and the contents of these images seem to have a structure that is fundamentally different from the structure of any sentence. Sentences are “digital” structures, meaning that they decompose into a finite number of distinct parts. Sense-perceptions are non-digital; they are “analogue” structures, meaning that they don’t decompose into discrete parts and are thus characterized by a kind of seamlessness that sharply distinguishes them from sentences.
4.2	Second reason
Knowing a language involves understanding the expressions belonging to it. Understanding such expressions involves knowing the rules that assign meaning to them. One can’t understand any language, including an

innately known one, without knowing such rules. But if one’s thought is entirely dependent on such a language, then one can’t know those rules, or anything else for that matter, without understanding those expressions. Therefore it is viciously circular to hold that we think in an innately known code.
4.2.1	How advocates of the view in question deal with this argument
Advocates of the view that we think in an innate code deal with this problem by saying that, strictly speaking, we don’t understand the sentences of our innate code. We are merely “built to conform” to those sentences. In other words, although we don’t understand those sentences, we are so neurologically structured that they cause us to act in ways that are appropriate to the meanings of those sentences. So if the sentence of my innate code that means fire is hot goes off in my head, that fact will cause me to go near fire if I’m cold and to stay away from it if I’m hot (or some such).
4.2.2	Why this move doesn’t work
If a sentence isn’t understood by so and so, then from so and so’s viewpoint it is not functioning as a sentence. If, as advocates of the viewpoint just presented maintain, nobody understands the sentences that mediate their thoughts, then those sentences aren’t really functioning as sentences and, for all intents and purposes, they cease to be sentences.
   Here’s an analogy. Suppose that you have a book, but that, instead of reading it, you use it as a weapon—you throw it at your roommate, of whose antics you are growing increasingly tired. Even though the thing you are using as a weapon is a book, it is not in this context functioning as a book and, for all intents and purposes, is not a book. Similarly, if nobody understands the sentences that are, supposedly, identical with their own thoughts, then those sentences aren’t really functioning as sentences anymore—they’re functioning more like the copy of War and Peace that, instead of being read, is being hurled at one’s roommate. In any case, to say that our thoughts are sentences that we never understand is to take a very artificial and implausible view.
   So we may tentatively conclude that we don’t think in language, even though, undeniably, knowledge of language enormously enhances at least some of our cognitive capabilities.
5.0	Given that thoughts aren’t identical with sentence-tokens, why is it that knowledge of language enhances cognitive ability and why does it feel as though we think in words?
On your computer desktop, there are various “icons.” By manipulating these icons, you can perform various operations—you can close a document, open your email account, etc. But these icon-manipulations are but representations of changes in patterns of electrical activity to which they bear only an extremely schematic resemblance.
   When I’m thinking—when, for example, I’m trying to solve a problem (especially one connected to my work)—my thoughts often take the form of a voice. I have mental images of spoken words. This also happens when I’m reading. Sometimes it happens that I read one book for a while (e.g., one by Frege) and then start reading another (e.g., one by comedian Dave Barry), and I’m startled as to why Frege would say such things. Then I realize that I’m no longer reading Frege and that I should therefore “switch voices.”
   And, of course, people think with the help of visual imagery. Many a student of calculus, or even of more advanced branches of mathematics, relies on mental images. I know I do. But the images that go through my head when solving some problem aren’t identical with the ratiocinative activities in which my problem-solving thought consists. Taken by themselves, those images are quite feeble. They don’t specify the exact shape of the object I’m thinking about. I’ll use a five-sided figure to stand for a ten-sided figure, since I can’t visualize

the latter. But it doesn’t matter, provided that I can find some mental icon that will stand for the relevant concept. The icon does not itself have to depict the concept or object it represents. It need only be sufficiently differentiated that I won’t confuse it with the image I am using to stand for some other concept of mine.
   But even if I were more visually adept and, for that reason, could produce more exact visual surrogates for the concepts I’m thinking about, my ratiocinative activity couldn’t possibly be identical with any sequence of images. For any given sequence of images, a creature that could experience those images wouldn’t necessarily have any of the concepts that they represent in my thought processes. No matter how conceptually impoverished a creature is, little or nothing follows as to what sorts of images can go off in its head.
   But everything constitutive of consciousness seems to be image-like or, at the very least, to share with images the property of being phenomenologically pregnant. Wittgenstein (1958) concluded from this that thinking isn’t a private psychological act. For reasons that we’ll discuss in the next section, he inferred that thinking consists of engaging in overt behaviors that involve symbols belonging to some public language.
   Wittgenstein’s position is rank absurdity. He’s right, of course, that tickles, itches, etc., aren’t thoughts. But what follows isn’t that thoughts aren’t mental entities. What follows is that thoughts, unlike itches and tickles, aren’t phenomenologically pregnant.
   Incidentally, the mistake Wittgenstein is making here is very similar to a mistake that David Hume makes in connection with the nature of personal identity. David Hume argues that there is nothing to one’s mind other than the conscious events that populate it. His argument is that, when introspects, he only encounters various tickles, pains, and other sensations. This argument assumes that everything there is to know about one’s mind is to be known in the same quasi-perceptual, phenomenology-drenched way in which we know of our sensations. But this assumption is blatantly false. I know that I believe that 2 + 2 = 4, and I know it in a relatively direct way. But it isn’t because I experience some sensation or mental image or other phenomenally pregnant entity that I know this.
   Wittgenstein’s view that thinking consists of manipulating expressions is inconsistent with the fact that, unless one can think, one cannot use expressions meaningfully. If I just bark out sounds, having no idea what they mean, I’m not in any real sense using language. For my noise-making to be speech, it must be guided by a knowledge of what those noises mean.
   Wittgenstein is right that the sensations and images that pass through one’s mind when one is having a given thought do not constitute that thought. But he’s wrong to conclude that thinking isn’t a psychological process. (As previously stated, what he should have concluded is that not all psychological activity consists of images and sensations.) He’s also wrong to conclude that those images categorically have no significant cognitive function. Mental imagery facilitates thought. Thanks to it, we have thoughts that we otherwise simply couldn’t have.
   Given this data, I would suggest the following. Though not themselves constitutive of thought, mental images allow us to manage thought-processes that we otherwise couldn’t manage. Just as one can manipulate otherwise uncontrollable patterns of electrical activity by manipulating the icons on one’s computer desktop, so one can manipulate otherwise uncontrollable patterns of ratiocinative activity by manipulating cognitive imagery.
   There is another point to make. Consciousness is a place where there are different streams of cognitive activity—where otherwise mutually isolated streams of cognitive activity can meet. The processes that create an olfactory or auditory perception are isolated from those involved in reading music or understanding facial expressions. But, in consciousness, sense-perceptions meet with judgments and with intentions to act, and so on. Consciousness has the effect, and maybe the purpose, of integrating otherwise mutually isolated streams of cognitive activity and, therefore, of pooling otherwise discrete bodies of knowledge. Mental imagery improves thought because it enables otherwise compartmentalized ratiocinative activities to borrow information from other similar activities from which they would otherwise be sealed off.
   By virtue of knowing a language, one automatically has at one’s disposal a rich and easily operated system of icons by means of which one can manage one’s cognitive activities in the way just described. This, I would suggest, is why knowledge of a language does so much for thought.

6.0	Wittgenstein on language, thought, and the relationship between the two
Ludwig Wittgenstein (1889–1951) put forth several provocative contentions about language.12 Perhaps the most celebrated of these is his contention that there cannot possibly exist such a thing as a private language. Human beings can devise private codes, he granted. But, Wittgenstein says, any such code must be a translation of an existing public language. It isn’t even theoretically possible, Wittgenstein thought, for there to exist a language that wasn’t created by several interacting individuals.
   Once such a language is created, Wittgenstein grants, a single person can use it on his own—he can go off into the woods and keep records with it. But any case of a single person’s using a language for his own private use is, in Wittgenstein’s view, parasitic on there being, or once having been, a multiplicity of people using that same language.
   Wittgenstein isn’t making the pedestrian point that, as a matter of psychological fact, it would be hard, maybe even impossible, for somebody to single-handedly create a language (other than one that was a translation of an existing language). He’s saying that it’s logically impossible—that such a language is a surd, like a square circle.
   Wittgenstein also held that one can’t think unless one knows a language.13 Wittgenstein seemed to grant that one could have mental states without knowing a language. But he pretty clearly thought that knowledge of a language was a prerequisite for any sort of reasoning.
   If Wittgenstein is right, one cannot think unless one is embedded in a society of some kind. It is logically, and not just psychologically, impossible, Wittgenstein thought, for a human being who isn’t either a current or erstwhile member of a society to think. These contentions, along with Wittgenstein’s arguments for them, are put forth in his book The Philosophical Investigations.
   Wittgenstein provides an interesting argument for his view that there cannot be a private language, which is known, appropriately enough, as the Private Language Argument (PLA). We’ll discuss PLA in a moment. Wittgenstein provides two distinct arguments for the position that one cannot think without knowing a language. Because of the similarities between them, contemporary authors tend not to distinguish these arguments from one another, and they are collectively referred as to the Rule Following Argument.
6.1	Wittgenstein’s first Rule-Following Argument
(RF114) Not all ideation is ratiocinative. For ideation to be ratiocinative, it must be rule-governed. That is, it must be guided by a knowledge of the canons of logic. Thus, thinking involves following rules.
   But there is no psychological condition or event that necessarily accompanies an act of following a rule. To see this, go ahead and follow some rule. (Add two multi-digit numbers together; read some passage out loud.) When you introspect, you may find that you are experiencing these or those feelings or images. But you could obviously follow the rule in question without having such experiences. Thus, following a rule is not a psychological act.
   
   Contrary to what this argument assumes, not all mental states are images or sensations.15 Your belief that 1 + 1 = 2 isn’t such a thing; and your deploying that belief on some specific occasion isn’t identical with your experiencing some image or sensation or series of images or sensations. Not everything in your mind is a fleeting conscious event. Much of what constitutes your mind consists of stable, enduring structures. Your belief that snow is white isn’t a flash in the pan. It’s been there for a while, and will continue to be there for a while and though it gives rise to momentarily conscious events, it isn’t identical with any such event or with any aggregate of such events. Contrary to what Wittgenstein alleges, given only that there is no tickle or itch or other fleeting mental event that necessarily accompanies an act of rule-following, it doesn’t follow that rule following isn’t a psychological act.

6.1.1	Wittgenstein’s second Rule-Following Argument
   (RF2) Consider the sentence “rabid dogs foam at the mouth.” For argument’s sake, let’s suppose that there exists some entity M that is the meaning of this sentence. Let’s also suppose that, without grasping or operating with the sentence “rabid dogs foam at the mouth” or any other expression, you behold M—you grasp it. You see it—through your “mind’s eye,” or some such. Finally, let’s suppose that you not only grasp M, but know it to be true. In other words, you know that rabid dogs foam at the mouth.
   If you can’t see that, given M, Fido can’t be rabid without foaming at the mouth, your grasp of M is, to that extent, useless and as good as non-existent. Thus, so far as you don’t grasp how M bears on other meanings—so far as you don’t grasp its significance, in other words—your grasp of M is useless and might as well not exist. The problem we had with the sentence “rabid dogs foam at the mouth” arises in connection with M. Wanting to explain what it is to understand that sentence, we posited M. But it turned out that M is just like that sentence: it’s useless unless its meaning is grasped. M turned out to be just another symbol—just another cognitively dead symbolic intermediary.
   Meanings are themselves symbols. So unless we already know what it is to understand symbols, positing symbol-meanings doesn’t help us understand the nature of symbol-comprehension. Positing symbol meanings in the hopes of explaining symbol-comprehension is like positing little people inside people’s heads in the hopes of explaining how people think.16 Positing these little people is useless unless it’s already understood how people think. Positing meanings is useless unless it’s already known how symbols are understood.
   
   This argument of Wittgenstein’s bears a striking resemblance to Aristotle’s Third Man Argument (TMA).17 The purpose of TMA is to undermine Plato’s contention that spatiotemporal entities are instances of properties and, in addition, that the latter are not spatiotemporal. It will help if we take a moment to consider Aristotle’s argument (it will soon be clear why the third and fourth sentences are italicized):
   
   (TMA) For argument’s sake, suppose that there is such a thing as the property of being a triangle. Let T1 be that thing. If Platonism is right, T1 must itself be a triangle. Further, if Platonism is right, any case of two objects’ sharing some property is a case of there being some third object of which they’re both instances. Thus, if T2 is some triangle, there must be some third object T3 such that each of T1 and T2 is an instance of T3. But, by the same logic, there must be some fourth thing T4 such that each of T1, T2, and T3 is an instance of T4. And so on ad infinitum.
   
   Aristotle’s argument assumes that properties are instances of themselves—that the property of being a triangle is itself triangular. But that’s precisely what Platonism denies.18 Platonism is the doctrine that spatiotemporal things are but instances of non-spatiotemporal things, the latter being properties. The property of being spatiotemporal is therefore itself non-spatiotemporal and, therefore isn’t an instance of itself. And the property of being a cat obviously isn’t a cat, since cats are spatiotemporal, whereas that property is not.19
   Just as, according to Aristotle, Platonism is struck with the problem of explaining why the property of being a triangle was itself a triangle, so according to Wittgenstein, those who believe in meanings are stuck with the problem of explaining how meanings are understood.
   But meanings are not themselves understood. They’re no more understood than the property of being a cat is a cat. Consider the expression “I.” I’m referring, not to specific occurrences (utterances, inscriptions) of that expression, but to that expression itself—the expression-type, in other words, as opposed to its tokens. The meaning of that expression is some rule that assigns referents to its tokens depending on the circumstances. More precisely, the meaning of “I” is a rule to the effect that a token t of that expression that is uttered by x refers to x. My knowing that “I” has that meaning is part of what enables me to understand utterances of “I’m getting really bored,” “I really like snow-boarding,” etc. But that meaning is not itself understood. Meanings are either grasped or they’re not. There’s no such thing as grasping a meaning but not understanding it.
   
A consequence is that meanings don’t have to be interpreted. It’s incoherent to suppose that Hoigaard (who, let’s assume, is Norwegian) should be able to grasp this meaning, but fail to see that people were referring to themselves when they said “I.” If, upon hearing you say, “I am cold,” Hoigaard has to thumb through his English-to-Norwegian dictionary to figure out what “I” means, then he doesn’t know the meaning of the word “I.”
   This isn’t to say, what would clearly be false, that one automatically recognizes every consequence of every principle that one grasps. People fail to see the consequences of the principles they grasp. In fact, since any given proposition has infinitely many consequences, people fail to grasp infinitely many consequences of anything that they grasp. But to the extent that one’s grasp of a given principle is determinative of what one knows, there isn’t a gap between grasping meaning, on the one hand, and applying it, on the other. And to the extent that one doesn’t see the consequences of some meaning or principle that one grasps, it isn’t because one has failed to interpret it.
   A story will clarify these points. Brown is a highly (but not superhumanly) intelligent person who not only speaks perfect English, but is exceptionally (but, again, not superhumanly) adept at understanding highly intricate sentences. XYZ is a sentence of English that is 100,000 words long but is otherwise normal. XYZ is grammatical, coherent, etc.20 Even though Brown knows the relevant semantic rules, he obviously can’t understand XYZ. But the problem isn’t that Brown can’t interpret the relevant semantic principles. The problem is that, because that sentence is so long, he can’t deploy his semantic knowledge. In and of itself, that semantic knowledge is good to go. But, under the circumstances, it’s weighed down by limitations on Brown’s part that have nothing at all to do with his semantic competence. Brown’s memory isn’t perfect; he can’t keep too many tasks going in his mind simultaneously, even if any given one of them is elementary. These aren’t semantic limitations on Brown’s part. The problem isn’t that he doesn’t know the relevant semantic rules. Nor is it that he hasn’t adequately interpreted the semantic rules that he grasps. The problem is that his grasp of those principles is being inhibited by shortcomings that in no way detract from his semantic competence, even though they do limit his ability to deploy it. To the extent that what Brown knows is determined by his grasping those semantic rules, Brown does understand the expressions to which they assign meaning. But, of course, what Brown knows is a function of many things besides his grasp of those principles.
   Wittgenstein’s idea that meanings, if grasped, must be interpreted reflects his erroneous belief that, whenever one can’t see a consequence of some principle that one grasps, it’s because one hasn’t adequately interpreted that principle. But principles aren’t interpreted. They’re grasped. And, if grasped, they guide judgments. And to the extent that one’s grasp of a principle is determinative of what one knows, those judgments are consistent with those principles. But, of course, one’s grasp of a given principle is but one factor among many determining the course of one’s thought-process; so one’s grasp of that principle may be prevented from eventuating in the judgments in which it would otherwise eventuate. But when that happens, it isn’t because that principle wasn’t adequately interpreted.
6.2	The Private Language Argument
Neither of Wittgenstein’s attempts to show that thinking isn’t a psychological act is probative. They’re interesting arguments, if I’ve interpreted them correctly; and if I haven’t, it’s an interesting question how they ought to be interpreted. But given what we’ve seen, we have no reason to reject the plausible, if not self-evident, position that thinking is a psychological act.
   But, of course, Wittgenstein doesn’t see it this way. Believing himself to have definitively established (the radically absurd principle) that rule-following and, more generally, thought aren’t mental processes, he attempts to show that there can be no private languages. Here is his argument:

(WA21) Imagine the following. Smith is alone on a desert island. He’s always been this way and, therefore, has never learned a language. But he wishes to create one. He thus decides to stipulate that the meanings of expressions X1...Xn are to be respectively, tree, berry, sand, sun, etc. (He also specifies how those symbols

are to be written down. For some reason, he has a notebook and a pen.) He does this all on Monday. We’ll refer to the language Smith creates as “Smithese1.” One of the semantic rules for Smithese1 is to the effect that:

X35: means that the berries on the dark side of the hill are poisonous.

That same day, Smith sees some poisonous berries on the dark side of the hill, and writes X35 down in his notebook. (Let “X35” be our symbol for that particular inscription.) On Tuesday, he reads what he wrote down. Question: is there any way that Smith can misinterpret what he’s written? If he takes “X35” to mean that the sun is out, his interpretation of “X35” will be inconsistent with his Monday intentions. But so what? Since Smith is the only person who speaks Smithese1. So the expressions belonging to it mean whatever he thinks they mean. An English-speaker can’t just decide that “snow is white” means that grass is green, since it is the thoughts (and practices) of people in general, and not of this or that specific person, that decides what is meant by “snow is white.” But in this context, Smith is “people in general.” So his believing that “X35” means that the sun is out is like everybody’s deciding that “snow is white” means that grass is green. And just as “snow is white” would mean that if everybody thought it did, so X35 means that the sun is out because, in effect, everybody thinks it does, the reason being that, in this context, Smith is everybody.
   Thus, the expressions of Smithese1 mean whatever Smith thinks they mean. This means that he can’t be wrong as to what they mean.
   But a symbol that can’t be used wrongly doesn’t mean anything. What makes utterances of “John is a soccer player” meaningful is that they are used wrongly if John isn’t a soccer player. If “John is a soccer player” couldn’t be used wrongly, you couldn’t conclude anything from the fact that such an utterance was correct—you would be no less entitled to conclude that the moon was made of styrofoam than you would to conclude that the dog ate your wig.
   Thus, there are languages only where there are right and wrong ways to use expressions. Since it is only where several people are using a language that there are right and wrong ways of using its expressions, it is only where there are several people that there are languages: all languages are public.
   
   WA is spurious and establishes nothing. The reason that expressions of English (or any other public language) are meaningful is that people remember what they mean. If everybody forgot what “snow” meant, it wouldn’t be of much use. To be sure, where English is concerned, no one person’s forgetting the meaning of a word is going to strip of it meaningfulness, since there are millions of others who still know it. But that only means that English is causally more deeply entrenched than a language, like Smithese1, that only one person speaks. This is not to mention that, if I forget the semantic rules for English, it will be as useless to me as Smithese1 would be to Smith if he forgets the semantic rules of Smithese1. By the same token, if Smith remembers the semantic rules for Smithese1, the expressions of that language will be useful for him. He’ll know not to eat the berries on the side of the hill; he’ll know where the good-tasting aardvarks are; etc.22
   What about Wittgenstein’s point that the expressions of Smithese1 mean only what Smith thinks they mean? A language is a set of semantic rules. If, on Monday, “X35” means that the berries on the dark side of the hill are poisonous, whereas on Tuesday that same inscription means that the sun is out, then the language Smith is using on Tuesday is ipso facto a distinct one from the language he is using on Monday. On Tuesday, he’s speaking Smithese2, not Smithese1. There, “X35” means that the sun is out only if it isn’t an expression of Smithese1. The expressions of Smithese1, then, don’t mean whatever Smith thinks they mean. If his opinions assign new meanings to X1...Xn, those opinions are creating a new language that happens to be orthographically and phonetically coincident with Smithese1; those opinions aren’t assigning new meanings to expressions constituting some existing language. So Wittgenstein is just wrong to say that the expressions of Smithese1 mean whatever Smith thinks they do.23
   Thinking seems to involve following rules. Wittgenstein grants that people think. But since he believes totally absurdly, that rule-following and, therefore, thinking aren’t psychological acts, he is forced to come up

with a different analysis of what thought is. He wrongly says that thought consists in the manipulations of symbols. Given his belief that there aren’t private languages, he holds that to think is to manipulate symbols of public languages.
   Given that RF and WA are spurious arguments for false conclusions, Wittgenstein has given us no good reason to accept this position. In any case, we know it to be an erroneous one. A prerequisite for speaking a language is knowing its semantic rules and being able to operate in an intelligent and, consequently, thought-mediated fashion.


Chapter 6
Russell’s Improvements on Frege’s Work
1.0 Why definite descriptions aren’t singular terms
In Chapter 1, we saw how Frege’s groundbreaking insights into language and logic made it possible for him to solve otherwise unsolvable philosophical puzzles.
   Bertrand Russell (1872–1970) extended Frege’s work. Russell also showed that some important aspects of Frege’s semantics are deeply incoherent, and Russell figured out how to eliminate those incoherencies without in the process sacrificing Frege’s groundbreaking insights.
   Russell’s famous Theory of Descriptions was one of his earliest and most important extensions of, and improvements on, Frege’s work. The theory of descriptions concerns definite descriptions. A definite description expression of the form ‹the phi›, where phi is in the singular. So “the inventor of Velcro” is a definite description, as is “the inventor of bifocals.” But “the people over there” is not a definite description, since “people” is a plural noun.
   Definite descriptions are in the same grammatical category as “Mary” and “Bob” and other proper names. (Note: in this book, very generic proper names—e.g., “Smith,” “Mary,” “Bob”—will often be used. Always assume, for argument’s sake, that they are unambiguous.) Thus, in respect of its grammatical form:
(V): “The inventor of Velcro is intelligent”
is just like
(B) “Bob is intelligent.”
   But we’ve seen that grammatical form and logical form sometimes pull apart. To determine whether this is going on here, let’s take a careful look at what V says.
   V clearly isn’t true if nobody invented Velcro. V isn’t true if several people invented it. (If nine people invented Velcro, one could be an inventor of Velcro, but the inventor of it.) Finally, any inventor of Velcro must be intelligent. So if somebody did single-handedly invent Velcro, V is false if that person is unintelligent and true if that person is intelligent.
   So here’s what V says: at least one person invented Velcro; at most one person did so; and any such person is intelligent. Thus, V says that:
(V*) somebody uniquely invented Velcro, and any such person is intelligent.
   In general:
(DD) ‹ the phi has psi›
says that
(DD*) something uniquely has phi, and any such thing is psi.
   
Even if Bob invented Velcro, (B) and (V) say different things. V would be false in a situation where Bob was intelligent and where some unintelligent person had invented Velcro. But B would be true in such a situation. B and V thus have different truth-conditions. In other words, the conditions that must hold if the one is to be true don’t coincide with those that must hold if the other is to be true. They aren’t true under the same conditions. Therefore, they don’t mean the same thing; they have different semantics.
   An expression’s semantics is its meaning. A semantic rule is one that assigns a meaning to an expression.
1.1 The differences between proper names and definite descriptions
There is some individual x, namely Bob, such that to know how to use “Bob” in a sentence—such that, in other words, to know the semantic rule for “Bob”—one must know that “Bob” refers to x. Thus, there is some individual x such that ‹Bob has psi,› for any property psi, is true iff x has psi.
   But there is no individual x such that ‹the inventor of Velcro has psi› is true iff x has psi. It doesn’t matter what property psi is. But to fix our ideas, let psi be the property of being 7-feet tall, and suppose that Bob is the actual inventor of Velcro (that he’s the person who, in our world, invented Velcro); and suppose that Bob is 7-feet tall. In that case, ‹the inventor of Velcro has psi› is true.
   In light of this, let W be a world that is semantically just like ours—a world where people use the same expressions that we use and use them in accordance with the same rules. Suppose that, in W, Bob is the inventor of Velcro, and Bob is under 7-feet tall. In that case, ‹the inventor of Velcro has psi› is false, even though that sentence has the very same semantics that it has in our world. Thus, there is no individual x such that, to know the semantics of “the inventor of Velcro” is to know that it refers to x. Obvious generalizations of this argument show that, for any property phi, there is no individual x such that the semantic rule for ‹the phi› is to the effect that it refers to x.
1.2 Definite descriptions not referring terms
Definite descriptions aren’t referring terms. No definite description refers to anything. The meaning of “the inventor of Velcro” isn’t given by saying who it refers to, but by saying what whole sentences it mean. What whole sentences containing it mean is given in at least some cases by the rule: “the inventor of Velcro has psi” says that something uniquely invented Velcro, and any such person has psi.” (Why “in at least some cases” as opposed to “always’’? Because, when it occurs in some contexts, which we’ll consider shortly, the relevant contextual definition isn’t the one just given.)
   In general, for any property phi, ‹the phi› is defined, not denotatively, but contextually—that is, by saying what whole sentences containing it mean. And what whole sentences containing it mean is (in general, though not, as we’ll see, in all cases) given by the rule: ‹the phi has psi› is true if there exists something uniquely having phi, and any such thing has psi.
1.3 Contextual definition and the semantics of definite descriptions
Where definite descriptions are concerned, grammatical and logical form pull apart. “Jane is tall” (JT) has the same grammar as “the captain of the volleyball team is tall” (CT). But the propositions they express are structurally very different. JT is, whereas CT is not, such that, for some person x, it is true just in case x is tall.
   Like the semantic rule for “someone,” the meaning of “the inventor of Velcro” is given by saying what whole sentences containing it mean; and in at least some cases ‹the inventor of Velcro has psi› is true if the property of being a Velcro-inventor is uniquely instantiated and, moreover, that property has one instance in common with the property of being a psi.

1.4 The Theory of Descriptions defined
This theory of Russell’s is known as the “Theory of Descriptions” (TD). The essence of TD is given by two assertions: (i) definite descriptions don’t refer to anything; and (ii) in virtue of containing a definite description, a sentence attributes properties to other properties, not to individuals.
   “The inventor of Velcro” doesn’t refer to anyone or anything. “The inventor of Velcro is seven-feet tall” doesn’t attribute the property of being 7-feet tall to anyone. That sentence says that the property of being a unique inventor of Velcro is instantiated and, in addition, that the property of being a 7-feet tall Velcro-inventor is also instantiated. So “the inventor of Velcro is seven-feet tall” is about properties, not individuals. It attributes the property of being instantiated to each of the two properties just mentioned.
2.0 Some arguments for the theory of descriptions: belief reports
Given only what we’ve said about TD, it might not seem like a very important theory. But it opens up new vistas, not just in semantics, but in metaphysics, epistemology, and the philosophy of mind.
   Consider the sentence:

(PFY) “Ponce de Leon believes that the fountain of youth exists.”

PFY is true. (To avoid irrelevant subleties relating to the use of past-tense markers, we’ll assume, falsely but innocuously, that Ponce de Leon is still with us.) It’s a simple historical fact. But does “the fountain of youth” refer to anything? No. There is no fountain of youth. For argument’s sake, suppose that “the fountain of youth” refers to something. It follows trivially that there exists some object such that “the fountain of youth” refers to that object. Given what is meant by “fountain,” “youth,” etc., that object must be a fountain of youth—that is, it must be something whose waters, when inbibed, give one eternal youth. But there is no such thing. So “the fountain of youth” isn’t a referring term.
   But now we have a problem. PFY is true. And it’s therefore meaningful. (Nothing can be true or false without being meaningful.) Before Russell, most philosophers didn’t want to give up on the idea that “the fountain of youth” does refer to something. They saw that it was meaningful, and they assumed, given its grammatical role, that it had to refer to something. This left them with the question: What does “the fountain of youth” refer to? As you might expect, a lot of them said that it exists “as an idea.”
   This doesn’t work. Fountains are not ideas. When people disagree about whether there is a fountain of youth, they aren’t disagreeing about whether some idea exists. I believe that Ponce de Leon was wrong. I believe it because I think that there is no actual fountain having the needed characteristics. For all I know, Ponce de Leon and I might see eye to eye when it comes to what ideas exist.
   Maybe when people say that the fountain of youth exists as an idea, they only mean that we have an idea of such a thing. To have an idea of such a thing is to know what such a thing would be like, were it to exist. Thus interpreted, “the fountain of youth exists as an idea” is just another way of saying: “there is no fountain of youth (but people know what something would have to be like in order to be one)” which leaves us no further along than before.
   Alexius Meinong (1853–1920) proposed a different solution. He said that, although it doesn’t exist, the fountain of youth “subsists.” For a thing to subsist is for it to have some status intermediate between existence and non-existence.
   This doesn’t work. First of all, something either exists or it doesn’t; there is no intermediate condition. Second, even if there is, it doesn’t help, since subsistence is, by Meinong’s own hypothesis, a way of failing to exist, which leaves us no further along than before.
   Russell straightened this whole mess out. Here’s what he said. (What follows will involve a repetion of some points made in Section 1.0.) “The fountain of youth” is a definite description. Definite descriptions don’t refer to anything and neither, therefore, does “fountain of youth.” Definite descriptions are to be defined contextually, and sentences containing them must be reparsed if their meaning is to be made clear.
   
If it’s grammatical form were to be trusted,

(E1) “the fountain of youth exists”

would attribute existence to some fountain. But, since it must be reparsed if its meaning is to be made clear, its grammatical form is not to be trusted. Appropriately reparsed, that sentence becomes:

(E2) “the property of being a fountain of youth is uniquely instantiated.”

The meaning of PFY is therefore:

(E3) “Ponce de Leon believes that the property of being a fountain of youth is uniquely instantiated.”
2.1 Some arguments for the theory of descriptions: negative existentials
Consider the statement:

(N1) “the monster under little Timmy’s bed doesn’t exist.”

N1 is true. But if “the monster under little Timmy’s bed” referred to something, it wouldn’t be true, since there would then exist some monster under little Timmy’s bed to which that definite description referred, in which case, of course, there would exist a monster under Timmy’s bed.
   What’s going on? For now familiar reasons, N1 must be reparsed if its meaning is to be exposed. The needed reparsing yields:

(N2) “the property of being a monster under little Timmy’s bed isn’t instantiated.”

That property exists. (All this means is that there is a way something would have to be in order to be such a monster.) But nothing has that property. N2 doesn’t refer to anything that doesn’t exist. Problem solved.
   This makes it clear how to deal with statements like “the monster under Timmy’s bed doesn’t exist.” The going line before Russell was to say that it says of some object that it doesn’t exist. But that makes no sense at all, since it’s the same as saying “there exists an object (viz. a certain monster) that doesn’t exist.” What it really says, Russell showed, is that a certain existent property (viz. that of being a certain sort of monster, etc.) has a very existent property (viz. that of being un-instantiated).
2.2 Some arguments for the theory of descriptions (continued): identity-statements
Let’s start with a few platitudes about reference. To say that expression R refers to object O is to say that, for any property phi, ‹R has phi› attributes phi to O. If you want to say of Benjamin Franklin (BF) that he’s bald, you can do so by saying “Benjamin Franklin is bald.” (Of course, BF is no longer with us. But to set aside some extremely intricate and, in this context, irrelevant issues relating to tense, let us pretend that Franklin is alive and that we can speak of him in the present tense.) And if you couldn’t attribute baldness to BF by uttering that sentence, then “Benjamin Franklin” wouldn’t refer to BF. If, in saying “Benjamin Franklin is bald,” one was attributing baldness to Aristotle, then, in that context at least, “Benjamin Franklin” would refer to Aristotle.
   
Let’s generalize these points. For any property phi, “Benjamin Franklin” refers to BF (and not to Aristotle, for example) because ‹Benjamin Franklin has phi› attributes phi to Benjamin Franklin; and if one couldn’t attribute phi to Benjamin Franklin by saying ‹Benjamin Franklin has phi› then “Benjamin Franklin” would not refer to BF. Further, if, in uttering that sentence, one was attributing baldness to Aristotle (but not BF), then “Benjamin Franklin” would refer to Aristotle (but not Benjamin Franklin).Thus, for “Benjamin Franklin” to refer to BF it is both necessary and sufficient that ‹Benjamin Franklin has phi› attribute phi to BF. The fact that “Benjamin Franklin” refers to BF is identical with the fact that ‹Benjamin Franklin has phi› attributes phi to Benjamin Franklin, for any property phi.
   In general, expression E refers to O if and only if for any property phi ‹E has phi› attributes phi to O. E’s referring to O may be identified with E’s being such that, in virtue of containing it, a sentence ipso facto attributes a property to O.
   In light of these points, let us look at an age-old puzzle that Russell neatly solved. Benjamin Franklin (BF)

invented bifocals and he was also the first postmaster general. Therefore:

(CB) the inventor of bifocals is identical with the first postmaster general.

It’s also true, of course, that:

(TB) the inventor of bifocals is identical with the inventor of bifocals.

But, whereas TB is trivial, CB is non-trivial.
   The non-triviality of CB is hard to explain if definite descriptions are supposed to be referring terms. As we just saw, “the inventors of bifocals” refers to BF exactly if “Benjamin Franklin has phi” attributes phi to BF. Given that “the inventors of bifocals” does in fact refer to BF, it follows that CB attributes the property of being identical with the first postmaster general to BF. And given that “the first postmaster general” refers to BF, it follows that CB attributes the property of being identical with the inventor of bifocals to BF. And given both of these facts (viz. the facts stated in the last two sentences), it follows that CB says of BF that it has the property of being identical with BF. Which is trivial.
   Frege proposed a famous solution to this. But we’re going to consider Russell’s solution first, since it’s easier to understand Frege’s solution in terms of Russell’s than vice versa.
   According to the theory of descriptions (TD) ‹the inventor of bifocals has phi› says that something uniquely invented bifocals, and any such thing has phi. And, according to TD, ‹the first postmaster general has phi› says that something was a unique first postmaster general, and any such thing has phi. It follows that, if TD is right, CB says the same thing as:

(CB3) “something uniquely invented bifocals, and any such thing is a unique first postmaster general; and something was a unique first postmaster general, and any such thing is a unique inventor of bifocals.”

It is readily seen that CB3 is more succinctly expressed as follows:

(CBR) “there is some one thing that uniquely invented bifocals and was also a unique first postmaster general.”

To sum up, if TD is right, then CB means the same thing as CBR. It is easily verified that, indeed, CB is true exactly if CBR is true. TD gets the right result. Given that CBR is non-trivial—given that historical knowledge is needed to know it—TD readily explains why CB is non-trivial.

2.3 Some arguments for the theory of descriptions: positive existentials
For argument’s sake, suppose there to be some non-existent object O such that

(E1) “the fountain of youth exists”

says that O exists. In that case, there ipso facto exists nothing to which E1 attributes existence. Thus, if it is to say anything at all, E1 must attribute existence to some existing object. Thus, supposing that E1 says of some object that it exists, a precondition for E1’s saying anything is that the object in question exist. But in that case, we could conclude from the mere fact that utterances of E1 are meaningful that E1 is true. Thus, a consequence of supposing that E1 says of some object that exists is that E1 is not only true, but trivially so.
   But, in actuality, E1 is both false and non-trivial. It’s false since there’s no fountain of youth. It’s nontrivial since, to know whether it’s true, is isn’t enough to know what it means—let alone to know that it has a meaning.
   The right analysis is the one proposed by Russell. It says that the property of being a fountain of youth is instantiated. Though nothing has it, the property of being a fountain of youth exists. In general, ‹the phi exists› doesn’t make the absurd claim that some non-entity exists; nor does it make the trivial claim that some entity exists: it makes the non-absurd, non-trivial claim that the property of being a phi is instantiated.
3.0 The incoherencies in Frege’s semantic system
Let us now consider how Frege deals with just-described puzzle concerning identity. This will expose some profound problems with Frege’s semantics, which we will discuss.
   Benjamin Franklin (BF) invented bifocals and he was also the first postmaster general. Therefore:

(CB) the inventors of bifocals is identical with the first postmaster general.

It’s also true, of course, that:

(TB) the inventor of bifocals is identical with the inventor of bifocals.

But, whereas TB is trivial, CB is non-trivial.
   A moment ago, we considered Russell’s solution to this problem. Now we’re going to consider Frege’s solution. Frege’s solution is much more congenial to commonsense. But, when scrutinized, it turns out either to coincide with Russell’s solution or to be totally incoherent.
3.1 Sense vs. reference
Here is Frege’s solution:
(FR) “The inventor of bifocals” is a referring term; it picks something out. That expression refers to a given thing if and only if that thing has the property of being a unique bifocal-inventor. If a given thing didn’t invent bifocals then “the inventors of bifocals” doesn’t refer to it. If lots of different individuals invented bifocals, then “the inventors of bifocals” doesn’t refer to anything. (If ten people collectively wrote War and Peace, it would be wrong to speak of the author of that book.) And if a given thing did uniquely invent bifocals, then “the inventors of bifocals” does refer to it.
   So there are two dimensions to the semantics of “the inventors of bifocals.” There is what it refers to: this is the referent of “the inventors of bifocals.” (Sometimes “reference” is used instead of “referent.”) And there’s the property that a thing must have to be its referent; this property is the sense of that expression. The referent is BF, and the sense is the property of being a unique bifocal inventor.
   
Analogues of these points hold with respect to “the first postmaster general.” There is its referent (which is BF); and there is its sense (which is the property of being a unique first postmaster general).
   The reason that TB is non-trivial is that, although the definite descriptions in it have the same referent, they have different senses. A comparison may help. Imagine that you’re looking at a certain person in the distance. That person is in fact Ralph, but you don’t know it, because he’s so far away and also, let us suppose, because he is (for reasons that aren’t important) wearing a suit of armor. You see that he is doing jumping jacks. Later Ralph is standing right in front of you and, of course, you see him. He’s wearing a plaid shirt. Once again, he’s doing jumping jacks.
   The first visual perception has the same object as the second. And each of those perceptions says of that object he or she is doing jumping jacks. But those two perceptions pick out that object in different ways. In the first case, that object is presented to you as something that has one set of properties (it’s far away, wearing a suit of armor, etc.); in the other case it’s presented as having a different set of properties (it’s nearby, is wearing a plaid shirt, etc.). And that’s why, even though those perceptions have the same object, and even though both attribute the property of doing jumping jacks to that object, those perceptions tell you different things.
   The relationship between “the inventors of bifocals” and “the first postmaster general” is to be understood along similar lines. They have the same object (referent); but they pick that thing out through different bodies of information. That’s why ‹the inventors of bifocals has phi› and ‹the first postmaster general has phi› tell you different things, even though they attribute the same property (phi) to the same object (BF).
3.2 The partial collapse of Fregeanism into Russellianism
This all seems not only plausible, but practically self-evident.
   But it’s false and, indeed, incoherent. Let’s consider the two sense-perceptions discussed in FR. The one perception tells you that there is something in the distance, wearing a suit of armor, etc., and that thing is doing jumping jacks. So the sense in which Ralph is the object of that perception is that your perception describes Ralph. Your perception says: “something or other is over there, in the distance, wearing a suit of armor, [etc.].” Who (or what) fits that description? In other words, who has the relevant properties? Ralph. So Ralph is the object of that perception in the sense it describes him.
   The information borne by that perception has the form “something has such and such properties [it’s wearing a suit of armor, etc.], and any such thing is doing jumping jacks.” Thus, the content of that perception is given by an existence-claim (a claim of the form “something has phi”). Ralph uniquely satisfies that existence-claim. (In other words, he and he alone has the relevant property.) And it is in virtue of his doing so that he is the object of the perception in question.
   The same thing mutatis mutandis is true of your second perception. The information borne by that perception is along the lines of “something has thus and such properties [it’s standing nearby, is wearing a plaid shirt ,etc.], and any such thing is doing jumping jacks.” Ralph is the object of that perception by virtue of the fact that he and he alone has the relevant properties—that he and he alone is a thing standing in the relevant place while wearing a plaid shirt, etc.
   In general, when a given thing x is picked out by way of descriptive information, what’s really going on is that some statement of the form “something has such and such properties” is being affirmed (not necessarily verbally), and x is what fits the description.
   If we bear this point in mind, we find that, so far as it isn’t totally incoherent, Frege’s analysis collapses into Russell’s. Consider the sentence:

(IB) “the inventor of bifocals is tall.”
   
   By Frege’s own admission, “the inventors of bifocals” picks something out if and only if something fits the relevant description (i.e., if and only if something is a unique inventor of bifocals). And if there is a unique inventor of bifocals, that thing, whatever it is, is the thing to which “the inventors of bifocals” refers. Supposing

that there is such a thing and that x is it, IB describes x as being tall. It goes without saying that, if there is no unique inventor of bifocals, then there is no way that IB can be true. (Frege himself emphasizes this last point. And he’s right. There’s no way that “the elephant in the corner is eating peanuts” can be true if there’s no elephant in the corner.)
   The upshot is that IB is true if and only if:

(IB*) something uniquely invented befocals, and any such thing is tall.

But what does the Theory of Discriptions (TD) say about IB? According to TD, the meaning of IB is: IB*. So Frege’s theory collapses into Russell’s.
   By obvious extensions of this, it follows that, if Frege’s theory is right, then CB’s meaning is identical with that of CBR. So Frege’s theory accounts for the non-triviality of CB in the same way as Russell’s theory (as TD).
3.3 Why Fregeanism doesn’t completely collapse into Russellianism
As we know, Russell’s theory is pretty good. The same is therefore true of Frege’s, at least to the extent that it coincides with Russell’s. The problem is that Frege’s theory doesn’t entirely coincide with Russell’s. Unlike Russell, Frege took it for granted that definite descriptions are just what, given their grammar, they appear to be: referring terms. We’ve just seen that, if Frege’s own theory of why CB is non-trivial is to be correct, then TD must be the right account of how definite descriptions work. But the essence of TD is that definite descriptions are not referring terms. It would obviously be incoherent to accept TD while also believing that definite descriptions are referring terms. We’ve just seen that it is precisely this incoherence that Frege is accepting, however unwittingly, in holding that definite descriptions are sense-bearing referring terms.
3.4 The incoherencies in Frege’s semantics
Frege’s view that definite descriptions are referring terms that have both sense and reference is one that has a lot of intuitive appeal, and people will hold onto it unless given very strong arguments to the contrary. Since the arguments just given may not be enough for some, here is another.
   Consider the following four sentences:

(1) “Smith believes that the inventor of bifocals is 6-feet tall.”
(2) “Smith believes that the inventor of bifocals is not 6-feet tall.”
(3) “Smith believes that the first postmaster general is 6-feet tall.”
(4) “Smith believes that the first postmaster general is not 6-feet tall.”
   
   Were Smith to believe both 1 and 4, he would not, at least not for that reason alone, be irrational. Of course, given the empirical fact that some one person uniquely invented bifocals and was a unique first postmaster general, one of those beliefs must be wrong. But taken by themselves, the italized parts of 1 and 4 are consistent with each other. At the same time, neither entails the other. In other words, each is compatible with the negation of the other. So supposing that Smith is rational and that 1 is true, it doesn’t follow that 3 is true or that 3 is false.
   For the time being, let’s suppose with Frege that definite descriptions are referring terms. In that case, the definite description in 1 co-refers with the definite description in 4. They both refer to BF. 1 says of BF that he has the property of being believed by Smith to be 6-feet tall; and 4 says of BF that he has the property of being believed by Smith to not be 6-feet tall. So Frege’s view that definite descriptions are referring terms has the false consequence that 1 and 4 cannot both be true if Smith is rational.
   Here’s another way of stating the problem. According to Leibniz’s Law, if x is identical with y, then x has a given property if and only if y too has that property. Leibniz’s Law isn’t directly concerned with language.

But it has a semantic corollary, namely, that if two expressions co-refer, they can be inter-substituted salva veritate. This means that, if E and E* co-refer, and S is a sentence containing E, then replacing E with E* will result in a sentence that is true if S is true and false if S is false. (It’s assumed that the expressions being inter-substituted belong to the same language, are inflected in the same way, etc.) “Cicero was a Roman orator” is true; and so, therefore, is “Tully was a Roman orator,” given that “Tully” co-refers with “Cicero.” “Cicero was a 19th-century logician” is false; and so, therefore, is “Tully was a 19th-century logician.” Another way of stating this principle is that “inter-substituting co-referring terms preserves truth-value.” The original sentence (“there is water in my glass”) is true (false) iff the new sentence (“there is H2O in my glass”) is true (false).
   Supposing, as Frege does, that “the inventor of bifocals” and “the first postmaster general” are referring terms, then, given that those expressions co-refer, replacing the one with the other should preserve truth-value. But it doesn’t. 1 may be false if 3 is true and vice versa.
   TD solves this problem. According to TD, the meanings of 1–4 are, respectively:

(1R) “Smith believes that something uniquely invented bifocals, and any such thing is 6 ft tall.”
(2R) “Smith believes that something uniquely invented bifocals, and any such thing is not 6 ft tall.”
(3R) “Smith believes that something was a unique first postmaster general and any such thing is 6 ft tall.”
(4R) “Smith believes that something was a unique first postmaster general and any such thing is not 6 ft tall.”

1 doesn’t entail 3, and 1 is compatible with 4. 2 doesn’t entail 4 and 2 is compatible with 3. (This is the hard data.) 1R doesn’t entail 3R, and 1R is compatible with 4R. 2R doesn’t entail 4R and 2R is compatible with 3R. So TD is compatible with the hard-data, whereas Frege’s theory is not. Frege was aware of the problem just described, and he added an epicycle to his theory that he hoped would save it. It did not, as we’ll now see.
3.4.1 Frege’s cover-up: the creation of intensional contexts
Frege made profound contributions to logic and the philosophy of language. None of these disciplines even existed in anything like their modern form before he invented them, and most of the principles that he laid down in doing so hold up.
   But Frege, like everyone else, had his less than stellar moments. Unfortunately, his blunders are treated with the same reverence as his discoveries. For this reason some very wrong and incoherent ideas of his are alive and well and continue to retard intellectual progress.
   One of the worst of these is Frege’s distinction between “extensional” and “intensional” contexts. An extensional context is an expression that is “substitution tolerant.” An expression E is substitution-tolerant if replacing any one of the referring terms occurring in it with a co-referring term yields a true sentence iff the sentence that hosted E was true and a false sentence iff the sentence hosted E was false. So “Smith is tall” is such a context, since replacing “Smith” a co-referring term will result in a sentence that has the same truth-value as the first. An intensional context is one which is substitution-intolerant.
   A story will help us move forward. The prettiest woman on the planet is also the most evil person on the planet. Smith wants to marry the prettiest woman on the planet, whoever that might be, but wants nothing to do with anyone who is evil. In that case:
(1) “Smith wants to marry the prettiest woman on the planet”
is true, but
(2) “Smith wants to marry the most evil person on the planet”
is false. And, of course,
(3) “it is necessarily the case that the prettiest woman on the planet is identical with the prettiest person on the planet”

is true, whereas
(4) “it is necessarily the case that the prettiest woman on the planet is identical with the most evil person on the planet”
is false.
   According to Frege, 2 is what results when a referring term in 1 is replaced with a co-referring term, and 4 is what results when a referring term in 3 is replaced with a co-referring term.
   But this isn’t what is going on. What (1) really says is that:
(1*) Smith wants it to be the case that Smith is married to a woman who is prettier than any other.
And what (2) really says is that
(2*) Smith wants it to be the case that Smith is married to somebody who is more evil than anyone else.
   (1*) and (2*) thus make it clear what (1) and (2), respectively, are actually saying. In other words, (1*) and (2*) expose the logical forms of (1) and (2). Notice that, in (1), the grammatical object is an expression referring to a person (“the prettiest woman on Earth”), whereas in (1*) the grammatical object (the italicized part) is an expression referring to a proposition. And in (2), the grammatical object is an expression referring to a person (“the most evil person on the planet”), whereas in (2*) the grammatical object (the italicized part) is an expression referring to a proposition.
   Thus, (1*) makes it clear that, if (1) is true, the object of Smith’s desire is not a person, but rather a proposition. In other words, Smith wants a certain proposition to hold, namely, that Smith is married to a woman who is prettier than anyone else. Similarly, (2*) makes it clear that, if (2) is true, the object of Smith’s desire is not a person, but a proposition, namely, that Smith is married to somebody who is more evil than anyone else. Since those two propositions are different, the fact that one of them has the property of being desired to be true by Smith, whereas the other does not lack that property, does not constitute a violation of Leibniz’s Law.
   Similar points hold in connection with 3 and 4. The real meanings of those sentences are, respectively:
(3*) it is necessarily the case that any woman who is prettier than every other woman is prettier than every other woman.
and
(4*) it is necessarily the case that any woman who is prettier than every other woman is also more evil than every other person.
   (3*) attributes the property of being necessarily true to one proposition (the one meant by the italicized part), and (4*) expresses that same property to some other proposition. Since those propositions are distinct, the fact that the one proposition is necessarily true doesn’t entail that the same is true of the other; and there is thus violation of Leibniz’s Law.
   Thus, there are no intensional contexts. (In other words, all contexts are substitution-tolerant.) Whenever two expressions that appear to refer to the same individual cannot be inter-substituted, they actually refer to different propositions. Nonetheless, the term “intensional” is useful as a way of abbreviating otherwise hard-to- state truths. Thus used, an “intensional context” in which expressions that otherwise refer to individuals (e.g., “Benjamin Franklin”) refer to propositions. An expression occurring in an intensional context does so intensionally. A context that isn’t intensional is extensional, and expressions occurring in it do so extensionally.
   A brief review will help us identify one last problem with Frege’s system. Frege’s distinction between sense and reference embodies a failure to distinguish between reference and quantification.  What Frege believes to

be sense-bearing referring terms (e.g., “the person who invented Velcro”) are quantifiers. (That is why “the man who invented Velcro is wealthy” is, by Frege’s own admission, equivalent with “somebody or other uniquely invented Velcro, and any such person is wealthy”). Frege’s distinction between intensional and extensional contexts embodies a failure to see that expressions that, given their grammatical properties, appear to refer to some one individual in fact refer to distinct propositions. Even though the inventor of bifocals is identical with the first post-master general,
(A) “Fred believes that the inventor of bifocals is smart”
may be true, even if
(B) “Fred believes that the first post-master general is smart,”
is false.
   The italicized expression in A refers to one proposition; its counterpart in B refers to a different proposition. (We’ll refer to the italicized expressions in A and B, respectively, as A* and B*). But B* is what results when a referring term is replaced with a co-referring term. According to the principle of special compositionality (PSC), A* and B* should co-refer.
   PSC says that what an expression refers to depends on what its parts refer to. “Mary’s favorite person” refers to Smith, whereas “Billy’s favorite person” refers to Jones. Why the difference in reference? Because “Mary” and “Billy” don’t co-refer, and what a given expression refers to affects what expressions containing it refer to. For the same reason mutatis mutandis, if “Crusher” is Mary’s nickname, and thus co-refers with “Mary,” “Crusher’s favorite person” co-refers with “Mary’s favorite person.” PSC is the obviously correct semantic corollary of the obviously correct principle that replacing equals with equals results in equals.
   But Frege’s semantics violates PSC. According to it, B* is what results when a referring term in A* is replaced with a co-referring term, and yet A* and B* don’t co-refer. Russell’s system doesn’t have this problem. Russell said, correctly, that A* and B* are contractions of, respectively:
(A#) “some smart person single-handedly invented bifocals”
and
(B#) “some smart person post-master general before anyone else.”
   It didn’t even occur to Frege to take anything at all like Russell’s position. To compatibilize his system with PSC, Frege said that, when expressions occur in intensional contexts, they undergo reference-shifts. According to Frege, “the inventor of bifocals” ordinarily refers to Benjamin Franklin (BF); in other words, its so refers when it occurs in extensional contexts. But when it falls within the scope of one intensionality-inducing operator, it refers to the sense of “the inventor of bifocals.” (An intensionality-inducing is what most other authos refer to as a “non-extensional connective.” It is an operator having the property that any sentences or open-sentences falling within its scope are substitution-intolerant.) “Fred believes” is such an operator. Given that he insists on seeing definite descriptions as sense-bearing referring terms, Frege has no choice but to take this desperate measure: if he doesn’t, his system violates PSC, in which case it’s false, since PSC is true.
   Thus, if Frege’s system is right, then the occurrence of “the inventor of bifocals” in
(C) “Fred believes that Larry believes that the inventor of bifocals is smart”
refers, not to BF, nor yet to the sense of “the inventor of bifocals,” but to the sense of an expression that denotes the sense of that expression.
   
For the same reason mutatis mutandis, a consequence of Frege’s system is that no two of the occurrences of “snow” in
(D) “snow is white, but Brad thinks that snow is green, even though Brad is convinced that Mary thinks that snow is purple”
co-refer, and only one of those occurrences (the first one) refers to snow. In addition to being radically counterintuitive, Frege’s position is logically and methodologically indefensible (or so I argue in Kuczynski (2007) and other places).
4.0 The theory of descriptions revisited: the wide-scope/narrow-scope distinction10
Let us refer to sentences containing definite descriptions as “D-sentences.” So a D-sentence is any sentence of the form ‹...the phi...› There is a certain sub-class of D-sentences that are systematically ambiguous. One of the virtues of the theory of descriptions is that it, unlike its Fregean competitor, accounts for the fact that these sentences are ambiguous and it also accounts for the exact way in which they are ambiguous.
   In this context, it will be helpful to remember that an open sentence is an expression that contains a free variable, and is therefore neither true nor false, but is otherwise just like a sentence. So ‹x is a human being› is an open-sentence; so is ‹x is even. › These open sentences are “true for” some values of their free variables. (The first is true for “Socrates,” “Plato,” etc. The second is true for “2,” “4,” etc.) But it must be emphasized that an open sentence is not itself true or false. (In this context, the word “sentence” will be short for “sentences or open sentences.”)
   An expression (or class of expressions11) is said to satisfy an open sentence if a true sentence results when that expression replaces the free variables in that sentence. Thus, “two” satisfies the open sentence “x is an even number,” whereas “Mr. T” does not satisfy it, and neither does “three.”
4.1 Scope, operators, and syntactic ambiguity
The semantics of these sentences is to be understood in terms of the concept of scope.
   Scope is a property of operators—that is, of expressions that, given sentences or open-sentences, form new sentences. So “John believes that” is an operator, since, when joined with “grass is green,” it yields the sentence “John believes that grass is green.”
   All quantifiers are operators. Examples of quantifiers are “all humans,” “some triangles,” “most dolphins.” So are their counterparts in formalized extensions of English (e.g., “given any human being x,” “for some triangle y,” etc.). Why is “all humans” a quantifier? First of all, given a predicate (e.g., “are tall”), “all humans” yields a sentence (“all humans are tall”). And predicates are all open sentences (e.g., “are tall” can be thought of as synonymous with “x is tall”). Given that “all humans” can be thought of as synonymous with “given any human x,” it’s clear why “all humans” is an operator. When coupled with the predicate (= open sentence) “are tall” (= “x is tall”), “all humans” (= “given any human x”), yields the sentence “all humans are tall” (= “given any human x, x is tall”).
   All conjunctions (e.g., “and,” “because,” “or,” “not”) are operators. And, “because,” and “or” are two-place operators, meaning that, given a pair of sentences as input, each yields a new sentence as output. Thus, given the pair of sentences (“grass is green,” “snow is white”), “and” yields the sentence “grass is green and snow is white.” Where “because” is concerned the pair must be ordered, since “grass is green because snow is white” doesn’t have the same meaning as “snow is white because grass is green.” It’s a matter of debate whether “are” and “or” operate on ordered, or unordered, sentence-pairs. “Not” is a one-place operator. Given the sentence “snow is white,” “not” yields a new sentence (“snow is not white”).
   In light of these points, consider the sentence:

(1) “In New York, someone gets mugged every five minutes.”
This is ambiguous.12 It could mean either:
(2) In New York, given any given five-minute interval x, there is some individual y, such that y gets mugged during x.
or
(3) In New York, there is some individual y such that, given any given five-minute interval x, y gets mugged during x.
(2) says that, in New York, no five-minute interval is free of muggings. It doesn’t say that there is some one unfortunate individual who gets mugged every five minutes. But that is what (3) says.
   The difference results from the fact that the relevant operators—the boldfaced and underlined expressions—are ordered differently. In (2), the operator “given any five-minute interval x” has wide-scope with respect to the operator “there is some individual y” (or, equivalently, the latter operator has narrow scope with respect to the former), whereas in (3) it’s the other way around.
   (1) isn’t ambiguous for the same reason as “Jim is dumb” or “Sally is going to bank.” Those sentences are ambiguous because the words “dumb” and “bank” are ambiguous. By contrast, none of the expressions occurring in (1) is ambiguous. (1) is syntactically ambiguous. It has multiple meanings because it stands for two distinct syntactic arrangements of expressions that are themselves unambiguous.
   The stock example of syntactic ambiguity is:
(4) “everyone loves someone,”
which could mean either
(5) given any person x, there is some person y, such that x loves y,
or
(6) there is some person y, such that given any person x, x loves y.
(5) says that no person is without love for some person or other. It doesn’t say that some one person is the object of every person’s love. But that is what (6) says.
   Grammatical surface structure makes it unclear how much scope operators actually have. For example, the scope of “because” in “snow is white because grass is green” includes both “snow is white” and “grass is green,” even though grammatical surface structure would suggest otherwise. And the scope of “not” in “snow is not white” includes “snow is white.” (“Not” = “it is not the case that.” “Snow is not white” = “it is not the case that snow is white.”) There would be no syntactically ambiguous sentences if grammatical surface-structure didn’t fall short in this respect.
   The fact that D-sentences are syntactically ambiguous can be understood in terms of these facts. The sentence:
(i) “Smith believes that the guy who is trying to kill him, after torturing him for several days, is well-disposed towards him.”
This sentence is ambiguous. It could mean either:

(ii) Somebody x wants to kill Smith, after torturing him for several hours, and Smith believes that x is well disposed towards him
or
(iii) Smith believes that somebody x wants to kill him, after torturing him for several hours, and also that x is well disposed towards him.
(iii) has little chance of being true. People don’t believe that people who are trying to torture and kill them are well disposed towards them. But it’s easy to think of a situation where (ii) is true. Jerry is Smith’s best friend. Jerry is actually very evil. But, like many evil people, he has mastered the art of appearing well-intentioned; and unbeknownst to Smith, Jerry wants to torture and kill him.
   Whenever a definite description falls within the scope of a modal or epistemic operator, the result is a syntactically ambiguous sentence. Before Russell came along, such syntactic ambiguities, not being seen for what they were, led people to accept the most rank absurdities. Consider the sentence:
(iv) Jerry is looking for the fountain of youth.
   Obviously there doesn’t have to exist a fountain of youth for (iv) to be true. People look for things that don’t exist. Russell saw this, and saw that, for this reason, (iv)’s meaning is:
(v) Jerry wants it to be the case that there exist a (unique) fountain of youth x, and, moreover, that he (uniquely) discover any such fountain.13
Pre-Russellian philosophers and contemporary non-Russellianism philosophers take (iv) to say that there exists a fountain of youth that Jerry is looking for. This is Nathan Salmon’s (2005) position. Salmon qualifies his position by saying that the fountain of youth, though existent, is a “mythical” object. But, since mythical objects don’t gush water, let alone immortality-giving water, Jerry won’t consider his search to have to an end when he discoveries the non-entity that Salmon describes. Given Russell’s insight, there’s no need to accept Salmon’s rather doubtful position.
   Because of his failure to grasp the implications of the wide-scope/narrow-scope distinction, another well known 20th century philosopher, W.V.O Quine (1908–2000), advocated the highly implausible view that “necessary,” “possible,” and modal terms in general, have no coherent meanings and that statements such as “it’s possible that there will be rain” and “it’s a necessary truth that triangles have three sides” are either false or meaningless.14
   Here is his argument.15 For argument’s sake, suppose that the concepts expressed by “necessary” and “possible” are meaningful. In that case:
(FB) “it’s a necessary truth that the inventor of bifocals was the inventor of bifocals”
expresses a truth, even though
(BF) “it’s a necessary truth that the inventor of bifocals was the first postmaster general”
expresses a falsehood. Given the truth of FB, says Quine, it follows that the inventor of bifocals necessarily has the property of being identical with the inventor of bifocals. It follows by Leibniz’s Law16 that the first postmaster general also has the property. But if he did, then BF would be true, which it is not.
   With one exception, all of our assumptions were clearly correct. Leibniz’s Law holds, and FB is a necessary truth if ever there was one. Since the only remaining assumption is that “necessary” and “possible” express coherent concepts, that assumption is wrong. It follows that all statements to the effect that something is possible or necessary or impossible (etc.) are either meaningless or false.
   
Arthur Smullyan (1948) saw that, given Russell’s points about definite descriptions, there is no problem. BF is ambiguous between wide-scope and narrow-scope readings, these being:
(BFWS) it’s a necessary truth that some one individual uniquely invented bifocals and, in addition, was the first postmaster general
and
(BFNW) some one individual x uniquely invented bifocals; and some individual y was uniquely a first postmaster general
and it’s a necessary truth that x = y.
BFWS is straightforwardly false. BFNW is true. As a whole, it is not necessarily true. (It didn’t have to be the case that some one person was a bifocal inventor and postmaster general.) But the underlined part is necessarily true: given any individual x, and given any individual y such that x is identical with y, it is a fact that x must be identical with y.17

Chapter 7
Some Remarks on Logicism and on Frege’s
Formalization of Logic
1.0	What did Frege do?
Pre-Fregean formal logic wasn’t so much a discipline as it was a collection of rules of thumb. This was because Frege’s predecessors weren’t able to systematize the few results they were able to obtain, the reason being that they didn’t see the principles underlying those results. But Frege saw those principles, organized those results, and added new ones of his own. In so doing, Frege released logic from the holding pattern it had been in for the previous two thousand years.
   Unlike his predecessors, Frege saw that a sentence’s logical form may diverge from its grammatical form. (In other words, he saw that a sentence S1 may be such that what S1 actually means is different from what S1’s grammatical structure suggests that it means.) And in many cases he figured out how to realign logical and grammatical form. (In other words, given many a sentence S1 such that S1’s logical and grammatical forms diverge, Frege was able to produce a sentence S2 such that S2’s logical form coincides with S1’s and such that S2’s logical and grammatical forms coincide.) It was because of these insights of his that Frege, unlike all of his many predecessors, successfully formalized inferences involving quantified generalizations.
   But what does this mean exactly? What is it to “formalize” an inference, and what is a “quantified generalization”?
1.1	What is it to formalize an inference?
Any deductive inference can be thought of as being expressed by a single sentence. For example, the inference from:

(a) “snow is white and grass is green”

to

(b) “grass is green”

corresponds to:

(c) “if snow is white and grass is green, then grass is green.”
   
   To formalize an inference is to show that the corresponding conditional is equivalent to a sentence that is an instance of an open-sentence all of whose instances are true. So in this particular case we need to find an open-sentence all of whose instances are true and of which (c) is an instance. Here is just such an open sentence:

(d) ‹if P and Q, then Q.›
   
   (c) is equivalent with itself. (All sentences are self-equivalent.) (c) is an instance of (d). So we’re done.

1.2	Frege on quantification
The inference just formalized contained no sentences containing any quantifiers. Frege’s successors had some success formalizing such inferences. They knew, for example, how to do what we just did. But they had little success with inferences containing sentences involving so much as a single quantifier (e.g., “all people smoke cigars”); and they had no success in the way of formalizing inferences containing sentences containing multiple quantifiers (e.g., “one can fool all of the people some of the time, and some of the people all of the time, but not all of the people all of the time”). But Frege did succeed in formalizing such inferences.
   We will henceforth refer to any inference involving at least one quantified sentence as a quantified inference. (So a quantified inference is an inference that involves so much as a single sentence containing a single quantifier.)
   To move forward, we must note that Frege sees:

(SS) “someone snores”

as comprising the function ‹x snores› along with another function. This other function is a “second-order” function: it is a function that assigns objects to functions. Those objects are truth-values. (A sentence has the truth-value true if it’s true and the truth-value false if it’s false.) Frege sees ‹x snores› as expressing a function F that assigns truth or falsehood to a thing depending on whether that thing snores. And he sees “someone” as expressing a function G that assigns truth or falsehood to F depending on whether there is anything to which F, in its turn, assigns truth. If there is some x such that F assigns truth to x, then G assigns truth to F; otherwise G assigns falsehood to F.
   This is a way of saying that “someone snores” is true just in case the property of snoring is instantiated. Since this is in fact precisely what SS says, Frege’s analysis is correct.
   Frege analyzes other quantifiers along similar lines. “Everything” expresses a function G that assigns truth or falsehood to a function F depending on whether there is something to which F assigns falsehood. If there is no object x such that F assigns falsehood to x, then G assigns truth to F; otherwise it assigns falsehood to F.
   Consider the sentence:

(SI) everything is self-identical.

Frege sees SI as saying:

(SI2) for any x, x is identical with x.

The occurrences in SI2 of “for any x” and “x is identical with x” correspond, respectively, to the occurrences in SI of “everything,” and “is self-identical.”
   Frege sees the italicized part of SI2 as expressing a function F that assigns truth to an object if that object is self-identical, and he sees the boldfaced part as expressing a function that assigns falsity to F if there is some individual to which F assigns falsity and that otherwise assigns truth to F. This is a way of saying that “everything is self-identical” says that the property of being self-identical is universally instantiated. Since this is, demonstrably, what that sentence is saying, Frege’s analysis is correct.
   A few final preliminary points: Frege chose to break up sentences containing the words “or” and “and.” Thus, he saw “John is a tall mammal” as saying: John is tall and John is a mammal. And he saw: “John is male or female” as saying: either John is male or John is female. Finally, Frege chose to export the word sentence-internal occurrences of the word “not.” Thus “snow is not white” becomes “it is not the case that snow is white.” (In other words, he chose to rewrite such sentences as sentences in which (a) that word is replaced with “it is not the case that,” and (b) “it is not the case that” is placed before the sentence being negated.)
   By reparsing sentences along these lines, Frege was able to formalize an extensive class of quantified generalizations. Some symbolic notation, some of it already familiar, will help us see how he did this. Let “→” be

defined as before. Let ‹P↔Q› be short for ‹P→Q and Q→P.› In other words, ‹P↔Q› means that P is a logical consequence of Q and vice versa. Let “~” mean “it is not the case that.” Let “(x)” mean “given any object x.” And, as before, we’ll use parentheses to indicate how sentences are to be grouped together. So “Smith is tall and (grass is green or birds fly)” says that it’s the case both that grass is green or birds fly and that Smith is tall. By contrast, “(Smith is tall and grass is green) or birds fly” makes the very different statement that either it’s the case that Smith is tall and grass is green or it’s the case that birds fly.
   Bearing these points in mind, consider the following argument:

Argument #1
Premise: No mammal is intelligent if it has pointy ears.
Premise: Smith is a pointy-eared mammal.
Conclusion: Smith isn’t intelligent.

This argument is valid. But, thus expressed, it isn’t formally valid. This is because “no mammal is intelligent if it has pointy ears” has the same syntax as “Jones is intelligent if he has pointy ears,” a consequence being that Argument #1 has the same syntactical form as the following, clearly invalid argument:

Argument #2
Premise #1: Jones is intelligent if he has pointy ears.
Premise #2: Smith is a pointy-eared mammal.
Conclusion: Smith isn’t intelligent.

But by reparsing the sentences occurring in these arguments, Frege showed why it is that, their surface-structures notwithstanding, Argument #1 is valid whereas Argument #2 is not.
   It will help if we make it clear at an intuitive level what the premises in Argument #1 are saying. The first premise is to the effect that anything that is an intelligent mammal does not have pointy ears. (In other words, given any object x, if x is an intelligent mammal, then x doesn’t have pointy ears. To put it yet another way, given anything x, if x is a mammal, then, if x is intelligent, it follows that x doesn’t have pointy ears.) The second premise is to the effect that Smith is a mammal and Smith has pointy ears. Finally, the conclusion is to the effect that it’s not the case that Smith is intelligent.
   Thus, duly reparsed, Argument #1 becomes:

Argument #1RP:

Premise #1: Given any object x, if x is a mammal, then, if x is intelligent, x doesn’t have pointy ears.
Premise #2: Smith is a mammal and Smith has pointy ears.
Conclusion: It is not the case that Smith is intelligent.

Duly symbolized, Argument #1RP becomes:

Argument #1S:

Premise #1: (x)(x is a mammal→((x is intelligent)→~(x has pointy ears)).
Premise #2: Smith is a mammal and Smith has pointy ears.
Conclusion: ~(Smith is intelligent).
   
   Replace the constants in Argument #1S with variables. In other words, replace “mammal,” “intelligent,” and “has pointy ears” with (let us say) F, G, and H, respectively, and replace “Smith” with A. Make the needed grammatical adjustments. The result is:

Argument #1G:

Premise #1: (x)(x has F→((x has G)→~(x has H)).
Premise #2: A has F and A has H.
Conclusion: ~(A has G).
   
   Replace the variables in Argument #1G with any (grammatically appropriate) constants you wish. The result will always be a valid argument. (It’s assumed that the replacements are uniform—i.e., that you don’t, for example, assign “intelligent” to one occurrence of “F” and “tall” to some other occurrence of it.) For example, replace F, G, and H, respectively, with “prime,” “even,” and “greater than 3”; and replace A with “7.” The resulting argument is:

Argument #1AA:

Premise #1: (x)(x is prime→((x is even)→~(x is greater than three)).
Premise #2: 7 is prime and 7 is greater than three.
Conclusion: ~(7 is even).
   
   This argument is clearly valid. The only even prime is 2. So no even prime is greater than three. Given that 7 is prime and greater than three, it follows that 7 isn’t even.
   The result of uniformly replacing the variables in Argument #1G with constants always yields a valid argument. Thus, Argument #1G successfully formalizes Argument #1, the reason being that (so-called) Argument #1G isn’t really an argument at all, being instead an argument-form, all of whose instances are valid.
   Now let’s subject Argument #2 to the same treatment. Reparsed, it becomes:

Argument #2RP
Premise #1: Jones is intelligent and Jones has pointy ears.
Premise #2: Smith is a mammal and Smith is pointy-eared.
Conclusion: It is not the case that Smith is intelligent.

To generalize argument #2RP, replace “mammal,” “intelligent,” and “has pointy ears” with F, G, and H, respectively, and replace “Smith” and “Jones” with A and B, respectively. Duly generalized, it becomes:

Argument #2G:

Premise #1: B has G and B has H.
Premise #2: A has F and A has H.
Conclusion: It is not the case that A has G.

There are instances of 2G that are invalid. Let A and B be the numbers ten and twenty, respectively. Let F, G, and H be the properties of being greater than one, greater than two, and greater than three, respectively. The result is:

Argument #2N:

Premise #1: the number twenty is greater than two and the number twenty is greater than three.
Premise #2: the number ten is greater than one and the number ten is greater than three.
Conclusion: It is not the case that the number ten is greater than two.

Since argument #2N is spurious and has the same form as argument #2, the latter isn’t formally (or otherwise) valid. Thus, Frege’s reparsing of intuitively valid arguments, such as #1, and of intuitively invalid arguments,

such as #2, enabled him to formalize those inferences. Once an inference is formalized, it can be carried out algorithmically and, therefore, without relying to any degree on ad hoc methods.
2.0 Logicism
Frege’s primary objective wasn’t to formalize logic. It was to formalize arithmetical truth. Frege invented formal logic in order to do this. But what does it mean to say he wanted to “formalize arithmetic”?
   The sentences by which arithmetical truths are ordinarily expressed are not formally true. For example, “2 + 2 = 4” has the same form as “2 + 2 = 5” and “1 + 1 = 3.” Thus, “2 + 2 = 4” is not a formal truth. It’s an informal, analytic truth, like “any case of knowledge is a case of true belief.” Frege was keenly aware of this fact.
   But Frege believed that, when their grammatical forms are brought into alignment with their logical forms, arithmetical truths turn out to be formal truths. To establish this, he needed to identify a systematic way of translating informally true arithmetical sentences into formally true ones. So he needed to find a translation-rule R that, when given an informally true arithmetical sentence (e.g. “1 + 1 = 2”), paired it off with a formally true, but otherwise synonymous, arithmetical sentence.
   Thus, Frege believed that, as they are conventionally stated, arithmetical statements, when true, are both informal and analytic. But he also believed that such statements are formal truths in disguise.
   The position that arithmetical statements are formal truths (in disguise) is known as “logicism.” Frege spent the better part of his career trying to prove logicism to be true.
   In the process of trying to establish the truth of logicism, Frege made some important discoveries. One is of special importance. Statements that, given their surface-structures, appear to be about objects are really about properties. So “nobody snores” is about the property of snoring, and it attributes the property of being uninstantiated (of having a null-class extension) to that property.
   This discovery of Frege’s is closely related to, and almost coincident with, his discovery of the fact that grammar doesn’t always reflect underlying logical structure.
2.1 Logicism (continued)
Analysis is elimination. To analyze causality is to show how statements of the form ‹x caused y to happen› can be translated into statements that don’t contain the word “cause” or any other comparable expression (e.g., “force,” “coerce”). Hume tried to do this. He argued that

(i) ‹x caused y to happen ›

is synonymous with

(ii) ‹x immediately precedes y and is adjacent with it, and the sequence consisting of those two events instantiates a general regularity. ›
   
   Notice that (ii) doesn’t contain “cause” or “force” or any other such term. (Unfortunately, this analysis is a complete failure. In Chapter 17, we will see why.)
   Similarly, to give an analysis of the number one is to say how statements about it can be purged of any expression referring to it. Frege did this, and he did the same thing mutatis mutandis for statements about all other whole numbers.
   On the basis of Frege’s work, Russell showed how the same thing can be done for fractions and irrationals. We won’t go into the specifics of how Frege and Russell do this, but we will discuss, in very general terms, some of the philosophically more important aspects of Frege’s impressive achievement.

2.2 Frege’s initial analysis of number-statements
The statement:

(1) “there are two apples on the table”

is equivalent with:

(2) “something x is an apple on the table; something y is an apple on the table; and x ≠y; AND FOR ANYTHING Z THAT IS AN APPLE ON THE TABLE, EITHER Z = X OR Z = Y.”

Let’s look at (2) for a second. The first (italicized) part, guarantees that there is at least one apple on the table. The second (boldfaced) part does not guarantee that there is a second apple on the table, since it has not been ruled out that the apple in question is identical with the one described in the first part. But taken in conjunction with the third (italicized) part, the second part does guarantee that there are at least two apples on the table. But the first three parts don’t guarantee that there are only two apples on the table; they guarantee only that there are at least two. But taken in conjunction with the fourth (capitalized) part, the first three parts do guarantee that there are exactly two apples on the table. Thus, (1) is equivalent with a sentence that contains no mention of the number two or, indeed, of any other number.
   By obvious extensions of this reasoning:

(3) there are three apples on the table

is equivalent with

(4) “something x is an apple on the table, and so is something y, and so is something z; and y ≠ x and y ≠ z and z ≠ x; and given anything w that is an apple on the table, w = x or w = y or w = z.”
   
   In Frege’s (correct) view:

(5) “there are zero apples on the table”

is equivalent with

(6) “the property of being an apple on the table is uninstantiated,”

and

(7) “there is one apple on the table”

is equivalent with

(8) “something x is an apple on the table and, given anything y that is such an apple, y = x.”
   
   The expressions “two,” “three,” “zero,” and “one” occur in sentences (1), (3), (5), and (7). Those sentences are equivalent with (2), (4), (6), and (8), respectively, even though no number-expression occurs in any of them. Thus, Frege has successfully eliminated any references to number occurring in (1), (3), etc., and therefore, has successfully analyzed them. But there’s a problem, as we’ll now see.

2.3 “Number” defined 
In (1), (3), etc. the expressions “one”, “two”, etc. are functioning as adjectives; and the method just described tells us how to eliminate those expressions from those sentences. In general, that method tells us how to eliminate number-expressions that are functioning as adjectives. But it doesn’t tell us how to eliminate number expressions that are functioning as nouns. It doesn’t tell us, for example, how to identify a sentence that is equivalent with “two is less than three” that doesn’t contain “two” or “three” or any other number-expression.
   Frege’s brilliant solution to this problem is to be understood in terms of the fact that two sets have the same number of objects if they can be put into a one-one correspondence with each other.
   Let’s suppose that Smith has five shirts and that Brown has five cars. Let S1 be the set of Smith’s shirts and let S2 be the set of Brown’s cars. S1 can be put into a one-one correspondence with S2. In other words:

(1) there is a rule (or “function”) that pairs off each member of each set with at least one member of the other set and pairs off no member of either set with more than one member of the other.

(1) says the same thing as:

(2) there is some function F such that, given any member x of either set, F assigns some member y of the other set to x and such that F assigns z to x iff z = y.

If two sets can be put into one-one correspondence, we’ll say that they are “similar.”
Given any two sets, S1 and S2, the statement:

(a) ‹S1 and S2 have the same number of members›

is equivalent with:

(b) ‹S1 and S2 are similar. ›
   
   Two sets are similar just in case they are both instances of the same number. A pair of shoes is an instance of the number two.
   Anything of which there are instances is ipso facto a property. We may thus identify the number two with the property of being a pair of objects (i.e., with the property had by all and only pairs of objects).
   A pair of objects is a set S such that, for some x and some y, x is a member of S and y is a member of S and x ≠ y and such that, for any z, if z is a member of S, then z = x or z = y.
   Thus, the number two is identical with the property of being a set S such that, for some x and some y, x ≠ y, and x is a member of S and y is a member of S, and for any z, if z is a member of S, then z = x or z = y.
   Notice that this analysis isn’t circular. “Two” is defined as “what all and only pairs of objects have in common,” and our definition of “pair of objects” uses no number expressions.
   Any given whole number is to be identified with a similar property. For example, the number three is the property of being a collection of three things (i.e., it is the property had by all and only such collections). Though this definition seems circular, it isn’t, since “collection of three things” can be defined without using the word “three” or any other number expression. To wit: S is a collection of three things iff there are objects x, y, and z such that x is a member of S and y is a member of S and z is a member of S; and such that x ≠ y and y ≠ z and x ≠ z; and such that, for any w, if z is a member of S, then w = x or w = y or w = z. The number three is thus the property of being a set of the sort just defined.
   The number one is the property of being a set S such that something x belongs to S and such that anything y that belongs to S is identical with x. The number zero is the property of being a set S such that nothing belongs to S.
   In general, a whole number N is the property of being an N-tuple.

2.4 Numbers as properties of properties
In

(JG) “Jim has green apples,”

the word “green” picks out a property that can be had by individual apples. But in

(J0) “Jim has zero apples,”
   
   the word “zero” can’t possibly pick out such a property. Let’s suppose that J0 is correct. In that case, Jim has no apples. A fortiori he has no apples having this or that property.
   In J0, the word “zero” denotes a second-order property—that is, it denotes a property of a property. More specifically, it denotes the property of being an uninstantiated property. Thus, J0 says that:

(J0*) The property of being an apple belonging to Jim has the property of being an uninstantiated property.

A moment’s reflection makes it clear that J0* and J0 do indeed say the very same thing.
   
   Whenever number-expressions function as adjectives, they denote properties of properties. To take another example, in

(J2) “Jim has two apples”

the word “two” couldn’t possibly pick out a property that could be had by individual apples. Any one apple ipso facto isn’t two apples. In J2, the word “two” picks out a property of the property of being a property that has two instances. In other words, it picks out the property of being a pair. And J2 says that

(J2*) the property of being an apple owned by Jim has the property of being a pair.
   
   Let’s sum up. J0 says that the property of being an apple owned by Jim is uninstantiated; J1 says that it’s uniquely instantiated; and J2 says that it’s instantiated exactly twice.
2.4.1 Numbers as properties of properties (continued)
The obvious thing to say about JG is that it attributes the property of being green to one or more apples belonging to Jim. But, as Frege pointed out, this isn’t what it’s doing. There is no specific apple x such that JG says that x is green. Given any apple x owned by Jim, JG could be true even if x was not green. This would happen if Jim had some other apple that was green. Thus, there is no apple x such that JG says that x is green. A fortiori JG doesn’t say of each of several apples that it is green. Since there is no one apple owned by Jim to which JG attributes any property, JG isn’t about apples owned by Jim. Rather, JG is about the property of being an apple owned by Jim; and JG says of this property that its extension overlaps with the extension of the property of being green. For this reason, JG’s logical form is no more in alignment with its logical form than J2’ s (or J0’s) logical form is in alignment with its logical form.
2.5 Some logicist paraphrases of arithmetical statements
Frege’s analysis of number (a whole number n is the property of being an n-tuple) makes it clear what is meant by statements such as:

(TLT) “two is one less than three (i.e., three is the successor of two).”
   
The number two is the property of being a pair. The number three is the property of being a triple. Thus, TLT says that:
   
(TLT*) given any instance C of the number three (i.e., given any triple), and given any member x of that triple, any class C* that doesn’t contain x but is otherwise like C is an instance of the number two.

Although number expressions occur in TLT*, these are all easily eliminated. A “triple” is any class K such that there are objects x, y, and z, all distinct, belonging to K and such that anything w belonging to K is identical with x or y or z. Since, as we know, “the number three” is the property of being a triple, the occurrence of “the number three” in TLT* is just shorthand for a much longer expression that contains no number-expressions at all, the same being true, for similar reasons, of the occurrence of “the number two.”
2.5.1 Adding whole numbers
Frege’s analysis of number (given any whole number n, n is the property of being an n-membered set) makes it possible to translate arithmetical statements into statements in which no number-expressions occur.
   “1 + 2 = 3” says that the union of a one-membered set and a non-overlapping two-membered set is a three-membered set. In general, ‹A + B = C› says that the union of an A-membered class and a non-overlapping B-membered class is a C-membered class.
   Here’s the idea. If Sally has one house, and Jerry has two yachts, then there are three things that are either houses belonging to Sally or yachts belonging to Jerry. If Larry has one pool and two cars, then there are three things that are either pools belonging to Larry or cars belonging to Larry. At the same time, if Larry has one expensive possession, and he also has two cars, one of which is expensive, there are only two things each of which is either a car belonging to Larry or an expensive thing belonging to Larry.
   This shows that, in general, if there’s one phi and there are two psi’s, then, provided that neither of the psi’s is a phi, there are three things that are either phi’s or psi’s. Another way of putting this is to say that: given any one-membered class and any non-overlapping two-membered class, the class of things belonging either to the one class or the other is a three-membered class. And “1 + 2 = 3” is a compressed way of saying exactly this. “3 – 2 = 1” says the same thing, given that it is a notational variant of “1 + 2 = 3.”
   In general, each of ‹A + B = C› and ‹C – B = A› is a compressed way of saying that, for any properties phi and psi, given A phi’s and B psi’s, none of them a phi, there are C phi’s or psi’s.
   The occurrences of “1,” “2,” and “3” in “1 + 2 = 3” are really adjectival. What is being said is that, given one phi along with two psi’s, neither of which is a phi, there are three phi’s or psi’s.
   Remember that, for any whole number N, it can be said what an N-membered set is without using any number expressions. Thus, despite first appearances, the just-stated analysis is not circular. The number two is the class of two-membered sets. A “two membered” set is one such that some member x of that set is not identical with some other member y and such that z belongs to that set just in case z is identical with x or y. No mention of the number two.
   In general, for any whole numbers A, B, and C, ‹A + B = C› can be translated into statements containing no number expressions.
2.5.2 Multiplying whole numbers
“2 × 3 = 6” says that the Cartesian product of a two-membered set and a three-membered set is a six-membered set. (For reasons that will become apparent, it doesn’t matter whether the sets overlap.) The Cartesian product of two sets S1 and S2 is the set of ordered pairs <a, b> such that a belongs to the one set and b belongs to the other.
   Explanation: “2 × 3 = 6” can be thought of as saying that double-counting the members of a three-membered group yields a total count of six. In other words, given a group of three objects, if you count that group once and then count it once more, the total count will be six.
   
Let C1, C2, and C3 be Sally’s three cars, and let A1 and A2 be Larry’s two apples. If A1 is allowed to couple with each of Sally’s cars, the result is the set containing the pairs <A1,C1>, <A1,C2>, and <A1,C3>. In this context, A1 is applying a distinctive marker to each member of the smallest set containing each of Sally’s cars. A1 is marking C1, C2, and C3 with the ordered pairs <A1, C1>, <A1, C2>, and <A1,C3>, respectively. When you count your socks, you apply a distinctive marker to each sock. You mark the first sock with a “one,” the second with a “two,” etc. Thus, A1 is doing to each of Sally’s houses what you are doing when you count your socks.
   If Larry’s other apple is allowed to do the same thing mutatis mutandis, the result is the set containing the following pairs:<A2,C1>, <A2,C2>, and <A2,C3>. Notice that none of the markers used by A2 is identical with any of the markers used by A1. Thus, the two counts will be independent, in the sense that if Z is a set containing the one count, and Z* is a set containing the other, Z won’t overlap with Z*. Thus, union of Z and Z* can be thought of as the result of double counting Sally’s houses. The members of that union-set are: <A1,C1>, <A1,C2>, <A1,C3>, <A2,C1>, <A2,C2>, and <A2,C3>. That union-set, which is the Cartesian product of Z and Z*, is a six-membered set.
   It’s obvious that, given any two-membered set and any three-membered set, the union of the headcounts collectively done by both members of the two-membered set will be a six-membered set. In other words, the result of double counting the three membered set will be a six-membered set. And this is just what “2 × 3 = 6” says. “6 ÷ 2 = 3” says the same thing, given that it’s a notational variant of “2 × 3 = 6.”
   “32 = 9” says the same thing as “3 × 3 = 9.” Thus, “32 = 9” says that the Cartesian product of a three-membered set and a non-overlapping three-membered set is a nine-membered set.
   In general, for any whole numbers A, B, and C, ‹A × B = C› and ‹A2 = B› can be translated into statements containing no number expressions.
   It’s obvious that statements about rational numbers (fractions) are equivalent with statements about whole numbers. In fact, they are such statements. To say that 1/2 is less than 3/4 is less than is simply to say that one quotient is less than some other quotient. For any whole numbers A, B, and C, ‹A × B = C› is a notational variant of ‹A = C ÷ B›. Since, as we’ve seen, ‹A × B = C› can be translated into a statement containing no number-expressions, the same is true of ‹A = C ÷ B.›
2.5.3 Adding and multiplying reals
22 is irrational. In other words, there are no whole numbers p and q such that 22 = p/q. But any given statement about /2, or any other irrational number, can be rewritten as a statement about rationals (and, therefore, can be rewritten as a statement about whole numbers and, therefore, can be rewritten as a statement not containing any number-expressions). Consider the statement:

(i) a1/a2<<2.

For (i) to be true, it is necessary and sufficient that a1 and a2 be such that (a1/a2)2<2. Thus, the meaning of (i) is:

(ii) (a1/a2)2<2.
   
   By analogous reasoning, the meaning of

(iii) a3/a4<<3

is:

(iv) (a3/a4)2<3.

It follows, given that no two reals are adjacent, that for

(v) (2<<3

to be true is for it to be the case that

(vi) there are whole numbers a5 and a6 such that 2<(a5/a6)2<3.

   Given any whole number n such that Gn is irrational, and given any statement S of the form

(vii) ‹...(n...›,

there is an equivalent S* statement of the form:

(viii) ‹...n...›
   
   Let us take stock. Statements about L2 can be represented as statements about the class all rational numbers whose squares are less than two. Thus, 22 may be identified with the class of all ratios R such that R2<2. Other irrationals are to be understood along similar lines. Thus, statements about irrational numbers can always be translated into statements about rational numbers.
   Statements about rationals can obviously be translated into statements about whole numbers. Statements about whole numbers can be translated into statements that don’t contain any number-expressions. (See Sections 2.5.1–2.5.2.) Thus, statements about irrational numbers can always be translated into statements that don’t contain any number-expressions.
2.6 A problem with Frege’s analysis
Though basically identical with the analysis given by Frege, the one given in Section 2.3 differs from Frege’s in one important respect. Frege identified numbers, not with properties of sets, with sets of sets. Frege identified the number two with the set containing all and only those sets S such that, for some x and some y, x is a member of S and y is a member of S and x ≠ y and such that, for any z, if z is a member of S, then z = x or z = y. So, for Frege, the number two is the set of all sets of the sort just described. The number one is the set containing all and only those sets S such that something x belongs to S and such that anything y that belongs to S is identical with x. The number zero is the set containing all and only those sets to which nothing belongs.
   The problem is that, if numbers are identified with sets rather than properties, it follows that the number two could have been something other than what it actually is. Consider some pair of objects (e.g., your two favorite socks) and let it be the set containing just those two things. Given a universe where those two socks don’t exist, if K2 is the class of all pairs in that universe, then K2 won’t be identical with the class of all pairs in our universe. Since two sets cannot be identical unless they have the same members, it follows that the number two could have something other than what it is, which is absurd. The same thing mutatis mutandis holds of any other whole number: if a whole number N is identified with a set of sets, that whole number will be different things in different universes.
   (The only exception to this is the number zero. If defined in the way that Frege proposes—that is, as the set of all sets S such that nothing belongs to S—it doesn’t change from universe to universe. This is because, in order for two sets to differ, one of them must have a member not had by the other. This is known as the axiom of extensionality. Since no empty set has any members not had any other empty set, there cannot be two distinct empty sets. Thus, there is only one empty set; and this is true in every universe, not just ours).
   But what it is to be a two-membered doesn’t vary from universe to universe. In any given universe, for S to be a two-membered set is for it to be such that, for some x and some y, x is a member of S and y is a member of S and x ≠ y and such that, for any z, if z is a member of S, then z = x or z = y. Thus, the property of 

being a two-membered set doesn’t vary from universe to universe. To that extent, it’s better to identity the number two with the property of being a two-membered set than it is to identity with the set of all such sets.
   But numbers can still be identified with sets of similar sets. The number two can be identified with sets of all pairs, actual and possible. This variant of Frege’s analysis isn’t open to the objection just made.
3.0 Incompleteness
Logicism was a failure. There is nothing wrong with the (set-theoretic) analyses of number, and of number statements, put forth by Frege and Russell and other logicists. What turned out to be false was Frege’s claim that there is some one algorithm such that, given any statement of arithmetic, that algorithm can correctly say whether or not that statement is true or false.
   This must be understood aright. Given any finite set of arithmetical statements, there is an algorithm that, given any statement falling into that set, correctly says whether or not that statement is true. But there is no one algorithm that, given any arithmetical statement, correctly says whether or not that statement is true.
   One must master some exceedingly intricate mathematics to understand precisely why this claim is false. But some of the philosophical conceits underlying this mathematics are pretty straightforward.
   First of all, the word “logic” is ambiguous. Sometimes it refers to formal truths, e.g., “either Smith is tall or it is not the case that Smith is tall”; and sometimes the word “logic” refers to analytic truths, e.g., “any case of knowledge is a case of justified belief, but not vice versa”.
   When logicists proclaimed that arithmetical truths are “logical” truths, they meant that they are formal truths. Formal truth, it must be emphasized, is a property of sentences and, therefore, of expressions; it is not a property of sentence-meanings.
   For argument’s sake, let’s make the following three concessions to the logicist. First, “1 + 1 = 2” is a formal truth in disguise. Second, the logicist paraphrase of “1 + 1 = 2” is a formal truth. We’ll refer to that paraphrase as TPT.(For the reasons given in section 2.5.1, TPT is some statement along the lines of “two non-overlapping unit classes form a dual class.”) Third, what we just said about 
“1 + 1 = 2” is true mutatis mutandis of any given arithmetical truth.
   Bearing these assumptions in mind, consider the statement that:

(EQ) “The logicist translation of ‘1 + 1 = 2’ is TPT.”

EQ is not a formal truth. After all, it has the same form as:

(EQ2) “The Spanish translation of ‘there will be justice’ is TPT,”

which is obviously false.
   It may be that EQ is analytically true. But that fact hurts logicism as much as it helps it. To describe a sentence as “analytically true” is to make an elliptical statement about a proposition. It isn’t analytic that “triangles have three sides” is true. That sentence could have meant anything; it’s an empirical fact that it means what it does and, therefore, that it’s true. What is analytic is the proposition that, the semantic rules of English being what they are, “triangles have three sides” must be true. The same thing mutatis mutandis is true of any other “analytic” sentence, including EQ.
   As previously stated, all formal truths are analytic truths (but not vice versa). Thus, to describe a sentence as “formally” true is to make a statement about the proposition describing the relationship between the semantic rules of the language to which that sentence belongs, on the one hand, and that sentence, on the other: it is to describe that proposition as analytic.
   There is thus no way to formalize every sentence describing such a proposition. If S1 is any one such sentence, formalizing S1 involves using some other sentence S2 that describes the relationship between the semantic rules of the language to which S1 belongs, on the one hand, and S1, on the other. S2 will invariably fail to be a formal truth. This is because S2 will have the form: ‹given such and such semantic rules, it follows

that S1 is formally true›, which isn’t formally true. The reason it isn’t formally true is that it has the same form as the false sentence: ‹given such and such semantic rules, it follows that “grass is green” is formally true. ›
   Thus no matter how many truths one formalizes, the justifications for those formalizations will always be given by informal truths. This means that, given any viable method M of formalizing some body of informal analytic truths, there is no complete formalization of the truths that establish the viability of M.
3.1 The concept of a formal procedure
In the last section, we often used words like “formal” and “formalize.” And in what follows, we’ll often use the term “formal procedure.” We’ll also use the related term “decision-procedure.” So let us make it clear what these terms mean.
   Consider the statement: “2 + 2 = 4.” You know that it’s true. But how do you know this? You know what it means; and you know that, given what it means, it must be true. Your judgment was based, not on the form, but on the content, of that sentence. Your decision-procedure (your way of determining whether “2 + 2 = 4” is true or not) wasn’t formal.
   Your decision would have been a formal one if it had been based entirely on rules that had nothing to do with the meanings of symbols. A story will clarify this statement. Although you are intelligent and literate (in your native language), you don’t speak English and you don’t know what “1”, “2”, “+”, etc. mean. (You are a good mathematician; but in your native country, different symbolic conventions are used to express mathematical statements.) You are on a military mission. This mission involves your being able, within certain very narrow limits, to distinguish between false arithmetical statements and true ones. Your commanding officer tells you that an inscription whose initial segment is “2 + 2 =” is true if it ends with a “4” and flase if it ends with a “5.” You have no idea what “2 + 2 = 4” means. (You’re not supposed to know.) You come across inscriptions of 
“2 + 2 = 4” and “2 + 2 = 5”; and, on the basis only of your commanding officer’s instructions, you judge that the first is true and the second is false. In this context, your decision-procedure was a formal one.
   This decision-procedure had minimal scope. Obviously mathematicians want to find decision-procedures that deal with large classes of statements. In order for there to be any decision-procedure for a sizeable class of arithmetical truths, those truths cannot be expressed in the customary way. Supposing the standard symbolic conventions to be in place, the truths of arithmetic cannot be expressed using symbols like “2”, “+”, etc. The reason is that, when arithmetical propositions are expressed in that way, there is no non-semantic method whereby true arithmetical sentences can be distinguished from false ones. Thus, in order for there to be a decision-procedure for arithmetic, sentences such as “2+2=4” must be rephrased (or “paraphrased,” as we’ll say). Logicists attempted to provide the requisite paraphrases. And, thanks to their paraphrases, it was possible to identify formal-decision procedures for huge classes of arithmetical truths.
   Kurt Gödel (1906–1978) showed that there is no way of paraphrasing or otherwise representing arithmetical truths that permits the construction of some one formal decision-procedure that decides the truth of any given arithmetical truth. He showed that logicism was doomed and also that any other attempt to formalize arithmetic was doomed. Let us now discuss his achievement in a little (operative word “little”) more detail.
3.2 Incompleteness (continued)
Gödel mathematically proved that there is no one formal decision-procedure such that, given any arithmetical statement, that procedure correctly says whether or not that statement is correct. His proof is extremely complex. But here is a way of stating the main idea that, although both inaccurate and incomplete, will at least initiate an interest on the part of the reader in the fascinating discipline of mathematical logic.
   First a definition: An “arithmetical” predicate is one that expresses a property of whole numbers, or a relation holding among whole numbers, that can be understood entirely in terms of (i) the concepts of addition and multiplication; (ii) the concepts expressed by the connectives “or”, “not”, “and”, “for any” (“all”), and “for some” (“there exists”); and (iii) the numbers zero, one, two, etc. (i.e., the members of the least inclusive set that contains zero and the successor of anything that it contains). Examples of arithmetical

predicates are “is even”, “is less than five”, and “when added to seven yields twelve.” (To say that 3 is less than 5 is to say that there is some whole number n such that, when n is added to 3, the result is 5.)
   Given any arithmetical predicate P, there is a class of numbers C such that a whole number n belongs to C iff P(n) (read: “n has P”). Consider, for example, the predicate “is even.” There is obviously a class containing every number n such that ‹n is even› is true and containing no number m such that ‹m is even› is false.
   For argument’s sake, suppose there to be formal procedure FM such that, for any whole number n and any arithmetical predicate P, FM assigns a TRUE to the sentence P(n) if that sentence is true, and assigns a FALSE to if it’s false. (In this context, TRUE and FALSE may be thought of as physical stamps. When given an ink-deposit (or whatnot) that expresses an arithmetical proposition, FM stamps TRUE on that ink-deposit if it’s true and a FALSE on it if it’s false.) This is the same as assuming that:

(1) There exists a formal procedure that correctly says of any given arithmetical statement whether it is true or false.
   
   Any given arithmetical predicate contains a finite number of letters. There are only finitely many different letters. This means that it’s possible to produce a list such that, given any finitely long combination of letters Z, there is some whole number n such that Z is the nth member of that list. A fortiori it’s possible to produce a list such that, given any arithmetical predicate P, there is some whole number n such that P is the nth member of that list. Let L be such a list; and assume that the items composing L are arranged alphabetically. Further, let L* be a list whose first entry is 1, whose second entry is 2, and so on.
   Given either list, the nth item on it can be thought of as being “coordinated” with the number n, i.e., as having n for its coordinate. Thus, the first item on L* (namely 1) has coordinate 1; the second (namely 2) has coordinate 2; and so on. To simplify exposition, let’s suppose that “is bigger than ten,” “is even,” and “is less than twenty” are, respectively, the tenth, twentieth, and thirtieth items on L.
   Let G be a graph whose x-axis consists of L* and whose y-axis consists of L. Thus, the coordinates on G of the statements “1 is bigger than 10,” “2 is even,” and “3 is less than 20” are, respectively, (1,10), (2,20), and (3,30).
   FM assigns FALSE to “1 is bigger than 10” and a TRUE to “2 is even” and to “3 is less than 20.” FM can thus be thought of as stamping a FALSE on (1,10), a TRUE on (2,20), and a TRUE on (3,30).
   Let K be a class such that, for any whole number n, n is a member of K iff FM assigns a FALSE to (n,n). And let Q be a predicate such that Q(n) is true iff n is a member of K. Supposing that Q is an arithmetical predicate, it follows that Q has some coordinate q on the y-axis. It also follows that the coordinates of Q(q) are (q, q) and, consequently, that Q(q) is true iff Q(q) is false.
Q is an arithmetical predicate. Let’s take a moment to make it clear why this is so.
   First, for any numbers m and n, ‹m has position n on the x-axis› is equivalent with ‹m=n›, which is obviously an arithmetical statement.
   Much the same holds of ‹m has position n on the y-axis›. The predicates composing the y-axis are arranged alphabetically. Each letter of the alphabet can be coordinated with a number. (“A” can be coordinated with “1”; “B” can be coordinated with “2”; and so on.) So the order in which they occur is to be understood strictly in terms of such garden-variety arithmetical facts like “1 is less than 2” and “2 is less than 3.” A consequence is that, for any arithmetical predicate m and any number n, ‹m has position n on the y-axis› is equivalent with some arithmetical statement.
   Thus, given either axis, an item m’s having position n on that axis is a strictly arithmetical fact. It follows that, given any arithmetical statement S and any whole numbers m and n, the statement ‹S has coordinates (m,n)› is equivalent with some garden-variety arithmetical statement. A consequence is that, for any statement S and any whole numbers m and n, the statement ‹FM stamps S with a FALSE› is equivalent with some purely arithmetical statementstatement. Since, for any n, Q(n) is equivalent with ‹FM stamps the statement with coordinates (n,n) with a FALSE›, it follows that Q(n) is an arithmetical statement and, consequently, that Q is an arithmetical predicate. Thus, Q(q) is an arithmetical statement. Since, as we saw, Q(q) is true iff it’s false, it’s false. (No true statement entails its own negation.) But FM stamps a TRUE on it, even though, by supposition, FM stamps a TRUE only true statements.
   
We started with the assumption that there exists a procedure that correctly says of any given arithmetical statement whether it is true or false. This was the only substantive (as opposed to purely procedural) assumption that we made. This assumption entails a false statement and is therefore itself false. There is thus no formal decision-procedure for arithmetic. There is no correct and complete formal characterization of arithmetical truth. Logicism, the doctrine that arithmetical truth is formal truth, is therefore false.
4.0 Analysis by abstraction
In the process of generating his insightful analysis of number, Frege used, for the first time in history, a powerful technique known as definition by abstraction.
   The term “definition by abstraction” refers to a way of analyzing properties. This term is thus a misnomer. Expressions are defined; properties aren’t expressions. I’ll therefore drop the term “definition by abstraction” and use the term “analysis by abstraction” in its stead.
   Analysis by abstraction is a technique for analyzing comparative properties. (A comparative property is one that can be had to varying degrees. Thus, weight and speed are comparative properties, whereas four-sidedness is not.) Given a comparative property phi, an analysis by abstraction of phi is given by a statement that explains what phi is in terms of what it is for one thing to have phi to a degree equal to, or exceeding, the degree to which some other thing has phi.
   It can be said what it is for two sets to have the same number of members, or for one set to have more members than another, without knowing how many members either set has. If the members of the one set can be paired off with the members of the other, they have the same number of members. If not, the set whose members don’t all have partners is the better populated one. Thus, for two sets to be similar (capable of being paired off in the way just described) is for them to be equally populated. We may therefore identify the degree to which a given set is populated with the class of (possible) sets that are similar to it, and we may also identify a set’s being populated to that degree with its being a member of that class.
   This technique can be used to analyze any comparative property. (In fact, there is no other way to analyze such a property.) To say that one event preceded some other is to say that the second exceeds the first in respect of the lateness of the time at which it occurred. One can know that one event preceded some other without knowing when either occurred. If there is some possible causal process (e.g., a light ray), beginning with the one and ending with the other, the event on the receiving end of that process is the later one; if there is no such process, the two events are simultaneous. Let us say that one event is “indifferent” to another if there is no possible causal process beginning with either and ending with the other. (If x is indifferent to y, y is indifferent to x.) Two events are simultaneous just in case they occur at the same time, and they are simultaneous if either is indifferent to the other. We may therefore identify the time at which an event occurs with the class of events that are indifferent to it.
   We defined ‹x precedes y› as ‹some causal process begins with x and ends with y.› Since the italicized terms are obviously temporal in nature, our analysis might be thought to be viciously circular.
   This isn’t so. Our analysis appears circular only to the extent that it is question-beggingly assumed to be false. If that analysis is right, the concept of causal-influence (i.e., of one’s event being the initiator of a causal process of which the other is the recipient) is more primitive than that of order in space-time. So the concept expressed by ‹x causally influences y› (in other words, ‹x is the initiator of a causal process of which y is the recipient›) is the primitive concept, and the concept expressed by ‹x precedes y› is the derivative one.
   It’s true that we defined ‹x influences y› as ‹some causal process begins with x and ends with y›. But that was merely a way of identifying the meaning of that expression. That act of identification, being one that preceded the analysis in question, had to be given in terms that would be meaningful to those who still held onto the idea that causal influence was to be understood in terms of order in time, and not vice versa.
   The concept of weight is to be understood along similar lines. One needn’t know how heavy two objects are to know that they have the same weight or that the one is heavier than the other. That means that, given any two objects, there is some relation such that their having the same mass can be non-circularly identified with the one’s bearing that relationship to the other. An object’s weight (the degree to which it has weight)

may therefore be identified with the class of all things to which it bears that relationship. The same thing mutatis mutandis holds of speed, length, conductivity, and of any other given comparative property.
   A moment ago we said that one can know that x is heavier than y without knowing the weights of either. This must be qualified. When you say that you know only the comparative weights of x and y, but don’t know the actual weight of either, what you are really saying is that, although you know how x and y compare to each other in respect of weight, you don’t know how either compares in that respect to objects in general. And when you say that you know the weights of x and y, and not merely their relative weights, you are saying that you know how each compares in respect of weight, not only with the other, but with objects in general.
   Thus, all knowledge of weight is comparative knowledge. The difference between knowing how x’s weight compares with y’s, on the one hand, and knowing how many pounds x weighs, on the other, is simply one of degree. ‹x weighs 27 lbs› is a condensed way of reporting a great many relative judgments concerning x’s weight—of reporting a great many judgments concerning x’s weight relative to some other object’s weight. What we think of as non-comparative knowledge is a condensed mass of comparative knowledge. It follows—though I leave it to the reader as an exercise to say exactly how it follows—that no viable analysis of a weight, or indeed of any other comparative property, is ever not an analysis by abstraction.
5.0 Putting Frege’s successes into perspective
Even though logicism turned out to be a failure, Frege’s formalization of logic was a success. (This is subject to heavy qualifications that lie outside the scope of the present work.) Many have thought that, to the extent that he was able to formalize logic, Frege succeeded in “mechanizing” the making of inferences—in showing that no thought need be involved in the making of inferences and, therefore, that inferences could be made by beings (e.g., punch-card automata) that are otherwise incapable of thought. The idea is that, given a sentence like:

(1) “for any object x, if x is a mammal, then, if x is intelligent, x doesn’t have pointy ears; and Smith is a mammal and Smith has pointy ears,”

a purely morphology-driven entity—i.e., an entity, e.g., a scanning-device that had no understanding of what anything meant and whose activities are driven only by the shapes of the symbol-tokens involved—could infer that:

(2) “it is not the case that Smith is intelligent.”
   
   It’s granted, of course, that Frege formalized only a miniscule class of inferences. But it’s held that to the extent, however limited that extent was, that he was able to formalize the making of inferences, he showed that suitably constructed machines could think. And those who hold this hold that others who, like Frege, have formalized some class of inferences have ipso facto shown that inferences could be made without thinking and could therefore be made by non-thinkers.
   This is deeply absurd. First of all, it’s tantamount to saying that thinking can be done without thinking. To make an inference is to think. So an unthinking being  ipso facto can’t make inferences.
   This argument is likely to be seen as nothing more than a joke. And it is a joke. But it’s a joke only because, like any good joke, it states the obvious.
   In any case, here’s a joke-free argument. Suppose that device M is given tokens of (i) and (ii) as inputs and that, in response, it outputs a token of (iii). It doesn’t follow M has inferred anything. If M’s outputting T3 is to embody an inference of any kind, it isn’t enough that T1 and T2 be what led M to do so. It is necessary that their being symbols be what led M to output T3.
   Imagine the following. You say to me: “The one copy of your manuscript has just been destroyed.” As a result of your saying this I faint. But I faint not because of what your utterance meant. Rather, I faint because you spoke so loudly that it traumatized me. My response wasn’t of a linguistic nature. It’s true that it was caused

by a linguistic act on your part. But your act’s being a linguistic act was irrelevant; it could just as well have been an explosion or the ringing of a bell.
   Let’s change the story. Because of experiments that I underwent as a child, I say “four” whenever I hear very loud sounds. You ask me “what is 2 + 2?” and I say “four.” But I say it not because of what it was that you were asking, but because you said it so loudly that my conditioning kicked in and I reflexively barked out “four.” My saying “four” was caused by a linguistic act on your part. But it wasn’t caused by your act’s being linguistic in nature. For this reason, my response wasn’t linguistic in nature.
   For exactly similar reasons, given only that M is outputting T3 in response to its being fed inputs T1 and T2, it doesn’t follow that M’s outputting T3 embodies an inference. Since it wasn’t in virtue of their being symbol-tokens that T1 and T2 led to M’s outputting T3, M’s outputting T3 is no more expressive or constitutive of a linguistic or inferential or otherwise ratiocinative act on M’s part than is my inadvertently getting a nose-bleed as a result of my hearing an extremely loud (and therefore nose-bleed-inducing) noise that happens also to be a case of somebody’s saying “if you get a nose-bleed right now, I’ll give you a million dollars.”
   Thus, so far as it’s correct to say that Frege “mechanized” thought, what it means is not that, thanks to his efforts, no thought is needed to execute inferences that were previously thought-dependent. It means that inferences that, prior to his efforts, had to made ad hoc could now be made in a systematic manner. Adding two multi-digit numbers together is easy if you use the standard algorithm, and it’s hard if you don’t. But, even if you use it, thought is involved. Applying the algorithm takes thought; and knowing that it’s applicable takes thought. Only a thinking being can make the judgment that given certain ink-marks (e.g. “456 + 785”) it is to be used, whereas given others, it isn’t. So even though it’s a lot harder to add multidigit numbers without the algorithm than with it, adding them with it involves thought.
6.1 Putting Frege’s successes into perspective (continued)
The inferences one must make in order to algorithmize a given task are often harder to make than the inferences that the algorithm, once applicable, will enable one to make. The same is true of the inferences one must make in order to superintend the application of an already identified algorithm.
   Once again consider Arguments #1 and #2. They’re obviously valid and invalid, respectively. True—thanks to the algorithms bequeathed to us by Frege, Argument #1RP is easier to evaluate than Argument #1. But what it takes in the way of intelligence to convert Argument #1 into something to which those algorithms are applicable is comparable to, if it doesn’t exceed, what it takes to decide whether or not Argument #1 goes through.
   Also, it’s no easy matter to figure out whether a given statement is expressed in a form suitable for the application of one of those algorithms. There are, as we know, arguments superficially similar to #1 that aren’t valid, and it’s only through the use of judgment that we can distinguish such impostors from their legitimate brethren. There is no mechanical way to do so. In general, there’s no mechanical procedure for determining the validity or the scope of one’s mechanical procedures, a consequence being that thought is inherently incapable of being mechanized.
   Imagine the following. You run a company that makes cars. You recently hired a new worker, who goes by the name of “Bucky.” Unlike your current employees, Bucky isn’t intelligent or skilled. But he works hard and he works cheap; and he’s an extremely good worker once he’s mastered a given task. However, Bucky can only do rote, mechanical tasks; and the amount of training he must undergo before he can perform a given task is twice what your average employee would have to undergo to perform that same task. Also, Bucky requires an unusual amount of supervision. He’s unusually likely to break equipment; and, being psychologically fragile, if conditions in the factory are changed slightly (e.g., the walls are repainted), he becomes confused and has to be coddled for a while before he can again work effectively.
   The benefits of keeping Bucky on will exceed the costs if, and only if, there is a large amount of rote work for him to do and you can spare the man-power needed to train and supervise him and you know that conditions won’t change in the factory in such a way as to render him incapacitated—and so on.
   
Algorithms are a lot like Bucky. A lot of time and effort is needed to put them to work; and once put to work, they can only do very specific things. If you need those specific things to be done often enough, it’s worth it to develop an algorithm for doing them and it’s worth it to check in from time to time to make sure that they’re being applied properly. But they’re useless unless heavily supervised, and they’re thus no substitute for real thought.
   
   
Chapter 8
The Relationship between Thought and Language: Literal Meaning vs. Cognitive Content
1.0 The objects of thought are always truths or falsehoods, and never objects, except in a derivative sense
We obviously think about rocks, trees, people, and other things. But things are the objects of thought only in a derivative sense. The real object of thought is always some truth or falsehood concerning a thing.
   Some fiction will help. At time t, you are looking at a rock. You recognize the rock. It’s the rock that Joey, your arch nemesis, threw at your car. That incident was an emotionally charged one for you, and you decided to write a book about it. In order to have a concise way of referring to it, you gave it a name: you decided to call it “R.” It’s been a while since you’ve seen R. But when, at time t, you see it, you instantly recognize it. You recognize it as R—as the rock that Joey threw at your car.
   Your eyes are obviously telling you something. But what exactly? Here we must be careful to distinguish what your visual perception itself is telling from what, given the backlog of knowledge at your disposal, you can read into that perception. No sooner do you see R than you recognize it. But do your eyes tell you that it is R you are seeing? No. Given only what they are telling you, you could be looking at some other rock that happened to look just like that rock. Maybe you know that this is unlikely. Maybe you know that there’s basically no real chance of this. And maybe you know all of this instantaneously. You don’t have go through a conscious, drawn out process of inference. It’s obvious—just as obvious as it is that the person in front of you at your wedding is your beloved fiancée.
   But your eyes aren’t telling you any of this. Given only the information encoded in your visual perception, you could be seeing some duplicate of R. Given only what your eyes are telling you, it’s possible that R no longer exists and that what you are seeing is a perfect duplicate of it.
   What your eyes tell you isn’t: “that’s R over there.” What they tell you is:

(RO) “there is a rock having such and such characteristics over there.”

R satisfies that existence-claim; and you know that. On the basis of that knowledge along with the information bequeathed to you by your visual perception, you know that R has such and such characteristics. But that perception itself doesn’t bear any R-specific message. What your eyes are telling you, taken by itself, is consistent with R’s not even existing. Obvious extensions of these points show that, given any message given to you through vision or any other sensory modality, and given any object in the external world, that message is consistent with that object’s not existing.
1.1 The exact way in which sense-perception is descriptive
Our sense-perceptions obviously represent objects to us and can thus be said to describe them. But what isn’t obvious is that there is nothing to perceiving anything other than being perceptually apprised of some existence-claim satisfied by that object.
   
Let’s suppose you are looking at your good friend Pat. Your seeing Pat obviously involves your seeing instances of various properties of various different kinds. Some of these property-instances are morphological (shape-related); others are chromatic (color-related); others are kinematic (motion-related). And so on.
   But you don’t just see various property-instances. You see an organized structure consisting of them. Your visual perception of Pat represents these property-instances as bearing various relations to one another. Being thus interrelated, they collectively form a coherent structure. Your seeing a coherent structure of property-instances, as opposed to a disorganized jumble of them, consists in your seeing various instances of various relations. It consists in your seeing that certain property-instances are to the right of certain others, that other property-instances are behind certain others, etc. Thus, your seeing Pat involves your seeing various instances of various properties and relations.
   It follows that your seeing him involves your being (visually, not verbally) apprised of an existence-claim: “there are, at the present moment, instances of such and such properties, in such and such places, bearing such and such relations to one another.” From now on, when I mention “property instances,” I am referring to instances of properties and of relations.
   We must now confront a delicate but deeply important question. You see Pat. That’s a given. This involves your seeing various instances of various properties and relations. That too is a given. But do you see anything other than property-instances instances? Is there something to your seeing Pat above and beyond your beholding these various instances? Do you see these instances, on the one hand, and Pat, on the other?
   No. Clearly you just see the instances. Your perception doesn’t represent Pat in addition to the various property-instances that are associated with him. Were your perception to have such a structure, it would involve Pat’s being represented to you as a featureless lump, a blank undifferentiated entity, with various property-instances piled on top of it, so to speak.
   But that clearly isn’t how that perception works. It’s absurd to suppose that a thing possibly be perceptually represented independently of the property-instances that it is being represented as having. That would involve its being represented as a featureless blank. The very idea of a thing’s being perceptually represented as a featureless blank is a non-starter. Thus, there is nothing to seeing (or otherwise sense-perceiving) an object other than seeing (same qualification) the property-instances associated with it.
   These properties are time- and place-indexed. Supposing what you are seeing is round, what you see isn’t just an instance of roundness, but an instance of roundness in a certain place, at the present time. So if O is what you are seeing, your seeing O consists in your being visually told that there are instances of various (time- and place-indexed) properties, these being properties had by O.
   Your seeing a given object consists in your being apprised of the truth of an existence-claim that it uniquely satisfies. And your seeing that a given object has property P consists in your being apprised of the truth of some existence-claim of the form: there exists exactly one object having such and such properties; moreover, any such object has P.
   Let me clarify these statements. Look at the last word of this very sentence. Your eyes don’t only tell you that certain (time- and place-indexed) properties are instantiated. They don’t only tell you that, at the present time, in a certain place, there is an instance of a certain morphology (i.e., that had by the following inscription: “sentence”) and of certain chromatic properties, and so on. They tell you that, in that place, at that time, there is exactly one such instance.
   Thus, you see objects by being visually apprised of existence-claims that they uniquely satisfy. And, of course, what we just said about vision is true of all sensory modalities. Perception is purely descriptive. For you to perceive an object is for you to be apprised (in a certain way) of an existence-claim that it uniquely satisfies. (Perceiving an object involves being causally connected to it. Some think this is inconsistent with the idea that perception is fundamentally descriptive in nature. Reasons to think otherwise are given later in the present Chapter.)

1.2 The pre-semantic basis of communicated meaning
The idea that anything should be perceptually represented as a featureless blank is not a complete non-starter, and so is the idea that anything should be cognitively represented in that way. Conception, like perception, is and must be fundamentally descriptive. To think of an object is to think some existence-claim that it uniquely satisfies. Russell (1917) saw this.
   But it’s easy to confuse issues relating to conception with issues relating to language. What people think isn’t always in complete lock-step with what is literally meant by the expressions that they use. Cognitive content doesn’t always coincide with literal meaning. There is a systematic relationship between the two—but it isn’t always one of identity.
   Another example will make it clear what I mean by this and will help us avoid confusing facts about thought with facts about language. (And this, in its turn, will help us develop a correct semantics along with a correct understanding of thought.)
   One day, you meet a person—you’ve never met this person before. You shake hands and introduce yourselves. He tells you his name (“Fred”). Of course, you see what he looks like and how, at that particular moment, he is behaving. You see that he has such and such features (e.g., he has brown hair), is moving about in such and such manner (he’s nervously wringing his hands), and wearing certain clothes (e.g., a checkered shirt).
   It is clear that, in seeing Fred, you are being a given a description of him. Your perception describes him to you as having such and such characteristics. In fact, it’s clear that your seeing him consists in your being given a description of him—not a verbal description, of course, but a visual description. Thus, your seeing him consists in your being a visually encoded description of Fred, and your seeing him for any length of time consists in your being given a series of such descriptions.
   Your visual perception tells you that, standing in front of you, at the present moment, there is a person (or, in any case, person-like entity) having such and such features (e.g., it has a certain general shape and height; it has certain facial and bodily characteristics; it has certain kinematic (movement-related) characteristics; it’s wearing clothes of a certain kind; and so on). Given that this person has told you his name, the information communicated to by your senses is, when described very approximately and abstractly, along the lines of:

(F1) There is, at the present time, in a certain place (relative to what where I am located at the present time) an object x having such and such characteristics (e.g., its morphology is characteristic of a human being, it’s wearing a checkered shirt, it’s nervously wringing its hands, etc.); and, given what x just said, it can safely be assumed that “Fred” refers to x.

   The italicized part identifies the semantic rule for “Fred.” Let’s refer to that rule as SF (this abbreviation will be frequently used in what follows). Notice how descriptively impoverished SF is. All it does is assign a certain label to a certain object. F1, by contrast, is a descriptively very rich claim; it says a lot about the world. And you learn SF through F1.
   Semantic rules can’t just be known. They must known through sense-perception. “Socrates” refers to Socrates. But we could refer to him as “Gronk” if we chose to, and it’s only because you and I have had certain sense-perceptions that we know that “Socrates,” not “Gronk,” is his name.
   But the sense-perceptions through which we learn semantic rules are replete with information that has nothing to do with sense-perceptions. The semantic information is always embedded in non-semantic information. Your learning SF is embedded in your learning F1, for example.
   Because of this, what sentence-utterances convey may contain vast sums of information that they do not have for their literal meanings. Let’s suppose that, a few hours after you meet Fred, your friend Larry produces the following utterance while addressing you:
(LS) “Fred is a professor of economics.” 

LS attributes a certain property (that of being an economics professor) to a certain individual. And that’s all it does. It’s a very simple statement. If that individual has that property, then LS is true; otherwise, it isn’t. To put it more formally, there is some individual x (namely, Fred) such that LS attributes the property of being a professor of economics to x and such that LS is true if and only if

(LP) x is a professor of economics.

But given how you learned who “Fred” refers to, what LS conveys won’t be so threadbare. True—for some object x (namely Fred), SF merely slaps the label “Fred” on x. But your knowledge of SF is replete with non-semantic content. You know of Fred’s existence only because he was described to you. In seeing him, you were visually told that there was some individual x such that you met x at a certain time, in a certain place, and such that x had certain characteristics; and you were also told that “Fred” was x’s name. Your perception of him was therefore descriptive, and the same is therefore true of your subsequent concept of him. Given that you cognitively access SF through this information, what LS communicates to you is likely to be along the lines of:

(LPC) There was, a little while ago a certain object x having such and such characteristics (e.g., was wearing a checkered shirt and nervously wringing its hands, etc.) and “Fred” refers to x and I’ve just been told that: x is a professor of economics.

   It should be pointed out that you’ll know that the literal meaning of LS is confined to the italicized part. You’ll know that “Fred” isn’t synonymous with ‹the guy who I met at time t and place p, who was wearing a checkered shirt and wringing his hands nervously [etc.].› And you’ll know that does not, at the level of literal meaning, say anything about anyone’s ever wearing a plaid shirt or wringing their hands.
   At the same time, given the circumstances under which you learned who “Fred” refers to, it’s inevitable that LS would convey some such message to you. Given the circumstances, the communicated, as opposed to literally meant, message soaked up some of the non-literal, descriptive information implicated in your initial tête-à-tête with Fred.
   To sum up, there is some individual x such that, in terms of its literal meaning, all LS does is to attribute the property of being an economics professor to x. So what LS literally means is pretty spare. But what it incidentally conveys to you isn’t so spare.
1.3 Interlude: Mill on reference
A moment ago we said that, for some object x (namely Fred), SF merely slaps the label “Fred” on x. This point, appropriately generalized, is that, given any proper name N, there is some object O such that N’s sole linguistic function is pick out O—such that, in other words, the semantic rule for N is simply: “N refers to O.” Names “denote” (pick out) but do not “connote” (describe). They are mere labels.
   This is what we said, and it’s plausible. But it’s not exactly self-evident. So we need an argument for it. John Stuart Mill provided that argument.
   Imagine, said Mill, that you decide to refer to a certain river as the “Dartmouth,” the reason being that, at the time of your naming it, that river’s mouth was at the sea-side city of Dart. (Let’s suppose that you’re royalty, so that your linguistic practices automatically become part of the English language.) Should that river change its course as a result of some cataclysm, so that its mouth were no longer anywhere near the city of Dart, it would still be called “the Dartmouth.” And therein lies the distinction between “Dartmouth,” which is a proper name, and “the river whose mouth is at the city of Dart,” which is not a proper name. The first merely labels a certain river; it doesn’t pick it out through a description. That’s why it labels that river even after that river ceases to fit the relevant description. And that’s why, if some other river were to change locations, in such a way that its mouth coincided with the city of Dart, “the Dartmouth” wouldn’t refer to it, and would still refer to the other river (the one whose mouth was originally at Dart).
   
By contrast, “the river whose mouth is at the city of Dart” is not a mere label. (Like the authors whose work we’re about to evaluate, we are in this context operating on the assumption, definite descriptions are referring terms.) It refers to whatever it is that fits a certain description (i.e., “unique river whose mouth is at the city of Dart”). So it refers by describing, not by labeling.
   Here is another, similar argument. Suppose that You and I are spies in enemy terrain. We see a person in the distance. We can’t make out who it is. We don’t know who he is. But, the circumstances being what they are, we know that, whoever he is, he’s important. You and I are going to be talking about him a lot. We thus need a way of referring to him that, unlike the “the man in the distance,” won’t cease to be useful the moment he moves to a new place. We thus decide to give him a name. We name him “Gargantuan.”
   Russell and Frege would say that “Gargantuan” is synonymous with “the man in the distance” or, at any rate, with some other definite description. But we’ve already seen why that view is the wrong one. That person, whoever he is, can move to a new place; and some other person who isn’t identical with him can move into the place that he has vacated. But “Gargantuan” would not on this account cease to refer to one person and come to refer to someone else. Let us develop this point by telling a story.
   We finally meet Gargantuan. He turns out to be Mr. X, a high-level official in the government of the nation we’re spying on. We now know X’s name, of course. But when speaking to each other, we still refer to X as “Gargantuan.” We befriend X, and he turns out to an amicable and easy-going fellow. He is no longer distant in any sense, and “the man in the distance” no longer refers to him. But “Gargantuan” does refer to him. “The man in the distance” picks out whoever it is that fits the relevant description, and that person won’t always be X. But Garguantuan always picks out X. Given any property phi, such that, at some point in time or other, ‹the phi› picks out X, a similar argument shows that there are possible circumstances where ‹the phi› fails to refer to X, even though, in those same circumstances, “Gargantuan” still does refer to X.
   Thus, “Gargantuan” doesn’t refer to X by describing him, and X’s being picked out by “Gargantuan” isn’t contingent on his having this or that property. “Gargantuan” simply labels X. All X has to do to be labeled by “Gargantuan” is continue to be X. By contrast, to be referred to as “the man in the distance,” one has to be a man in the distance, which isn’t always easy.
   Mill’s argument decisively shows that proper names are mere labels. They are not “connotative;” they don’t have Fregean “senses.” By contrast, definite descriptions (supposing them to be referring terms) are connotative; they do have Fregean senses.
   Non-connotative referring terms are said to refer directly; connotative referring terms are said to refer indirectly. In Chapter 6, it is shown that all reference is direct reference and that the concept of indirect reference is a completely incoherent one. But we will not assume that here, since the authors whose work we're evaluating don't assume it.
1.4 Perception, conception, literal meaning
The just-discussed principles just are crucial. True—they’re obvious and easy to understand. But for some reason some leading analytic philosophers have overlooked them. The results have been catastrophic. Talented thinkers have wasted decades of their lives defending broken ideas.
   To prevent you from suffering the same hideous fate, I’m going to subject you to two more stories that, although little more than boring repetitions of the already boring stories already boringly told, will ensure that you base your philosophical career on the right principles. Somebody with a handle-bar mustache who is wearing a bolo tie who introduces himself to you as “Larry.” You obviously know that “Larry” isn’t synonymous with “the guy with the handle-bar mustache who is wearing a bolo tie who is introducing himself to me right now.” (When your spouse—who we’ll call “Pat”—was first introduced to you, did you think that “Pat” was synonymous with “the well-dressed charming person with whom I’m now having a conversation”? No!)What you know is that there is a certain individual—an individual who, it is true, has a handle-bar mustache, is wearing a bolo tie, and is currently introducing himself to you—and “Larry” refers to that individual. Thus, if it is stated in a formal and perspicuous manner, what you know is:

(LD) There is some individual x such that x uniquely has the property of being a person with a handle-bar mustache who is wearing a bolo tie who is introducing himself to me at this exact moment; and “Larry” refers to x.

Thus, there is some x such that the semantic rule for “Larry” is simply:

(LSR) “Larry” picks out x.

A corollary is that there is some x such that, at the level of literal meaning:

(LT) “Larry is a talented astrologer”

is true just in case x is a talented astrologer. Thus, for some x (such that x is Larry), LT has for its meaning the threadbare proposition:

(LX) x is a talented astrologer.
   
   But given the circumstances under which you learned the semantic rule for “Larry,” LT will convey the descriptively much richer proposition:

(LT2) There is currently somebody in front of me who is wearing a bolo tie and has a handle-bar mustache [etc.], and that person is a talented astrologer.

So what LT will have one proposition (LX) for its literal meaning, but will non-literally suggest (or, as philosophers of language say, “implicate”) some richer proposition. This second proposition is (similar to) the one meant by the sentence:

(LT3) “The person currently standing right in front of me who is wearing a bolo tie and has a handle-bar mustache [etc.], and that person is a talented astrologer.”
1.5 Our ability to distinguish literally meant from presemantically implicated content
The following extension of our Larry-story will ram these ideas home and will also help us move onto a new and important point.
   Brown is a friend of yours who knows Larry, and Brown is at the party where you meet Larry. While you are talking with Larry, Brown utters LT to you. For reasons already discussed, there is some x (namely, Larry) such that Brown’s utterance will have LX for its literal meaning, but will non-literally impart the richer proposition (LT2).
   But—and this is the just-advertised new (and important) point—you know that LT isn’t synonymous with (LT2) or with any other such sentence. You know (at some level) that nothing having to do with bolo ties or handle-bar mustaches is any part of what is literally meant by LT.
   I don’t mean that, if you have some training in semantics, you’ll know this. I mean that you’ll know it merely by virtue of being a competent and cognitively normal speaker of English—that, merely by virtue of satisfying these minimal conditions, you know (or would readily come to know, if you thought about it) that what is literally meant by Joe’s utterance doesn’t encode any information about anybody’s wearing a bolo tie or having a handle-bar mustache.
   Here’s why I say this. If asked whether:
   
(LSC) “Larry does not have a handle-bar mustache”

is self-contradictory, like “squares don’t have four sides,” as opposed to merely false, like “Barack Obama isn’t the president in 2009,” you’d know right away that it’s merely false. You’d know that, although Larry happens to have such a mustache, the idea of his not having one makes perfectly good sense. And given that you speak English, you know that LSC, though false, could be true, unlike “squares don’t have four sides.”
   But if “Larry” were synonymous with “the person who uniquely has the property of being somebody in front of me right now who is wearing a bolo tie and has a handle-bar mustache,” then LSC would be self-contradictory, since it would then be synonymous with the definitionally false sentence:
   
(LSC2)’the person in front of me right now who is wearing a bolo tie and has a handle-bar mustache does not have a handle-bar mustache.”
   
   If LSC were definitionally false, you’d know it. You’d know it for the same reason that you know that “squares do not have four sides” is self-contradictory and, for that reason, doesn’t have a meaningful role in discourse. You’d know it because your knowing it is constitutive of your ability to speak English—of your ability to use English expressions in accordance with the appropriate rules.
   You can’t necessarily articulate this knowledge. But that means little. Given how you speak and what judgments you make, it’s clear that you are guided by it and, therefore, that it’s no less known to you than your own name.
1.6 No non-descriptive knowledge
But—and this must be emphasized—there is no way that you can non-descriptively think about Larry (or anything else). Larry can’t just be represented to you. He must be represented as having these or those properties. Circumstances being what they are, he is represented to you as the guy currently right in front of you wearing a bolo tie [etc.].
   This doesn’t mean that you’ll always think of Larry this way. You won’t. Tomorrow, you’ll think of him as the guy who yesterday was standing right in front of you and, at that time, had a handle-bar mustache [etc.]. And if you come to be friends with Larry, that description will be replaced by others.
   But you’ll always think of him descriptively. More precisely, it will always be by virtue of your knowing the truth of some existence-claim uniquely satisfied by Larry that you’ll be able to have thoughts about him. Your being able to think about him will always consist in your knowing that something uniquely has P, where P is some property that Larry has.
1.7 Reference-fixing vs. meaning giving
Question: how is it that you can think of Larry as “the person in front of me right now who is wearing a bolo tie and has a handle-bar mustache,” and yet know that Larry might not have had a handle-bar mustache (or been standing right here or been wearing a bolo tie)?
   Simple. Remember what Russell said about definite descriptions. (‹The phi has psi› means ‹something or other uniquely has phi, and any such thing has psi.›) In light of this, consider the sentence:

(LD1) The guy now standing right in front of me who is wearing a bolo tie and has a handle-bar mustache [etc.,] is named “Larry.”

There are two ways to interpret LD1. Here’s the first interpretation, which is the correct one:

(LD2) Somebody x is uniquely such that x is now standing right in front of me and x has a handle-bar mustache [etc.]; moreover, “Larry” is x’s name.

Here’s the second interpretation, which is the wrong one:

(LD3) “Larry” names anyone x uniquely such that x has the property of now standing right in front of me and x is wearing a bolo tie and has a handle-bar mustache [etc.].

LD3 says that “Larry” is by definition a unique handle-bar mustache having object x such that x is standing x right in front of me [etc.]. LD2 says that “Larry” names the person who, under the circumstances, is a unique handle-bar mustache having object x such that x is standing x right in front of me [etc.]. Both LD2 and LD3 use the same description (“unique thing x such that x has a handle-bar mustache [etc.]”). But they use it in different ways. LD3 says that “Larry” by definition picks out something fitting that description. LD2 says that “Larry” picks out the thing that, as it happens, fits that description. More precisely, LD2 says that something x fits that description and the semantic rule for “Larry”—the rule that you must know to know how to use “Larry” correctly—is: “Larry” refers to x.
   So, as Saul Kripke puts it, LD2 uses that description to fix the referent of “Larry,” whereas LD3 uses it to give its meaning of “Larry. LD3 is obviously wrong, since “Larry” obviously isn’t synonymous with “the guy now standing in front of me right who is wearing a bolo tie,” or anything of the sort; and LD2 is therefore correct.
   Given that LD3 is correct, there is some x such that, at the level of literal meaning, “Larry” does nothing other than pick out x, and such that, at the level of literal meaning, ‹Larry has psi›, does nothing other than attribute psi to x. But for reasons that we’ve made clear, ‹Larry has psi› has non-literal connotations, to use John Stuart Mill’s expression, that very much affect what it conveys and also, therefore, what it is used to convey.
1.8 Identity statements and modality
Suppose that, a day after meeting Larry, you meet a person who is clearly wearing a disguise. (Let’s not worry about why he is wearing a disguise or why you don’t find it alarming.) That person introduces himself to you as “Oliver.” You and he then proceed to have an amicable conversation. At that point, a series of events occur that parallel those of the previous day. Your friend Brown is in attendance and joins the conversation. Brown knows Oliver; and, addressing you, Brown says:

(OT) “Oliver is a talented astrologer.”

Given what we’ve already said, it’s clear what the consequences are. There is some x such that the semantic rule for “Oliver” is:

(OSR) “Oliver” refers to x.

A corollary is that OT has for its literal meaning the descriptively impoverished proposition:

(OT1) x is a talented astrologer.

At the same time, given the circumstances under which you learn who “Oliver” refers to, what Brown’s utterance of OT will convey to you (non-literally) will be descriptively richer than OT and will be along the lines of:

(OT2) There is some individual such that, right now, that person uniquely has the property of being a person wearing a disguise who is standing right in front or me; moreover, that person is a talented astrologer.
   
But, for reasons analogous to those given earlier, you will know (at some level) that OT doesn’t have OT2 or any other comparable proposition for its meaning; you know (at some level) that nothing having to do with disguise-wearing is any part of what is literally meant by OT.
   But Oliver is Larry. You don’t know this. It just happens to be the case. Unbeknownst to you, the person you know as “Larry”—the guy with the handle-bar mustache—is identical with the guy you know as “Oliver”—the guy wearing the mask.
   There is some one individual who goes by “Larry” and “Oliver.”
   It follows that there is some one individual x such that the semantic rule for “Oliver” is:

(OSR) “Oliver” refers to x,

and such that the semantic rule for “Larry” is:

(LSR) “Larry” refers to x.
   
   There is thus some one individual x (this being Larry) such that, given that OSR and LSR are the semantic rule for “Oliver” and “Larry” Jones respectively, and such that, consequently:

(OT) “Oliver is a talented astrologer”

means

(OT1) x is a talented astrologer

and such that

(LT) “Larry is a talented astrologer”

means:

(LX) x is a talented astrologer.

   In other words, OT and LT have the very same meaning. OT1 and LT are the same proposition. And that one proposition is what is meant by OT and by LT. LT and OT mean the same thing.
   But we have a problem. OT and LT convey very different things. LT conveys:

(LT2) There is currently somebody in front of me who is wearing a bolo tie and has a handle-bar mustache [etc.], and that person is a talented astrologer.

OT conveys the proposition that:

(OT2) There is some individual such that, right now, that person uniquely has the property of being a person wearing a disguise who is standing right in front or me; moreover, that person is a talented astrologer.

LT2 and OT2 are obviously very different propositions. Neither entails the other. Neither even makes the other probable (they’re confirmationally independent of each other).
   But how can this be? How can LT and OT convey such different propositions, given that they have the very same literal meaning?
   We’ve already explained this. Semantics isn’t learned in a vacuum. It’s learned empirically, that is, through sense-perceptions, and those sense-perceptions convey a lot of information that has nothing to do with the

semantic information that they are also conveying. To access these semantic rules, one must work through this pre-semantic, and non-semantic, information; and the result is that what is communicated by a sentence may be much richer than its literal meaning. We’ve already explained why, under the circumstances in question, these particular sentences (LT and OT1) happen to convey these particular propositions (LT3 and OT2).
   Let’s continue our story. Addressing you, your friend Brown says:

(LOI) “Larry Jones is identical with Oliver.”

You are surprised. After all, “Oliver” was wearing a mask, and (we may suppose) his demeanor was very different from that of “Larry Jones.” Your initial reaction is one of disbelief. But “Oliver” takes off his mask and he is indeed Larry Jones. It also turns out that this person is legally named both “Oliver” and “Larry Jones.” (We don’t have to worry about the details.)
   Let’s consider the time just before Oliver takes off his mask—the time when you are still skeptical about Brown’s claim. Letting psi be any property, obvious extensions of what we’ve already said show that, under these circumstances:

(LTP) ‹Larry has psi›

will convey something along the lines of:

(LTP*) yesterday, there was somebody in front of me who was wearing a bolo tie and had a handle-bar mustache [etc.], and that person has psi

and

(OTP) ‹Oliver has psi›

will convey something along the lines of:

(OTP*) There is some individual such that, right now, that person uniquely has the property of wearing a mask while standing right in front of me and having a conversation with me that’s been going on for a while; moreover, that person has psi.

It follows that, given the circumstances, LOI will convey much the same thing as the sentence:

(DLOI) “the guy who, yesterday, was standing in front of me and wearing a bolo tie [etc.] is identical with the guy who is currently standing in front of me and wearing a mask [etc.]”

We know from Russell’s theory of descriptions that the meaning of DLOI is:

(DLOITD) somebody x uniquely has the property of being a person who, yesterday, was standing in front of me while wearing bolo tie [etc.], and having that property being such a person also uniquely has the property of standing in front of me right now and wearing a mask [etc.].

Of course, DLOITD is not a trivial proposition. It does not say of some individual x that x is identical with x. It says something radically different. It says that some one individual uniquely has each of two very different properties.
   But remember that names are mere labels, and that, consequently, there is some x such that “Oliver” and “Larry Jones” simply label x. It follows that there is some individual x (namely, Oliver/Larry Jones) such that what is literally meant by LOI is simply:

(LOX) x is identical with x,

which, of course, is utterly trivial. But that’s ok, since the non-triviality of what LOI communicates has already been accounted for.
1.9 Frege and Russell on proper names
Though they lived after Mill, Frege and Russell didn’t internalize his very good analysis of proper names and chose to replace it with a deeply defective one.
   Here was their reasoning. You and a friend are looking at the last celestial body to disappear from the morning sky—your friend tells you that it’s called “Hesperus.” (You don’t know anything about astronomy, but your friend does.) Later that day, just as evening is approaching, you and he are again looking at the heavens. He points to the first celestial body that appears in the evening sky and tells you it’s called “Phosphorous.”
   Given only how they appear to you on the occasions in question, you have no way of knowing whether or not “Hesperus” and “Phosphorous” co-refer. If you had to guess, you’d probably say that they did not, given that the celestial bodies referred to by “Hesperus” and “Phosphorous” respectively were in very different parts of the sky and seemed to have quite different features, so far as you could make out their appearances.
   In the late morning, just after being told what “Hesperus” refers to, your friend tells you (correctly):

(H1) “Hesperus is less massive than the Earth.”

In the early evening, just after being told what “Phosphorous” refers to, your friend tells you (correctly):

(P1) “Hesperus is less massive than the Earth.”

Given the circumstances, H1 and P1 convey very different propositions to you. H1 conveys the proposition that would be conveyed to you by:

(MS) “The morning star is less massive than the Earth.”

(In this context, take “the morning star” to be an abbreviation for “the last celestial body to disappear from the morning sky” and take “the evening star” in the same way mutatis mutandis.)
   And for the same reasons mutatis mutandis, P1 conveys the proposition that would be conveyed to you by:

(ES) “The evening star is less massive than the Earth.”

Thus, the propositions conveyed by MS and ES are, respectively, to the effect that:

(MSTD) something is uniquely a last celestial body to disappear from the morning sky, and any such thing is less massive than the Earth

and

(ESTD) something is uniquely a first celestial body to appear in the evening sky, and any such thing is less massive than the Earth.

Obviously MSTD and ESTD are different propositions. Neither entails the other. They are confirmationally independent of each other.
   Since MS and ES convey MSTD and ESTD, it might seem to follow that MS and ES have MSTD and ESTD for their respective literal meanings. And this is just what Russell and Frege inferred.

The Russell-Frege analysis of proper names is this:

(RF) If N is a proper name of some object O, that is because N is synonymous with ‹the phi›, for some property phi that O, and O alone, has. Thus N is O’s name only because O fits the description encoded in O. Proper names are not mere labels; Mill was wrong. They are descriptive.

(Note: Russell and Frege disagreed about how to analyze ‹the phi.› Frege thought that it was a referring term. Russell thought otherwise. But they both accepted RF, and that’s what’s important here.)
   So “Homer” is, in their view, synonymous with “the blind bard who authored the Iliad,” or some such, and “Shakespeare” is synonymous with “the author of Hamlet,” or some such.
   We’ve already seen why this theory is wrong and also that Mill, whose work was known to both Frege and Russell, refuted this theory. But, for whatever reason, they didn’t internalize Mill’s argument. (That happens. There are many arguments that I’ve read and that, if I had understood them, I would have seen to refute cherished positions of mine.) And, even though (unbeknownst to them) there was a cogent reason not to hold it, there were some excellent reasons to hold it. In other words, apart from the fact that it’s wrong, it’s an excellent theory—one that models the data pretty well.
   Let us state these reasons as explicitly as possible. There are basically three.
1.9.1 Reason #1: Since conception is descriptive, and since language mirrors thought, proper names are descriptive
Russell and Frege believed that conception is descriptive—that to think O has psi is to think the phi has psi, where phi is some property had by O and O alone.
   They were 100% right about this. For reasons to be discussed in a moment, this insight of theirs, though accepted for the first 70 years of the last century, was promptly rejected in the early 1970s (for not very good reasons).
   Here’s where they went wrong. They assumed that what is true of language must be true of thought. Thinking (rightly) that one’s concept of Socrates, if put into words, would have the form ‹the phi›, for some property phi, they inferred (wrongly) that “Socrates,” the word, must be synonymous with ‹the phi.›
   They’re wrong, as we’ve seen; and, contrary to what they thought, the descriptive nature of conception is perfectly consistent with the supposition that proper names are mere labels.
   What made it possible for them to overlook the flaws in their logic was that they focused on names of historical figures (“Homer,” “Shakespeare,” “Napoleon”) or celestial bodies (“Hesperus,” “Phosphorous”)—names that are likely to be associated with a single definite description. It isn’t likely that “Phosphorous” will stop being “the evening star.” (It could happen; there could be some cataclysm. But it isn’t likely.) And it isn’t likely that “Shakespeare” will stop being synonymous with “the author of Hamlet.“ (It’s possible; it could be discovered that Francis Bacon wrote Hamlet. But it isn’t likely.) So each of “Hesperus” and “Shakespeare” is tethered to a definite description whose aptness events probably won’t threaten.
   But this isn’t true of names of living people. Remember what we said about “Larry.” What makes it so obvious that “Larry” isn’t synonymous with “the man with the handle-bar mustache [etc.]” is that Larry might shave his mustache tomorrow; maybe he already has. And maybe I’m now at some other party and am talking to some other man with a handle-bar mustache, and it is now this other man, not Larry, to whom “the man with the handle-bar mustache [etc.]” corresponds. Since living people change and, as it were, move from definite description to definite description, it’s clear, if one focuses on the names of the living that names aren’t definite descriptions. And it’s clear for the reasons that Mill gave. But Russell and Frege focused on a different class of names, and there it is.

1.9.2 Reason #2: Replacing co-referring proper names changes meaning
Let’s suppose that Mill is right—that names are mere labels and are not “connotative” (descriptive). In that case, there is some object—let O be that object—such that each of “Hesperus” and “Phosphorous” simply labels O. It follows that:

(H1) “Hesperus is less massive than the Earth”

has the very same proposition for its literal meaning as

(P1) “Phosphorous is less massive than the Earth,” namely:

(O1) O is less massive than the Earth;

Indeed, it follows that, for any property psi,

(H*1) ‹Hesperus has psi›

has the very same proposition for its literal meaning as

(P1) ‹Phosphorous has psi›,

namely:

(O*1) O has psi.

In particular, it follows that:

(IHP) “Hesperus is identical with Phosphorous”

has the very same meaning as

(IHH) “Hesperus is identical with Hesperus,”

namely:

(IO) O is identical with O.

But this all seems very wrong. IHP is non-trivial. H1 and P1 convey very different propositions (namely, O*1 and P*1); the same is true, for any property psi of IHP and IHH. Given these facts, it seems de rigueur to accept the Russell-Frege position that “Hesperus” and “Phosphorous” are synonymous with different definite descriptions (“the morning star” and “the evening star,” or whatnot).
   But this reasoning is no good. We’ve already seen why. But let’s adapt what we said earlier to deal with the Hesperus-Phosphorous case. Let’s go back to the time when your friend was first telling you what “Hesperus” refers to. He points to a certain celestial body x, which is clearly the last one to disappear from the morning sky, and tells you that “Hesperus” refers to that thing—that is, that “Hesperus” refers to x. Thus, there is some x such that you know that x is the last celestial body to disappear from the morning sky and such that you are now being told that the semantic rule for “Hesperus” is:

(HSR) “Hesperus” refers to x. 

Given these circumstances, an utterance:

(HSR2) “Hesperus is hotter than the Earth”

would convey to you the information that:

(HSR3) something is a last celestial body to disappear from the morning sky and any such thing is hotter than the Earth.

And HSR2 would convey this even though its literal meaning would be the descriptively more impoverished proposition that:

(HSLM) O is hotter than the Earth

for some object O.

In general, for any psi, an utterance of (H*1) would convey the information that:

(HSRG3) something is a last celestial body to disappear from the morning sky and any such thing has psi.

And, echoing what we just said, an utterance of H*1 would convey that even though its literal meaning was simply:

(O*1) O has psi.

And for the same reasons mutatis mutandis, an utterance of P*1 would convey:

(PSRG3) something is a last celestial body to disappear from the morning sky and any such thing has psi

enough that the utterance’s literal meaning would be O*1.
   Russell and Frege overlooked the fact that semantics isn’t learned in a vacuum and that, as a result, the non-semantic information through which semantic rules are learned is sometimes smuggled into the messages borne by utterances.
Reason #3: Replacing co-referring sometimes proper names changes truth-value
A person can know that:

(H1) “Hesperus is less massive than the Earth”

expresses a truth without knowing that

(P1) “Phosphorous is less massive than the Earth”

does so as well. Many a person who knows that

(IHH) “Hesperus is identical with Hesperus”

is true doesn’t know that

(IHP) “Hesperus is identical with Phosphorous”

is true as well.
   This data is naturally accounted for by supposing that “Hesperus” is synonymous with “the morning star” and “Phosphorous” is synonymous with the evening star. And that’s just what Frege and Russell did suppose. But, as we’ve seen, this isn’t the right way to model the data and it isn’t the only way. The supposition that H1 (IHH) and P1 (IHP) coincide in literal meaning does model that data provided that the points concerning pre-semantic information made earlier are taken into account.
2.0 Kripke’s revival of Mill
In 1969, Saul Kripke gave three very clever lectures in which he definitively showed that the Russell-Frege analysis of proper names is wrong. Those lectures are now published under the title Naming and Necessity. He said many insightful things in the course of those lectures, many of which went far beyond the scope of semantics. He also said some things that are quite clearly false, but that, oddly, were nevertheless accepted and, indeed, turned into orthodoxies. Let’s start with the insightful, correct things that Kripke said.
2.1 The modal differences between names and definite descriptions
For argument’s sake, suppose that:

(SOC) “Socrates” is synonymous with some definite description—with, let us suppose, “the great philosopher who died of hemlock poisoning.”

If SOC is right, then:

(1) “Socrates did not die of hemlock poisoning”

would be self-contradictory, since it would mean the same thing as

(2) “the great philosopher who died of hemlock poisoning did not die of hemlock poisoning.”

But (1) isn’t self-contradictory at all. We could imagine its being true. Suppose that historical research reveals that it wasn’t hemlock poisoning that killed Socrates—that the poison he drank was some other sort of poisoning. In that case, (1) would be false. This may not be likely, but there’s nothing incoherent in the idea of its happening; supposing this about Socrates isn’t like supposing that squares were really circles.
2.1.1 The modal differences between names and definite descriptions (continued)
A related point is that:

(3) “Socrates died of hemlock poisoning”

is not analytic. (An analytic statement is one that, given only what it means, must be true. So “squares have four sides” is analytic, but “Socrates was a wrestler” is not.) But it would be analytic if SOC were right, since it would then be synonymous with:

(4) “the great philosopher who died of hemlock poisoning died of hemlock poisoning.”

Why isn’t (3) a tautology? Because lots of people who know who “Socrates” refers to—who know that he’s the lead character in the Republic, or whatnot—may not know that he died of hemlock poisoning. Those people are not, for that reason, guilty of some semantic deficiency; they may know as well as anyone what the semantic rule governing “Socrates” is. There is some x (namely, Socrates) such that “Socrates” refers to x, and they know that. (4) is thus an empirical point.
2.1.2 The modal differences between names and definite descriptions (continued)
A consequence of these points is that:

(5) “it’s necessarily the case that the great philosopher who died of hemlock poisoning died of hemlock poisoning”

is true, whereas

(6) “it’s necessarily the case Socrates died of hemlock poisoning”

is false. Even if Socrates did die of hemlock poisoning, he might not have; he might fallen off a bridge on his way to the hemlock-drinking ritual.
   For exactly similar reasons, “Benjamin Franklin” isn’t synonymous with “the inventor of bifocals.” For:

(7) it’s necessarily the case that the inventor of bifocals invented bifocals”

is true, but

(8) “it’s necessarily the case that Benjamin Franklin invented bifocals.”

   Kripke’s basic point is that proper names don’t have the same modal properties as co-referring definite descriptions. The “modal status” of a sentence lies, not in whether it is true, but in whether it, or its negation, can be true. The proposition that squares have four sides is necessarily true. That is its modal status. To say that it is necessarily true is to say that it cannot be false. (1) and (2) express propositions that have different modal statuses and are therefore distinct. Thus, replacing the occurrence in (1) of “Socrates” with “the great philosopher who died of hemlock poisoning” results in a sentence that expresses a proposition different from that expressed by (1). Thus, “Socrates” isn’t synonymous with “the great philosopher who died of hemlock poisoning” or, by the same logic, with any other definite description. Given obvious extensions of this reasoning, no proper name is synonymous with any definite descriptions.
2.2 Kripke on identity and necessary a posteriori truth
To understand Kripke’s influential non-semantic claims, we must define four terms and also assimilate an important principle that Kripke discovered.

2.2.1 A priori vs. a posteriori knowledge
The first two terms are “a priori” and “a posteriori.” These expressions are adjectives, and they modify expressions denoting knowledge. A priori knowledge is knowledge that one either has, or can acquire, merely by virtue of how one’s mind is structured; it can be thought of as knowledge that is coded into one’s cognitive structure or that follows from such knowledge. When you a buy a new computer, it typically comes “bundled” with new software. A priori knowledge can be compared to such software. A posteriori knowledge is knowledge that is not a priori.
2.2.2 Rigid vs. non-rigid designators
The remaining two terms are “rigid designator” and “non-rigid designator.” For reasons that will emerge in due course, the distinction between rigid and non-rigid designators is meaningless unless definite descriptions are taken to be referring terms. So in this context, we’ll suppose, just as Kripke does in Naming and Necessity, that definite descriptions are referring terms.
   Consider a world W that is semantically just like ours except that, in it, Al Gore, not Barack Obama, is the U.S. President in 2009. In W, “the U.S. President in 2009” would refer to Al Gore. So even though that expression would have the semantics that it has in our world, it wouldn’t pick out the same thing that it picks out in our world. In fact, given that, in W, Barack Obama isn’t the president in 2009, if “the U.S. President in 2009” did pick out “Barack Obama” in W, it couldn’t possibly have the same semantics that it has in our world.
   But suppose that, in world W* that is distinct from both W and our world, “Barack Obama” referred to Joseph Biden. In that case, W* would ipso facto not be semantically identical with our world. In our world, there is some individual x such that x is Barack Obama and, as a matter of semantics, “Barack Obama” refers to x. And any language in which “Barack Obama” picked somebody else would to that extent semantically diverge from the specific version English actually spoken (even if it was otherwise just like it). Given that “Barack Obama” refers to Barack Obama, it couldn’t possibly fail to refer to him in a world that is semantically like ours. It could fail to refer to him only in a world where expressions were not in all cases governed by the semantic rules that govern them in our world.
   “Barack Obama” is a rigid designator. E “rigidly designates” x if there is no possible world that is semantically just like ours where E fails to designate x. Proper names are rigid designators. Definite descriptions are not. “The inventor of bifocals” refers to Bob Denver in some possible worlds, to Walt Disney in others, and so on.
   Sometimes demonstrative expressions (e.g., “that person”) are described as “rigid designators.” The reasons for this are explained in Chapters 6 and 9. Suffice it to say that they are not rigid designators. In fact, they are about as non-rigid as designators can be. “The inventor of bifocals” is non-rigid in the sense that there are possible universes in which it refers to people other than Benjamin Franklin. But “that person” refers to many different people in our world.
2.3 Identity and necessity
Suppose that x and y are contingently identical—that, in other words, they’re identical but they don’t have to be. By Leibniz’s law, x and y have the very same properties. Obviously x is necessarily identical with x. Therefore, y has that property as well and, contrary to what we assumed, is necessarily identical with x.
   In general, identities hold necessarily if they hold at all. It isn’t a contingent fact that you are identical with you. If you exist, you can’t fail to be you.
   Some sentences seem to be counterexamples to this; for example, “the person standing over there is the person who owns the ice-cream store down the street.” But that isn’t really an identity claim. We know from Russell that its real meaning is: “something is both a person standing in that corner, unaccompanied by other people, and is also a sole proprietor of the ice-cream store down the street.” Given any apparent exception to

the principle that, when it holds, identity holds necessarily, reparsing that sentence shows it not to be an identity claim.
   A sentence of the form “A is identical with B” expresses an identity claim only if “A” and “B” are rigid designators. Thus:

(IHP) “Hesperus is identical with Phosphorous”

is an identity claim. And so is

(WH) “water is H2O”

and so is

(MT) “Mark Twain is Samuel Clemens.”
2.4 Why Kripke believes that there are necessary a posteriori truths
Kripke made it clear that “Hesperus” isn’t synonymous with “the morning star” or with any other non-rigid designator, and he showed the same thing mutatis mutandis to be true of “Phosphorous.” Given that Hesperus is Phosphorous, Hesperus can no more fail to be Phosphorous than it can fail to be Hesperus. So given that it holds, IHP holds necessarily.
   Kripke says that “IHP” encodes an a posteriori truth. The idea is that it can’t be known a priori that IHP (or any other synonymous sentence) is true. It can be known only through astronomical observation. Given that IHP is necessarily true, it follows that IHP is both necessary and a posteriori.
2.5 Evaluating Kripke’s attempt to show that there are necessary a posteriori truths
This is not a good argument. We made it clear earlier in this chapter that, although it doesn’t have such a claim for its literal meaning, IHP communicates a proposition of the form the phi is identical with the psi. In other words, it (non-literally) communicates a proposition of the form: something uniquely has phi, and anything that has phi also uniquely has psi.
   So IHP communicates a contingent truth. It communicates, as we saw, the proposition that is expressed by the sentence:

(MS) “the last celestial body to disappear from the morning sky is identical with the first to appear in the evening sky” (which we’ve abbreviated as: “the morning star is identical with the evening star”).

The proposition meant by MS is:

(MSP) something is uniquely a last body to disappear from the morning sky, and anything having that property also uniquely has the property of being a first thing to appear in the evening sky.

MSP is a posteriori. But it’s also contingent. It wouldn’t be true if matter were differently distributed.
   Kripke is quite right that IHP has a necessarily true proposition for its meaning. But that proposition is also analytic and knowable a priori.
   Here’s why. We’ve agreed with Kripke that, for any property phi, “Hesperus” isn’t synonymous with ‹the phi.› And we’ve also agreed with Kripke, and with commonsense, that “Hesperus” is a referring expression—

that, in other words, there is some object x such that “Hesperus” picks x out. Trivially, either “Hesperus” picks out this object through the mediation of a description or it doesn’t. In other words, supposing that O is what “Hesperus” picks out, it either is, or is not, by virtue of O’s fitting some description that “Hesperus” picks out it. If it is, then “Hesperus” is ipso facto a non-rigid designator—a definite description. For supposing that the description that O must satisfy is unique thing having phi, “Hesperus” must be synonymous with ‹the phi.› But we know, from Kripke himself, that “Hesperus” is not synonymous with any such expression. So “Hesperus” does not refer to O through the mediation of a description. It picks O out—but not because it has this or that property. It picks it out because the semantic rule for “Hesperus” is to the effect that, no matter what properties O has, “Hesperus” is to pick it out—because, in other words, “Hesperus” picks out O, this not being contingent on O’s satisfying any condition (other than its being O). Thus, there is some object x (namely, O) such that the semantic rule for “Hesperus” is to the effect that, no matter how O is, “Hesperus” picks it out. In other words, “Hesperus” picks out O directly. It is directly referential.
   A consequence is, for some object x (such that x is Hesperus) such that, in virtue of having the form, ‹Hesperus has psi›, a sentence is true if and only if x has phi. For exactly similar reasons, “Phosphorous” is directly referential. It co-refers with “Hesperus.” Thus, there is some object x (such that x is Hesperus and Phosphorous) such that, in virtue of having the form, ‹Hesperus has psi›, a sentence is true if and only if x has phi and such that, in virtue of having the form, ‹Phosphorous has psi›, a sentence is true if and only if x has phi. Thus, ‹Hesperus has psi›and ‹Phosphorous has psi› have the very same literal meaning. In general, inter-substituting “Hesperus” and “Phosphorous” doesn’t change literal meaning. (This is entirely consistent with the fact such inter-substitutions may dramatically change suggested meaning, the reason being that one may learn what those two words refer to under very different circumstances and thus in connection with very different bodies of descriptive data. The way the “referent is fixed” will obviously affect the connotation of sentences containing the word in question, even though it won’t affect the literal meanings of such sentences.) Given that such inter-substitutions preserve meaning, it follows that:

(IHP) “Hesperus is identical with Phosphorous”

has the same literal meaning as

(IHH) “Hesperus is identical with Hesperus”

(even though, given how it is typically made known what these words refer to, they have very different non-literal connotations). We’ve agreed that, for some x, each of ‹Hesperus has psi› and ‹Phosphorous has psi› is true just in case x has phi. It follows that, for some x, each of IHP and IHH is true just in case x has the property of being identical with x. Thus, for some x, IHP means:

(XSI) x is x.

And XSI is an analytic, a priori knowable proposition if ever there was one.
   There is no a posteriori necessary truth. It appears otherwise only if one fails to distinguish sentences from the propositions that are their meanings. The gulf between the two can be large. This is but another example of the fact that metaphysics can’t be read off of sentential structure. Kripke’s disregard for this shibboleth of analytic philosophy comes as a shock. But that shock is nothing compared to the one we’re in for.
3.0 A cure for Salmonella
Kripke (1979) wrote an article in which he put forth a new argument (one not stated in Naming and Necessity) as to why the Russell-Frege analysis of the non-triviality of IHP fails. Pierre is a monolingual speaker of French. He reads many books about London (which he knows as “Londres”). On the basis of the information

contained in those books, he draws the rational inference that London is a beautiful city. Expressing this belief, he says:

(1) “Londres est jolie.”

It is to be emphasized that, given the data at his disposal, it is rational of Pierre to accept (1).
   Our story continues. Pierre is kidnapped and forced to live in a terrible part of London. He doesn’t know that he’s living in the city known to him as “Londres.” He learns English, but he learns it as one learns a first language. In other words, he doesn’t learn what English words mean by learning what their French translations are—he learns them the way that a native speaker of English learns them. He learns what “snow” means, not by learning that it co-refers with “neige,” but by learning a certain crystalline substance that falls on rooftops in the winter is called “snow.” And he learns what “London” refers to in the same way. Given the data at his disposal, it is rational of Pierre to believe that the sentence:

(2) “London is not pretty”

expresses a truth—a truth to the effect that the city he is living in is not pretty. And Pierre does assent to it, and he utters that very sentence, knowing what it means.
   Of course, (2) is the (English translation of the) negation of (1).
   “London” is the translation of “Londres.” So if “London” is synonymous with some definite description—with, let us suppose, “the most populous city on the Thames”—then “Londres” is synonymous with the French translation of that definite description. But if that were the case, then (1) would mean the same thing as:

(1R) “the most populous city on the Thames is pretty”

and (2) would be mean the same thing as:

(2R) “the most populous city on the Thames is not pretty.”

Pierre clearly isn’t in the same category as somebody who accepts both (1R) and (2R). So even if, as Russell and Frege thought, “London” was synonymous with some definite description, that wouldn’t explain the fact that (1) and (2) communicate such different propositions. In other words, it would fail to account for the cognitive values of those sentences. (The “cognitive value” of a sentence is what it communicates.) Since the whole point of the Frege-Russell theory that proper names are (abbreviated) definite descriptions is to account for the cognitive values of sentences containing proper names, that theory fails to do what it’s supposed to do.
3.1 A cure for Salmonella (continued)
But Kripke’s parable exposes a problem much more profound than anything having to do with the semantics of a proper name. It’s a datum that Pierre understands each of (1) and (2), that he assents to each, and sincerely utters each. So it’s a datum, or follows from data, that Pierre is rationally accepting some sentence and its negation.
   This seems like a problem. A paradox. What’s the solution? Pierre is rational. No denying it. And Pierre understands each of (1) and (2). No denying that either. (To be sure, he doesn’t know as much about the thing that is referred to as “London”/”Londres” as some other people. But so what? If I know who it is that “Larry” refers to, then I know the semantics of “Larry.” Obviously I don’t know who Larry is as a person as well as his therapist. But I know the semantics of “Larry” every bit as well.)
   
Kripke says that he doesn’t know how to solve the problem. He says only that he’s inclined to suspect that “the apparatus of propositions breaks down here.” He doesn’t say what he means by this. Nor does it matter, since, whatever it means, it’s false, as we’ll see.
   Nathan Salmon says that, given Kripke’s parable, it follows that, at a given time, one can rationally accept a proposition and its negation. Pierre would be rational, given what we’ve said so far, to believe that “Londres ≠ London” is a true sentence. Thus, there is some x (namely, London) such that, according to Salmon, Pierre can rationally believe that: x ≠ x—that is, that x is not self-identical. Thus, Salmon’s position is that one can rationally believe that London is not self-identical—that, in fact, any given object is not identical with itself.
3.2 Why, contrary to what Nathan Salmon ways, it is not rational to believe both P and not-P
Salmon’s solution is not only desperate, but utterly incoherent. What is rationality? It’s the ability to draw the consequences of the information at one’s disposal. No truth is a consequence of its own negation, and every truth is incompatible with its own negation. Given that P and not-P is always false, it can never be rational to accept it or, therefore, to infer it. Salmon’s position is inconsistent with the very meaning of the word “rational.”
   Salmon sometimes defends his position by saying that one can rationally accept P and not-P only if one doesn’t know that what one is accepting is a proposition and its negation. But this makes no sense. You are irrational if you believe P and not-P or if you grasp both P and not-P and yet fail to generate the additional belief that they’re inconsistent with each other. For acceptance of P and not-P to be rational, it would be necessary that the data at your disposal not make it clear that you were accepting some proposition and its negation, which would be possible only if you didn’t know what it was you were accepting. And this seems to be what Salmon holds.
   But, contrary to what Salmon evidently thinks, you can’t accept a proposition without knowing what it is. The counterexamples to this are spurious. Suppose that Smith believes anything that he believes Jones to believe. If Jones believes that Lima is the capital of Peru, does it follow that Smith also believes it? No. What follows it is if Smith were to know that Jones believed it, then Jones would believe it. In order to accept a proposition, it is not enough that it be described to you. You must actually grasp it. Another story will make this clear.
   Person X is never convinced of anything unless it actually is true. This has been verified, and I know this. Smith and I have a mutual friend, Green, who has been missing for the last three weeks. One day Smith tells me that he knows where our friend Green has been for the last three weeks. I have no idea where Green has been. I couldn’t even guess. But Smith doesn’t tell me where Green has been—only that he knows where he’s been. So there is some proposition P such that, if correct, P says where Green has been and such that Smith accepts P. I know that whatever it is that Smith believes about Green’s whereabouts is correct. But do I, under these circumstances, accept the proposition that identifies his whereabouts? No. If I were told what that proposition was, I would accept it. But I do not now do so. I don’t know what the right value of P is.
   Suppose that, as Smith knows, Green has been in Spain for the last three weeks but that I’m not told this. Under these circumstances I don’t accept the proposition: Green has been in Spain for the last three weeks. I would accept it if I knew that Green accepted it. But I don’t yet know this, and I don’t yet accept it. The proposition that I do accept is this: I know that, whatever Smith believes to be the proposition describing Green’s whereabouts over the last three weeks, that proposition must be correct. But that proposition is very different from Green has been in Spain for the last three weeks. And I don’t yet accept the latter.
   What this shows is that one cannot accept a proposition without knowing that one is doing so. When it seems as though one does this, one accepts some distinct proposition that describes some unknown proposition. If you accept a proposition, you know it. So if, for some P, you accept both P and not-P, you know it. But if you know it, you’re not rational, since anyone who makes a faulty inference is ipso facto irrational (to that extent), and any inference whose conclusion is P and not-P is ipso facto faulty. 

3.2.1 Why, contrary to what Nathan Salmon says, it is not rational to believe both P and not-P (continued)
Salmon was driven to accept this preposterous view by his failure to take into account even the most basic points concerning the relationship between thought and language. Pierre doesn’t learn what “London” refers to in a vacuum. He is air-dropped into a horrible part of a certain city. There is garbage all around. His captors are rude to him, and so are the people with whom his captors associate. (The only Londoners with whom Pierre’s captors consort are, uncharacteristically for Londoners, not very nice people.) He is then told: “Welcome to London! This is your new home.” Let us suppose, in fact, that one of his captors is a philosopher of language who, like all those in that field, has a penchant for making things explicit. So, when first introducing Pierre to his new home, he says: “there is a certain city x, such that x is the city you are now occupying— this being the city whose dirty, garbage-ridden streets you are now beholding—and such that ‘London’ refers to x.”
   What Pierre is being told, in being told this, is something along the lines of:

(L1) there is some vile, squalid, garbage-infested city x such that I am now in x and such that I was dragged here against my will and such that, because of x’s obvious horridness, I am now depressed; moreover, “London” refers to x.

An inevitable consequence of the fact that these are the circumstances under which Pierre learns what “London” refers to is that what an utterance of

(2) “London is not pretty”

would impart (not semantically encode) is something along the lines of:

(L2) there is some vile, squalid, garbage-infested city x such that I am now in x [etc.] and such that “London” refers to x; moreover, x is not pretty

and, in general, that for any property psi

(Ln) ‹London has psi›

would impart (not semantically encode) something along the lines of:

(L*P2) there is some vile, squalid, garbage-infested city x such that I am now in x [etc.] and such that “London” refers to x; moreover, x has psi.

   We’ve already made it clear why, even though Ln would convey L*P2, Pierre wouldn’t be under any illusions as to what the former literally means. It’s also obvious that, since it’s through L1 that Pierre knows what “London” refers to, it is rational of him to accept (2).
   Let’s think back to the time when Pierre, not yet having been abducted, was still in Paris. As we’ve said, Pierre has a lot of information about the city he knows as “Londres” and he draws the only reasonable inference that, given that information, he can draw; namely, that it is a pretty city. For he has read in various books that he knows to be authoritative that:

(##) There is a certain city x such that x is more populous than any other in Britain, such that is the Capital of Britain, such that there are beautiful buildings in x, such that x’s streets are generally very clean, there isn’t much violent crime in x, there are beautiful buildings in x, etc.; moreover, “Londres” refers to x.

Given that it is through some proposition along the lines of ## that Pierre knows what “Londres” refers to, it is inevitable that an utterance of:

(1) “Londres est jolie”

would convey to him something along the lines of:

(##^) There is a certain city x such that x is more populous than any other in Britain [etc.] and “Londres” refers to x; moreover, x is pretty.

And given that (1) communicates (##^) to Pierre, it’s clear, given the information at his disposal, that he’s rational to accept (1).
   Here’s what’s going on. Pierre knows what “London” refers to and he also knows what “Londres” refer to. He doesn’t know that they refer to the same thing, since the body of descriptive information that he uses to attach “London” to the right thing is different from the body of descriptive information that he uses to attach “Londres” to that thing. This is consistent with the supposition that he knows what “Londres” and “London” refer to. (I may not know that my friend Smith is also the masked bandit and, therefore, that “the masked bandit” refers to Smith. But I know who “Smith” refers to—he refers to my amicable next-door neighbor. And I also know who “the masked bandit” refers to—it refers to the cape-wearing buffoon frequently featured on the evening news.) Given that Pierre speaks both French and English, he understands (1) and (2). He rationally assents to both, even though the one is the negation of the other. This is not because he ratio-nally accepts some proposition and its negation. Nor is it because “the apparatus of propositions breaks down,” whatever that means. No—it’s because, given the information through which he learned the relevant semantic rules (the ones that, for some x (namely London), are to the effect that “Londres” refers to x and that “London” refers to x), (1) and (2) communicate very different propositions to Pierre. Those propositions don’t entail each other, and they are, in addition, supported by very different bodies of data.
   There is no proposition that Pierre both accepts and rejects. Salmon is just plain wrong to think otherwise. And his contention that one can rationally accept propositions and their negations involves a number of rather obvious fallacies. First, sentences are not propositions. Suppose that sentence S1 encodes proposition P1 and that sentence S2 encodes the negation of P1. Given only that information, it doesn’t follow that a person who understands S1 and S2 can’t rationally accept both of those sentences. For it could be that, given the information through which that person learned the relevant semantic rules, the propositions conveyed to him by those sentences could both be true. Salmon agrees that, given only that the proposition encoded in the one sentence is the negation of the proposition encoded in the other, one can rationally accept both sentences. But he thinks this is because one can rationally accept propositions that are inconsistent with each other; Salmon thinks that one accept the propositions P and not-P without being irrational. This is a deeply irrational belief. Irrationality is acceptance of incoherencies, such as P and not-P.
   Salmon holds, correctly, that Pierre is rational in accepting both (1) and (2). According to Salmon, it follows from this that Pierre is rationally accepting some proposition and its negation. But that would follow only if what (1) and (2) conveyed to Pierre were confined to what they literally mean. But what sentences convey isn’t always confined to what they literally mean. It’s seldom confined to it. (See Chapters 9 and 18.) Every semanticist knows this. It’s unclear why Salmon doesn’t know it or why, if he does, he didn’t see its bearing on this issue.

3.3 Some final remarks on Frege’s conception of reference: Frege’s distinction between sense and reference are a distortion of the distinction between pre-semantics and semantics
We’ve seen that if a proper name N refers to some object x, then, in virtue of having the form ‹N has psi›, a sentence S is true just in case:

(i) x has psi.

It immediately follows, as we’ve noted, that Frege’s analysis of proper names is false. According to Frege, proper names, and indeed all referring expressions, have “senses.” If a referring term M refers to y, M’s sense is some property phi that y uniquely instantiates. And, if Frege is right, in virtue of having the form ‹M has psi› a sentence S* is true just in case:

(ii) phi is uniquely instantiated; moreover, any such instance has psi.

   No sooner is Frege’s analysis made clear than its incoherence is plain to see. (ii) is an existential generalization, and the reason for this is that it contains what Frege regards as a referring term. Thus, if Frege’s analysis of proper names is right, they are semantically indistinguishable from existential quantifiers and, therefore, are such quantifiers. But Frege says they’re referring terms. Since, therefore, Frege’s position is, in effect, that proper names both are and are not quantifiers, it is incoherent.
3.3.1 Indirect reference = quantification = non-reference, direct reference = only true form of reference
Frege’s position is that names refer indirectly. In other words, they refer through the mediation of a sense, and that sense is what makes it into the propositions meant by sentences containing those names. The referents of those names don’t make it into those propositions. By virtue of containing proper names of those objects, sentences containing those names merely describe their referents. But we’ve just seen that “indirect reference” is really just quantification.
   Frege’s distinction between “sense” and “reference” is an incoherent way of describing the distinction between semantics and pre-semantics. There is some entity O, namely London, such that the proposition literally meant by 2 is true just in case:

(ONP) O is not pretty,

but such that, because of how Pierre learned what “London” refers to, what 2 conveys to him is (L*P2).
   Frege would have said that the sense of “London” is some property uniquely had by London (e.g., the property of being a city that is vile, squalid, etc.). But that isn’t true. One’s knowing what “London” refers to consists in there being a property phi—it doesn’t matter which one—such that one knows that phi is uniquely instantiated and that “London” refers to any instance of it. There is no one property phi such that one’s knowing of what “London” refers to consists in one’s knowing that phi specifically is uniquely instantiated and that “London” refers to an instance of it.
   And yet Frege constantly speaks of the sense of “Socrates,” “London,” etc. Although this view is patently false, Frege has a good reason for holding it. He thinks that if “London” had as many senses as there were people who knew what it referred to, then “London” would be useless as a device of interpersonal communication. When I said “London is pretty,” I’d mean one thing (e.g., the most populous city in the UK is pretty) and what you’d mean by that sentence would be something else (e.g., the city where grandma lives is pretty).
   
But we’ve already seen why this is spurious. There is some x such that I know that x is the most populous city in England and such that I know that “London” refers to x and, finally, such that, when I say “London is pretty,” what I am affirming, and what other English-speaking auditors (who know that I speak English) know me to be affirming, is:

(LP) x is pretty.

And there is some x such that you know that x is where your grandmother lives and such that “London” refers to x and, finally, such that, when you say “London is pretty,” what you are affirming, and what other English-speaking auditors (who know that you speak English) know you to be affirming is

(LP) x is pretty.

   So while it’s a fact that “London” has one sense for me and a different sense for you, that doesn’t prevent us from using it to make ourselves understood to each other. And the reason is that these senses don’t make it into what we are affirming or what we believe ourselves to be affirming.
   Bearing these points in mind, let’s wrap up our discussion of Pierre. Pierre has a thorough grasp of the semantics of “London.” For him, the sense of “London” is a squalid and horrible city where my kidnappers have forced me to live, or some such. There are others who grasp the semantics of “London” but don’t associate that property with that expression. The sense of “London” varies from person to person. (We’ve just explained why this does not undermine people’s ability to use that expression to make themselves understood to others.) This is because what the sense of “London” is for a given person depends, not on its literal meaning, but on the information through which that person grasps that literal meaning. Sense, therefore, is pre-semantics, not semantics.
3.4 Salmon on non-existence and mythical objects
Nathan Salmon holds that one can say of a given thing x that x exists or that it does not exist. Indeed, Salmon says that one can correctly say of a given thing x that x does not exist. Of course, for one to correctly say of a given thing x that it doesn’t exist there must exist some thing such that one is correctly saying of it that it doesn’t exist. So there must exist something that doesn’t exist. Since this isn’t possible, Salmon is wrong.
   But arguments like the one just given have been around since Russell first produced them over a hundred years ago; and Salmon, being a devotee of Russell’s works, is well aware of these arguments. So why does he hold that one can correctly attribute non-existence and existence to objects?
   Salmon has a couple of reasons. The sentence:

(1) “Socrates is Socrates”

doesn’t mean the same thing as

(2) “Socrates is the main character in most of Plato’s dialogues.”

Thus, “Socrates” isn’t synonymous with “the main character in most of Plato’s dialogues” or, by obvious generalizations of this argument, with any other definite description. This argument, duly generalized, shows that proper names are not in general synonymous with definite descriptions. From this it follows that proper names are mere labels. “Socrates” no more describes “Socrates” than your social security number describes you.
   Definite descriptions describe their referents. To be referred to by “the tallest person in the room,” you have to have certain characteristics. You must uniquely be a tallest person in the room. If a taller person walks in the room, that expression won’t pick you out. But, whatever your name is, there isn’t any way you have to be

for that expression to pick you. It doesn’t matter how tall or short you are; what your job is; etc. Thus, names are mere labels.
   It follows that, if you say “Bill Jeffries is tall,” there is some individual x such that “Bill Jeffries” refers to x and such that for your statement to be true, it is necessary and sufficient that x be tall—it being entirely irrelevant what other properties x has. The same thing mutatis mutandis obviously holds with respect to “Socrates,” “Winston Churchill,” etc.
   Thus, if N is a proper name (that isn’t a make-believe name or is otherwise one that doesn’t pick anything out) and psi is any property, there exists some object x such that ‹N has psi› is true iff x has psi—it being irrelevant what other properties x has or lacks.
   But now we have a problem. “Winston Churchill” isn’t an “empty” (non-referring) name. It isn’t in the same category as “Rooster Cogburn.” And “Winston Churchill was bald” is meaningful. But Churchill no longer exists. Thus, there does not exist an object x such that “Churchill” refers to x.
   Some people deal with this by trying to revive the idea that proper names are definite descriptions. But this isn’t a good idea, since the arguments just given are clearly probative. Salmon rightly avoids this path. Others deal with it by saying that, since existence is “four-dimensional,” nothing ever ceases to exist. But Salmon rightly rejects this tortured and implausible view.
   Unfortunately, the way Salmon deals with the problem is no more plausible than the two views that he rightly rejects. Salmon says that it is meaningful to say of a given thing (e.g., Churchill) that it doesn’t exist. Salmon’s position is that “Winston Churchill” does have a referent—a non-existent one.
   If Salmon were right to say that one could say of specific non-existent things that they were non-existent, it would follow that one could say of specific non-existent things that they were existent. If a proposition can be affirmed, so can its negation. (Of course, one couldn’t correctly say of a given non-existent thing that it existed. But one could still say it—just as one can say, albeit falsely, that Barack Obama is eight-feet tall.) For similar reasons, it would follow that one could meaningfully (though, of course, falsely) say of a given existing thing that it didn’t exist and also that it did exist.
   Of course, in saying that “Winston Churchill” has a non-existent referent, Salmon is saying that there exists something x such that “Winston Churchill” refers to x and such that x doesn’t exist. And, of course, that statement is self-contradictory—so far as, given the points made earlier, it isn’t completely meaningless. For some reason, Salmon isn’t bothered by the consequence of this theory.
   Salmon is quite right to hold that proper names are mere labels. But, contrary to what he thinks, that fact doesn’t license his desperate and incoherent views about existence. Consider the sentence:

(S1) “JMK plays tennis.”

This sentence is meaningful. In other words, there is some proposition that it expresses. Let P1 be this proposition. We’ve seen that there is some x such that “JMK” refers to x such that S1 is true just in case x plays tennis—that, in other words, P1 is true iff x plays tennis. Salmon knows this, and he concludes from this that JMK is a veritable constituent of P1. In other words, there is some proposition that I am actually a part of. This is a very contrived view, given that I’m a spatiotemporal entity, whereas propositions are not.
   In any case, it isn’t the right view. Under what circumstances is P1 true? First of all, the property of being a tennis player must be instantiated. (If nobody plays tennis, P1 is false.) For obvious reasons, it’s also necessary that the property of being identical with JMK be instantiated. Let PTP and PJMK be the property of being a tennis player and the property of being identical with JMK, respectively. Finally, let PJMT be the property of being identical with JMK and being a tennis player.
   Supposing that P# is the set containing PTP, PJMK, and PJMT, and not containing anything else, the members of P# are collectively instantiated if and only if P1 is true. There is thus no reason not to say that P1 is P# and that for P1 to be true is for all of P#’s members to be instantiated.
   The property of being identical with JMK will exist even after I no longer do, and it existed before I was born. It wasn’t until I was born that PJMK was instantiated; and when I die, it will cease to be instantiated. But that’s irrelevant: properties pre-exist and post-exist their instances.
   
This analysis is consistent with the view (held by Salmon and myself) that “JMK” refers to me, not by describing me, but just by labeling me. Supposing, as we are, that P# is identical with P1, S1 has exactly the truth-conditions that Salmon believes it to have. There is some x (namely, JMK) such that for P1, as we’ve analyzed it, to be true, it is necessary and sufficient that:
   
   (TCS1) x likes tennis
   
After I die, there won’t exist an object of the kind just described. But that’s irrelevant. After I die, P1 won’t be true; it will be false to say, at that point, that JMK plays tennis, the reason being that, sadly, he won’t be doing anything. But our analysis is consistent with that. After I die, PJMK won’t be instantiated.
   It will be true at that point that JMK did play tennis. But our analysis is consistent with that fact as well.
The sentence:

(S2) “JMK used to play tennis”

says the same thing as:

(S3) the proposition that JMK plays tennis used to be true.

According to our analysis, S3 is true iff PTP, PJMK, and PJMT used to be collectively instantiated. And if uttered after my passing, S3 will be true exactly if, at the time of that utterance, those three used to be instantiated. Exactly similar points hold of the propositions expressed by “Churchill was bald,” “Socrates couldn’t read,” etc. Given each of these propositions, Salmon says that it contains a non-existent object. Salmon also says that each of these sentences has a “non-existent proposition” for its meaning. He grants that “Churchill was bald” is meaningful and, therefore, that it encodes a proposition. But he says that this proposition doesn’t exist. So that sentence is meaningful by virtue of encoding a non-existent proposition.
   This is disastrous—and unnecessary. Unlike Salmon’s analysis, ours doesn’t require that there exist anything that doesn’t exist. Ours doesn’t require any violations of logic or commonsense. Our analysis makes only three demands: (i) that there is such a thing as being me; (ii) that to be such a thing as being a tennis player; and (iii) that there be such a thing as me playing tennis. Each of those demands is met.
   I happen to be a Platonist, and I happen to think that each of those three things is a non-spatiotemporal object. But that’s irrelevant. This analysis goes through as long as those three things exist. It doesn’t matter how they’re thought of.
   Salmon doesn’t even consider anything like this analysis. Instead, he holds that, since proper names are labels, it follows more or less directly that there exist things that don’t exist. But surely it’s a very bad idea to throw out the most basic principles of logic and to overhaul our most basic beliefs about reality, just so as to validate some semantic result concerning a certain class of nouns. Moreover, Salmon’s way of validating that fact isn’t even the right one, since, as we’ve seen, that fact is easy to validate within a framework that is entirely congenial to commonsense and its philosophical derivatives.
   Salmon has another, similar reason for holding that one can meaningfully say of a given non-existent object that it exists (or that it doesn’t) and also that one can meaningfully say of a given existent object that it doesn’t exist (or that it does). It’s obvious that:

(ZA) “Zeus is very angry right now”

isn’t in the same category as “blarg blurbo gloxo.” Utterances of ZA communicate propositions. We don’t believe the proposition communicated by such utterances. But all that is relevant here is such that utterances do in fact convey propositions.
   Note: ZA is a sentence of English. But it will help if, whenever necessary, you let ZA represent its Ancient Greek translation.
   
There was a time when people actually believed ZA (or its Ancient Greek equivalent rather). There may be people who believe it to this day. In general, there are proper names that don’t refer to anything. Here I’m not referring to names, such as “Socrates,” whose referents died long ago. I’m referring to genuinely “empty” names.
   Supposing that N is an empty name, one would think that:

(NS) ‹N is a fierce warrior›

would fail to convey anything—that, so far as what it communicates is concerned, it would be in the same category as:

(ES) “__ is a fierce warrior.”

But this isn’t the case. A story will make this clear. Your friend Smith, who is generally pretty credible, tells you a story about a friend of his who has the unusual name of “Gigantus.” You don’t know Gigantus. When Smith first tells you about him, he says:

(SG) “My friend Gigantus is truly extraordinary. Gigantus was the first person to translate the complete works of Shakespeare into Albanian. Gigantus used to be a professor, but he now lives in the woods. He actually lives in a hollowed out tree trunk. For a while he was the best paid male model in Europe [etc.].”

   Smith entertains you with stories about Gigantus for several weeks. Of course, these stories are replete with statements of the form ‹...Gigantus...› (e.g., “Gigantus recently read War and Peace,” “You’d really like Gigantus if you met him,” etc.). It goes without saying that, at least from your viewpoint, these statements aren’t like ES, let alone “blarg blurbo gloxo.” They’re quite as meaningful as “Socrates was a fine orator.”
   Then one day Smith tells you that there is no Gigantus. Smith made him up. It was all a hoax. There is no individual x such that “Gigantus” refers to x. It follows that:

(GW) “Gigantus recently read War and Peace”

fails to have a proposition for its literal meaning. So far as that sentence (or pseudo-sentence) has a meaning, its meaning is comparable to ES’s. (It’s meaning, it would seem is a propositional function, viz. __ recently read War and Peace.) So how are we to explain the fact that, as far as what it communicates is concerned, GW is in the same category as “Socrates was tall,” as opposed to “blarg blurbo gloxo”?
   Here is my answer. When you first encountered it, the name “Gigantus” was embedded in SG. (Remember that SG was told to you by your friend Smith.) It immediately follows that, when you first heard GW, what that utterance communicated to you was some message quite a bit richer than its (as it turns out, nonexistent) literal one. What that utterance of GW communicated to you was along the lines of:

(GWC) There exists a certain extraordinary individual x such that “Gigantus” is x’s name, such that at this moment my friend Smith is telling me about x, such that x lives in the woods in a hollowed tree-trunk, even though x used to be a professor [etc.]; moreover, x recently read War and Peace.

GWC is not GW’s literal meaning. This cannot be emphasized enough. But it is what, because of your circumstances, GWC conveys to you.
   The point is that, even though GW doesn’t have any proposition for its literal meaning, there is no difficulty accounting for the fact that, empty of literal meaning though they be, utterances of it are replete with non-literal communicated meaning. We’ve already seen why much of what sentence-utterances communicate isn’t literal meaning—why much of it is really pre-semantic content that reflects the idiosyncrasies of our knowledge of semantics and that we have some tendency to mistake for semantic content.
   
Nowhere in all this did we suppose that “Gigantus” is synonymous with a definite description. We didn’t have to make that supposition to account for the data. Nor would it have been advisable for us to do so. “Gigantus” isn’t a definite description. It’s a proper name, albeit an empty one. Whatever it is that utterances of ‹...Gigantus...› might communicate, it isn’t because “Gigantus” is a definite description that they communicate it.
   Notice that our analysis is a very conservative one. We didn’t posit any new entities. We didn’t assume facts not in evidence (e.g., we didn’t presuppose the truth of any uncorroborated hypotheses or otherwise prejudge open questions).
   Now let’s look at what Nathan Salmon says about empty proper names, like “Gigantus.” He says that socalled “empty” proper names aren’t empty. He says that “Zeus” does refer to a Greek God. He says that “Vulcan” does refer to an actual planet. (“Vulcan” was the name given by astronomers in the 19th century to a planet that they posited, but that turned out not to exist.) Salmon concedes that Zeus and Vulcan don’t exist in space-time. If you flew around the solar system, you’d never come across Vulcan; if you climbed Mt. Olympus, you’d never see Zeus. But they do exist—they exist, Salmon says, as abstract entities.
   Salmon’s primary reason for accepting this view is that, since he thinks that names are mere labels, he (rightly) doesn’t see it as an option to see “Vulcan” and “Zeus” as being synonymous or identical with definite descriptions. But he finds it puzzling that, for any psi, utterances of ‹Zeus has psi› and ‹Vulcan has psi› are so rich in communicated meaning. He doesn’t consider the proposal that we put forth a moment ago, and instead tries to solve the problem by saying that, in fact, “Vulcan” and “Zeus” do refer to things.
   This isn’t necessary. It’s also pointless. What is communicated by sentence-utterances of the form ‹Joseph Biden has psi› and ‹Charles Keating has psi›, and other sentence-utterances containing no non-empty names, diverges dramatically from what such utterances literally mean. This is a well-known fact. So what it is that “Joseph Biden is a democrat” conveys cannot be explained solely in terms of what it literally means. So even if Salmon were right to say that there is some actual God to whom “Zeus” refers, that wouldn’t explain any of the relevant data—it wouldn’t explain why utterances of “Zeus has a beard” communicate what they do.
   There’s also the fact that Zeus, if he exists, isn’t an abstract object. If he’s anything, he’s a God. If you pay me $1,000,000 to find Zeus, and all I find is an abstract object, I should give you your money back.
   Salmon says that “Vulcan” is a planet—albeit a mythical one. Planets are giant hunks of rock in outer space. “Mythical” planets aren’t hunks of rock. So they aren’t planets. The expression “mythical planet” is in the same category as “Mr. Right.” Its semantic function isn’t to refer to anything and is instead to help us abbreviate otherwise long and unwieldy statements.
   Salmon published an article, titled “Mythical Objects,” in which he attempts to corroborate these views of his. Here is the argument presented therein:
   
   
(MO) Imagine the following. Smith and Jones both believe that Zeus exists, and they both think that he lives on Mt. Olympus and can hurl lightning bolts. One day Smith wakes up with a terrible headache. He thinks that Zeus gave it to him. That same day, Jones can’t find his car. He thinks that Zeus destroyed it. Smith and Jones tell each other about their misfortunes, and they’re in agreement that Zeus is indeed the culprit in both cases. It is thus a fact that:
   
(1#) Smith and Jones believe some one deity (who lives on Mt. Olympus and can hurl lightning bolts) to be responsible for Smith’s headache and also for the disappearance of Jones’ car.
   
(1#) is ambiguous, as it could mean either:
   
(2#) there exists some deity x (such that x lives on Mt. Olympus and can hurl lightning bolts) such that Smith and Jones both believe that x destroyed Jones’ car and also gave Smith a headache
   
or

(3#) Each of Smith and Jones believes there to be some deity x (such that x lives on Mt. Olympus and can hurl lightning bolts) such that x is identical with Zeus, such that x destroyed Jones’ car, and such that x gave Smith a headache.
   
(3#) cannot be the right disambiguation. (3#) says that Smith believes some one deity to be responsible for those two misfortunes, and that Jones believes some one deity to be responsible for them. But (3#) leaves it open whether the deity that Smith has in mind is identical with the one Jones has in mind. That means that (2#) is the correct disambiguation, and therefore, that there exists some deity who lives on Mt. Olympus, etc.
   
   MO presupposes the truth of its own conclusion. Smith’s belief that Zeus exists is identical with his acceptance of something along the lines of:
   
(Z) there exists a deity who lives on Mt. Olympus and hurls lighting bolts (etc.),

the same being true of Jones’ corresponding belief.
   Thus, Smith’s belief that Zeus is responsible for both misfortunes is identical with his acceptance of something along the lines of:

(ZMF) there exists a deity x who lives on Mt. Olympus and hurls lighting bolts (etc.); moreover, x is responsible for both misfortunes

the same being true of Jones’ corresponding belief.
   And the statement that Smith and Jones “believe some one deity [etc.] to be responsible for Smith’s headache and the disappearance of Jones’ car” is just a loose way of saying that Jones and Smith both accept ZMF.
   If there is no Zeus, there is no one entity that Smith and Jones both blame for these misfortunes. Each individual may think that he and the other are both blaming some one deity. But they’re wrong. And (1#) is either false or it’s a misleading way of saying that Jones accepts ZMF and so does Smith. Salmon’s argument therefore fails unless it’s assumed that Zeus exists. But if this is assumed, the argument assumes the truth of its conclusion and is therefore broken.
4.0 Natural kinds and the modality of identity-claims
Consider the statement:

(WH) “water is H2O.”

According to Kripke, WH encodes a necessary a posteriori truth. Here is his argument.

(KA) It obviously can’t be known a priori that water is H2O. Look at a glass of water. Can it be known through “pure reason” or through sheer logic chopping that it consists of H2O molecules? No! Thus, WH is a posteriori.
   We’ve discovered that water is H2O. Given this, suppose that we discovered some substance that was macroscopically just like water, but upon examination turned out not to be H2O. Would we say that it was water? Would we say that water can be something other than H2O? No. We’d say that we had discovered a water imposter. Since, therefore, water must be H2O, WH is necessary, while also being a posteriori.

4.1 Evaluating KA
There is much that is right in this argument. Consider the substance that we bathe in, drink, etc. If that substance is in fact H2O, it couldn’t fail to be H2O. And, just as Kripke says, you can’t have a priori knowledge of the chemical composition of the liquid you bathe in.
   But, contrary to what Kripke thinks, it doesn’t follow that there are any necessary a posteriori truths. The problem is that, as before, Kripke confuses semantics with pre-semantic information.
   Let us suppose that, when you were a child, your father pointed to the liquid in your drinking cup and said “that’s water,” and he said the same thing when pointing to the liquid in the bath you were about to step into, and so on. Kripke correctly says that:

(W0) “water” refers to anything that is a clear liquid in drinking cups, bathtubs, etc.

is false. There could, in principle, be liquids in bathtubs, drinking cups, etc. that weren’t H2O but in day-today contexts were macroscopically indistinguishable from water, and those liquids wouldn’t be water. But your father isn’t mis-defining “water.” For the correct interpretation of his definition is this:

(W1) there is something x such that x is a clear liquid in drinking cups, bathtubs, etc., and “water” refers to x.

W0 has the false consequence that “water” would refer to anything that is a clear liquid in bathtubs (etc). W1 doesn’t have this consequence. W1 says that there is a liquid x that as it happens is in bathtubs and is clear, etc., but may or may not necessarily be so, and “water” refers to that liquid.
   Let’s look at the fact that you learn what “water” refers to throughW1. W1 describes the referent of “water.” It says of this reference that, whatever it should turn out to be, it happens right now to be the clear liquid in bathtubs, etc. So it is through that description, or some other similar one, that you think about water. This doesn’t mean that you incorrectly believe that anything that fits that description is water. It means that you think that what in fact fits that description—but might fail to—is what is referred to as water. So you know that there is something x that in fact fits that description (i.e., is a clear liquid in bathtubs, etc.) and that “water” refers to x.
   Given it is by way of this sort of descriptive information that you know what “water” refers to, it’s inevitable that:

(W2) “water becomes ice when it’s very cold outside”

will convey the message to you that:

(W3) there is something x that is a clear liquid in bathtubs, etc., and is referred to as “water”; moreover, x becomes ice when it’s very cold outside.

To be sure, W3 is not W2’s literal meaning. Kripke has made this clear. There is some clear liquid L such that, as it happens, L is in bathtubs, etc., and such that “water” refers to x and such that W2’s literal meaning is:

(W4) L turns to ice when it’s cold outside.

There’s nothing about bathtubs (etc.) inW4.
   For exactly analogous reasons, there is some liquid L that we bathe in, drink, etc., such that, for any property psi,

(W5) ‹water has psi›

has for its literal meaning the proposition:

(W6) L has psi,

even though it will convey the proposition that:

(W7) there is something x that is a clear liquid in bathtubs, etc., and is referred to as “water”; moreover, x has psi.

In particular, it follows that:

(W8) “water is H2O”

will convey the message that:

(W9) there is something x that is a clear liquid in bathtubs, etc., and is referred to as “water”; moreover, x is H2O (i.e., consists of dihydrogen monoxide molecules),

even though there is something L such that W8’s literal meaning is:

(W10) L is H2O.

W9 is a posteriori. But it’s also contingent. Water doesn’t have to be in bathtubs. (There was water before there were bathtubs.) So we don’t yet have anything that’s both necessary and a posteriori. But, of course, it isW10, not W9, that is W8’s literal meaning. For the appropriate value of L, W10 is indeed necessary (just as Kripke says). But is W10 a posteriori?
   We must make two preliminary points before we take a stand on this delicate question. First, we must distinguishW10 from the information through which it might be grasped. W9 is an example of the sort of descriptive information through one graspsW10. Since one grasps W10 through such propositions, it’s easy to attribute their features to it. Since they are contingent, and we grasp W10 through them, it’s easy to think that W10 is contingent.
   The second point involves our outlining points that will be discussed more fully in Chapter 9. Consider the proposition:

(JS) John snores.

Under what circumstances is it true? The property of being identical with John must be instantiated. The property of being a smoker must be instantiated. And the property of being something that is and is also a smoker must be instantiated.
   We can thus identify JS with a set S consisting of those three properties (viz. that of being identical with John, that of being a smoker, and that of being a thing that is John that is smoking). Since all the members of S are instantiated if and only if JS is true, we may identify JS’s being true with its being the case that all the members of JS are instantiated. Thus, JS may be identified with a set of properties, and the fact that it’s true may be identified with the fact that those properties are instantiated.
   Let’s apply this reasoning to L10. That proposition is true if and only if anything that is an instance of the property of being identical with L is also an instance of the property of being identical with water. L is water. So the first property is the property of being identical with water. The property of being identical with water is the property of being identical with H2O. As Kripke himself stresses, it isn’t the property of being the clear liquid in bathtubs, etc. No—it’s the property of having a certain chemical composition, for something to have

that composition is for it to consist of H2O molecules. So if W10 is true the property of being with water is instantiated just in case the property of having a certain chemical composition, viz. that of being H2O, is instantiated. Since the former is the property of having that composition, W10 is true just in case anything having that chemical composition has that composition. In other words, W10 is true just in case:

(W11) anything that is H2O is H2O

which, though necessary, is a priori.
   Once again, we find that Kripke’s claim that he’s found a necessary a posteriori truth involves his conflating two truths: one a posteriori and contingent, the other necessary but also analytic.
5.0 The causal vs. the descriptive theories of conception
According to Russell, “Socrates” is synonymous with a definite description; this might be “the great philosopher of antiquity who died of hemlock poisoning.” To understand the word “Socrates,” and thus to understand sentences of the form ‹...Socrates...›, one must obviously know the semantics of “Socrates.” So one must know that “Socrates” is synonymous with that definite description. Consequently, anyone who uses the word “Socrates” with understanding is able to produce a description that applies to Socrates and Socrates alone. In general, if one knows the semantics of a referring term, then one knows some description that applies uniquely to the referent of that term. (A description “uniquely applies” to x if x uniquely satisfies it. So the description “president of the U.S. in 2009” applies to/is uniquely satisfied by Barack Obama.)
   As we’ve seen, Kripke demolished this view. Consider any description of Socrates that Socrates uniquely satisfies (e.g., greatest philosopher to have died of hemlock poisoning). One can understand ‹Socrates had psi› without knowing that a unique greatest philosopher to have died of hemlock poisoning had psi. The same thing mutatis mutandis holds of any description that singles out Socrates. It follows that “Socrates” isn’t synonymous with “the greatest philosopher to have died of hemlock poisoning” or with any other definite description and that the same thing mutatis mutandis is true of any other proper name.
5.1 The causal theory of reference
Rightly rejecting Russell’s view, according to which “Socrates” is a definite description that picks out Socrates, Kripke an alternative—to wit, “Socrates” refers to Socrates because a certain kind of causal relation holds between tokens of “Socrates” and Socrates himself (or, more exactly, states of affairs involving Socrates).
   According to Kripke, somebody saw Socrates. (Let’s call that person “Smith,” even though that obviously wasn’t his name.) Thus, Socrates’ presence caused Smith to have certain visual experiences. Smith then gave a name to Socrates. (Since it doesn’t matter in this context that Socrates’ actual name was something of which “Socrates” is a distorted Anglicization, we’ll make the false but expedient assumption that Socrates was in fact named “Socrates.”) Smith passed that name along to people who did not themselves see, or otherwise sense-perceive, Socrates. In order for Smith to pass along that name to a given person, that person had to be causally connected to Smith, and that person had to be causally connected to anyone to whom he transmitted that word. Since, let us assume, I am the 521st installment in this sequence, I can refer to Socrates by saying “Socrates.” Thus, when I say “Socrates,” my words refer to Socrates because they are causally connected to him in a certain way.
   In general, if an expression E refers to an object O, that is because tokens of E stand in a certain causal relation to states of affairs involving O.

5.2 The anti-descriptivist theory of conception
We’ve see that, for any property phi uniquely had by Socrates, one can refer to Socrates using the word “Socrates” without knowing that “Socrates” refers to a unique instance of phi. Presumably, understanding ‹Socrates had psi›, for any property psi, involves having a concept of Socrates. Taken together, these points strongly suggest that one can understand “Socrates,” and can therefore have a concept of Socrates, without knowing some truth of the form: something x uniquely has phi, and “Socrates” refer to x. This position is, of course, antithetical to the descriptivist conception of conception advocated by Russell.
5.3 The causal theory of conception
Because of Kripke’s work, many philosophers accept both a causal theory of reference and an anti-descriptivist theory of conception. Many such philosophers believe that, since these two views of theirs are true, it is de rigueur to accept a causal theory of conception. According to such a theory, x has a concept of y if and only if y has certain sorts of effects on x.
   David Kaplan (1968), himself an advocate of this view, made a point that helps bring out the raison d’être for it. Let X be a low-resolution, distorted photograph of Smith. Let Y be a high-resolution, undistorted photograph of somebody who isn’t Smith but looks just like him. X can be thought of as a distorted, low-resolution, inaccurate, description of Smith, and Y can be thought of as a very good and accurate description of some Smith look-alike. The reason that, despite its shortcomings, X is a picture of Smith is that X is an effect of Smith (or, more accurately, of some situation involving Smith—light bounced off Smith and headed in the direction of a certain camera, etc.). And the reason that, despite its encoding a description that Smith satisfies to a tee, Y is not a photograph of Smith is that it lacks just this sort of causal connection to him.
   Advocates of the causal theory of reference hold that concepts of Smith are to Smith what photographs of Smith are to him and that, for any x, concepts of x are to x what photographs of x are to x.
   I reject this view. I accept Kripke’s point that names aren’t definite descriptions. And, with some qualifications to be stated forthwith, I accept Kripke’s theory of reference. I agree that there is a causal component to conception, at least where spatiotemporal entities are concerned. (One’s concept of a non-spatiotemporal entity does not, I believe, have such a component.) But I agree with Russell that one’s concept of Socrates is descriptive. There is, we will see, an ineliminable causal component to it. But that component is internal to a description that singles out Socrates. And I agree with Russell that one’s concept of Socrates is descriptive and is expressed by a definite description. But, contrary to what Russell says, those definite descriptions aren’t at all like the ones that Russell had in mind.
   How can all of this be true? Simple: pre-semantics isn’t semantics. For elucidation, read on.
5.4 The causal-descriptivist theory of conception
Imagine the following. There are 30 numerically different, but qualitatively identical men in a certain place. Your friend Bob goes up to one of them, put his hand on his shoulder, and says:

(1) This guy is named “Fred.”

You thus know that:

(2) there is some individual x such that x is uniquely a person whom Bob just picked out; and “Fred” names x.

   You thus know to whom “Fred” refers only because you know some true proposition of the form:

(3) something x uniquely has phi; moreover, “Fred” refers to x.
   
Your knowing who “Fred” refers to also depends on your having a causal connection to Fred. Your seeing Fred is important to your having this knowledge, and your seeing him involves your being at the receiving end of a causal process beginning with him. (x cannot see or otherwise sense-perceive y without being affected either by light signals bouncing off y or by other information-bearing processes originating with y.) But it’s involved only because it’s involved in your knowing some truth like (2)—some truth that describes the referent of the expression in question.
5.4.1 The causal-descriptivist theory of conception (continued)
Imagine that you are talking with your friends Smith and Jones. They suddenly starting talking about somebody named “Argo.” They are acquainted with Argo, but you are not. At no point in the conversation do they ever say anything like “Argo was my divorce lawyer” or “Argo was the best man at my wedding.” They never explicitly or implicitly tell you anything of the form:

(4) something x uniquely has phi; moreover, “Argo” refers to x.

   Suppose that, during this conversation, at time t, Smith says “Argo was a cad.” Obviously the description ‹x is a cad› is indefinite, and many satisfy it. But on that occasion, there was, as you know, exactly one person who Smith was describing as being a cad, and you thus pick up knowledge of some claim along the lines of:

(5) on occasion t, there was exactly one person who Smith described as being a cad, and ‘Argo’ refers to x.

And, of course, (5) has (4) for its form.

   So merely by virtue of being in a position to “pick up” use of the term “Argo,” you are ipso facto in a position to know the truth of (1). Thus merely by virtue of being in a position to “pick up” use of the term “Argo” some existence-claim of the form: there is some x such that x uniquely has phi and “Argo” refers to x.
   It is plain that what enables you to pick up the term “Argo” is your knowledge of some claim of the sort just described. Your picking up a term like “Argo” involves your hearing or reading a sentence of the form ‹...Argo...›. It thus involves your encountering a case of somebody’s ascribing a property to Argo. (This is true even if you read such sentence: you are still, in effect, encountering somebody’s using that sentence to make such a statement.)Whenever you hear a token of ‹Argo has phi› you are thereby made aware of the fact that there is somebody x such that, on that occasion, the property of being a phi is being ascribed to x and x alone; and you are also being made aware of the fact that, on that occasion, “Argo” is being used to refer to x. On any such occasion, therefore, you are being apprised of an existence-claim that Argo uniquely satisfies, even though no such claim is being overtly stated.
   We must be careful to distinguish the following claims:

(a) Exactly one person has phi.
(b) Exactly one person is being described, on some particular occasion, as having phi.

   There are many cads. But there are many occasions where only one person is being described as a cad. Your learning who “Argo” refers to doesn’t involve your learning that:

(6) exactly one person x is a cad, and “Argo” refers to x.

You couldn’t possibly “learn” (6), since it’s false, given that there are many cads. Your learning who “Argo” refers to involves your learning that, on some occasion, somebody x is being described by some specific person (Smith) as a “cad.” 
   
What these remarks show is that, even though names are merely labels, we can attach them to their referents only because we know of descriptions that single those referents out. Semantically, “Argo” and “Socrates” are mere labels. But pre-semantically, they are descriptions. The information that one must use to affix them to their referents is descriptive in nature, and so is the information one must work through to interpret utterances containing occurrences of them.
5.5 The problem of forgotten start-up descriptions
One typically forgets the existence-claim through which one added a name to one’s lexicon. One typically forgets the first time one heard “Shakespeare” or “Aristotle”; one often forgets one’s first meeting of a person. Given this, one is tempted to say:

You don’t necessarily associate any uniquely individuating description with “Aristotle” or “Smith” or “Jones.” Such a description was needed to enable you to refer to those people, and to think about them. But once that ability is in place, the description drops out. At that point, there can be pure thought about the entities in question. You can just think about Aristotle and Smith; you don’t have to think about them through a uniquely individuating description.

   Remember what we said earlier about “Fred.” Your adding “Fred” to your lexicon involves your learning some truth of the form: somebody x uniquely has phi and “Fred” names x.
   Bearing this in mind, suppose that you and a friend are at a party. You see somebody wearing a bowler hat, talking animatedly. At time t, your friend points to that person and says “that is Fred.” Your adding “Fred” to your lexicon involves your knowing some existence-claim along the lines of:

(E1) there is now somebody x who I am sense-perceiving and who is wearing a bowler hat; and “Fred” names x.

   Let us suppose that, a minute or so after “Fred” is ostensively defined for you, you go up to him and start talking. Now you have new information about Fred; you have a new uniquely individuating description of him. There are a number of reasons for this, the mere passage of time being one of them. At time t, E1 was your uniquely individuating description. But now that time has passed, E1 has been replaced with:

(E2) there is somebody x whom, a minute or two ago, I was sense-perceiving and attending to, and who was then wearing a bowler hat, and “Fred” names x.
   
   Notice that E2 “interlocks” with E1. The uniquely individuating description changes. But the new one is related to the old one in such a way that some one object uniquely satisfies both of them. The new one thus “inherits” the verifier of the old one. In a moment we will say more about this process of inheritance or transmission.
   Things other than the mere passage of time, will lead to E1’s being replaced. Let’s suppose that you are now engaged in a conversation with Fred. You can see him more clearly than before. (Although, when looked at from afar, he looked healthy and strong, you now see that he is puffy and out of shape.) He is talking about the national debt. As a result, you generate a new uniquely individuating description of Fred, this one being given by an existence-claim along the lines of:

(E3) there is somebody x such that, a minute or two ago, I was sense-perceiving x while standing several feet away from him, and such that, at the present time, I am listening to his puffy and out of shape self talk about the national debt; moreover, “Fred” names x.

Notice that E3 and E2 interlock; E2 transmits its verifier to E3.
   
Now that you have E3, you can drop E2 and E1. You can completely forget them; and that will not jeopardize your ability to think about Fred. Supposing that a moment has passed and that you have stopped talking with Fred, the mere passage of time replaces E3 with a slightly different claim:

(E4) there is some x such that, a moment ago, x was talking about the national debt, and x looked puffy and unhealthy, and “Fred” names x.

Given that you now know E4, you can forget each of E1–E3 without ceasing to be able to think about Fred. And, so long as you are able to think about Fred, this will continue to be the case.

   One’s ability to think about, and refer to, something can only be started up by one’s acquiring knowledge of the right kind of existence-claim. Typically, that specific claim is forgotten. But it is replaced by another interlocking existence-claim. And that second one will, in its turn, be replaced by a third; and so on. Thus, an integral part of one’s ability to think about or refer to an external object is one’s having knowledge of an existence-claim that it uniquely satisfies; i.e., it is my having a uniquely individuating description of him.
   None of this belittles the role that causal connections play in conception and reference. I am able to think about, and refer to, Fred precisely because I saw him: and seeing something involves being causally connected to it. But how is the causal connection involved? What enables me to think about Fred is my knowledge of some existence-claim that describes him: there is some guy whom I am now seeing and attending to, who is wearing a bowler hat, and “Fred” names that guy. The causal connection is involved in my seeing Fred; and my seeing Fred, in its turn, is involved in my having a uniquely individuating description of him. So what is doing the work is my knowledge of a uniquely individuating description of Fred; the causal connection, though essential, has a role that is subordinate and internal to my knowledge of that description.
   Here we need to very clear about a certain distinction: the distinction between literal meaning and cognitive content. “Fred” is just a label. The following statement is true:

(F1) There is somebody x who I met on such and such occasion and who looked pale and talked about communism; and the semantic rule for “Fred” is: “Fred” names x.

The following statement is false:

(F2) The semantic rule for “Fred” is this: There is somebody x who I met on such and such occasion and who looked pale and talked about communism; and “Fred” names x.

The following embodies even more falsehoods than F2:

(F3) The semantic rule for “Fred” is this: for any predicate ‹...x...›, ‹...Fred...› means: There is somebody O who I met on such and such occasion, and who looked pale and talked about communism and...O...

There is some x such that the literal meaning of

(*) “Fred looked puffy and pale”

is simply:

(*LM) x looked puffy and pale.

   But remember that one knows what “Fred” refers to only insofar as one knows some claim of the form: somebody x uniquely has phi and “Fred” refers to x.
   
Tyler Burge (1941–) overlooked these points. The result of his doing so was a doctrine known as content externalism that, in order to be kept from crashing, has had more epicycles added to it than just about any theory in human history. It is to this dark chapter of intellectual history that we turn.
   
   
Chapter 9
Putnam’s Insight and Burge’s Blunder: Semantic Externalism vs. Content-Externalism
1.0 Is linguistic meaning a strictly psychological notion?
In Naming and Necessity, Kripke decisively showed that proper names are not definite descriptions. In doing this, Kripke was making a specific point concerning the semantics of a specific class of expressions. It might therefore seem that what Kripke was doing in NN, though non-trivial, was too narrow to be of great philosophical importance.
   But implicit in what Kripke said about proper names are many deep and important principles concerning the very nature of meaning and the relationship between language and thought. In 1975, Hilary Putnam published an article titled The meaning of “meaning” (henceforth, “MM”) in which he explicitly stated one of these principles and cogently argued for it. What he showed is that what we think does not, by itself, establish what our words and sentences mean.
   It’s obvious that what we think largely determines what it is that our expressions mean. The word “snow” could refer to anything; it would be easy to create a language in which it referred, not to so snow, but to Julius Caesar. (Let’s create such a language right now. Let L be a language that is just like English except that, in L, “snow” refers to Julius Caesar and “Julius Caesar” refers to snow. L is a perfectly good language—it’s as expressively powerful a language as English.) It’s obviously at least partly because of what some people were thinking at certain times that “snow” refers to snow, and not to Julius Caesar.
   But Putnam made it clear that there is an important non-psychological dimension to linguistic meaning. Given only that, at any given moment, person X is psychologically and behaviorally indistinguishable from person Y, it does not follow that the words leaving X’s mouth have the same meanings as the words leaving Y’s mouth. So, supposing that at any given moment X is having a given thought if and only if Y is having an exactly similar thought, and that X is producing a given utterance if and only if Y is producing an exactly similar utterance, it does not follow that what is meant by X’s utterance coincides with what is meant by Y’s. Even though the psychological state that gave rise to the one utterance is just like the psychological state that gave rise to the other, the meaning of the one may diverge from that of the other.
1.1 Putnam’s argument
Let Twin-Earth be a planet in some distant galaxy that satisfies the following conditions. Given any person x on Earth, there is a person y on Twin-Earth who is an atom-for-atom duplicate of x. At any given moment, y has a given thought if and only if x has that thought; y has a given feeling if and only if x has that very feeling. y acts a certain way if and only if x acts in an exactly similar way; y makes a certain noise if and only if x makes an exactly similar noise. Thus, Earth people are psychologically and behaviorally exactly like Twin-Earth people. They think, feel, do, and say the very same things at the very same times.
   It is merely coincidence that Earth people are in lock-step with Twin-Earth people. There is no causal interaction between Earth people and Twin-Earth people. No messages are sent from one planet to the other; nobody on either planet in any way influences anyone on the other.
   Even though Earth and Twin-Earth are extremely similar, there is an important difference between them. On Twin-Earth, the liquid in bathtubs, drinking glasses, lakes, etc., isn’t H2O—it’s XYZ. (“XYZ” is an abbreviation for some long chemical formula.) With that qualification, Twin-Earth is, at any given moment, exactly like Earth.
   
Let’s continue our story. Smith is a psychologically normal, English speaking, adult Earthling who lives in the 1600s. One day, after doing back-breaking work for several hours, Smith desperately wants to drink some cool water. Addressing his companion, Smith says:

(SE) “When people are thirsty, they find it more refreshing to drink cool, glacial water than warm, swamp water; and if there were no clean water, people couldn’t survive.”

This utterance takes place at time t.
   Important point: SE doesn’t refer to a sentence. It refers to a specific utterance of a sentence. It refers to the specific burst of noise produced by Smith at time t. (Different people can utter a given sentence; different people can utter the sentence uttered by Smith (viz. “when people are thirsty, they find it more refreshing to drink cool, glacial water than . . .”)
   Bear in mind here that, in Smith’s time, nothing was known about the chemical composition of water. People obviously had thoughts about water; they wanted to drink it; bathe in it, and so on. But they didn’t know that it was H2O; they didn’t even grasp the concepts needed to grasp the concept of an H2O molecule.
   On Twin-Earth, there is somebody who, at any given moment, is psychologically and behaviorally just like Smith. (This follows from what we said earlier.) Let Twin-Smith be that person. At any given time, Twin-Smith makes the very noises as Smith and, in so doing, expresses the very sentiments. (This too follows from our earlier points.) Thus, at time t, Twin-Smith says:

(TS) “When people are thirsty, they find it more refreshing to drink cool, glacial water than warm, swamp water; and if there were no clean water, people couldn’t survive.”

Important point: TS doesn’t refer to a sentence. It refers to a specific utterance of a sentence—to the specific burst of noise produced by Twin-Smith at time t.
   Question: Does SE have the same meaning as TS? I am not asking whether Smith and Twin-Smith coincide in respect of what they mean by their respective utterances, but whether SE and TS coincide in respect of what they mean. The question doesn’t concern what Smith and Twin-Smith are trying to convey through their respective utterances; it concerns what those utterances themselves mean.
   SE and TS don’t have the same meaning. They have different propositions for their respective meanings, and the one proposition is true in circumstances where the other is false, and false in circumstances where the other is true.
   “Water” refers to the substance whose chemical composition is H2O. That’s a simple fact. A thoroughly competent speaker of English can easily fail to know that “water” refers to that substance. Newton didn’t know it, even though he was an exceptionally intelligent person who spoke perfect English. But that doesn’t matter. Here on Earth, there is a certain liquid x such that x is found in bathtubs, drinking glasses, lakes, and oceans, and such that that is referred to as “water.” That substance was referred to as “water” for many hundreds of years before anything was known about chemistry or, in particular, about the chemical composition of that substance. When, finally, that substance was analyzed, it turned out to consist of H2O molecules. Thus,

(WAT1) “there is some substance x such that x is found in bathtubs, drinking glasses, lakes, and oceans, and such that x consists of H2O molecules, and such that: ‘water’ refers to x.”

Of course, we now know that the substance referred to as “water” is H2O. And if we were to discover some substance that consisted of XYZ, not H2O, but was otherwise just like water, at least as far as the conditions that are likely to obtain on the surface of the Earth are concerned, that other substance wouldn’t be H2O. The chemists who discovered XYZ would not come to the conclusion that water is sometimes H2O and is sometimes XYZ. No—they’d say that water is always H2O, but that a different substance, namely XYZ, is extremely water-like, at least within certain horizons.
   When they weren’t referring to XYZ by its chemical name, chemists would not refer to it as “water.” Maybe they’d refer to it as “pseudo-water” or as “fool’s water”—but not “water.” This practice of theirs wouldn’t be a

case of hair-splitting pedantry. If chemists did refer to this other substance as “water,” their doing so would violate beliefs that are deeply embedded in common sense. Even the most philistine, intellectually narrow human being desperately wants real diamonds, not zirconium imitation diamonds, and thus knows that being diamond-like isn’t the same thing as being a diamond. Similarly, everybody knows that being water-like isn’t the same thing as being real water. And even if some people don’t know it, they’d quickly learn it, no matter how scientifically uninformed they were, if the distinction between water and XYZ became a financially significant one, like the distinction between diamonds and chunks of zirconium paste that resemble diamonds.
   For the same reasons mutatis mutandis, on Twin-Earth “water” would refer to XYZ, not H2O. And it would always have referred to XYZ—even before scientists on their planet discovered its chemical composition.
Before proceeding, let’s deal with an objection that is likely to be heard:

An English-speaking physical chemist obviously knows a lot about water that other English speakers don’t . But what the physical chemist knows that other English speakers don’t has nothing to do with the English language or, therefore, with semantics. Given only that somebody doesn’t have a PhD in physical chemistry, it doesn’t follow that they have any linguistic deficits—that they don’t really know the identities of the semantic rules governing expressions like “water,” “gold,” “lead,” etc. This is all quite uncontroversial.
   But it’s inconsistent with the view you (speaking on Putnam’s behalf) are advocating. You say that, for something to be water, it isn’t enough that it have certain macro-characteristics: it must have a specific chemical composition—it must be H2O. Given that, as a matter of semantics, “water” refers to water, what you’re saying entails that, as a matter of semantics, “water” refers to H2O. But if that were right, one couldn’t master the English language without knowing the chemical composition of water or, by obvious extensions of this argument, the chemical composition of gold or aluminum. But that’s preposterous.
   
   One doesn’t have to know anything about chemistry to have a complete mastery of English (or any other natural language), and it would be preposterous to deny that. But the view I’m describing doesn’t have that consequence. There is some individual x such that the semantic rule for the expression “Barack Obama” is to the effect that:

(BO) “Barack Obama refers to x.”

BO pairs off a name with an individual. If one doesn’t know which individual that is, then one doesn’t know the semantic rule for “Barack Obama” and, therefore, one doesn’t know all of the semantic rules constitutive of the English language in 2009.
   But there are infinitely many ways of singling out any given entity. This is a consequence of the fact that, as a matter of logic, any given object uniquely satisfies infinitely many different descriptions. Let P be the region of space you were occupying the instant you began reading this sentence, and let t be that instant. You uniquely satisfy each of the following predicates: “thing that occupied p one minute before time t + one minute,” “thing that occupied p two minutes before time t + two minutes,” and so on. We’ll henceforth abbreviate the first of these predicates as “P1,” the second as “P2,” etc.
   For argument’s sake, let’s suppose that your name is “Jack Jones.” There is some x such that x uniquely satisfies each of P1, P2, P3, etc., and such that, in order to the know semantic rule governing that expression, one must know that:

(JJ) “Jack Jones refers to x.”

If Smith knows that:

(JJ75) there is some x such that x uniquely satisfies P75 and such that: “Jack Jones” refers to x

and Jones knows that:

(JJ143) there is some x such that x uniquely satisfies P143 and such that: “Jack Jones” refers to x

Smith and Jones are, to that extent, in complete semantic accord. There is some one x such that x satisfies each of P75 and P143, and such that, given any property psi, when Smith says:

(JJ1) ‹Jack Jones has psi›

he is affirming that

(JJ2) x has psi,

and such that when Jones utters JJ1, he too is affirming that x has psi. Further, it is each individual’s intention in uttering JJ1 to affirm JJ2. What each wishes to do is to attribute psi to some person—nothing more. Neither wants to say anything about his way of thinking about that person. Neither wishes to say of P75 or P143 or any other property that it is uniquely instantiated or that all its instances are psis.
   Points exactly similar to those just made about “Jack Jones” hold with respect to “water.” At time t, bathtub B is filled with pure water, on which your rubber ducky is floating. Your mother points to that B and says:

(*) The liquid in the tub is known as “water.”

A few days later, at time t*, you burn your finger in scalding water. Given that water is H2O, it follows that each of the following statements is true:

(1) there is some liquid x such that, at time t, x is what your rubber ducky is floating on; moreover, “water” refers to x.
(2) there is some liquid x such that, at time t, x is what your bathtub is full of; moreover, “water” refers to x. (3) there is some liquid x such that x and x alone is H2O, and such that “water” refers to x.
(4) there is some liquid x such that, at time t*, x and x alone is what scalded your finger; moreover, “water” refers to x.
(5) there is some liquid x such that x and x alone is H2O and such that, at time t*, x and x alone is what scalded your finger; moreover, “water” refers to x.

And so on.
To know what “water” refers to, it is necessary only that you know some truth of the form:

(n) there is some substance x such that x uniquely has property phi; “water” refers to x.
   
   Since water uniquely has each of infinitely many different properties, n is true for each of infinitely many values of phi. Where any given one of these truths is concerned, knowing it is sufficient, but not necessary, for knowing what “water” refers to and, therefore, for knowing the semantics of that expression.
   Since n is a sentence-schema, not a sentence proper, it does not itself express any one of these truths. But in what follows, take n to stand for an arbitrary one of them.
   Only the italicized part of n describes a semantic rule. The rest describes the information through which one grasps that rule. Anyone who knows the semantics of water knows this (though they might not recognize what it is that they know in the statements just made).
Let’s tell another story about Smith and Jones. Both are competent speakers of English. Smith knows that:

(7) there is some liquid x such that x is what is in bathtubs and drinking glasses; moreover, “water” refers to x.

Jones, who is more scientifically minded than Smith, knows that:

(8) there is some liquid x such that x is H2O and such that creatures with gills can breathe when immersed in x and creatures with lungs cannot; moreover, “water” refers to x.

There is some liquid x such that individual’s sole intention in saying

(w2) “water covers most of the Earth’s surface”

is to say:

(w3) x covers most of the Earth’s surface.

Neither wishes to affirm either that:

(w4) there is some liquid x such that x is what is in bathtubs and drinking glasses, and such that “water” refers to x; moreover, x covers most of the Earth’s surface,

or that

(w5) there is some liquid x such that x is H2O and such that creatures with gills can breathe when immersed in x and creatures with lungs cannot; moreover, x covers most of the Earth’s surface.

Each individual’s intention in uttering w2 is to ascribe a certain property to a certain substance. They have the same substance in mind. They wish to attribute the same property to it. Neither wants to say anything about how he thinks about that substance. Neither wants to attribute any property to anything other than that substance. Thus, what Smith means when he says “water covers most of the Earth’s surface” is exactly what Jones means when he utters the same sentence. And so long as each knows that the other agrees with him about what it is that “water” that refers to, any difference between them in respect of how they think about its referent will in no way jeopardize the one person’s ability to understand the other. To put it more formally: provided that, for some x, each believes that “water” refers to x and that each knows that the other believes this, the differences between these two individuals in respect of how they think about that substance won’t jeopardize their ability to communicate with each other.
1.2 Putnam’s semantic externalism (continued)
These points make it clear why it is that Smith and Twin-Smith, though driven to make the very same noises by the very same internal conditions, are nonetheless affirming different propositions. Let’s suppose that when Smith was a child, his mother pointed to the liquid in the tub in which Smith regularly bathed, and which Smith recognized as the liquid that he had to drink in order to live, and said: “That is water.” The message that is communicated to Smith is along the lines of:

(8) There is some liquid x such that x is what I (Smith) bathe in and must also drink in order to survive and “water” refers to x.

Given that the liquid indicated by Smith’s mother is, of its very nature, H2O, it follows that when, at time t, Smith utters SE, his utterance is true exactly if:

(SE*) “When people are thirsty, they find it more refreshing to drink cool, glacial H2O than warm, swamp H2O; and if there were no clean H2O, people couldn’t survive.
   
Because he lives hundreds of years before the birth of modern chemistry known, Smith has no idea what it would even mean to identify water with H2O. Moreover, nobody who is alive at the time has any such idea. Nonetheless, the statement he is making does concern H2O. This shows that:

(PTM) the meanings borne by our utterances are not determined solely by the thoughts we have; there is a strictly non-psychological, strictly environmental dimension to linguistic meaning.
   
   Given what we know about Twin-Smith and Twin-Earth, it follows that, when Twin-Smith utters TS, what he is saying is true exactly if:

(TS*) “When people are thirsty, they find it more refreshing to drink cool, glacial XYZ than warm, swamp water; and if there were no clean XYZ, people couldn’t survive.”

And this is obviously consistent with Putnam’s thesis (henceforth “PTM”).
   The doctrine that PTM is true is known as semantic externalism. It is so-called because, according to PTM, the determinants of the semantics of our expressions are (in some cases, in some respects) external to us.
2.0 Burge’s blunder—the (mis)step from semantic to content externalism
PTM is a deep, important, and original insight, and Putnam deserves sole credit for it. And unlike many of the philosophers who were influenced by his important article, Putnam’s views as to what PTM does and does not imply were correct. In MM, Putnam says that Smith’s words don’t have quite the same meanings as Twin-Smith’s words, even though Smith and Twin-Smith have the same thoughts.
   Under pressure from other philosophers, especially Tyler Burge, Putnam later rejected this correct and profound insight, and he came to accept Burge’s position, which is that, not only do Smith’s words have different meanings from Twin-Smith’s, Smith’s thoughts don’t have the same contents as Twin-Smith’s.
   Burge’s work has been enormously influential. It didn’t just influence Putnam, but analytic philosophy as a whole. Thanks largely to Burge’s work, it came to be widely held for 20 years or so that Smith and Twin-Smith have different thoughts. This must be understood aright. Nobody denies that Smith and Twin-Smith have numerically different thoughts. Burge is making the much less innocuous claim that what Smith is thinking is different from what Twin-Smith is thinking. In Burge’s view, just my thought that it’s hot during the summer has a different content from your thought that it’s cold during the winter, so, according to Burge, the thought that Smith expresses in saying, for property psi, “water has psi” is different from the thought that Twin-Smith expresses by means of that same utterance.
   This interesting chapter in the history of analytic philosophy began in 1979, four years after Putnam published MM, with the publication of Burge’s article “Individualism and the mental” (henceforth, “BI”). Here is what Burge argues. There is a planet, which we’ll call “Twin-Earth,” that is exactly like Earth, with one qualification to be stated in a moment. The events on Twin-Earth are in lockstep with those on Earth. So given that earthling Smith sneezes at a certain time, Twin-earthling Twin-Smith sneezes in the exact same way at the exact same time.
   Given what we’ve said, it follows that English is spoken by many people on Twin-Earth. Twin-Smith is one of these people. On our planet—on Earth, in other words—“arthritis” refers to a disease exclusively of the joints. On Twin-Earth, “arthritis” refers to a malady not only of the joints, but also of certain bones (as opposed to the cartilaginous joints linking bones to one another). So, on Twin-Earth, “arthritis” doesn’t refer to the same disease that it refers to on Earth. It refers to a similar, but distinct ailment. Let us refer to that ailment as “twin-arthritis.”
   On Earth, Smith regards the sentence:
   
(AU) “arthritis is unpleasant”

as expressing a truth. And because he personally suffers from arthritis, he often utters AU. (In this context, it is to be assumed that Smith is speaking sincerely, is cognitively competent, etc., and these same assumptions are to be made about Twin-Smith).
   Like Smith, Twin-Smith regards AU as expressing a truth. But, according to Burge, the thought underlying Twin-Smith’s utterance of AU is different from the thought underlying Smith’s utterance of it. Twin-Smith is thinking about twin-arthritis, not arthritis, and Smith is thinking about arthritis, not twin-arthritis. In a moment, we’ll evaluate this important claim.
   Burge concludes from this that two people who are atom-for-atom duplicates of each other, each a perfect physiological and psychological clone of the other, may have thoughts with different contents. Twin-Smith is thinking Descartes (or Twin-Descartes, rather) was a great philosopher, whereas Smith is thinking Ted Danson is a great philosopher, notwithstanding that Smith and Twin-Smith are, by Burge’s hypothesis, psychologically exactly the same.
   Is Burge right? First of all, he’s right that, on Twin-Earth, “arthritis” doesn’t refer to arthritis, and instead refers to twin-arthritis. This is precisely what Putnam showed. But is Burge right that Smith and Twin-Smith are cognitively different?
   No. How does Smith learn what “arthritis” refers to? Here’s a possible answer (and it’s representative, in the relevant respects, of all the other possible answers). Addressing Smith, so and so says:

(A1) “the unpleasant inflammation in your knees is due to arthritis; arthritis can do terrible damage to one’s joints.”

A1 is to the effect that:

(A2) there is some x such that the swelling in your knees is due to x and such that x can do terrible damage to one’s joints; moreover, “arthritis” refers to x.

For now familiar reasons, it follows that when Smith hears someone say:

(A3) “arthritis has psi,”

the message that is communicated (not literally meant) is:

(A4) There is some x such that the swelling in your knees is due to x, such that x can do terrible damage to one’s joints, and such that “arthritis” refers to x; moreover, “arthritis” refers to x.

Remember that Twin-Smith’s life precisely parallels Smith’s. It therefore follows that, when Twin-Smith hears someone utter (A3), is the message that is communicated (not literally meant) is (A4).
   Thus, contrary to what Burge says, Smith’s thoughts do have the same content as Twin-Smith’s. It’s true that, for the reasons given by Putnam, the sentences they use to express those thoughts don’t always have the same literal meanings. But unless one countenances the obviously false assumption that what we think coincides exactly with what our expressions mean, it doesn’t follow that Smith’s thoughts have the same contents as Twin-Smith’s .
2.1 Literal meaning vs. cognitive content
An utterance on Earth of “arthritis is painful” does have a different literal meaning from such an utterance on Twin-Earth. There is some malady x, namely arthritis, such that x only afflicts the joints and such that an utterance on Earth of:

(A5) “arthritis is painful”

is true just in case:

(A6) x is painful,

it being irrelevant whether some disease that afflicts things other than the joints is also painful. And there is some y, namely twin-arthritis, such that y does not afflict only the joints and such that an utterance on Twin-Earth of

(A5) “arthritis is painful”

is true just in case:

(A6) y is painful,

it being irrelevant whether some disease that afflicts only the joints is also painful. But Burge is wrong to conclude from these facts that Smith and Twin-Smith have different thoughts.
2.2 A second Burge-style argument
Let W1 be the actual world and let W2 be some other possible world. In each of W1 and W2, my friend Max has an identical twin Gary. Gary and Max are cosmetically, physiologically, and behaviorally completely and totally indistinguishable. To know that one is seeing Max as opposed to Gary, or vice versa, one has to rely on ulterior knowledge (e.g., that Gary is now in Finland and that he couldn’t possibly be the person with whom one is now lunching in New York).
   In W1, at time t, my friend Sally and I are 10 feet away from Max, and I’m looking right at him. In W2, at time t, Sally and I are 10 feet away from Max’s identical twin, Gary. Otherwise, W1 at t and W2 at t are indistinguishable (at time t). Given only the information available to me by virtue of having the perception involved in my seeing Max, it is not even a theoretical possibility that I might encounter some evidence or have some experience on the basis of which I could rationally conclude that I was in the one world as opposed to the other.
   Moreover, the experiences that I have had in W1 up until time t have been qualitatively identical with those that I’ve had in W2 up until time t. So neither my current experiences nor my memories nor the two combined could possibly enable me to determine whether I’m in the one world as opposed to the other.
   It is to be assumed in what follows that all my utterances are sincere—they express beliefs that I actually have.
In W1, while pointing at Max, I tell Sally:

(U1) “That entity is wearing a plaid shirt.”

(In due course, it’ll be clear why I’m using the word “entity” as opposed to individual.) In W2, while pointing at Gary, I tell Sally:

(U2) “That entity is wearing a plaid shirt.”

U1 and U2 are specific utterances. So U1 is an utterance that occurs in Max’s presence in W1, and U2 is an utterance that occurs in Gary’s presence in W2. In each world, I know that I’m seeing either Gary or Max, but in neither world do I know which of the two I’m seeing.
   In W1, there is some individual x, namely x, such that such x ≠ Gary and such that U1 is true exactly if:

(MP) x is wearing a plaid shirt.

In W2, there is some other individual y, namely Gary, such that y ≠ Max and such that U2 is true exactly if:

(GP) y is wearing a plaid shirt.

MP is true just in case Max is wearing a plaid shirt, it being irrelevant whether Gary is wearing one. And GP is true just in case Gary is wearing a plaid shirt, it being irrelevant whether Max is wearing one. Neither entails the other; neither entails the negation of the other. MP and GP are different propositions.
   U1 expresses what I’m thinking in W1, and U2 expresses what I’m thinking U2. U2s ’ truth-conditions coincide with those of the thought I’m having in W1, and are therefore given by MP; and U2’s truth-conditions coincide with those of the thought I’m having in W2 and are therefore given by GP. Thus, the belief expressed by U1 has a different content from the belief expressed by U2.
   Of course, in W1, my visual experience results from light bouncing off Max, not Gary; and in W2, it results from light bouncing off of Gary, not Max. But apart from that fact, there is absolutely nothing that at that time distinguishes my situation in the one world at time t from my situation in the other world. My intracranial situation in W1 is just like my intracranial situation in W2.
   But we just saw that the content of what I’m thinking in W1 at t is different from the content of what I’m thinking in W2. This difference must derive from the fact that, in W1, my mental state has a certain external cause (light bouncing off of Max), whereas in W2 it has a different external cause (light bouncing off of Gary).
2.3 Burge’s failure to distinguish what we know directly from perception from what we infer from perception
The conclusion of this argument is false, and there is thus something wrong with the argument itself. The problem with it is that it assumes that the relationship between linguistic meaning and cognitive content is much tighter than it actually is.
   Let’s suppose the following. I’m in some world W3 (not identical with W1 or with W2). I’m with my friend Sally. I bet her $10 that within the next 24 hours we’d see somebody wearing a plaid shirt. She doesn’t know, or know of, either Max or Gary. W3 is exactly like each of W1 and W2 except that, in W3, the thing standing in front of me isn’t Max or Gary—it’s a robot that looks exactly like both of them. I don’t (yet) know that such a robots exists. I’m friends with Max and Gary. I happen to know that Gary is out of the country. I also know that Max is somewhere in the vicinity. So, given that I’m looking at something that looks exactly like Max, I believe that I am seeing Max. I’m with my friend Sally. I see that the thing I’m beholding is wearing a plaid shirt, and I say:

(U3) “That entity is wearing a plaid shirt.”
   
   Let VR be the visual perception of which my seeing this thing consists. VR is utterly high resolution and veridical. I’m seeing the thing before me, whatever it is, as it is. Given that this thing looks exactly like Max and Gary, my seeing it as it is involves my having a perception exactly like the one that I’d have in that very situation if ceteris paribus, it was Max or Gary I was seeing.
   Thus, VR does not itself tell me who it is that I’m seeing. Given only what VR tells me, that thing could be Max or Gary or some third person (or thing). VR does tell me that I’m seeing somebody with such and such characteristics, among them that of wearing a plaid shirt.
   I’m wrong about who (and what) that entity is. But that doesn’t affect the belief I’m trying to get across. I don’t care who or what that entity is, and neither does Sally. All we care about is whether it’s wearing a plaid shirt. I correctly believe that it is wearing a plaid shirt, and that’s the belief I’m trying to get across by uttering U3. Therefore, the belief embodied in U3 is correct.
   This has two very important consequences, each of which is incompatible with Burge’s position. Consequence #1: There is no particular x such that VR tells me that it’s x I am seeing. This follows from the fact, just noted, that VR does not itself apprise me of the identity of the thing that I’m seeing.
   
Consequence #2: There is no particular x such that the belief embodied in U3 is correct only if x is plaid shirt. This follows from the fact, earlier noted, that the belief embodied in U3 is correct as long as the thing we’re seeing is wearing a plaid shirt, it being irrelevant who or what that thing is.
   Suppose that Robo-Max is the entity that I’m seeing—that he’s the object of VR. Given only what VR is telling me, I could be seeing any number of different individuals. What VR tells me is that there is somebody having such and such characteristics—that there is somebody standing in a certain place and wearing a plaid shirt. So the content of VR is existential. It tells me that:

(CVR) There is some entity x such that x has such and such characteristics, such that x is standing in a certain place and such that x is wearing a plaid shirt.
   
   Obviously, CVR is at least one of the things that, on the basis of VR, I believe to be true. And it’s the relevant belief in this context, since it’s the one embodied in U3.
   Supposing that VM is the perception I’m having in U1 of Max, and that VG is the perception I’m having in U2 of Gary, it follows that the belief embodied in U3 has the very same content as the belief embodied in U1 as well as the belief embodied in U2. Remember that, from an experiential standpoint, no two of these situations are distinguishable, even in principle.
   Let’s state as clearly and explicitly as possible how Burge goes wrong. Burge says that what VR is telling me is different from what VM is telling me and also from what VG is telling me. Burge thinks that there is some x, namely a certain robot, such that VR is correct just in case:

(bx) x is wearing a plaid shirt.

And Burge thinks that there is some y, namely Gary, such that VG is correct just in case:

(by) y is wearing a plaid shirt.

Finally, Burge thinks that there is some z, namely Max, such that VM is correct just in case:

(bz) z is wearing a plaid shirt.

Of course, none of these three propositions is equivalent with other; none so much as entails either of the others. So if Burge is right, then the proposition encoded in my visual perception in W3 is different from my visual perceptions in W1 and W2, and the propositions encoded in the latter two perceptions are different from each other.
   But Burge is not right. Given only what VR is telling me—in other words, given only what I know on the basis of VR without the help of pre-existing, background knowledge derived from some source other than VR—I can’t possibly know that I’m seeing robot x as opposed to person y as opposed to person z as opposed to Martian w. The content of my perception on W3 is, quite obviously, neutral with respect to the identity of the object of that perception, and its content is therefore, in that respect, general and, more specifically, is given by CVR.
Russell (1927) makes this point very clearly:

Prejudice tells you that you see the same table on two different occasions; you think that experience tells you this. If it really were experience, you could not be mistaken; yet a similar table may be substituted without altering the experience . . . there is nothing to show that one identical entity causes the two sensations.
   
   The message embodied in VR goes through regardless of who it is that I am seeing to be wearing a plaid shirt. That identity-independent message is embodied in the belief underlying my utterance of “that guy is wearing a plaid shirt,” and it’s embodied in that utterance. Therefore, Burge is simply wrong to identify the

content of that belief with bx. For exactly similar reasons, Burge is just plain wrong to identify bx (by)with what VM (VG)tells me and with the belief embodied in U1 (U2).
   Of course, there are differences between those situations. In the first, it’s Max who’s standing in front of me; in the second, it’s Gary; in the third it’s a robot. But these differences don’t lead to any experiential differences, since those three things all look exactly the same. In none of these worlds can the content of my visual perception, taken by itself, register that it’s Max, Gary, or some third thing that’s in front of me. Given that
CVR is the content of my visual perception in W3, it follows that CVR is also the content of my perception in U1 and also of my perception in U2. (The content of my visual perception in the one world coincides with the content of my visual perception in each of the other worlds.) Given that, in W3, it’s my belief that CVR is true that leads me to utter U3; it follows that it is that same belief that prompts me to utter U1 and also U2.
2.4 Burge’s failure to distinguish literal meaning from cognitive content
U3 does indeed have different truth-conditions from each of U1 and U2. But it doesn’t follow that the thought underlying U3 is different from the thought underlying U2/U3.
   Not only does it not follow: it isn’t true. What VR is telling me, and what I believe strictly on the basis of it, is CVR. It’s true that I have other beliefs. I believe (incorrectly) that it’s Max I’m seeing. But that belief is a derivative of my belief that CVR is true. And the belief that prompts me to utter U3—the belief I’m expressing—is true, it being irrelevant who or what the plaid-shirt wearer turns out to be.
   An extension of our story about W3 makes this clear. In plain view of Sally and myself, this entity takes its face-plate off, revealing a complex web of circuitry, as opposed to various organic tissues. I now know that it’s a robot, and, given my pre-existing knowledge that Max isn’t a robot, that it therefore isn’t Max. Now that I know that it was a robot that I was seeing, am I to conclude that the belief embodied in U3 is wrong? No. If I look at what is in fact a green car and say “that car is green,” what I’m saying is correct and the belief embodied in that utterance is correct, even though I also happen to have the false belief that the car belongs to Smith when, in fact, it belongs to Jones.
   Nor am I to conclude that VR wasn’t veridical. VR was high-resolution and veridical. The problem had to do with the fact that, in having VR, the thing I was accurately seeing, though not identical with Max, looked just like him, and with the consequent fact that, on the basis of my correct belief in CVR, I erroneously assumed that it was Max I was seeing.
2.4.1 Burge’s failure to distinguish literal meaning from cognitive content (continued)
To clarify and substantiate the points just made, let’s modify what we said about the events taking place in W2.
   You and I are both looking at Gary. (We both have good vision.) I happen to know that the thing we’re seeing really is Gary. I have pre-existing knowledge to the effect that nothing other than Gary looks quite like Gary.
VG is my visual perception of Gary. From an experiential standpoint, VG is completely indistinguishable
from the perception that, in W1, prompted me to utter U1 and also from the perception that, in W3, prompted me to utter U3. VG is the perception that prompts me to utter U2.
   It follows that from a purely experiential standpoint VG is completely indistinguishable from VM and also from VR. It also follows that the belief embodied in U2 is identical with the belief embodied in U1 and also in U3. U1–U3 all express the same belief. So CVR is the belief embodied in each of these three utterances.
   Although I know that it’s Gary I’m seeing, VG itself obviously doesn’t tell me this. Nor does it tell me that, apart from Max, nothing in the universe looks just like Gary. These things were learned independently of VG. My knowledge of them is background knowledge.
   
Thus, there is no individual x such that x is identical with Larry and such that by itself VG tells me that it’s x specifically that I’m seeing. I do indeed know who I’m seeing. But it’s VG plus my background knowledge that gives this information, not VG by itself. Given only what VG is telling me, I could be seeing Gary or Max or some third thing, and the correctness of what I believe strictly on the basis of VG doesn’t depend on who (or what) it is that I’m seeing.
3.0 The gappiness of Burge thoughts
The erroneousness of Burge’s position becomes painfully clear when we register its most immediate consequences. Of those consequences, here’s the one I find most striking. Given two people who are psychologically identical, one of them may be having all sorts of thoughts while the other is a zombie—a mental blank who is no more having thoughts than a tomato.
   Remember that, in W1, there is some individual x such that x = Max and such that U1 (my utterance of “that guy is wearing a plaid shirt”) is true exactly if:

(MP) x is wearing a plaid-shirt.

This is true. Notice that it’s a claim about language, about literal meaning—about what is literally meant by an utterance. It isn’t, at least not directly, a claim about the content of my visual perceptions or my thoughts.
   But Burge holds that, indeed, positions exactly similar to the one just stated about that utterance hold with respect to my perceptions and thoughts. Burge’s holds that, in W1, there is some individual x such that x = Max and such that the content of VM (the visual perception I’m having) is true exactly if:

(MP) x is wearing a plaid shirt.

Burge also holds that, in W1, there is some individual x such that x = Max and such that the content of what I believe on the basis of my visual perception is true exactly if MP.
   This last claim has a very interesting corollary. Let W4 be a world that, with one qualification, is like each of W1–W3. The qualification is that, at the time in question, Sally and I are hallucinating. In other words, I’m not really seeing a man who is wearing a plaid shirt; there’s only empty space in the place where, so I believe, I “see” there to be such a person. But I am having a hallucination that is phenomenologically (experientially) just like VM (and, therefore, VR and VG). We’ll refer to that hallucination as “VH” (short for “visual hallucination”). Prompted by that hallucination, I say:

(U	4) “That entity is wearing a plaid shirt.”

If U4 were correct, it would be because, in the place in question (the one at which I’m pointing), there was some individual w such that w was wearing a plaid shirt; and the proposition that U4 would encode under that circumstance would be:

(bw) w is wearing a plaid shirt.

But U4 is not correct. It’s not true or false. It’s abortive. If I point to a non-existent gnome on my bed, and I say:

(G1) “that gnome weights 8 lbs,”

my utterance presupposes that there is such a gnome, and since that presupposition is false, my statement is neither true nor false. By contrast, if I pointed to the bed and said:

(G2) “there is a gnome on my bed, and that gnome weights 8 lbs,”

that statement would be false. (G1 and G2 are supposed to be utterances of sentences, not sentences per se—sentence-tokens, not sentence-types.) U4 is abortive for the same reason that G1 is abortive. It is neither true nor false. Since any expression that is true or false ipso facto encodes a proposition, and since any proposition is ipso facto true or false, it follows that U4 fails to encode a proposition.
   Burge rightly believes that U4 fails to encode a proposition. But he believes—partly on the basis, it seems—that VH has no content. In other words, he believes that VH isn’t giving me any message. What VH is giving me, Burge believes, is the following message-fragment:

(BLNK) __is wearing a plaid shirt.

The underlining (the ___) is meant to denote a gap or blank of some kind.
   Burge also thinks that the thought I’m having on the basis of VH has a blank in it—that it’s like BLNK. In Burge’s view that thought (or non-thought, as the case may be) is identical with BLNK.
   If Burge is right, what VH gives me has a hole in it, and therefore isn’t really a message; and to the extent that it’s based on VH, the mental activity that follows it doesn’t mediate any bona fide thoughts. Since the mental activity underlying U4 is obviously based on VH, Burge’s view entails that no thought underlies that utterance.
   Burge’s position is preposterous. It’s obvious that VH gives me a complete message. It tells me that there is an individual in a certain place who wearing a plaid shirt (etc.). More precisely, it tells me that:

(CVR) There is some entity x such that x has such and such characteristics, such that x is standing is in a certain place and such that x is wearing a plaid shirt.
   
   CVR is a false message, of course. But that only proves our point, since false messages are complete messages. Burge’s analysis entails that the message given to me by my visual experience is BLNK, not CVR. Since BLNK, unlike the message that is in fact given to me, is neither true nor false, Burge’s analysis is false.
4.0 A corollary of Burge’s externalism: the impossibility of knowing one’s conscious thoughts any better than one knows facts about the spatially and temporally remote past
Let’s continue to think about my situation in W4. In that world, I think that I’m seeing somebody—and I’m wrong. But there’s something I’m not wrong about. In W4, if, at the time I was having VH, I were asked “are you having a thought and, if so, what is it?” I’d say without any hesitation: “yes, I’m having a thought; I’m thinking that the fellow standing over there is wearing a plaid shirt.” Surely my answer to the second question is right. I know what I’m thinking. What I’m thinking is wrong, since there’s no man there. But I’m right to think that I’m thinking it.
   But Burge’s position entails the opposite. In the context in question, I’m not thinking anything. There’s a blank where, had I been in W1–W3, I would have been having a thought. A consequence is that, when you ask me “are you having a thought and, if so, what is it?” I’d be wrong to say: “yes, I’m having a thought; I’m thinking that the fellow standing over there is wearing a plaid shirt.” Why would I be wrong? Two reasons. First, I wouldn’t be having a thought at all. I’d be having a would-be thought, a pseudo-thought, but not a thought. Second, since I wouldn’t be having any thought, my belief as to what specifically I was thinking would also be wrong.
But that’s obviously false.

4.1 The causal conception of conception
To appreciate the depth and severity of this problem, we have to make a few facts about Burge’s views explicit. Here is Burge’s view (this is paraphrase, not a quotation):

(BV) Let’s take another look at the situation described a moment ago—the one in which, in W1, you are thinking about Max. The reason you’re thinking about Max, opposed to Gary or some other entity, is that you’re on the receiving end of a certain causal process that began with Max. Your current thought about Max (i.e., your thinking that he’s wearing a plaid shirt, etc.) resulted from a perception that you had of him. That perception was the result of changes to your physiological condition that were brought about by light-rays that bounced off of him. That is why the sense-perceptions in which those disturbances eventuated were perceptions, not of Gary, but of Max; and that is also why the thoughts in which those sense-perceptions eventuated were thoughts, not of Gary, but of Max. So your current thought—the one embodied in U1—concerns Max, and no one else, because it “tracks back” to Max, meaning that it bears a causal relation of the just-described kind to Max.
   
   In Burge’s view, conception is to be understood in causal terms, not in descriptive terms. Why does he think this? Remember Putnam’s story about Smith and Twin-Smith. Smith’s mental contents are descriptively just like Twin-Smith’s. So far as Smith has a mentally encoded description that picks out H2O, it’s “liquid that we bathe in, drink, is found in lakes [etc.]”; and so far as Twin-Smith has as a mentally encoded description that picks out XYZ, it coincides with Smith’s . At the same time, when Smith says “water covers most of my planet’s surface,” he’s making a statement about H2O, not XYZ; and when Twin-Smith utters those same words he’s making a statement about XYZ, not H2O. Given that Smith’s thoughts encode the same descriptions as Twin-Smith’s thoughts, why do Smith’s words concern H2O whereas Twin-Smith’s concern XYZ? The answer: Smith is on the receiving end of a causal chain beginning with H2O, whereas Twin-Smith is on the receiving end of a causal chain beginning with XYZ.
   The essence of conception, in Burge’s view, isn’t description, and is instead the causal back-tracking relation just described. Smith is thinking about H2O because his thoughts track back to H2O, not XYZ.
   A story makes it clear how untenable this is. Right now it’s 5:38 P.M., April 11, 2009. Let t be our abbreviation for that time. Right now, at t, I’m thinking about Descartes. More specifically, I’m thinking:

(D*) Descartes was a fine philosopher.

I must emphasize that I’m doing a very a thorough job of reflecting on what’s going on in my head right now; and, on that basis, I can say with complete confidence that D* is among the things that I’m thinking. Next year, historical research makes it clear that Descartes never existed—that there was no Descartes. It was all a hoax, we find out; the documents—all forgeries. According to Burge, I’m thinking about Descartes only in so far as my thoughts track back to him in the relevant way. They can’t do that if he didn’t exist. So when it’s discovered that Descartes never did exist, it not only turns out that, at t, I wasn’t thinking D*: it also turns out that D* doesn’t even exist to be thought. Let us momentarily suppose that Descartes did exist. In that case, there is some x such that x = Descartes, and such that D* is correct iff x is a fine philosopher and—Burge concludes from this—such that, for that very reason, if x didn’t exist, D* wouldn’t exist either. Burge thinks that Descartes is an actual constituent of the proposition—of the truth—that he was a fine philosopher. (I myself don’t think this. I discuss this in Chapters 3, 6 and 8, where I identify the fallacies concerning the nature of propositions that underlie this view of Burge’s.)
   So, supposing that Descartes turns out never to have existed, despite years of thought to the contrary, it will turn out, in Burge’s view, that D* doesn’t even exist to be thought. So I can’t even think that I’m thinking it—it doesn’t exist, after all.
   But that seems very wrong. Right now, I’m thinking that I’m thinking that Descartes was a fine philosopher. If JMK* is an occupant of a world where Descartes never existed who is otherwise exactly like me, JMK*’s psychological condition at the current time is exactly like mine. But, whereas I am now thinking that I’m

thinking that Descartes was a fine philosopher, JMK* is failing to have that thought. To the extent that what I am doing right now is thinking D*, JMK* is altogether failing to have a thought. He’s shooting a cognitive blank. That doesn’t mean that he isn’t thinking anything. But to the extent that what I’m thinking right now is D*, he isn’t thinking anything. That means that all of the psychological activity that, in my case, is mediating the thought that D* is, in JMK*’s case, failing to mediate anything. And supposing that, for a split second, D* were the one thought passing through my mind, it follows on Burge’s view that JMK* is, during that split second, not thinking anything at all. Thus, a consequence of Burge’s view is that, given two people who are psychologically identical, one of them may be having a thought whereas the other is thinking nothing at all. But not only is that clearly false: it’s incoherent. Thought is psychological activity. Burge’s view has the absurd result that thought isn’t a psychological process.
4.1.2 Burge’s response
Burge denies that his position is inconsistent with the presumption that people know what they are consciously thinking. To evaluate this claim of his, let’s start out by saying what he does admit. Burge admits three things, which we’ll refer to as “B1,” “B2,” and “B3”:

(B1) No matter what mental states I have, it’s a possibility that Descartes didn’t exist. The documents on which my belief is based could have been forged (etc.).
   Thus, even though (so I think, and so let us assume) I do know that Descartes existed (at least insofar as I know anything about what happened in France centuries ago), I don’t know for sure that he did. Moreover, given only what my own mental states are, it’s a theoretical possibility that he never did exist.

(B2) For argument’s sake, suppose that, in reality, Descartes really did exist. Let’s also suppose that I’m now thinking:

(D*) Descartes was a fine philosopher.

A consequence of my (Burge’s) position is that there existed some individual x, namely Descartes, such that D* is correct if and only if

(D1*) x was a fine philosopher

and such that the mental events and structures involved in my having that thought are correct if and only if D1* is correct.

(B3) B2 entails that if I were to be in the very same mental state I was in when I was thinking D*, but it happened to be the case that Descartes had never existed, then I would not be thinking D*. In other words D2 entails that the very mental events and brain-events that in fact constituted my thinking D1* would fail to constitute any thought. By virtue of having those mental and neural events, I’d be shooting a blank, not having a thought—I’d no more be having a bona fide thought than a tomato.
   
   B1–B3 are all correct. B1 is correct, since I can’t know for sure that my mental states correctly represent the external world or a fortiori that the inferences involved in my believing in Descartes’ existence are correct—inferences that are made on the basis of possibly faulty perceptions of possibly faulty records concerning 17th century France. B2 is correct, since Burge’s position does indeed entail that Descartes must have existed if anyone is to think that he was a fine philosopher. And B3 is correct since Burge’s position does indeed entail that the very mental events involved in my thinking D1* would fail to constitute my having any thought at all if, supposing that everything else were the same, Descartes had never existed.
   
B1–B3 entail that:
   
(B4) If I’m now thinking that:

(D*) Descartes was a fine philosopher,

then I cannot be any more certain of the fact that I'm thinking D* than I can be of the fact that Descartes existed.
   
   B4 is wrong. I obviously know what I’m consciously thinking with greater certainty than I know about medieval France. I want to make it as clear as possible why B1–B3 entail B4. Given B2, I can think D* only to the extent that Descartes really did exist. Burge admits this. (He has to. B2 is Burge’s whole position.) Given B1, I can know that he existed only to the extent that various beliefs of mine concerning the external world to be accurate—beliefs that presuppose the accuracy of many perceptions of mine and also of many historical documents. Burge admits this as well.
   B3 entails that there is no experiential difference—no difference that is even theoretically detectable—between how I am when I’m actually thinking D*1 and how I am in a world where Descartes never existed but is otherwise like the world where I’m actually thinking D*1.
   B3 entails that, if I am to know that I’m thinking D*1, or anything else about Descartes, I’d jolly well better know that he existed; and I’d therefore jolly well better know that various Descartes-related perceptions of mine were accurate and, in addition, that various inferences of mine concerning various records of mine were also accurate. Which means that a precondition for my thinking about Descartes is my knowing that Descartes existed Which, in its turn, means that, supposing that I’m consciously thinking about Descartes right now, I can’t possibly know that fact with very much certainty at all. I can know it only with the certainty with which I know that Descartes existed.
But that’s false.
   Since knowing that Descartes existed obviously involves knowing a lot of other things about the external world—since it involves my knowing that I was in fact reading certain books at certain terms, that certain records in fact exist and were made under certain circumstances, etc.—my knowing a huge amount about the external world is a prerequisite to knowing that I’m thinking this or that about Descartes.
But that’s false.
   This reasoning is easily generalized to show that, if Burge’s position is right, my knowledge that I am consciously thinking about anything x in the external world is no more certain than my knowledge that x existed and, therefore, is no more certain than my knowledge of the various things on which that knowledge is based.
   To sum up, Burge’s position is false, since it has the false consequence that my knowledge of my own conscious mental states is as tentative as my knowledge of occurrences in remote regions of time and space.
   Around six years after he wrote “Individualism and the Mental,” Burge became aware of this problem. He and various followers of his have spent the last 23 years attempting to show that, even though B1–B3 are all correct, Burge’s position is completely compatible with the presumption that we know our conscious mental states better than we know about Descartes’ existence.
   To those who would join Burge in this heroic quest, I must say, quoting Sponge Bob Square Pants: “Good luck with that!”
5.0 The consequences of Burge’s big blunder: the need to deny independently known truths about causation
But there are problems with Burge’s position far worse than any thus far mentioned. To see what they are, let’s revisit the situation involving Smith and Twin-Smith—the one where, according to Burge, one of them, but not the other, believes that he has arthritis.
   
By supposition, Smith and Twin-Smith are psychologically and physiologically exactly the same. Given this, it follows that the causal properties of Smith’s thoughts coincide with those of Twin-Smith’s thoughts. This means that the supposed difference in content doesn’t make a difference, and is completely and totally inert. Although Smith’s belief in the proposition expressed by A3 (or whatever) obviously has effects (on what Smith does, etc.), and although the same is obviously true of Twin-Smith’s corresponding belief, the alleged difference between these beliefs is absolutely without any consequences. It has no consequences for anybody’s overt behavior or for anybody’s internal, psychological condition.
5.1 Fodor’s insight
Jerry Fodor (1987) was one of the first people to note this consequence of Burge’s view. Fodor’s argument is a brisk and incisive one. What is it, Fodor asks, for two numerically distinct things, x and y, to be causally different (i.e., to differ in respect of their causal properties)? It is for them to be such that, were they to switch places with each other but all other factors were left unchanged, the one would behave in the way in which, in actuality, the other behaves.
   Here’s the idea. Suppose that x and y are two billiard balls that are atom-for-atom duplicates of each other. At time t, x collides with a green billiard ball and causes that billiard ball to move. At the same time, y collides with a red billiard ball and causes that billiard ball to move.
   It’s clear that the effects of the one collision are different from those of the other. In the one case, the effect is to make a green ball move; in the other, it is to make a red ball move. But this doesn’t mean that the two billiard balls differ in their causal properties. It means that a given causal property has different effects in different contexts. Suppose that I’m moderately strong. In some contexts, that will have the effect that I easily lift the barbell I’m trying to bench press. (Such contexts include those where the barbell weighs under 100 lbs.) In other contexts, that will have the effect that I can barely make the barbell budge. (Such contexts include those where the barbell weighs over 350 lbs.).
   But, assuming that my level of strength hasn’t changed in the intervening time period, the difference between a situation where I’m trying to lift 50 lbs and one where I’m trying to lift 350 lbs isn’t that my causal properties have changed; it’s that one and the same set of causal properties are sufficient for certain jobs but insufficient for others. You can’t make a rocket out of plywood. But you can make a birdhouse out of plywood. That doesn’t mean that the causal properties of plywood vary, depending on whether they’re composing a rocket or a birdhouse. It means that those causal properties, though sufficient for certain purposes (e.g., bird-house building) are insufficient for others (e.g., rocket building).
   In his landmark work, A system of Logic, John Stuart Mill made it clear that the just-described criterion of causal identity is presupposed by all experimentation and, setting aside the empirical fact that scientists rely on it, is correct as a matter of logic.
   This is not to detract from Fodor’s achievement. Fodor stated that criterion more sharply and clearly than any author that I know of who preceded him. Plus, Fodor deserves credit for seeing the bearing of this principle on Burge’s views. Fodor deserves a lot of credit for many positive developments in recent analytic philosophy, as we’ll see.
5.1.2 Why thoughts must have causal powers
Causality is indistinguishable from spatiotemporal existence. It makes no sense to say that x occupies a certain region of space-time but has no causal properties. This is because occupancy is itself a causal notion. My occupying the chair I’m in is indistinguishable from my altering the conditions that other things (e.g., you) must satisfy if they are to occupy the chair. If I weren’t in the chair, you wouldn’t have to displace me to occupy the chair; and given that I am occupying the chair, you do have to displace me to occupy it yourself. Which, though certainly possible, would require an otherwise unnecessary expenditure of energy on your part.
   Given that Smith and Twin-Smith are absolutely the same in respect of their causal properties, it follows that the alleged differences between the one person’s mental content and the other’s is causally impotent. A

moment ago we saw that it makes no sense to posit the existence of anything spatiotemporal that has no causal powers at all. The just-cited alleged difference has no causal powers. Therefore, it makes no sense to suppose that it exists. Therefore, Burge is wrong.
5.2 Burge’s response to Fodor
Burge’s response to Fodor is rather curious. Burge denies that billiard balls x and y are causally identical. Burge says that the causal properties of an object are to be understood in terms of what it actually does and not at all, contrary to what Fodor says, in terms of what it would do in different circumstances.
   A story will help make it clear what Burge is saying. On Monday, I run a 6-minute mile without wearing a 20-pound backpack. On Tuesday, I run a 7-minute mile wearing such a backpack. On both days, I run on the same path. The weather is the same. I’m no worse and no better rested or nourished on the one day than on the other.
   According to Burge, my level of fitness has declined, the reason being that I ran the mile more slowly on Tuesday than on Monday. It’s irrelevant, says Burge, that, on Tuesday, I would have run the mile as quickly as I did on Monday if I hadn’t been wearing the backpack. Why is it irrelevant? Because, says Burge, the causal properties of physical objects are to be understood in terms of the peculiarities of the environments in which they happen to be embedded.
   Let’s look at the example that Burge himself uses. Let A and B be two very large celestial bodies that are atom-for-atom duplicates of each other. A is revolving around a star. (A is a planet.) B is not revolving around any star. (So B is not a planet.) Burge says (rightly) that the concept of a planet is an explanatorily important one. We explain at least some things in terms of the fact that some things are planets. Burge concludes from this that A and B have different causal properties. It is not, says Burge, that A and B merely differ in their behavior. It is that, by virtue of being a planet—albeit one that is exactly like B down to the last atom—A has causal virtues that B lacks.
   Is Burge’s argument a good one? No. Suppose that Smith and Jones are atom-for-atom duplicates of each other, but that Smith has a nephew whereas Jones does not. Obviously there are, or at least could be, behavioral differences between Smith and Jones that are to be explained in terms of the fact that the one, but not the other, is an uncle. Why did Smith spend an hour shopping for toys? Because he’s six-year old Timmy’s uncle, and Timmy loves toys, as Smith knows. Why didn’t Jones spend an hour shopping for toys? Is it because Jones is mean and stingy, whereas Smith is kind and generous? No. It’s because Jones, unlike Smith, isn’t an uncle and thus does not (at least not for that reason) have go toy shopping. Burge’s position concerning planets, if transposed to this other context, is that Jones is in fact a very different person from Smith. Smith is a nice guy. (Let’s assume for argument’s sake that his toy shopping is an expression of genuine love for his nephew.) But Jones, not having gone to the trouble of buying toys for his non-existent nephew, is not such a nice guy, even though Jones is just as likely as Smith to buy a present (or otherwise behave amicably towards) the people in his life who, unlike his nephew, actually exist.
   Because A is embedded in a certain way in a certain solar system, it’s going to do things that B won’t do. It’ll move in ways that B will not. It’ll draw the astronauts who land on A towards itself, whereas B will not do that, since (we may suppose) no astronauts bothered to go to B.
   Do any of these facts entail that A has different causal properties from B? No. In describing A as a “planet,” one is saying that it is embedded in a certain way in a certain environment. In describing B as a non-planet, one is saying that it is not embedded in that way in that sort of environment. Burge is quite right that what things do depends on the circumstances. If I’m underwater, I don’t breathe; if I’m not, I do. Since A is part of

a solar system, it does certain things; since B isn’t, it doesn’t. But this doesn’t show that A and B differ in respect of their causal properties from each other. It shows that:

(i) A’s being embedded in a certain environment in a certain way

has different effects from

(ii) B’s being embedded in a totally different way in a completely different sort of environment.

(i) is not identical with A. (ii) is not identical with B. (I am sitting in a chair right now. But I’m not identical with the state of affairs consisting of JMK’s sitting in a certain chair at 1:22 P.M. on April 9, 2009.) A’s being a planet is identical with (i)’s being the case. Since A’s being a planet is no more identical with A than I am identical with the fact that, at this instant, I’m sitting in a certain chair, and since the same thing mutatis mutandis holds of B, it would be deeply illogical to accept Burge’s judgment that A and B differ in their causal properties. In order for that judgment to be correct, A would have to be identical with the fact that it was embedded in a certain way in a certain sort of environment, and by parallel reasoning you would be identical with the fact that, right now, you are holding a certain book in your hands. But so far as it isn’t obviously false, this position borders on meaninglessness.
   Despite all these problems with content-externalism, and despite some comparably gruesome ones that I haven’t even mentioned, content-externalism still has some loyal followers who are indefatigable in their attempts to make content-externalism work. To these tenacious individuals, I can only say, quoting the great Marion Barry: “Let it go!”
   
   
   
PART III
Knowledge and Inductive Inference


Chapter 10
Knowledge
1.0 The ambiguity of the word “know”
The term “know” is ambiguous. Sometimes it refers to awareness of objects, as in “I know Smith.” But oftentimes it refers to awareness of truths, as in “I know that snow is white.”
   Other languages use different verbs to mark this difference. For example, in Spanish, when one speaks of knowing people, one uses the verb “conocer,” and when one speaks of knowing truths, one uses the verb “saber.” German also uses different words to mark this distinction (“kennen,” for knowing people, and “wissen” for knowing truths). Russian does not. It is like English, and uses one verb—“znat”—for awareness of both people and truths.
   This last fact is suggestive. If English were the only language that had just one word for both kinds of awareness, its doing so would be a mere idiosyncrasy—a random fact about one language that didn’t reveal anything inherent in human thought. But the fact that other languages do the same thing suggests that there is a general tendency not to distinguish these two very different kinds of knowledge. We will find that, in fact, this tendency of ours has a solid epistemological basis and is therefore not a logical faux pas. However counterintuitive it may seem, knowledge of people is, we will find, knowledge of truths.
1.1 The philosophical meaning of the word “know”
In philosophy, when we talk about “knowledge,” we are primarily, but not exclusively, concerned with knowledge of truths. Nonetheless, we will find that the distinction between knowledge of truths, on the one hand, and knowledge of individuals, on the other, is of great importance.
   We will find later that the word “know” is actually ambiguous in additional ways. For example, psychologists and philosophers often talk about “procedural” knowledge. Any case of anyone’s being able to do anything is a case of procedural knowledge. My ability to play the piano is a case of procedural knowledge; so is my ability to speak English; and so is my ability to tie my shoes.
   Many deny that procedural knowledge is bona fide knowledge. This is the exact opposite of the truth. What the virtuoso knows procedurally, the incompetent neophyte knows only discursively. As it deepens, knowledge becomes increasingly proceduralized. Non-procedural knowledge is poorly integrated knowledge; it is knowledge that hasn’t yet established the links to other pieces of knowledge that are needed to mobilize it. Procedural knowledge is knowledge that is sufficiently well-integrated to have established these links. It is therefore indefensible to hold that procedural knowledge is non-knowledge. We’ll say more about this in Section 9.3.
   We’ll find that the word “know” has meanings additional to those already discussed. But for the time being, when the word “know” is used, assume that it is referring to knowledge of truths, unless there is an explicit indication to the contrary.
   It should be pointed out that, even though, for the reasons given, the word “know” seems to have many meanings, some philosophers maintain that ultimately all knowledge is identical with knowledge of truths—in other words, that awareness of objects and also procedural knowledge, along with the other kinds of knowledge that we will talk about, are ultimately just different ways of knowing truths. But this is extremely controversial.

2.0 Knowledge as justified true belief
One cannot know something false. Of course, people often firmly believe that they know things that are in fact false. People can believe that the Earth is flat with as much conviction as they can believe that the Earth is round. The distinction between a true belief and a false one is not always marked by internal psychological or emotional differences. For example, one cannot tell whether a belief that one has is true or false merely on the basis of the intensity of that belief. In any case, it is a simple fact that only truths can be known.
   All cases of knowledge are cases of belief. If you know something, you believe it. If you know that Paris is the Capital of France, you believe it. If, speaking non-ironically, somebody said “I know that Paris is the capital of France, but I don’t believe it,” that person would be uttering nonsense.
   But not all instances of belief are instances of knowledge. We’ve already seen one reason for this. False beliefs are not knowledge. But there is another reason why not all belief is knowledge. A belief must be justified if it is to be knowledge.
   A lucky guess is not knowledge. Suppose that you’re taking a multiple-choice test and you come across the following question:

With what digit does Professor Kuczynski’s phone number end?

(a) 9
(b) 3
(c) 2
(d) 0
(e) none of the above
   
   A lucky guess will be enough for credit on the test, but it won’t be enough for knowledge. You have must have some good reason for your choice. Your opinion as to what the right answer is must be justified for it to qualify as knowledge.
   There are a lot of ways that you can have such a justification. Maybe I’ve told you my number. Maybe you saw it on one of my class handouts. Maybe you hired a private detective to find it out. All of these would be good sources of justification. But without some such source, you don’t have knowledge.
   Also, spurious reasons that happen to lead to the right answer are not enough for knowledge. Suppose that you believe, wrongly, that all people with red hair have cancer; and also suppose that, for that reason, you believe that your red-haired friend Bob has cancer. It may be that Bob does have cancer. But your reason for believing this is spurious; so you don’t know it.
   It is a general principle of logic that false premises can lead to true conclusion; misinformation can lead to correct beliefs. Of course, accurate information is much more reliable than misinformation. A person whose methods are sound and whose premises are correct is considerably more likely than he would otherwise be to find out the truth. But false premises and unsound methodologies can lead to truth. When it happens, it’s a kind of accident, as our previous example shows. But accidents do happen.
So for something to be knowledge it must have the following three characteristics:

(1) it must be true;
(2) it must be a belief; and
(3) it must be justified.

Thus, all cases of knowledge are cases of justified true belief.

2.1 What constitutes justification?
We must define a few more terms before we can answer this question. The term “perceptual” means having to do with sense-perception—that is, with sight, hearing, sound, taste, smell, bodily sensations (e.g., stomach aches), and also sensations of motion and resistance. I know that there is a computer in front of me because I can see it. (In any case, this is part of the story: there’s more to it, as we’ll see later.) I know that the stove is hot because I touched it. I know that one cup is heavier than another because I feel a greater degree of resistance when I try to move the one than when I try to move the other. (Notice that this last kind of perception isn’t identical with one’s sense of touch, even though it involves the use of touch.)
   The term “introspective” refers to the direct awareness that one often has of one’s own mental contents. Right now I am aware of the fact that I am having thoughts—that, more specifically, I am having thoughts about the theory of knowledge (I’m writing about it), about this chapter (I hope that I’ve finished writing it by tomorrow), and about tonight’s dinner (it’ll be chicken). My knowledge of this is not based on the use of my senses: I don’t see or touch those thoughts. At the same time, that knowledge seems not to involve my making inferences: I seem to be directly, non-inferentially aware that I am having them.
   Bearing all of this in mind, let us consider the question: under what circumstances is one justified in having a belief? Many different kinds of facts can be known; and, as we’ll see, the way in which a belief must be justified for it to be knowledge depends on the category into which the fact in question falls. But there are ultimately only three sources of justification: (a) perceptual evidence, (b) introspective evidence and (c) rational inference. Some cases of knowledge involve only (c); some cases of knowledge are a combination of (a) and (b); the majority of cases involve a combination of both (a) and (c). Some philosophers have argued that whenever (a) is involved, so is (b).
2.2 Can testimony constitute a source of justification?
There is much that a given person knows that he hasn’t personally verified—much that he knows because he is told it. Such telling can take various forms: it can consist of written or spoken speech, photographs, and drawings. (This list is not complete.)
   I haven’t personally looked at the Earth from outer space. But I still know that it is approximately spherical. How do I know this? Because I’ve been told it. Using speech, writing, photographs, drawings, and possibly other media, various people have told me various things that justify me in believing that the Earth is spherical. For similar reasons, I have at least some knowledge about what kinds of activities are likely to bring about lung cancer and about the political situation in distant parts of the Earth, even though I have not personally done cancer research or personally visited those parts of the Earth.
   But, of course, not all beliefs that are based on testimony qualify as knowledge. First of all, much of what we are told is false. But even true beliefs that are based on testimony are not always knowledge. To qualify as knowledge, testimony-based belief must (a) come from a reliable source and (b) the person being given the testimony must have independent evidence of the reliability of that source.
   A story may clarify this. I belong to a cult. My cult leader wants me to drink a certain beverage. He has told me that it is extremely nutritious. As it happens, it is nutritious—the cult leader has told me the truth. Further, I believe that the beverage is nutritious. But the reason for this is not that I have any actual evidence that the cult leader is well-informed or truthful; the reason is that, for purely emotional reasons, I believe everything the cult leader tells me.
   Here I have a true belief—I believe, correctly, that the beverage is nutritious. But do I know this fact? No. And the reason is that I don’t have good reason to believe that the cult leader is in fact telling the truth—even though, in this case, he is telling the truth. The data that I have concerning the cult leader—more specifically, concerning the likelihood of his stating truths as opposed to falsehoods—does not warrant my accepting what he is saying.
   Here’s another story. A world-renowned physician has told me that I have arthritis. His opinion is based on his expertise and also on the results of various tests that he has performed on me. He is right—I do in fact

have a mild case of arthritis. Further, I am aware of the fact that he is an arthritis expert and that he has conducted various tests.
   In this case, I obviously do have reason to believe the testimony I am being given. My belief is therefore justified and it is, or at least could be, a case of knowledge. (I say “or at least could be” because, for reasons that we’ll discuss later, even beliefs that are true and justified aren’t always knowledge.)
   So a testimony-based, true belief can be knowledge. But it is necessary that the person who has that belief have some reason to believe that the source of the testimony is accurate.
   Notice that testimony-based belief involves a combination of perceptual knowledge and also of rational inference. You must perceive the words that are being told to you. (You hear them or see them, depending on whether they are written or spoken.) You must also have perceived some kind of evidence of the truthfulness of the source of testimony. Finally, from those two sources of perceptual information, you must infer that the source of testimony is reliable. So testimony-based knowledge involves a combination of (a) and (c).
2.2.1 A point concerning testimonial knowledge
When we’re growing up, we’re told many true things by parents, teachers, and other figures of authority. During our earlier years, we obviously don’t have independent corroboration for the testimony of these people. And yet we’re inclined to say that we know the things they told us.
   What I believe to be going on is that, at first, we didn’t know these things. We just believed them. But then we either came to have evidence of the reliableness of the people who told them to us or we discovered them for ourselves.
3.0 Knowledge as hyper-justified true belief
Not all cases of justified true belief are cases of knowledge. It is only when one has a belief that is true and that is justified in a rather specific way that one has knowledge. More specifically, one has knowledge only when one has a belief that is true and justified and, moreover, one’s being justified in holding that belief is non-accidentally related to that belief’s being true.
   A story will help clarify this. You work at some company. Smith is a fellow employee of yours. He is an excellent worker; the boss likes him; he’s overdue for a promotion; and the boss, who is honest and rewards good work, has just announced that he’s going to give a promotion to somebody (but he hasn’t said who). Further, you know all of these facts. You also know that Smith drives a Ford. On the basis of this information, you form the belief that:

(*) somebody who drives a Ford is about to be given a promotion.

Obviously this belief is justified, since your reasons for holding it are solid.
   And that belief turns out to be true—but not for the reason that you have in mind. Smith does not get the promotion. The boss gives the promotion to Jones. Jones is a terrible employee, as you know. But what you don’t know, and had no way of knowing is that the boss owes a huge favor to Jones’ dad, who is a local and exceptionally vindictive Mafia boss. So, acting with an uncharacteristic disregard for merit, the boss gives the promotion to Jones. By sheer coincidence, Jones drives a Ford.
   In light of this, let’s look at your belief in *. First of all, that belief is true—a Ford driver (namely, Jones) was given a promotion. Second, it’s justified. We’ve already seen why. You were justified in believing that Smith, whom you knew to be a Ford driver, was going to be a given a promotion. That belief turned out to be wrong—but it was still justified.
So your belief in * is true and justified. It is thus a justified true belief.
   But is it knowledge? No. It’s pure coincidence that Jones, who you had no way of knowing would get the promotion, drives a Ford. You’re right a Ford driver would get the promotion, and your belief is justified. But you still believe it for the wrong reasons. (A justified belief can thus be had for the wrong reasons.) And that’s 

why it isn’t knowledge.
   This shows that there can be justified true beliefs that are not knowledge. It shows that, for something to be knowledge, it is not sufficient that it satisfy conditions (1)–(3), even though, for the reasons discussed earlier, it is necessary.
   The argument just stated was given by Edmund Gettier (1963). Bertrand Russell (1912) gave a similar argument. You look at a clock that is in fact broken but that you believe, and have every reason to believe, is in good working order. According to the clock, the time is 4:00 P.M. In fact, that is the actual time. But the clock is broken, and it is therefore a fluke that it gave you the right time. Your belief that it is 4:00 P.M. is thus true and justified, but it isn’t knowledge.
3.1 Knowledge as non-accidentally justified true belief
We’ve seen that for something to be knowledge, it isn’t enough that it be a justified, true belief, and that it must therefore satisfy some fourth condition. There is considerable debate as to the precise nature of that fourth condition, but it is seems clear that, when stated very approximately, it must be this:

(4) if a given belief is to be knowledge, there must be a non-accidental connection between one’s reason for having that belief, on the one hand, and the fact in virtue of which that belief is true, on the other: justification and truth must be non-accidentally connected.

So for something to be knowledge is for it to satisfy the following four conditions:

(1) it must be true;
(2) it must be a belief;
(3) it must be justified; and
(4) there must be a non-accidental connection between the justification for the belief and the fact which makes the belief true.

Thus:

(K) knowledge is a non-accidentally justified true belief.
   
   There must, in other words, be some kind of principled, as opposed to a strictly fortuitous, relationship between the justification of the belief, on the one hand, and its being true, on the other.
   But K is much too vague to be considered a solution to the problem at hand. What does the word “non-accidentally” mean in this context? Until we know the answer to that, we don’t know what knowledge is. We’ll now try to supply that answer.
3.2 This position refined
Let’s consider Russell’s clock story. You were right to believe that it’s 4:00 P.M., and you are also justified in having that belief. Your immediate justification consists in your belief that:

(RT) The clock is now telling me that it’s 4:00 P.M.

But by itself a belief in RT wouldn’t be enough to justify you in believing that it’s 4:00 P.M. If you had no grounds for accepting RT, or only bad grounds, your acceptance of it would not provide you with any justification for believing the time to be 4:00 P.M. But you are justified in accepting RT; and here is that justification:

(OB) In my extensive past experience, the clock has always been right. I also know that the building superintendent, who is in charge of making sure all the clocks are working, is very capable and diligent. These facts ensured that, if the clock says that it’s a certain time of day, that’s because it really is that time of day. That’s why the clock is now telling me that t it’s 4:00 P.M.

Of course, the italicized part of OB is identical with rt.
   Notice that OB is an explanation of a fact—of the fact that the clock is now telling you that it’s 4:00 P.M. It is on the basis of your acceptance of RT that you believe the time to be 4:00 P.M. But OB is the wrong explanation of RT. The right explanation is that the clock is broken and, for that reason, always reads 4:00 P.M.
   A story will help us move forward. You believe that Larry is in Texas, and your belief is justified. Earlier today, you saw Larry get on a plane. By all indications, the plane was Texas-bound. (It’s flight 71 and, according to the overhead monitor, that flight is bound for Texas.) When Larry got to Texas, he called you on his cell phone/video phone. He was standing next to a well-known Texas landmark (or, at the very least, a perfect duplicate therefore). On that basis, you believe that, indeed, Larry is in Texas. And, in fact, he is in Texas.
   Moreover, no off-the-wall, Gettier-type event infiltrated this sequence. In other words, what happened is nothing like the following:

Alternative Scenario (AS): Larry got on the plane. But Martians re-routed the plane to Barbados. For some reason, they then transported Larry to Texas. In Texas, somebody other than Larry, who looks and sounds just like him, calls you and tells you that “he” (which you take to mean “Larry”) safely arrived in Texas. On that basis, you believe that Larry is in Texas. Which he is, and which you’re justified in believing, but which, clearly, you don’t know to be the case.

No—neither AS nor anything at all like it occurred. What happened is exactly what you thought happened. And you therefore know that Larry is in Texas. (Let’s say that this story—the one where you know that Larry is in Texas—takes place in the “real world,” even though, of course, it’s no less a hypothetical than AS.) 
   Why do you know it in the real world, but not in the world described by AS? Let’s look at the data on which, in the real world, your belief is based. Although you see Larry get on the plane, you don’t see him deplane in Texas. You do see various images (on your cell phone/video phone) that are consistent with his being in Texas; and you encounter a lot of other things that, were Larry not to be in Texas, would be very hard to explain. Your belief that Larry is in Texas (after sitting on a certain plane, etc.) is not only justified: it also constitutes a correct explanation of the data that justifies your belief that he is in Texas. Your belief that, after sitting on a certain plane (etc.), Larry is in Texas correctly explains why your cell phone is giving rise to these various images and noises.
   Thus, your belief is not only justified, but hyper-justified. A belief is hyper-justified if it’s justified and, moreover, embodies a correct explanation of the data that is doing the justifying.
   In AS, your belief is justified, but not hyper-justified. Your belief is based on the same images and, in general, the same data that it’s based on in the real world. But, in AS, your beliefs as to what caused those images and noises to occur are wrong. (You explained their occurrence by wrongly supposing that Larry produced them after being transported by non-Martians to Texas.) So, in AS, your justified belief isn’t knowledge because it isn’t hyper-justified. I propose, then, that:

(KN) Knowledge is hyper-justified true belief.
4.0 Conceptual (analytic) versus empirical (synthetic) knowledge
Some knowledge is purely conceptual; and some knowledge has a non-conceptual component. Knowledge that is purely conceptual is described as “analytic.” Knowledge that has a non-conceptual component is described as “synthetic.”

Consider the statement:

(#) Circles are figures of uniform curvature.

# is true. And you know that it's true. You thus have knowledge of #. How does one become justified in believing #? Answer: by examining the statement itself. More specifically, by examining the components of that statement—the concepts circle, curvature, uniform, and so on. So your knowledge of # is purely conceptual. In other words, it is “analytic.”
   Analytic knowledge is so-called because it is acquired by analyzing the object of belief. Whenever statement-analysis is sufficient, by itself, to yield knowledge, that knowledge is analytic.
Most knowledge is non-analytic. Consider the statement:

(##) Donald Rumsfeld was born in the United States.
   
   An examination of that statement is not enough to know whether it is true or false. It doesn’t matter how much you dissect it and examine its components. In order to be justified in having a view, one way or the other, as to whether it is true, and in order therefore to know whether it is true, it is necessary to consider matters of fact of which no amount of conceptual analysis will apprise you. It is necessary to look at birth records or to ask informed people, or some such.
   Thus, if one knows that ## is true, that knowledge is non-conceptual. In other words, it is non-analytic or, as philosophers sometimes say, synthetic.
4.1 More on the analytic-synthetic distinction
Although some philosophers have held otherwise, I think it is fair to say that synthetic knowledge is identical with knowledge of spatiotemporal facts, whereas analytic knowledge is knowledge of properties.
   To know ##, for example, is to know something about the spatiotemporal world—the world of things that occupy space and time. By contrast, to know # is to know about unchanging, non-temporal (and therefore non-spatial) relations among properties.
   In this chapter, we will operate on the reasonable, though debatable, assumption that all synthetic knowledge is knowledge of some fact or other about the spatiotemporal realm. So, in this context, the terms “spa-tiotemporal knowledge” and “synthetic knowledge” may be used interchangeably. In Chapter 18, it is shown that, in fact, synthetic knowledge is identical with spatiotemporal knowledge.
5.0 Knowledge of specific facts versus knowledge of dependence-relations among facts
There is an important division within the category of spatiotemporal, or synthetic, knowledge. There is knowledge of specific facts, and there is also knowledge of causal or nomic relations among facts.
   The term “nomic” means “having to do with natural law.” Consider the fact that there is a combustion whenever a lit match is brought in contact with gasoline. Obviously that is not a coincidence. There is clearly some kind of principled relationship between, on the one hand, something’s being gasoline that is brought into contact with flame and, on the other hand, something’s combusting. Some kind of causal relationship is at work.
   Technically speaking, not all nomic relations are causal. But the distinction between causal and nomic relationships is a rather subtle one, and in this chapter we will ignore it. (In Chapter 17, Sections 9.0–9.6, it is made clear why not all nomic dependencies are causal dependencies.)
   
Causal relations are instances of natural laws. If x causes y, that is because there is some law of nature to the effect that things that, in some relevant respect, resemble x always bring about things that, in some relevant respect, are like y.
   Causal relations typically involve sequences of events. But not all sequences of events are causal. When I bring my hands together quickly, a noise occurs—there is a clapping sound. That sequence of events is clearly causal in nature: the collision of my hands caused the sound to occur. But suppose that, just after I bring my hands together, one of you suddenly feels a tickle. That is not a causal sequence: it’s just a coincidence.
   The natural law of which a given causal sequence is an instance is known as the covering law for that sequence.
   To know a natural law is to know a fact about the spatiotemporal world. Natural laws are not in the same category as #: such laws are not of a strictly logical, philosophical, or mathematical nature. It is not possible to know of natural laws merely on the basis of conceptual analysis. Such knowledge can be acquired only through investigation of the spatiotemporal world. It is only through such investigation that one can know that the speed of light is 186,000 mph/second, that objects gain mass as they accelerate, that the force with which two bodies attract each other is proportional to their masses.
   Of course, some natural laws strike us as extremely obvious. We find it obvious that unsupported objects fall. But that is not because such knowledge is analytic; it is only because the relevant spatiotemporal knowledge constantly forces itself upon us.
   Even though knowledge of natural law is spatiotemporal knowledge, such knowledge tends to have a highly general character and is thus, in that respect, comparable to many cases of analytic knowledge (e.g., one’s knowledge of #). Knowledge of the laws of physics is very general knowledge. To know such laws is to know this or that specific fact, and is instead to know a fact about how events in general are interrelated.
   But most spatiotemporal knowledge is highly specific. You know where you live; you know what toothpaste tastes like; you know where you parked your car; you know that Barack Obama is now the president. Such knowledge concerns matters of specific fact and not dependence-relations holding among facts in general.
   It must be emphasized, however, that even though knowledge of natural law is general and is, from that viewpoint, similar to knowledge of logical or philosophical principles, knowledge of natural law is synthetic, whereas knowledge of logico-philosophical truths is analytic.
6.0 Knowledge of the future, the past, and the merely possible
Many future facts are not known and many future facts cannot possibly be known. But surely we are able to know at least some facts about the future.
   One can know about the future because (i) on the basis of sense-perception, one can know about the present and (ii) one can know general principles, or causal laws, that link the present with the future. Right now I know that there is water in the pitcher in front of me. I also know of the general fact that, under conditions relevantly like those that obtain in my kitchen, an open, overturned pitcher containing non-viscous liquid will release that liquid. Further, I know that I have an intention to tip the pitcher, so as to fill the glass of water in front of me. On the basis of these pieces of knowledge, I can obviously have a non-accidentally justified true belief to the effect that, in a moment, water will be flowing from the pitcher into the glass.
   Knowledge of the future always has two ingredients: first, knowledge of present conditions and, second, knowledge of causal laws that, given circumstances similar to those known to obtain, yield certain outcomes. In some cases, the causal laws in question are of a relatively non-theoretical character. This was the case in the example, given a moment ago, concerning the water in the pitcher. In other cases, knowledge of the future may have an extremely theoretical character. This would be the case when, on the basis of relativity theory, a physicist predicts that the mass of a certain body will increase by a certain amount, by a certain time. But, in all cases, knowledge of the future is constituted by knowledge of causal laws that link known current states of affairs to future states of affairs.

6.1 Knowledge of the past
We can obviously have knowledge of the past. There are two forms that such knowledge takes. In some cases, knowledge of the past is direct: one actually remembers the fact in question. I remember driving to work yesterday. My knowledge of this fact doesn’t involve inferences made on the basis of causal laws.
   But in other cases one’s knowledge of the past is indirect, and all such knowledge does involve some knowledge of some kind of causal law. We know facts about the political institutions of ancient Rome. We obviously don’t remember such facts, since we didn’t personally experience them. So how do we know them? We have knowledge of certain current facts (e.g., certain currently existing records and ruins); and we also have knowledge of causal principles on the basis of which, given our knowledge of those current facts, inferences concerning the past—specifically, concerning what went on in Rome thousands of years ago—can be made.
   Here’s a simple example of the principle in question. You know that if you press an ink-filled pen against paper, inky lines will be deposited on the paper. (You also know, so let us suppose, that such lines are not likely to be deposited on paper in any other way.) This is knowledge of a causal principle. On the basis of your knowledge of this principle, plus your knowledge of current conditions, you can acquire either knowledge of the future or knowledge of the past. If you see that Smith is about to press his pen against the paper in his notebook, you know a fact about the future—you know that inky lines will soon result. On the other hand, if you see inky lines that were clearly made by a person, you know a fact about the past—you know that somebody dragged a pen across a certain piece of paper. Our knowledge of past events that we don’t personally remember (e.g., facts about ancient Rome) falls into this second category.
   When it is indirect, knowledge of the past has a structure that is similar to knowledge of the future. More specifically, past knowledge can be thought of as inverted future knowledge. We know the future when, using known causal laws, we project forward from known current conditions. We know the past when, using known causal laws, we project backwards from such conditions.
6.2 Counterfactual knowledge
We can have knowledge of what would have been. Even though Smith did not in fact fall off the ledge, I know that:

(S) if Smith had fallen off the ledge, he would now be dead or severely injured.
   
   Propositions like S are called counterfactuals . In general, a counterfactual statement is one of the form if P, then Q, where it is assumed that P is false.
   Knowledge of counterfactuals is identical with knowledge of relations of either logical or causal dependence. To know S is to know of some causal law that, given a case of somebody’s falling from a great height, leads to that person’s breaking his or her leg. To know that “if x were a square, x would have four sides” is to know that “x has four sides” is a logical consequence of “x is a square.”
   Many contemporary philosophers take counterfactual statements to be statements about events in other universes. So they take:

(K) “If Kennedy hadn’t been assassinated on Nov. 22, 1963, he would have been reelected in 1964”

to mean that:

(K#) There is some other universe where Kennedy was not assassinated on Nov. 22, 1963, but, up until that time, was as much like our world as that fact allows it to be. In that universe Kennedy was reelected in 1964.

And they argue that:

(S) “If Smith, who is 6-feet tall, were half his current height, he’d been 3-feet tall”

means that:

(S#) There is some alternative universe where Smith is half his current height. In that universe, Smith is 3-feet tall.
   
   This is preposterous. Any knowledge that we have about other universes is parasitic on our knowledge of modal truths. First, we know the counterfactuals. Only then do we know what’s going on in other worlds. It’s only thanks to our knowledge that 6 divided by 2 is 3, along with out knowledge that Smith is six feet tall, that we know that Smith would be 3 feet tall in a world where he were half his actual height. It’s only thanks to our knowledge that Kennedy was an enormously popular first-term President, along with our knowledge that popular incumbent Presidents win re-election, that we know that Kennedy would have won in 1964 had his life not been cut short.
   These pedestrian points show that other worlds are useless in the way of giving us modal knowledge. It also shows that modal truths don’t hold in virtue of what goes on in other worlds. S is obviously correct. Whatever it is that makes it correct, we don’t have to leave this world to have access to it. It follows that, given any true counterfactual statement S, it is in virtue of what happens in this world, and this world alone, that S is true.
The real meanings of S and K are:

(S*) the statement that Smith is 6-feet tall entails that the statement, for all values of x, ‹x is half Smith’s height› entails ‹x is 3-feet tall.›
and

(K*) “Kennedy’s assassination caused an otherwise unthreatened Kennedy not to be reelected.”

For further discussion of the nature of counterfactual truth, see Chapter 17.
7.0 Theoretical versus observational knowledge
It seems that much of what we can know comes directly from sense-perception. I open my eyes in a well-lit room, and I can just see that there are chairs and people there.
   But much knowledge is theoretical. We don’t have direct knowledge of electrons or even of gravitational fields. We have direct knowledge of the effects of these things. (More accurately, we have relatively direct knowledge of such effects. We’ll see in a moment that our knowledge of these effects is itself indirect, even though it’s obviously less so than our knowledge of electrons, etc.) But in characterizing something directly perceived as the effect of “gravitation” or of the activity of “electrons,” we are going well beyond what we can literally see (or hear or touch, etc.), and we are assuming the existence of things whose existence can be justified only by theories of some kind or other. A theory is an explanation of what is directly experienced in terms of what is not directly experienced and whose existence is therefore not directly known.
   Freud and others have posited the existence of mental activity that we are not directly aware of and of which we are therefore “unconscious.” One obviously can’t be directly aware of unconscious mental activity. (Any mental activity that one is directly aware of is ipso facto conscious.) Thus, any knowledge that we have of the unconscious is inferential. In addition, such knowledge is also theoretical. But here we must take a moment to clarify the distinction between inferential and theoretical knowledge.
   
A theory is an integrated set of statements that, if correct, describe some sector of reality that cannot be known strictly through sense-perception or introspection. All theoretical knowledge is inferential, but not all inferential knowledge is theoretical. If I see smoke, and I infer on that basis that there is fire, my inference isn’t theoretical. It doesn’t presuppose the truth of a theory. It assumes the truth of the statement “where there’s smoke, there’s fire,” which merely describes an observable concomitance, and therefore doesn’t qualify as a theory. But, supposing for argument’s sake that there is unconscious mental activity and that we can have knowledge of it, the inferences that yield such knowledge do presuppose theoretical knowledge. If I infer from the fact that you are accident-prone that you have hostility towards yourself, I am obviously making several assumptions as to the nature of the psyche. Further, those assumptions don’t merely register observable concomitances, and they aren’t independent of one another. Thus, those assumptions jointly constitute a theory. It follows that any knowledge that we have of the unconscious is of a theoretical character. In sections 7.0–7.1 we’ll say more about the distinction between theoretical and inferential knowledge.
7.1 Is all knowledge theoretical?
Some epistemologists and cognitive scientists maintain that even perceptual knowledge is theoretical. This position may seem strange at first, but there is at least one reason to think that it may be true.
   Even though you don’t have to do any work to generate your own sense-perceptions, your mind and nervous system certainly have to do a great deal of work. Consider the disturbances of your sensory surfaces that lead to your sense-perceptions. If the surface of a rock or a piece of wood were similarly disturbed, no sense-perception would result. What is the difference between you and a rock? Your mind can, whereas a rock cannot, process the relevant disturbances in the right way. It’s quite extraordinary that your mind is able to do this; for all it is given are various disturbances that, in and of themselves, bear no resemblance, or only an extremely abstract resemblance, to the things off of which the relevant photons (or whatnot) are bouncing. Nonetheless, on the basis of this meager information, your mind is able to generate perceptual representations that accurately depict those objects. The gulf between input and output—between, on the one hand, the surface-stimulations on the basis of which your mind generates its perceptions and, on the other hand, those perceptions themselves—bears a striking resemblance to the gulf between, on the one hand, the data on the basis of which a theoretical physicist posits the existence of a swarm of a certain kind of sub-atomic particle and, on the other hand, that particle-swarm itself. In the case of the theoretical physicist, that gulf can be bridged only by a theory. This suggests that the same is true of the gulf between disturbances of your eyes and the perceptions in which those disturbances eventuate.
7.2 A priori versus a posteriori knowledge
Thus, one must have knowledge in order to acquire perceptual knowledge. Given that even a newborn can have sense-perceptions, it follows that knowledge of some kind is coded into the innate structures of our minds.
   Such knowledge is referred to as a priori knowledge. Thus, knowledge is a priori if it is coded into the very structures of our minds and therefore pre-exists any perceptions that we have.
   If knowledge is not a priori, then it is referred to as a posteriori. Thus, a posteriori knowledge is acquired knowledge, and a priori knowledge that is within us, in some form, from the outset.
   It is a matter of considerable debate whether there is a priori knowledge and, if so, precisely what it is that known a priori. (My own strongly held view is that there is a priori knowledge.) Among those who believe that we have a priori knowledge are Plato, Leibniz, Kant, and Chomsky. Among those who deny it are Aristotle, Locke, and Quine.

7.3 A second reason to think that perceptual knowledge is theoretical
Suppose that X is some stop sign. If you look at X from a certain distance—from, say, a hundred feet away—it will appear a certain way to you. Given only how X appears to you from that distance, you cannot tell whether you are looking at an object that is around 8-feet tall and a hundred feet away or an object that is 1,000-feet tall and much further away or an object that is 6 inches tall and very nearby. Nonetheless, you know, when you are looking at X, that it is not 1,000-feet tall and far away or 6-inches tall and very close, and that it is around 8-feet tall and about a hundred feet away. Given that X’s appearance, by itself, does not reveal this to you, how do you know it? It is your background knowledge that, in conjunction with how X appears to you under the circumstances described, enables you to assign the right height to X. A continuation of our story may clarify this. Your friend Larry is right next to X. You can see the comparative heights of X and Larry; you can see that Larry is around three-fourths the height of X. So it is because of X’s appearance plus this background knowledge that you are able to determine X’s height.
   This must be understood correctly. You can just see how tall, approximately, X is. But, for the reasons just given, it seems that background knowledge of the kind just described seems to be involved in, and to some degree to constitute, your seeing this.
   An argument similar to that just given in connection with seeing X’s size can be given in connection with seeing any object’s size. Indeed, similar arguments can be given in connection with seeing any fact about any object—in connection with seeing how fast an object is moving, what shape it has, how far it is from one, and so on. And extensions of those arguments suggest what is true of seeing facts about physical objects is true of any kind of perceptual awareness of any fact about them.
7.4. Inferential vs. theoretical knowledge
There is a reason to hold that not all knowledge is theoretical, namely that many inferences are involved in knowing a theory and, consequently, inferential knowledge is a precondition for theoretical knowledge. Some background points are needed to make it clear why, at least arguably, this holds.
   First of all, not all inferences—not even all inferences that lead to correct conclusions—yield knowledge. If I infer that Bob has cancer on the grounds that he has red hair, my inference doesn’t yield knowledge, even if, by coincidence, Bob does have cancer. The reason my inference doesn’t yield knowledge is that the “inference rule” implicit in it—in other words, the principle that licenses it—isn’t a good one. That inference rule is: “if a person has red hair, he or she has cancer.” Since that rule obviously isn’t “truth-conducive”—since, in other words, that rule isn’t likely to yield correct conclusions, given correct premises—no inference made on the basis of it is legitimate. So for an inference that yields a correct conclusion to yield knowledge, one must make that inference on the basis of a legitimate inference rule.
   Theories are systems of statements standing in various dependence-relations with respect to one another. (The word “statement” here is not meant to have any linguistic overtones and should be taken as shorthand for “truth or falsehood.”) A dependence-relation holds between two statements if one of them supports the other—if, in other words, one of them provides some basis for inferring the other. Knowing that a dependence-relation holds between two statements involves either inferring the one from the other or, failing that, recognizing that such an inference could be legitimately made. For example, my recognizing that there is a dependence-relation between “there is fire at time t in place p” and “there is smoke at t* in p*,” where t* and p* are neighbors of t and p,” involves either my knowing one of them on the basis of the other or it involves my seeing that such inference would be legitimate. In either case, I have inferential knowledge. (Even if I happened to see the fire and the smoke, and thus didn’t have to infer “fire at t in p” from “smoke at t* in p*” or vice versa, my knowing that a dependence-relation holds between them involves my knowing that the one could be legitimately inferred from the other. And that knowledge, surely, deserves to be characterized as inferential.) Since, as we noted a moment ago, knowledge of dependence-relations precedes knowledge of theories, and since knowledge of such relations is inferential, it follows that inferential knowledge precedes theoretical knowledge.
   
Of course, those who deny that all knowledge is theoretical don’t have this in mind. Usually those who hold that there is “direct” knowledge mean that there is no inferential knowledge—they use the terms “inferential” and “theoretically” interchangeably and therefore, since they’re not interchangeable, loosely.
7.4.1 Inferential vs. theoretical knowledge (continued)
To be made cogent, the foregoing discussion must be qualified in a couple of ways. These qualifications will bring out some principles whose importance extends far beyond the points just made.
   I said that a dependence-relation holds between two statements just in case one of them can be legitimately inferred from the other. Some might object to this on grounds like the following:

Smith’s crashing the car might have resulted from his being drunk. So the statements “Smith was drunk at t” and “Smith crashed the car at t*.” But surely I cannot legitimately infer the second from the first. Given only that Smith is drunk, I can’t infer that he’ll crash his car. So, contrary to what you say, dependence-relations aren’t always backed by legitimate inference rules.
   
   First of all, it wasn’t merely Smith’s being drunk that led to his crash. It was his being drunk while being behind the wheel. (In fact, more than this is involved. He wouldn’t have crashed had the car in front of him not slowed down or if he hadn’t been talking on his cell phone when this happened. It was a confluence of factors—his drunkenness, the behavior of the driver in front of him, his own distractedness—that led to the crash. Total causes are always confluences of circumstances. Thus, the dependence-relation in question holds, not between the two statements cited by the objector, but between “at t, Smith crashed” and “at immediately preceding time t*, Smith was driving while drunk and talking on his cell phone, when the car in front of him suddenly slowed down.” The second statement does make it reasonable to infer that, at or around t, Smith crashed.
   Admittedly, the second statement doesn’t make it certain that he crashed. This is because the presumption that, given the various factors at play (his drunkenness and distractedness, the sudden deceleration of the car in front of him, etc.) the imminent crash could still be headed off. Maybe the person in the passenger-seat of Smith’s car wrenched the steering wheel to the right, just in time to avoid the crash. Not likely, but possible. Maybe Smith is somebody whose driving is enhanced by drunkenness. Not likely, but possible. But even though, given the operative conditions, Smith’s crashing cannot be known with certainty to occur, it doesn’t follow that the inference from “Smith was drunk and chatting on his cell phone [etc.]” to “Smith crashed” isn’t legitimate or, therefore, isn’t licensed by a truth-conducive inference rule. What follows is that the inference rule in question is defeasible. An inference rule is defeasible if (i) it provides a reasonable presumption that, given certain premises, a certain conclusion holds, but (ii) that presumption may turn out to be false if other facts, not in evidence, happen to intercede.
   There is a big difference between an inference rule that is defeasible, on the one hand, and one that is simply bad (i.e., not truth-conducive), on the other. A bad inference rule provides no reason for inferring one thing from another. A defeasible inference rule (when good) does provide such a reason. It doesn’t provide as good a reason as a non-defeasible inference rule. But that doesn’t mean that it’s not good at all; goodness (truth-conduciveness) comes in degrees.
7.4.2 Rules vs. principles
There’s also a big difference between a principle and a rule. Rules are about outcomes. Principles are about tendencies. Rules have the form: “if this, then that.” (If it’s a raven, then it’s black.) They’re categorical. (All members of the category raven are members of the category black.) A rule that admits exceptions is false. (A single non-black raven falsifies the rule that all ravens are black.) A correct rule can be obtained by replacing a counter-exampled rule with one that is duly hedged with exception clauses. (So, supposing that Smith is the one non-black raven, then “all ravens other than Smith are black” is indeed a correct rule.)
   
But a duly hedged rule is not a principle. Principles are not watered down rules. It is no accident that so many drunk drivers crashed; it’s not a statistical fluke. Nor is it parasitic on some other, more robust connection. In a society where the government forced blond people to live near nuclear waste, there would be a connection. Drunk driving is to crashing what being exposed to radiation (as opposed to being blonde in the society just described) is to getting cancer.
   As we’ll see in Chapter 17, empiricists think of principles as being watered-down rules—as being expressed by categorical statements to which there are exceptions. This isn’t the right way to think about them. Principles are better thought of as registering the existence of defeasible forces. Being drunk can be thought as a car-crash-conducive force (or, more likely, confluence of forces) that, like most forces, can be overridden. Note that, whereas inference-rules are defeasible in a logical sense, forces are defeasible in a causal sense.
8.0 Knowledge of ourselves and others
A person’s knowledge of himself is obviously much better than his knowledge of others. You obviously have a much more accurate understanding of your own mind than you do of the other people’s minds. Nonetheless, we can, within limits, have some knowledge of what others are thinking.
   It is a matter of considerable dispute how we can acquire such knowledge. But here is a hypothesis that, I think, must surely be correct—at least for some, though perhaps not all, instances of knowledge of others.
   We can, at least within limits, have direct knowledge of what is going on within our own minds. And we often know how we are likely to behave in response to an experience of a given kind. When others behave in a given way, I tend to ascribe to them the kind of mental state that accompanies instances of my behaving in that way. I know that when I am in pain, I tend to wince or clutch at the wounded part of my body (or some such). So when I see somebody else behaving in that way, I tend to assume that he or she is in pain. Comparable points hold with respect to our ascriptions of other kinds of mental states to others.
8.1 Self-knowledge
People know much about themselves. I know that, right now, I have the intention of producing a helpful essay on the theory of knowledge. I know that, right now, I’m in a pretty good mood. I know that I enjoy playing the piano. I know that I wish that I could play as well as Arthur Rubenstein; I also know that I’m sad that I cannot play as well he could. All of you have comparable knowledge about yourselves.
   A striking feature of at least some of our self-knowledge is how direct it is. My knowledge that I’m in a pretty good mood is even more direct than knowledge that I am now typing on a computer. But how is this possible? Isn’t my knowledge that I’m now typing on a keyboard as direct as knowledge can be?
   No. My knowledge that I’m typing on a keyboard is based on the sensory experiences I’m having. These experiences are both visual and tactile. (“Tactile” means “having to do with the sense of touch.”) But, given only the nature of those experiences, it is a possibility, if only a theoretical one, that I’m dreaming or hallucinating.
   My having accurate perceptions of, for example, the computer screen in front of me involves my body’s being stimulated in very specific ways by causal processes that originate with that computer screen. (Light waves must bounce off of that computer screen and disturb my retinas.) Further, those light waves mustn’t be distorted or altogether cut-off by intervening influences. If there were an uneven, thick piece of glass between me and the screen, those light waves would be distorted, and my perception of the screen would be inaccurate. If there were a piece of thick wood between me and the glass, those light-waves would be cut off, and I wouldn’t see the screen at all. So my having an accurate perception of the screen involves more than just my having a certain visual experience: that experience must be caused in a very specific way by very specific events in the external world (i.e., the world outside of my body).
   A corollary is that an experience that is just like the one I’m having, but that is caused in the wrong way; it isn’t a perception of the screen. Suppose that, using precision instruments, an extremely skillful surgeon is creating disturbances of my retinas that are exactly like the disturbances that would ordinarily be created by

light bouncing off of a nearby computer screen. In that case, I will have an experience just like that of seeing a computer screen, even though I’m not seeing a computer screen.
   There are typically many different ways of creating a given effect. If you want to hang a painting on the wall, there are a lot of different ways to do it. If you want to make it look as though Smith killed Jones, there are a lot of different ways to do that. One way, of course, would be to get Smith to kill Jones (by, for example, paying him to do so). Another would be to frame Smith. Thus, even if Smith is innocent, he can be made to look guilty. Similarly, even if there’s no computer screen nearby, my retinas and, consequently, my nervous system, can be made to undergo the kinds of disturbances that would ordinarily be caused by light-rays that had bounced off of a computer screen.
   Of course, remarks similar to those just made about visual experiences hold with respect to all other kinds of sensory experience. (I’ll leave it to you to think of examples of this.)
   Basically, sensory experiences, like forensic data, can be “forged”; they can be “fakes.”
   But such fakery seems impossible when it comes to at least certain kinds of self-knowledge. I can have an experience  just like that of seeing a computer screen even if I’m not seeing a computer screen. But could I have an experience just like that of experiencing intense pain if I weren’t experiencing intense pain? Surely not. After all, an experience just like that of intense pain is an intense pain. Of course, what we just said about pain is true of many other psychological conditions.
   Thus, where some psychological occurrences are concerned, the appearance and the reality merge. By contrast, where knowledge of the external world is concerned, the appearance and the reality are always distinct and are often (in fact, usually) separated by a large tract of space. (Even where touch is concerned, the object touched is remote from the events in your central nervous system that mediate your experience of the object.) Thus, from an evidential, and in fact a spatial, point of view, knowledge of at least some facts about one’s psychological condition is considerably more direct than knowledge of facts about the external world—even when the externalities in question are literally being seen (or touched or heard, etc.).
8.2 Some limits to self-knowledge
Notwithstanding what was just said, there are reasons to believe that, in many cases, self-knowledge is as difficult to obtain as knowledge of the external world—that, in fact, knowledge of some facts about our own minds is as theoretical and indirect as our knowledge of sub-atomic events.
   Before we can discuss these reasons, we must define a term and we must also make a distinction. The term to be defined is “consciousness.” In everyday speech, that word is ambiguous. Sometimes, it simply means “knowledge” or “awareness.” For example, in the sentence, “Smith’s consciousness of the complexities involved in running a municipality is extremely limited,” the word “consciousness” seems to have more or less the same meaning as the term “knowledge” or “awareness.”
   In philosophical contexts, the word “consciousness” has a different and narrower meaning. In such contexts, it refers to one’s immediate experience. (Henceforth, we will use the term “consciousness” only in its narrow, philosophical sense.)
   This must be understood aright. The term “consciousness” does not refer to the objects of your experience. Right now, let us suppose, you are feeling a cool breeze. The cool breeze is something that you are conscious of. In other words, it is an object of consciousness. But that cool breeze isn’t identical with your consciousness or with any part of your consciousness. What is a part of your consciousness is the sensation that the cool breeze causes you to have. What is also a part of your consciousness is your visual perception of the piece of paper that the cool breeze is blowing across your front lawn. But, to echo what we said a moment ago, the piece of paper itself is not identical with your consciousness or even with a part of it, even though it is something that you are conscious of (i.e., it is an object of your consciousness).
   Here we must make a delicate point. Many constituents of our minds exist even when we are sleeping and even when, more generally, they are not occupying our consciousness in any way. You believe that 1 + 1 = 2. But it is only very rare occasions that this belief of yours is occupying your consciousness. Nonetheless, you obviously don’t lose that belief when it’s not occupying your consciousness. You still have that belief. This is

made clear by the fact that it can readily make an appearance in your consciousness. For example, if I tell you that I’ll give you an A in the class if you answer the question “what is 1 + 1?”, you will without any difficulty be able to draw on your belief that 1 + 1 = 2, even though, in all likelihood, that belief was remote from your consciousness prior to my asking you that question.
   So that belief, existing as it does when it is outside of consciousness, is not a part of consciousness. It is not, as we will henceforth put it, a constituent of your consciousness.
   Thus, there are instances of knowledge that are not consciousness. And there are instances of consciousness that are not knowledge. The euphoria induced by a drug is an instance of consciousness; it is a component of somebody’s immediate experience. But it isn’t an instance of knowledge. (This is consistent with the fact that somebody experiencing such a euphoria could, and probably would, have knowledge of that experience, just as you have knowledge of the piece of paper blowing across your lawn).
8.2.1 An important fact about consciousness
One feature of consciousness (as philosophers use that term) is that, if something has consciousness, then there is “something it is like” to be that thing. If you are in pain, then there is “something it is like” to be you. So the presence of consciousness in something is sufficient for there to be “something it is like” to be that thing. Further, the presence of consciousness in something is necessary for there to be “something it is like” to be that thing.
   There is nothing it is like to be pinecone, since pinecones are not conscious. But if, by some miracle, a pinecone were to become conscious, then there would be something it was like to be that pinecone. The presence of consciousness in something is thus both necessary and sufficient for there to be something it is like to be that thing. In fact, consciousness may be identified with a thing’s having the property there being something it is like to be that thing.
8.2.2 An important fact about your belief that 1 + 1 = 2
These points help clarify our earlier point that your belief that 1 + 1 = 2 is not a constituent of your consciousness (even though it may occupy your consciousness, just as the spectacle of litter blowing across a street may occupy your consciousness without, of course, being a veritable ingredient of that consciousness). Although there is something it is like to have a pain or a tickle, or to experience a sense-perception, there isn’t anything it is like to believe that 1 + 1 = 2.
   Of course, that belief may have effects on your consciousness—in other words, it may generate constituents of consciousness (without itself being such a constituent)—and there is something it is like to experience those constituents. For example, your having that belief may lead to your getting an A on a test, which in turn may fill you with joy.
8.2.3 A consequence of this important fact: the existence of the unconscious
Thus, your belief that 1 + 1 = 2 is not a constituent of your consciousness. It is not like a pain or a tickle or a perception. But it is clearly “conscious” in some sense of the word. (It is not buried in your subconscious; it isn’t like the previously discussed processes by which your mind converts disturbances of your sensory surfaces into perceptions.) It is not a part of your consciousness. So in that sense it is unconscious. So to the extent that it is “conscious,” it is in the sense that you are conscious of it.
   What we just said about that particular belief is true of many, if not all, beliefs and, indeed, of many desires, aspirations, regrets, intentions, and emotions. Consider your intention to receive a degree from an institution of higher learning. That intention obviously has effects on what you do. (You choose to show up to class, take 

exams, and so on.) And it therefore obviously has effects on what is occupying your consciousness. (Because of that intention, you are now reading a handout and are therefore having various perceptions and feelings that are constituents of your consciousness.) But that intention cannot be identified with any constituent of your consciousness. (That intention continues to exist even when you are asleep.) That intention is better thought of a structural fact about your mind that underlies and regulates the events that populate your consciousness, without itself being such an event. Similar remarks hold with respect to (for example) your affection for certain people, your dislike of other people, your confidence in your ability to (for example) play tennis, your doubts about your ability to (for example) play the harmonica, and so on.
   These points give us insight into an issue of great importance. You don’t have to be conscious of anything that you are in fact conscious of. You are now conscious of a piece of paper (or computer screen) in front of you. But you don’t have to be, and in a few minutes you won’t be. You may, at a certain moment, be conscious of the fact that you believe that 1 + 1 = 2. But you obviously don’t have to be conscious of the fact. In fact, most of the time, you are not thinking about that fact and therefore aren’t conscious of it (though you readily become so). So the truth is that we don’t have to be, and in fact are usually not, conscious of much of what is in our own minds. This shows that, contrary to what a number of authors have alleged, there is at least some reason to accept the thesis, which is urged by thinkers in the psychoanalytic tradition, that we are not conscious of much of what is in our own minds.
   Of course, thinkers in that tradition hold not only that we aren’t conscious of much of what occurs in our own minds, but also that emotional blocks may lead to our having very wrong and distorted and impoverished beliefs about our own minds. Whether that thesis is correct lies outside the scope of this book. But what seems reasonably clear is that there are good grounds for at least one contention of that school of thought—namely, that we are, at any given time, unaware of many of the events that constitute our very own mental lives. And, once this is granted, it becomes a garden-variety empirical question whether, unless we take special measures to learn about ourselves, we have more than a superficial understanding of our own minds.
9.0 Knowledge by acquaintance versus knowledge by description
At the beginning of this chapter, we distinguished between two kinds of knowledge. The one consists of awareness of people (or, more generally, objects); the other consists of awareness of truths. There is reason to think that up to a point, but probably not entirely, the first kind of knowledge collapses into the second. The reason for this is that, with certain very specific exceptions, awareness of objects is identical with knowledge of truths of a certain kind—that, more specifically, it is identical with knowledge of truths to the effect that certain descriptions are in fact satisfied.
   A story will help clarify what it means to say that a description is “satisfied.” In order to collect insurance money, an unscrupulous store owner falsely claims that he is robbed. He gives a description of the (nonexistent) perpetrator of the (non-existent) crime. He goes to the police station and tells the police: “the person who robbed me was a tall male; he had a tattoo that said “I love mom” on his forehead; he had pointy gold teeth . . .” Here the store owner is really saying that there exists an object (a person) that has certain characteristics. To put it another way, he is saying that a certain description is satisfied, that description being “entity that is a human being who robbed me and has pointy gold teeth and is male and . . .” Any statement to the effect that a description is satisfied is known as an existence-claim. So the store owner is affirming the following existence-claim:

(1) There exists an object that is a person, that robbed me, that is a male, that has pointy gold teeth, that has a tattoo that says “I love mom” on his forehead . . .

That existence-claim is false, of course, the reason being that the relevant description (the underlined part of 2) is not satisfied.
   
But, of course, many existence-claims are true, the reason being that many descriptions are satisfied. For example, the following existence-claim is true:

(2) There exists a person who is currently (in Feb. 2008) the U.S. president.

And the reason that 2 is true is, of course, that the relevant description (the underlined part of 2) is satisfied. (It is satisfied by George W. Bush.)
9.1 Theoretical knowledge as descriptive knowledge
Whenever knowledge is theoretical or otherwise indirect, it is descriptive (i.e., it consists of knowledge of the truth of an existence-claim). We are aware of the existence of electrons. But we don’t see them or otherwise sense-perceive them; and we certainly don’t have the kind of direct experience of them that we have of some of our own psychological states (e.g., our joys and sorrows). So in what sense are we are of electrons? The answer: we know the truth of various existence-claims that they satisfy, for example:

(e) there exist various macroscopic, and therefore perceptible, phenomena that, given known physical laws, are most plausibly explained in terms of theories positing the existence of negatively charged particles orbiting around the nuclei of atoms . . .

We are aware of electrons in the sense that we know the truth of existence-claims that they satisfy. Since, as we discussed, an existence-claim is a statement to the effect that a description is satisfied, our awareness of electrons is entirely descriptive in nature.
   Remarks similar to those just made about our knowledge of electrons hold with respect to our knowledge of anything theoretical or, indeed, anything whose existence is inferred, as opposed to known directly.
9.2 Perceptual knowledge as descriptive knowledge
Our knowledge of directly perceived objects is strictly descriptive. Consider your current visual perception. What it tells you is that a certain existence-claim is true, that existence-claim being along the following lines:

(sp) There exists a piece of paper that is in such and such a location with respect to me, that has such and such a shape and color, that has such and such discolorations on it . . .
   
   Perception is description. It is inconceivable that one should have a perception that didn’t describe the world in a certain way and that did not, therefore, say of the world that it contained an object of having certain characteristics. (Even if you are looking into empty space, your perception is to the effect that the description stretch of empty space is satisfied by at least one entity in the world.) Thus, a given perception tells you that some existence-claim is satisfied, and perceptual awareness is therefore descriptive in nature.
   This shows that awareness of sense-perceived objects, and therefore of other people, is identical with knowledge of truths of a certain kind (existence-claims), vindicating our earlier suggestion that knowledge of objects at least sometimes collapses into knowledge of truths.
   Are there any cases where knowledge is not descriptive? The answer seems to be “yes.” If you have an intense pain, it seems that your awareness of that pain is utterly direct and doesn’t involve your knowing that some existence-claim is satisfied. The pain is right there, so to speak, in the theatre of your consciousness, and it needn’t be represented to you through the intermediary of some description. So we have non-descriptive knowledge of at least some of our psychological states. But, for the most part, it seems that our knowledge is descriptive.

9.3 Procedural versus declarative knowledge
We have found that, at least arguably, there are some cases of awareness that are not awareness of truths. At least arguably, we can be directly aware of some of our own psychological states and can therefore be aware of them without being aware of truths that describe or otherwise implicate them. Are there other kinds of awareness or of knowledge that are not awarenesses of truth?
Some philosophers and psychologists say “yes,” the reasoning being as follows:

(KH) We must distinguish knowledge-that from knowledge-how. I know that Paris is the capital of France. This is knowledge of a truth. It is knowledge-that. I know how to ride a bike. This is knowledge, but it isn’t knowledge of a truth. It is knowledge-how, not knowledge-that.
   Any skill is a case of knowledge-how. It’s easily shown that knowledge-how and knowledge-that are fundamentally different things. No matter how much I know about the physics and geometry of bike-riding, I may not be able to ride a bike at all; and no matter how good I am at riding a bike, I may not be able to tell you the first thing about the geometry or physics involved.
   No amount of knowledge-that adds up to a skill, and no amount of skill adds up to knowledge-that. So knowledge-how is not knowledge-that, but it is, of course, knowledge of some kind or other.
   
   But it’s a spurious argument for a false conclusion. Knowledge of a language is knowledge-how. To be able to speak English is to have a skill. But that skill involves having knowledge-that, for you must know various syntactic and semantic truths (e.g., the truth that “snow” picks out snow) to speak English. Knowledge of a language is operationalized semantic and syntactic knowledge. In general, procedural knowledge is operationalized declarative knowledge. (By “declarative knowledge,” I mean knowledge of truths.)
   Of course, not all procedural knowledge starts out as declarative knowledge. (Your ability to ride a bike didn’t start out as non-procedural knowledge. It was procedural all along.) Moreover, one has no conscious access to the declarative knowledge internal to one’s procedural knowledge. (One has conscious access only to analogues of that knowledge. A given piece of knowledge may be stored at many different cognitive levels. Knowledge is oftentimes “over-represented.” A baseball player who is also a physicist may have two distinct pieces of knowledge of some one fact.) Contrary to what Ludwig Wittgenstein (1889–1951) and John McDowell (1942– ) hold, the conclusion to be drawn from these facts is not that knowledge-that is no part of knowledge-how, and is instead that the mind is compartmentalized, and the right hand doesn’t always know what the left is doing.
10.0 Intuitive versus discursive knowledge
Whenever we know something without knowing how we know it, we have intuitive knowledge. Whenever we know something and we do know how we know, we have discursive knowledge. So to know something intuitively is to “just know it,” whereas to know something discursively is to know it while also knowing the grounds on the basis of which one knows it.
Some short stories will clarify these points.
   Story #1. Timmy, who is 10 years old, is in a classroom and he is looking at a figure on the blackboard. The teacher points to the figure and asks Timmy “what shape does that have?” Timmy correctly says “it’s a circle.” The teacher asks: “how do you know? Why is it a circle as opposed to oval?” Timmy says: “I just know. It’s just obvious that it’s a circle.”
   Story #2. Jones, who is a math major, is in a classroom and he is looking at a figure on the blackboard. The professor points to the figure and asks Jones “what shape does that have?” Jones says “it’s a circle.” The professor asks: “how do you know? Why is it a circle as opposed to oval?” Jones says: “because, if x and y are any two arbitrarily short segments of that shape’s periphery, x’s degree of curvature equals y’s.”
   Commentary: Obviously both Jones and Timmy know that the figure on the board is a circle. But Jones knows something that Timmy does not know. But what, exactly? A possible answer is this: “Timmy doesn’t

know why the figure is a circle, whereas Jones does have that knowledge.” But surely Timmy’s belief is based on the very fact about the figure’s shape that Jones has described. It seems to me that—in some way, at some level—Timmy is aware of the fact about that figure that Jones is describing. He doesn’t know it in the same way as Jones—but he still knows it. So it is wrong, or at least very misleading, to say that Timmy doesn’t know what it is about that figure that makes it a circle.
10.1 How intuitive and discursive knowledge differ
Here’s what I think. Jones does, whereas Timmy does not, know on what grounds he himself is judging the figure to be a circle. Timmy and Jones both believe that the drawing is a circle, and (so we may assume) each believes it for the right reasons. But Jones knows, whereas Timmy does not know, what the considerations are that are moving him to make that judgment. The difference between Timmy and Jones is that Jones has a kind of self-knowledge that Timmy lacks.
10.2 How intuitive and discursive knowledge differ (continued)
Here’s another hypothesis (which, I think, is compatible with the one just given). Even though both Jones and Timmy know that the drawing is a circle, Jones knows this in two distinct ways, whereas Timmy knows it in only one way. Timmy has a strictly visual (or, in any case, sensory) knowledge of this fact, whereas Jones has what might be described as propositional knowledge of this same fact. Let us now develop this point.
   First of all, a proposition is what is meant by a sentence—it is the information encoded in a sentence. The information provided by sentences has two striking features: first, it is very schematic; second, it is the kind of information that can be grasped only through an act of judgment, as opposed to perception. (These two facts are related.)
   Suppose you see a certain man, whom you know to be Smith, next to a certain telephone pole, and you report that fact by saying:

(SP) “Smith is next to that telephone pole.”
   
   Compare what you actually see to SP. You don’t just see Smith. You see an individual with very specific characteristics (a specific shape, a specific posture or series of specific postures, wearing specific clothes, having hair of a specific color, and so on). And you don’t just see a telephone pole. You see an object having a specific shape, in a specific location, with a specific color (and with specific discolorations on it), with wires of a certain kind attached to certain parts of it, and so on. Thus, the sentence provides a very schematic and abstract representation of the information provided to you by your visual perception. So, from one viewpoint, the sentence under-represents the content of your visual perception.
   But, from another viewpoint, the sentence over-represents the content of your perception. Given only what you see—given only what your eyes are telling you—it could be that you are seeing somebody other than Smith; it could be that you are seeing somebody who looks just like him but isn’t him—or even that you aren’t seeing a person at all and are in fact seeing a robot. When you characterize that thing as “Smith,” you are making a judgment as to who and what that thing is; you are making a judgment as to the biological species and as to the specific identity of that individual. Though partially based on what your eyes are now telling you, that judgment incorporates information that is not derived from that specific perception—information that is derived from past meetings with various individuals and from inferences drawn therefrom.
   And given only what your eyes are telling you, you don’t know that you are seeing a telephone pole. A telephone pole is something that serves a specific function within a complicated network of social and physical relations. When you are staring at the telephone pole, you cannot literally see it performing these functions. Thus, implicit in your characterization of that thing as a “telephone” pole is a judgment as to its social function. And, though partially derived from your sense-perception, the grounds for that judgment have roots in

past experiences of yours and also in inferences drawn therefrom. So, from that viewpoint, SP over-represents what your eyes are telling you on this occasion.
   Similar points hold with respect to the differences between Timmy and Jones. Jones isn’t simply seeing a certain object’s shape; he isn’t simply uploading perceptual information. He is making a judgment about that information. (So Jones is generating “meta-information.”) By contrast, Timmy is just uploading the information.
   A related point is that, although both Timmy and Jones know that the drawing is a shape, Jones knows this fact in more ways than Timmy. This can be understood in terms of our earlier point that knowledge is descriptive. Here the fact known is that the drawing is a circle. Timmy knows one description of that fact—he knows a visual or graphic description of that fact. But Jones knows both this graphic description and a conceptual or propositional representation of it.
   We thus seem to have two answers to the question “what does Jones know that Timmy doesn’t?” First, Jones has a certain kind of self-knowledge that Timmy lacks: Jones does, whereas Timmy does not, know what the considerations are that led him to believe (rightly) that the drawing is a circle. Second, Jones knows the fact in question under two different descriptions (one pictorial, the other conceptual), whereas Timmy knows it only under one description.
10.3 The paradox of analysis
These points may give us some insight into an old philosophical dispute. Consider the statement:

(CR) x is a circle if and only if x is a two-dimensional figure of uniform curvature.

Obviously CR is informative. It isn’t like the statement:

(CC) x is a circle if, and only if x is a circle.

CR is an example of a conceptual analysis. A conceptual analysis is a statement that lays bare the structure of a concept.
   According to G.E. Moore, it is paradoxical to suppose that conceptual analyses can be informative. There is, he says, a “paradox of analysis.” Moore’s reasoning seems to be this. The sentence “water is H2O” expresses an analysis of water. In that sentence, the words flanking the “is” refer to the same substance. If they didn’t, that sentence wouldn’t express a correct analysis. For the same reason, the expressions flanking the “iff” in a sentence express a conceptual analysis must refer to the same concept. But if they did, then CR would be trivial, like CC, and thus fail to be an analysis.
   This is not good reasoning. True—“water is H2O” expresses a “chemical analysis”; and, in it, the two words flanking the “is” co-refer. True—CR expresses a “conceptual analysis.” But it doesn’t follow that, in it, the expressions flanking the “iff” must co-refer. Moore’s reasoning is comparable to that of somebody who thinks that, since so and so isn’t interested in having “legal” (law-related) discussions, so and so has no wish to have “legal” (law-permitted) discussions.
   In any case, Moore’s paradox is easily enough dissolved. The truth that one grasps in virtue of knowing that:

(i) x is a circle

is different from the truth that one grasps in virtue of knowing that:

(ii) x is a two-dimensional figure of uniform curvature.
   
Both of those truths describe the same fact—the fact that a certain object has a certain shape. But a given fact can obviously be described in different, but equally correct ways. The fact that x is a triangle can be described by saying that x is the area bounded by three straight edges, any two of which intersect, but not all of three of which do so. And that same fact can be described by saying that x is a three-sided, straight-edged, closed, planar figure. And:

(iii) x is a triangle iff x is the area bounded by three straight edges, any two of which intersect, but not all of three of which do so iff x is a three-sided, straight-edged, closed, planar figure

is just another way of saying that there are three different ways of describing x’s shape.
11.0 Justification vs. discovery
The question:
   
   (1) What events in Newton’s mind led to his coming up with his theory of gravitation?

must be distinguished from the question:
   
   (2) What merit does that theory have?
   
   One can know the answer to the one question without knowing the answer to the other. To know why Newton had such and such beliefs, I don’t need to know whether those beliefs are correct or otherwise meritorious, and to know whether those beliefs are correct or otherwise meritorious, I don’t need to know why Newton had them.
   Given a belief, the question “is it correct?” is to be distinguished from the question “how was it arrived at?” and knowing the answer to the one question doesn’t necessarily involve knowing the answer to the other.
   “Justification isn’t discovery.” Philosophers of science often say this. In so doing, they’re affirming the points just made.
11.1 The connection between justification and discovery
Granting that an idea’s pedigree is to be distinguished from its merits, it’s misleading to say that justification isn’t discovery. To discover something is to come to know it. Knowing something involves having a justified belief in it. The justification for that belief will be encoded in the thoughts that led to that belief. No justification, no knowledge. No knowledge, no discovery. Thus, justification is discovery—or at least a good part of it.
   We must distinguish discovering something from merely coming to believe it. One cannot discover something without coming to believe it, but one can come to believe something without discovering it. Coming to believe something doesn’t necessarily involve being justified in believing it or, therefore, in knowing it or, therefore, in discovering it.
   But to the extent that a person’s thought-processes are expressions of intellectual ability, and not of prejudice or some other discovery-thwarting factor, that person’s beliefs are likely to be justified and, consequently, that person won’t come to believe something without being justified in doing so. Given that the conjectures that led to great scientific and intellectual advances are obviously reflections of intellectual ability, as opposed to blind luck, it follows that oftentimes the justification for such a conjecture is to be found in its psychological antecedents. It follows that justification is inherent, not just in scientific discovery, but also in scientific proto-discovery. In other words, it’s inherent not only in the processes that lead to advances, but in the processes that lead to the conjectures that lead to such advances.
   
Great ideas often consist of many intricately interconnected subsidiary ideas. The odds of accidentally stumbling upon those ideas, as opposed to arriving at them on the basis of knowledge and insight, are exceedingly slim. Unless Newton and Keynes were just lucky, which is unlikely, the thoughts they had along the way to making their discoveries were driven by an understanding of how the evidence at their disposal ought to be interpreted. Those thoughts were therefore to the effect that, since such and such evidence justifies thus and such contentions, thus and such contentions ought to be accepted; therefore, thus and such contentions are true. So, setting aside cases where the discoverer was simply lucky, the psychology and the logic of discovery mirror each other.
   Pascal said “it is through intuition that we discover; it is through logic that we prove.” This is wrong. It is through logic that we discover and it is through logic that we prove. For there is no discovery without justification. An unjustified intuition isn’t a discovery at all. And if an unjustified intuitions happens to be right, it’s a matter of luck. While some non-trivial theoretical innovations may be made through luck, most of them are not. (I doubt that any of them are.) And a correct belief arrived at through intuition, as opposed to luck, is ipso facto justified. Proof is the identification of the logic embodied in discovery.
11.2 Discovery vs. prediscovery
“For all we know,” many a philosopher of science says, “it was Newton’s being hit on the head by an apple that led him to posit the inverse-square law. So we can’t expect to find much of relevance to the justification of a conjecture in the processes that led to it. While it may be of interest to psychoanalysts, the psychological back story is no concern of those interested in the logical structure of science.”
   Not everybody who is hit on the head becomes an innovator in physics. So far as a blow to the head had anything to do with Newton’s discoveries, it was only by way of its triggering an intricate train of thought. We must distinguish the instigators of a thought process from the thought process itself. Being hit on the head was no part of Newton’s discovery process. It was, at most, a part of his discovery pre-process. The blow, supposing that it happened, merely activated the relevant processes and therefore wasn’t constitutive of them.
11.3 The roots of the problem
The connection between discovery and justification is easy to overlook if one doesn’t bear in mind the following three points:

(1) Having a justification for a belief doesn’t always involved knowing what that justification is.
(2) Knowing that justification doesn’t always involve being able to say what it is. (One can’t always articulate what one knows.)
(3) Being able to articulate that justification is different from actually doing so and, therefore, from transmitting that justification to others.
11.3.1 (1) explained
There is often a delay between having a justification for a belief and knowing what that justification is. My intuition tells me that so and so is ill-intentioned, even though, on the surface, he is behaving amicably; that a given sentence is grammatical, even though my grammar book classifies it as ungrammatical; that a given animal is about to attack, even though it isn’t giving off any of the obvious signs.
   We trust our intuitions, and our confidence in them is usually vindicated. (Speaking personally, I always regret second-guessing my intuitions.) But when we have them, we don’t know why they are to be trusted. If we did, they wouldn’t be intuitions, since an intuition is, by definition, a belief whose justification, if it exists, is unknown to the person having the belief.
   
Some have said that, for this very reason, intuitions are never knowledge. “If one has grounds for believing something,” it is said, “one knows what those grounds are.”
   This reasoning couldn’t possibly be more off the mark. It is only to the extent that one hasn’t fully internalized the relevant principles that one’s thought fails to be intuitive. It is only pedants and neophytes who rely on discursive thought. Good pianists don’t have to think before they hit every note. Bad pianists do. Good pianists, unlike their bad counterparts, have internalized the relevant rules and, for that reason, don’t need crutch of conscious, discursive mentation. Relying no consciously executed operations to apply rules is like relying on an instruction manual.
   Discursive thought is remedial thought, and thought is non-remedial only insofar as it’s intuitive. It doesn’t follow that all non-discursive is good. But it does follow that not all intuitive thought is bad. Given that knowledge is intuitive only in so far as its possessor doesn’t know the justification for it, it follows that one can be justified in having a certain belief without knowing what that justification is.
   Nonetheless, philosophers of science tend to hold that one has a justification only when one states, or at least can readily state, one’s justification. For this reason, they’re forced to say intuitions are never justified. Given that scientific breakthroughs result largely from intuitive thought and often themselves take the form of intuitions, philosophers of science have no choice but to see the generation of discoveries as having no connection, or only a fortuitous connection, to the eventual justification of them.
11.3.2 (2) explained
One can know one’s reason for having a given belief without being able to state them. A skillful interrogator may know why he believes that the suspect his lying but not able to say why he thinks this. His judgments are made on the basis of subtle cues that he might have a hard time articulating. Articulating one’s knowledge may involve translating it from one medium into another. This is the case with the interrogator. His judgments are responses to visual information. Articulating those judgments would involve translating that information into a non-visual medium.
   Imagine the following. Max believes that metal usually expands when heated, and this belief of his is thoroughly justified. (He’s done numerous experiments, absorbed copious amounts of theory, and so on.) But for some reason Max refuses to state his reasons for having that belief. Max’s situation is very different from the interrogator’s. Unlike the interrogator, Max knows what the justification for his belief is. In any case, even though Max’s belief is thoroughly justified, it could be said that Max has “failed to justify” it. Thus, the expression “unjustified belief” is ambiguous. On the one hand, it can refer to beliefs that aren’t justified. On the other, it can refer to beliefs the justifications of for which, if they exist, haven’t been stated.
11.3.3 (3) explained
Even though a given scientist has cogent reasons for accepting a given hypothesis, and makes every effort to communicate them to others, it doesn’t follow that others know what those reasons are. Others may not understand what that scientist is saying—maybe his theories are too advanced for them. Maybe they do understand what he’s saying but haven’t yet a chance to authenticate his results. Until they have good reason to accept the scientist’s testimony, his justification for accepting the theory in question isn’t yet theirs.
   When epistemologists say that a belief is justified, they mean that the person who has it is justified in having it. When philosophers of science say that a belief is justified, they mean either what epistemologists mean or, what is more likely, they mean that people in general are justified in having it.
   There was a time when many people believed that smoking causes lung cancer, but when only a few researchers actually knew it, since those researchers alone knew the relevant clinical data. During that time, it would have been correct to describe “the widespread belief that smoking causes cancer” as unjustified.
   In general, there are many cases where the belief in such and such is unjustified and therefore isn’t knowledge, even though specific scientists had already discovered such and such and, therefore, knew it and, therefore, were justified in believing it. It thus happens that such and such is discovered before the belief in it is 

justified. It’s obvious why this might lead one to hold that discovering might precede justification and thus have nothing to do with it, and this is exactly what philosophers of science were led to hold. But it’s the wrong conclusion to draw. No one person can discover something without knowing it or, therefore, be justified in believing it. The scientists who discovered that smoking causes cancer were justified in believing it. Their non-scientific contemporaries were not justified in believing it—but they didn’t know it either. And when in due course they did know it, it was only because they were justified in believing it. Nowhere in all this do justification and discovery pull apart.

Chapter 11
Cartesian Skepticism and the Birth of Epistemology
1.0 Descartes’ importance to philosophy
Pre-modern philosophy tended to focus on two questions: (i) Does God exist? (ii) Do universals exist independently of thought? A universal is a property or characteristic.
   Modern philosophy is generally held to have begun with the work of Rene Descartes (1596–1650). Descartes believed in God’s existence, and he also believed that he knew exactly how God’s existence was to be proved. He therefore considered the case to be closed on question (i). Descartes wasn’t interested in question (ii) and said little about it.
   Descartes’ single-handedly invented the discipline of analytic epistemology. But Descartes’ specific epistemological views aren’t what make him so important to philosophy. What did so was his conviction that we shouldn’t believe anything that cannot be rigorously established. For Descartes, nothing ought to be taken on faith. Everything, including God’s existence and the legitimacy of scripture, had to be established. Even though he himself believed in God, he felt it necessary to justify his belief in God. And did he justify it, or at least tried to, by providing two carefully constructed argument’s for God’s existence, which we’ll consider in a few pages.
   Thus, the central tenet of Descartes’ work is that nothing ought to be accepted unless there is a logical, as opposed to faith-based, reason for doing so. So far as this was even a tenet or pre-Cartesian philosophy, it wasn’t the main tenet of it. But it is the main tenet of modern philosophy, which is why Descartes is generally seen as the founder of it.
   In addition to being a great philosopher, Descartes was a great mathematician. He invented the discipline of analytic geometry. This fact about him is deeply relevant to his philosophical work. Descartes believed that all knowledge ought to be modeled on geometrical knowledge—more specifically, on Euclid’s axiomatization of geometry.
   Euclid attempted, with some success, to show that every accepted principle of geometry could be derived from a small number of assumptions that he referred to as “axioms” or “postulates.” (The distinction between axioms and postulates isn’t important, and these days only the term “axiom” is used.) As contemporary logicians and mathematicians use it, the word “axiom” refers to any statement that, in a given argumentative context, is simply assumed to be true and therefore isn’t argued for. But Euclid used this word (or its Ancient Greek counterpart, rather) to refer to what he believed to be self-evident truths—truths that could not be grasped without being seen to be true and that neither required nor admitted of justification. (Among Euclid’s axioms are “all right angles are equal to each other,” “any two points are connected by some straight line,” and “a given line segment can be extended ad infinitum.”)
   Descartes tried to show that what Euclid did for geometrical knowledge could be done for all knowledge. That is, he tried to show that human knowledge could be derived from a few self-evident truths. This was one of the objectives of his most famous work, the Meditations on First Philosophy (or simply “the Meditations”).
   The other objective of that work is to refute skepticism. Skepticism is the doctrine that we can’t establish that any of our sense-perceptions represent the world as it really is—that we can’t know that our experiences aren’t just one big hallucination or dream.
   I believe that I am now typing on a keyboard. But how do I know this? This question might seem trivial. But it turns out not to be so easy to answer. Descartes tried to answer it. He failed. He also failed to axiomatize human knowledge. But he made some good points along the way. Plus, many a correct and important epistemological view is to be understood in terms of Descartes’ views, which is why, even though the latter are often wrong, they deserve careful consideration.
   
Even though the Meditations are concerned primarily with the justification of our beliefs, they also concern the existence and nature of God, the roles played by reason and sense-perception in the acquisition of knowledge, and the relation of mind to body. Descartes felt it necessary, with some justice, to deal with these topics in order to deal with the epistemological problem with which the work is primarily concerned. Below are summaries and critical evaluations of the meditations.
2.0 Meditation 1: “Of the things of which we may doubt”
How do I know that I have two hands? The obvious answer is: I can just see that I do. But how do I know I am not hallucinating or dreaming? This question is not so easy to answer.
   Historically, there have been two ways of answering this question: the foundationalist way and the coherentist way. Aristotle was a foundationalist, and so was Descartes. According to foundationalism, all knowledge coincides with, or rests on top of, knowledge of certain self-evident principles. So the structure of a person’s knowledge is like that of a building. There is a ground floor, or foundation, on which everything else rests. Different foundationalists have different views as to which principles are foundational. We’ll discuss Descartes’ views on this in a moment.
   Coherentists say that there are no foundational pieces of knowledge; there is no ground floor, so to speak— no self-evidently correct beliefs with which either all knowledge coincides or on which it rests. Coherentists say that knowledge is what results when, given various data that are not knowledge—for example, various sensations or perceptions—if those data support one another in certain ways, then certain reasonable inferences can be made on their basis, those inferences leading, in favorable cases, to knowledge. For example, right now, I am having various sense-perceptions (or, in any case, various experiences that I take to be sense-perceptions). I see (or think I see) a table and computer in front of me, etc. I also have various other perceptions (e.g., I feel a certain resistance every time I push one of the buttons on the keyboard that, so I believe, I am using to write this document). I have had various similar experiences in the past. For example, visual experiences of a certain kind (e.g., experiences as of seeing keyboards) have been accompanied by tactile experiences of a certain kind (e.g., experiences as of touching keyboards); and I’ve noticed that experiences of the one kind are connected, in regular and predictable ways, with the experiences of the other kind. This point mutatis mutandis holds of our sensory experiences in general. So my various experiences, taken jointly, form a coherent and consistent picture of the world; and for that reason, I can reasonably infer that there is an external world of which those experiences are a more or less faithful picture, albeit a very incomplete one.
   For the coherentist, no perception by itself constitutes knowledge. Only vast collections of experiences, supplemented by inferences, do so. For the foundationalist, on the other hand, there are some self-evidently correct beliefs—some beliefs that cannot be had without ipso facto having knowledge.
   Descartes is, ultimately, a foundationalist, although towards the end of the Meditations he makes some coherentist points. Aristotle is a hard-core foundationalist. (See the first five pages of the Posterior Analytics.) Since around 1950, coherentism has been more popular than foundationalism, even though there are some contemporary foundationalists (e.g., Roderick Chisholm, who died in 1998, advocated a very compelling form of foundationalism—one which, incidentally, is not unlike Descartes’).
   In any case, when trying to answer the question “how do I know that my perceptions are not hallucinations?” Descartes does not, at least not in Meditation 1, consider the possibility that a coherentist answer might be correct. He says that what he must do to answer that question is to find “indubitable” principles on which all knowledge rests. This brings us to:
3.0 Meditation 2: “Of the nature of the human mind; and that it is more easily known than the body”
Descartes says that certain beliefs about our own minds are self-evidently correct, but that the same can never be said of our beliefs about external objects. First of all, Descartes says, whereas I can doubt that there is an external world, the reason being that I might be perpetually hallucinating or dreaming, I cannot doubt that

my mind exists. After all, I can doubt the existence of my own mind only if I have a mind: there is doubt only where there are minds, since doubting is a form of mental activity. (Author’s commentary: This point seems spot on.) So any doubt as to the existence of mental processes is self-undermining. But doubt as to the existence of the external world is not self-undermining: given only that I seem to see a stick, it doesn’t follow that there really is a stick there (for, as we said before, I could be hallucinating or dreaming).
   In another work (not in the Meditations), Descartes famously says “I think; therefore I am.” We have just seen the meaning of this. One cannot think without existing. Since doubting is a form of thinking, and since thinking involves existing, one cannot doubt one’s existence without existing. Therefore, doubt as to one’s own existence is incoherent. This gives Descartes an Archimedean point on which to build the structure of human knowledge: he knows that he exists; and, so he believes, he can on that basis justify all of the beliefs that we pretheoretically regard as true (e.g., that there is an external world with people and rocks and dogs in it).
   Descartes makes another good point about the difference between knowledge of self and knowledge of the world. As just noted, given only that you have an experience like that of seeing a stick, it doesn’t follow that there really is a stick there. But given only that you have an experience like that of being in pain, it does follow that you really are in pain. After all, an experience like pain is pain, whereas an experience like that of seeing a stick isn’t necessarily an experience of seeing a stick. Descartes seems to hold that what we just said about knowledge of pain is true of all cases of self-knowledge. This is, in my view, a gross over-statement. But we don’t need to pursue this, since it isn’t central to Descartes’ main project; and Descartes’ core point (that at least certain kinds of self-awareness couldn’t be delusional) seems correct.
   Descartes makes another, extremely clever point. He says that, although we think that our basic beliefs about the physical world are purely perceptual, those beliefs are actually replete with inferential, even theoretical, content. Imagine the following. There is a piece of wax in front of you. It is solid and has a definite shape. You put it on a warm pan. It slowly loses its shape. You are watching it the whole time. After 10 minutes, the wax doesn’t really have a shape, and is just an amorphous puddle. Nonetheless, you know, after the 10 minutes have passed, that the puddle you are looking at is identical with the hexagonal solid object that you were looking at 10 minutes earlier. This knowledge, Descartes says, cannot be purely perception-based. For, if you stick strictly to what your senses are telling you, you would hold that the waxy puddle now in front of you is not identical with the previously seen solid object, your reason being that the puddle and the hexagon have different shapes. Therefore, your identification of the puddle with the solid object must involve a certain theoretical or inferential component: it involves your having the belief that an object does not lose its identity solely on account of changes in its shape—that is, that certain kinds of transformations undergone by objects (e.g., changes in temperature, shape, or fragrance) are consistent with the continued existence of those objects. That piece of knowledge is not perceptual and is better characterized as metaperceptual or as preperceptual, since it is a precondition for your acquiring knowledge from your senses. For if you didn’t have it, then every time you saw an object change, you would falsely believe that it had been obliterated and then replaced by an other, similar object. But that isn’t how it works: you believe that you are seeing some one object undergo change; and that is why you form the correct belief that the world consists of objects that, although constantly changing, do so more or less continuously, as opposed to the false belief that, at every moment, everything is obliterated and immediately thereafter replaced with new objects. (Author’s commentary: I am touching up Descartes’ argument a bit, so as to make it continuous with our discussion of rationalism. But the touch-up is more or less consistent with Descartes’ original argument.)
   Thus, any belief about the external world involves an element of inference, an element of theoretical extrapolation, and is to that extent precarious: after all, the more inferences you make, the more likely you are to be wrong. By contrast, one’s knowledge that one is sad doesn’t involve any inference and is thus not precarious. So our beliefs concerning our own minds—concerning their existence and natures—are considerably more solid and reliable than those concerning the external world. And those beliefs constitute the core of self-evident truths on which, in Descartes’ view, our knowledge of everything else (apart from purely conceptual truths; e.g., 1 + 1 = 2) rests. To clarify the parenthetical remark: Descartes is a hard-core rationalist and thus believes that not all knowledge is derived from the senses. Indeed, as we just saw, he thinks that some knowledge is a precondition for perceptual knowledge. He also thinks that it can be known, without having to any empirical work, that triangles have three sides, that causes precede their effects, etc. Descartes’ foundationalism

is strikingly modern and resembles Chisholm’s quite a lot. (I happen to accept Chisholm’s foundationalism, at least with some reservations.)
4.0 Meditation 3: “Of God, that He exists”
Although Descartes believes that some beliefs about oneself are self-evidently true, he doesn’t think that our common-sense beliefs about the external world, which he believes to be true and which he wishes to justify, can be justified solely on the basis of our self-knowledge. Descartes thinks that, in order to justify our beliefs about the external world, it must be supposed that God exists and that, moreover, God is all-good (and would, for that reason, guarantee that our beliefs are more or less on the right track, at least most of the time).
   In this Meditation, Descartes provides an argument for God’s existence. (In Meditation 5, he provides a different argument.) The argument given in Meditation 3 is much better than the one given in Meditation 5.) Here it is.
   The cause of an event must have “at least as much reality as the effect.” The idea seems to be that something cannot come from nothing. If you make a statue, you’re not going to create new clay (or marble); you’re simply going to redistribute the clay that was there to begin with. (Everything comes from pre-existing materials: the quantity of matter in the universe is preserved, and all changes involve redistribution in that matter, as opposed to creation ex nihilo of new matter. “Ex nihilo” means “out of nothing.”) Similarly, events consist in redistributions of objects, not in creation ex nihilo. (Author’s commentay: This point has been denied, and perhaps it is false; but it is obviously reasonable enough.)
   Descartes actually goes on to affirm a very strong version of the principle that something never comes from nothing. He says that effects must not only consist of the same material as their causes but must actually resemble their causes. The idea seems to be that the hotness of the pan resembles the hotness of the flame which made the pan hot and, further, that all cause-effect relations can be understood on this model. (Author’s commentary: This doesn’t seem right. Redistributions in mass-energy often lead to states of affairs that have little or no resemblance to their predecessors. Mozart’s 40th symphony resulted from various mental and neural events, but it doesn’t resemble those events very much, except perhaps in some extremely abstract sense. Effects are often wildly different from their causes.)
   Here is the next step in Descartes’ argument. Each of us has concepts of various forms of infinity—of infinite goodness, infinite intelligence, etc. That means, says Descartes, that infinite goodness, intelligence, etc., must in some sense be in each of us. (Author’s commentary: This is where I think Descartes goes totally wrong. I can have an idea of a trillion dollars without a trillion dollars being “in” me, in any significance sense. Similarly, I can have an idea of infinite intelligence without being infinitely intelligent myself.)
   Descartes then combines the points just made. He says that since
(i) something never comes from nothing,
(ii) that effects resemble their causes, and
(iii) that there is, in some way or other, infinite goodness, intelligence, etc., in each of us,
it follows that
(iv) there really must be an infinitely intelligent, good, etc., being in the world—that, in other words, there must really be a God.
5.0 Meditation 4: “Of the true and the false”
Having, so he believes, established that a good God exists, Descartes has, so he believes, made it possible to establish that most of our beliefs are correct. The argument here is straightforward. Since God is good, he wouldn’t want us to be wrong all the time. So God has given us the power to generate correct beliefs and he

has set up the world in such a way that our belief-forming mechanisms (our senses and our methods of inference) tend to generate a correct picture of the world.
   But here, as Descartes points out, we run into a problem. Even though we seem to have some correct beliefs, we’re also disastrously wrong a great deal of the time. If God is so well-disposed towards us, why would he let us have so many wrong beliefs?
   Here Descartes provides a rather Byzantine argument, which may be summarized as follows. God has given us free will. That was good of him to do, of course, since we’d rather be free than be robots. Next step: We arrive at wrong beliefs only when we abuse our free will. Just as a person may abuse his/her free will by doing drugs, so he/she may abuse it by drawing inferences without sufficient evidence. So, being good, God had no choice but to give us free will. But since we have free will, some of us will inevitably abuse it and make wrong inferences (and also do other bad things).
   But, says Descartes, there is a bright side to this story. If we don’t draw conclusions that are not warranted by the evidence, we’ll have only correct beliefs. Here Descartes ends up putting forth an argument to the effect that most of our beliefs about the external world are correct, and that argument has both foundationalist and coherentist elements. (It’s a pretty good argument, I think, even though two of the premises are clearly false.) First of all, we have self-evidently correct beliefs about our mental states (as we discussed a while ago). Second, something never comes from nothing and, moreover, effects resemble their causes. So the perceptions that we have must have causes and, moreover, they must resemble those causes. Further, Descartes says, those causes don’t lie within us. How do we know this? Because, Descartes says, one’s mind is completely transparent to its owner; and when a given person looks inside himself, he doesn’t encounter anything that resembles the perception he is having of (say) the table in front of him—he just encounters the perception. So the causes of our perceptions must lie in the external world. Thus, our perceptions are accurate, at least most of the time, the same being true of the beliefs based thereupon.
   Why do some unfortunates have hallucinations, etc., despite God’s infinite goodness and his desire for our perceptions to be correct? As Descartes realizes, this question cannot be answered by saying “because those people have abused their free wills,” since hallucinations are involuntary. Descartes’ way of dealing with this problem is ad hoc and unconvincing; so we’ll skip it.
5.1 Evaluating Descartes’ argument
Descartes’ first premise (minds are completely transparent to themselves) is unqualifiedly false. (See Chapter 10 for a discussion of why this is so.)
   The second premise (effects always resemble their causes) is also false. How does your pushing the alarm button resemble the ensuing noise?
   But it might be possible to fix up this premise. My pushing the button is a highly indirect cause of the bell’s ringing. The shorter the series of events linking (distal) cause and effect, the more likely cause and effect are to resemble each other. It may even be (though this is a very strong claim) that, for any degree of resemblance R, short of 100%, there is some length L such that, if the series is cut down to L or less, output will resemble input to degree R. So even though Descartes is not right to say, without qualification, that effects resemble their causes, a closely related point may be correct, namely: effects tend to resemble their causes.
   Twentieth- and twenty-first-century philosophers ridicule Descartes for assuming that effects resemble their causes. I myself think it is in this point that an adequate refutation of skepticism lies. This cryptic assertion is clarified and defended in Chapter 12.
6.0 Meditation 5: “Of the essence of material things; and, again, of God: that he exists”
The main point of this Meditation is that there is a second proof of God’s existence. This second argument coincides, nearly enough, with Anselm’s “ontological argument.” Here it is. God is maximally excellent, by

definition. Anything bad or ugly or stupid would, for that reason, not be God. In general, anything that is deficient in any way cannot be God. Not existing is a way of being deficient. So God exists.
   In Chapter 25, it is explained why this argument fails.
7.0 Meditation 6: “Of the existence of material things, and of the distinction between the mind and body of man”
Here Descartes puts forth his (in)famous argument for mind-body dualism, the doctrine that mental entities (e.g., beliefs) are not identical with physical entities (e.g., patterns of neural stimulation). Here is that argument.
   Let x be a belief. Suppose that I rightly believe x to be a belief. In other words, suppose that x has the property of being believed by me to be a belief. For any pattern of neural stimulation y, it doesn’t follow that I believe that y is a belief. That is, it doesn’t follow that y has the property of being believed by me to be a belief. So x and y don’t have the same properties and therefore cannot be identical.
   The customary response to this argument is to say that it involves an “intensional fallacy.” Benjamin Franklin was the first postmaster general and he was also the inventor of bifocals. So the first postmaster general = the inventor of bifocals. But one can believe that the first postmaster 
general = the first postmaster general without believing that the first postmaster general = the inventor of bifocals. And from the fact that one can have the first belief without having the second, it obviously doesn’t follow, and it isn’t the case, that the first postmaster general ≠ the inventor of bifocals. For the same reason, from the fact that believing that belief x = belief x doesn’t entail believing that belief x = pattern of neural stimulation y, it doesn’t follow that x ≠ y.
   The idea is that, in certain sentential contexts, Leibniz’s Law breaks down (or, rather, appears to breakdown), and that verbs such as “believe,” “know,” and “doubt” create such contexts. Such contexts are referred to as “intensional” contexts. A context that is not “intensional” is “extensional.” So a context is “intensional” if it is one where there can be an apparent violation of Leibniz’s Law, and a context is otherwise “extensional.” Why, exactly, intensional contexts are created by certain expressions is an extremely delicate question, as is the related question of how these apparent breakdowns are to be reconciled with the fact that there are surely no actual exceptions to Leibniz’s Law, since Leibniz’s Law is identical, ultimately, with the obviously correct principle that nothing can fail to have a property that it has. But in this context we may set these subtleties aside. (They are thoroughly discussed in Chapter 6.)
   Given only that Descartes’ argument fails, it doesn’t follow that mind is body. But it does mean that Descartes’ argument must either be augmented, or replaced with a different argument, if it is to be established that mind and body are distinct. Efforts in this direction have been made in recent years, some by yours truly (although I now believe that beliefs are patterns of neural stimulation). The relationship between mind and body is the topic of the rest of the present chapter.
8.0 Different views as to the relation between mind and body
Beliefs, hopes, tickles, pains, aspirations, dreads, intentions, fantasies, and longings are mental entities. Chairs, explosions, rocks, gusts of air, and quagmires are physical entities.
   How is the mental related to the physical? Here are the different views:
   
(1) Dualism: mental entities are not physical entities.
(2) Materialism: mental entities are physical entities.
(3) Dual aspect theory: the mental and the physical are different aspects of the same thing.
(4) Mental eliminativism: there is no such thing as the mental. There are brain-states—but no beliefs, tickles, etc.
(5) Idealism: there is no such thing as the physical. There are experiences, hopes, etc. but no chairs, rocks, etc.,
   
Right now, let us focus on (1) and (2), since they are, pretty obviously, the only two of these five views that have any real chance of being correct. Later we’ll discuss why, despite their obvious falseness, people have held (3)–(5).
   First of all, (2) is not the view that mental entities don’t exist. (2) must be distinguished at all costs from (4). According to (2), perceptions, beliefs, doubts, and so on, all exist—but they are identical with brain-states. The materialist says that, just as water is H2O, so your belief that 1 + 1 = 2 is identical with some pattern of neural stimulation (or some such). Just as the physical chemist isn’t denying the existence of water in identifying it with H2O, so the materialist isn’t denying the existence of the mental in identifying it with physical entities. Although there may be some tendency on the part of materialists to be dismissive of certain features of the psychological realm, they don’t have to be thus dismissive: Chomsky is a materialist, as was Freud—and those two were nothing if not great believers in the psyche.
   Advocates of (2) typically (but not universally) hold that mental entities are identical with brain-events and brain-structures. For obvious reasons, they don’t usually hold that mental entities are identical with trees or rocks or anything else that is not a part of one’s body (or, more specifically, one’s central nervous system).
   I have published some papers arguing for dualism. I am now a materialist. But I am still fundamentally open on this issue.
   Here are my own views. I believe (as I just said) that materialism is correct. Second, I believe (very strongly) that functionalism (a very popular form of materialism: to be defined later) is wrong. Third, although I believe that materialism is correct, I don’t think (paradoxical though it may sound initially) that it can ever be explained why the mental is identical with (some aspects of) the physical.
   Right now, let us focus on some of the basic arguments for and against (1). (In the process of discussing these arguments, we will find that there are different versions of both materialism and dualism.) Of course, since (1) is the negation of (2), any argument for (1) is an argument against (2), and any argument for (2) is an argument against (1).
9.0 Arguments for dualism
First argument

The mental obviously has properties not had by the physical. For example: mental entities are representational; they are purposive; they have “phenomenology” (i.e., there is something it is like to have them). Since physical events obviously don’t have those properties, physical events aren’t mental. (This argument was given by Franz Brentano in Psychology from an Empirical Standpoint.)
This argument evaluated
Though it has force, there is a problem with this argument. The materialist can say that physical events do have these properties, but that this simply isn’t obvious to introspection. For example, physical events have lots of properties that aren’t obvious. When you look at a chair or a rock or a pool of water, your perception doesn’t tell you anything about the microstructural properties of what you are seeing—but it would obviously be absurd to conclude that what you were seeing didn’t have invisible (to the naked eye) microstructural properties. Similarly, says the materialist, when you introspect a pain or a tickle or a belief, your introspection doesn’t tell you anything about the neural properties of what you are introspecting—but it would be absurd to conclude, on that basis alone, that what you were introspecting didn’t have neural properties.
A counter-argument
Some mental entities seem to be appearances. Consider your perception of (e.g.) some nearby table. Your perception is just the event of something’s appearing to you. It doesn’t make sense to say that there is more to an appearance than meets the eye. After all, what doesn’t meet the eye is ipso facto not an appearance. Your perception of the table obviously doesn’t seem to consist of lots of neural events. So if it did consist of such events, they are beneath the surface—they don’t “meet the eye” of introspection. But given what we said a moment ago, this would mean that such events aren’t part of that perception.

This counterargument evaluated
I’m genuinely open as to whether this argument is a good one. I believe (for reasons that I will follow) that materialism is correct. But I cannot find any errors in the just-stated counter-response (though others claim to be able to do so). If you can identify some consideration that resolves the matter, or that gives some weight to a certain (attempted) way of resolving the matter, I would be extremely interested in what you have to say.
Second argument for dualism—the explanatory gap
Consider some psychological statement; for example,

(P) Last year I was very sad, because I completely failed in my efforts to write a best-selling novel.

(P) is obviously the kind of statement that could be true. But can the truth of (P) be understood in terms of facts about neural-firings? Can we conceive of some statement about a person’s body that made it clear why (P) was true? Of course, we can imagine discovering that people feel sad when, and only when, certain neurons in their brains are firing. But would such a discovery really give us any insight into the nature of the dependence (if any there be) of that psychological fact on the existence of those neural states of affairs?
   Let us generalize this point. There is no denying that we can discover psycho-physical concomitances; that is, that we can discover truths of the form mental phenomenon m occurs when, and only when, physical phenomenon p occurs. But there always seems to be a “gap” between the neural event and the associated psychological event. Permit me to clarify this last point.
   Water is H2O. Of course, when you look at a glass of water, you cannot see that it consists of H2O molecules. But suppose that you could shrink yourself down to the size of such a molecule. In that case, you could literally see the molecules with which physical chemists identify water.
   When you look at a brain, you see beige tissue—you don’t see emotions, beliefs, etc. If you were to shrink yourself down the size of a molecule, you still wouldn’t see emotions, beliefs, etc. In other words, you still wouldn’t see the entities that the materialist identifies with brain-states. You would see the entities with which the physical chemist identifies brain-states (atoms, molecules of various kinds) but not, as we just said, those with which the materialist identifies such states. This suggests that psychophysical identifications (e.g., “pain is c-fiber stimulation”) are not comparable to typical scientific identifications (e.g., “water is H2O”); and this makes it questionable whether psychophysical identifications are correct.
   Also, the fact that you could coherently imagine seeing water molecules (even though, for many reasons, our ability to see such things is limited) seems to be bound up (in a way that isn’t easy to articulate) with the fact that identifications such as “water is H2O” are explanatory. The identification of water with H2O renders explicable otherwise inexplicable facts about water (e.g., that the amount of space occupied by a frozen gram of water is larger than that occupied by a liquid gram of water). But, at an intuitive level at least, it doesn’t seem that a comparable gain of insight into the nature of pain is gained as a result of the identification of pain with c-fiber stimulation. Imagine somebody who, because of some defect, didn’t feel pain. If that person were to learn everything there was to know about structure of the neural events underlying pain, he would still be ignorant of what pain was. By the same token, somebody who has no idea what a neuron is can know exactly what pain is.
   This suggests that psychophysical identifications are, in a fundamental way, not comparable to garden-variety scientific identifications. Somebody who knows what water tastes like, looks like, etc., doesn’t necessarily know what water is. But somebody who knows that water consists of H2O molecules really does know what water is—it doesn’t really matter what other knowledge he has or lacks. It thus becomes very hard to sustain the idea that (A) “pain is c-fibre stimulation” is in the same category as (B) “water is H2O.” There is a clear sense in which somebody who knows (A) may not know what pain is but in which somebody who knows (B) cannot possibly fail to know what water is. In connection with this, there is reason to think that there is an explanatory gap between the mental and the physical—to believe, in other words, that there is no way to understand the mental in terms of the physical. And if this is the case, then it would seem to follow that the mental is not the physical.

This argument evaluated
Even if the mental cannot be understood in terms of the physical, it doesn’t follow that the mental isn’t identical with the physical. Even if the fact that Jerry is sad cannot be understood in terms of the fact that Jerry’s brain is in such and such a condition, it doesn’t follow that Jerry’s sadness isn’t identical with his brain’s being in that condition.
   We know that biological phenomena (e.g., digestion, respiration) are identical with interactions of atomic and sub-atomic parts. But there would be no way to translate a biological statement (e.g. “Smith is now breathing”) into a statement about atoms bouncing off of one another. Because statements belonging to biology involve concepts (e.g., respiration) that aren’t found in physics, it is to be expected that the former are not going to be capable of being translated into, or otherwise understood in terms of, the latter. Biology talk isn’t physics talk, even though all biological events are physical events. Similarly, psychology talk isn’t physics talk (or chemistry talk or biology talk), even though psychological events are physical events. Because psychology uses concepts not found in any physical science (e.g., chemistry or physics), it is to be expected that statements belonging to the former are not going to be capable of being translated into, or otherwise understood in terms of, statements belonging to the former to the latter.
Counter-response
Although this argument obviously has merit, and is widely accepted, I am not convinced by it. (But it is an argument that must be thoroughly understood.) There seems to me to be a significant difference between the relationship that holds between statements belonging to physics and statements belonging to biology, on the one hand, and the relationship holding between statements belonging to psychology and statements belonging to physics (or chemistry or biology . . .) on the other. This viewpoint is defended in Sections 9.1–9.2.1 of the present chapter.
A counter-response to the counter-response
The mental can be understood in terms of the physical. There is no more of an explanatory gap between the mental and the physical than between the biological and the chemical. In other words, there is no explanatory gap. Right now we’ll discuss why, according to many, there is no such gap.
9.1 Is there an explanatory gap?
So far as advocates of the view just described provide clear grounds for it, those grounds lie in two doctrines. Right now, we will discuss just one of them. (In a moment, we’ll discuss the other.)
   Some—for example, Carl Hempel (1905–1997)—hold that to explain why one state of affairs accompanies or follows another simply to show that , taken together, they instantiate a general regularity. To explain why, in this one instance, smoke follows fire is simply to identify some comprehensive regularity of which this particular sequence of events is an instance. If it is shown that fire is always followed by smoke, it has ipso facto been explained why, in this case, fire was followed by smoke. Similarly, were we to establish perfect concomitances between mental events and physical events, we would ipso facto have explained the mental in terms of the physical.
A counter-response to the argument given
Hempel’s conception of explanation is wrong. The basic problem is that it’s too liberal: if it were right, anything could be said to be the cause of anything. The reasons for this are given in Chapter 17. But here’s the basic idea.
   I grab my phone, so as to pick it up and make a call; just after I do so, it rings. By coincidence, I’m getting a call at that exact moment. Hempel’s theory has the obviously false consequence that my grabbing the phone is what caused it to ring. Let E1 be the event consisting of my grabbing the phone, and let E2 be the event

consisting of the phone’s ringing. Obviously E1 will be unique in many respects—no other event will involve exactly the same mass-energy distributions that it does. It follows that E1 uniquely has some property P1. The same thing mutatis mutandis is true of E2; and E2 therefore uniquely has some property P2. Thus, the sequence of events consisting of E1 and E1 is a unique instance of the true universal generalization that any instance of P1 is immediately followed by, and adjacent to, an instance of P2. If Hempel’s analysis were right, then my grabbing the phone would have caused it to ring. Since it didn’t, Hempel’s analysis is wrong.
Another counter-response
Setting this aside, it isn’t widely held that mind-brain concomitances (other than obviously contrived, explanatorily irrelevant ones similar to the one just described in connection with E1 and E1) are to be found. The reason: it is widely believed that the mental is “multiply realizable.” Instances of any kind of mental category can, it is alleged, be constituted by physical events of very different kinds; and for this reason, there are no true statements of the form “events having such and such biochemical properties occur iff events having thus and such psychological properties occur.”
9.1.1 How the functionalist tries to eliminate the explanatory gap
But, even though, for the reason just given, the alleged multiple realizability of mental states seems to eliminate one way of closing the explanatory gap between mind and matter, it actually opens what many (myself not included) claim to be a promising way of closing that gap. As previously noted, almost all contemporary materialists hold that mental entities are multiply realizable—that, for example, a belief that snow is white could be composed of virtual material. For X to be such a belief, it is said, is not for it to be composed of this or that material, but is for it to have certain cause and effects. They hold, in general, that given any mental category M, for a given physical entity P to fall into M simply is for P to have certain causes and certain effects. This doctrine is known as functionalism.
   In Sections 12.0–12.1.3 of the present chapter, it will be argued that functionalism is false, the reason being that it collapses into the obviously false view that there are no mental entities. It goes without saying that, if it’s false, functionalism does nothing to close the explanatory gap. In any case, I’d now like to put forth a positive reason to believe that there is no way to close the explanatory gap.
9.2 The reason there is an explanatory gap
For argument’s sake, suppose that every mental event is identical with (or realized by) some physical event. In that case, my feeling remorseful that I stole my sister’s cookie is identical with some brain-event of mine. Let M be my feeling of remorse, and let B be the corresponding brain-event. Suppose that I sincerely and accurately express my remorse—taking care to discuss its origins, its exact content, etc. Let SM be this statement. And suppose that I see an accurate image of B on a giant monitor, and I thoroughly and accurately describe what I see. Let SB be this statement.
   SM describes the very same event as SB. But the data of which SM is a synthesis doesn’t even overlap with the data of which SB is a synthesis. Even if mental events are identical with physical events, the data of which mentalistic statements are syntheses doesn’t even overlap with the data of which physicalistic statements are syntheses. This means that, given the data of which any mentalistic statement is a correct synthesis, it is epistemically possible that none of the data of which any given physicalistic statement is a correct synthesis even exists. Mentalistic statements don’t model the same data as physicalistic statements, or vice versa. So even though the facts described by the former probably are identical with (a subset of) the facts described by the latter, any statement belonging to the one category leaves it completely open whether any given statement belonging to the other is correct or not.

9.2.1 Davidson’s argument for the explanatory gap
In his paper “Mental Events,” Donald Davidson argues that there is an explanatory gap. Here is his argument:
   
   (DA) Suppose the following. x is some event in Smith’s brain. x also constitutes a desire on Smith’s part to become a lawyer.
   Question: why does x constitute such a desire? Answer: because, given the thoughts and deeds on Smith’s part that x follows and given the thoughts and Smith’s part that x precedes, it makes sense to see x as a desire on Smith’s part to become a lawyer. It is analytic that a desire on somebody’s part to become a lawyer have certain causes and also certain effects. It is analytic that, given certain circumstances, a desire to become a lawyer lead one to study for the LSAT, apply to law school, and so on. And it’s analytic that, given certain circumstances, a desire to become a lawyer result from one’s belief that the lawyering is the best way to promote the interests of justice (or whatnot).
   Before we take the next step in our argument, we must generalize these points. Let P be an arbitrary physical event and let M be an arbitrary mental category. (An example of a mental category would be belief that snow is white, desire to become a senator, regret at never having learned to play a musical instrument. So for x to fall into the category desire to become a senator is for x to be a desire to become a senator.) If P is to fall into M, it is necessary and sufficient that, given what P’s owner thought and did prior to P’s occurrence, and given also what P’s owner thought and did after its occurrence, it makes sense to suppose that P is an instance of M. In other words, for P to fall into M is for P to be such that it can be reasonably interpreted as falling into M. To be a belief that 1 + 1 = 2 is to be interpretable as being such a belief.
   This must be understood aright. Supposing that P is a belief that 1 + 1 = 2, there isn’t anything other than P’s being interpretable as being such a belief that makes it be such a belief. It’s being thus interpretable isn’t a consequence of it’s being such a belief: it is its being such a belief. In general, there isn’t anything to anything’s being an instance of mental category M other than it’s being such that it can reasonably be seen as being such an instance.
   To move forward, let us continue to suppose that P is a belief that 1 + 1 = 2. Let us also suppose that P is a brain-event and, in addition, that P falls into physical category C.
   For P to fall into C isn’t for P to be such that it can reasonably be interpreted as falling into C. It isn’t in virtue of what P’s owner does or thinks before or after P’s occurrence that P falls into this as opposed to that physical category. If P falls into a given physical category, it is in virtue of its chemical structure, or some such, it being irrelevant whether so categorizing P has the consequence that P’s owner is rational or not.
   It follows that, even though mental events are identical with brain-events, the reasons for which a given event is mental are different from those in virtue of which it’s physical. Moreover, the former reasons cannot be understood in terms of the latter. Thus, there is an explanatory gap.
   
   Although I personally agree with Davidson that there is an explanatory gap, DA utterly fails to establish this. This is because it depends on two false assumptions.
   The first is the assumption that to be a belief that 1 + 1 = 2 (or a desire to lose weight or an intention to buy a car, etc.) is to be interpretable as being such a belief (or desire or wish, etc.). In addition to being deeply counterintuitive, Davidson’s “interpretivist” view of the mental is demonstrably false. According to Davidson’s interpretivism, for brain-event x, had by person A, to fall into mental category M is for it to be the case that, if x is assumed to fall into M, then A is, to that that extent, rational. If this were right, nobody could possibly make any erroneous inferences; nobody could ever think or act irrationally. For, by Davidson’s lights, if x doesn’t have the consequences that a belief that 1 + 1 = 2 should have, it ipso facto isn’t a belief that 1 + 1 = 2. But people make erroneous inferences from their beliefs; people aren’t always rational. Therefore, Davidson is wrong.
   Also, Davidson’s argument assumes the truth of functionalism which, as previously stated, we will find to be false in Sections 12.0–12.1.3.

9.3 Descartes’ arguments for dualism
Descartes provided a straightforward and, at an intuitive level, compelling argument for (1). Here it is. I can believe that x is a feeling (or belief or intention) without believing that x is a brain-state. Therefore, x cannot be a brain-state if x is a feeling (or belief or intention).
This argument evaluated
This argument is guilty of the so-called “intensional” fallacy. Remember what we said about intensional contexts: given only that “Smith thinks that the inventor of bifocals invented bifocals” is true, it doesn’t follow that “Smith thinks that the first postmaster general invented bifocals” is true, even though the first postmaster general is identical with the inventor of bifocals. Similarly, given only that “Smith thinks that x is a belief” is true, it doesn’t follow that “Smith thinks that x is a brain-state” is true, even if beliefs are in fact brain-states.
   Let us put this more explicitly. The objects of doubt, belief, and all other propositional attitudes are (as you might guess) propositions. So when Descartes says:
(i) I can doubt the existence of a world that is not made of matter,
what he is really saying is:
(i*) I can doubt that there exists a world that is made of matter.
And when Descartes says:
(i) I cannot doubt the existence of my own mind,
he is really saying.
(i*) I cannot doubt that my mind exists.
The italicized propositions are distinct. So while it is true that they differ in their properties, since only one of them has the property of being capable of being doubted by Descartes, it doesn’t follow that mind isn’t matter, since the entities that, in this case, differ in their properties are not mind and matter, but are instead the two underlined propositions.
   An aside: these reflections show that intensional fallacies arise, at least sometimes, when grammatical complements don’t coincide with logical complements. The grammatical complement of the occurrence of “doubt” in (i) is “the existence of a world that is not made of matter,” but its logical complement is “that there exists a world that is made of matter.” The second expression denotes a proposition; the former does not. In general, intensional fallacies arise when it is assumed that, since the grammatical object of some expression doesn’t denote a proposition, the actual object of that expression is also non-propositional.
A refinement of Descartes’ arguments for dualism
Here is an improved version of Descartes’ argument that, so its proponents believe, isn’t vulnerable to the points just made.
   I can coherently think:
(*) “x is a feeling, but x is not a brain-state.”
In other words, (*) is not analytically false.
   All necessary truth is analytic truth. In other words, if a statement is necessarily true, that is because it holds entirely in virtue of the concepts composing its meaning (i.e., it is analytic). Therefore, given that (*) is not

analytically false, it follows that it isn’t necessarily false and, therefore, that it could be true. So feelings could be distinct from brain-states.
   Next-step: identity holds necessarily if it holds at all. If x and y are identical, then they are necessarily so. Proof: suppose that x and y are identical, but only contingently so. Obviously x cannot be contingently identical with itself. So if x and y are contingently identical, then y has a property that x lacks: y has the property of being contingently identical with x, whereas x does not have the property. Thus, contrary to our supposition, x is not identical with y, showing that it is incoherent to suppose that there is such a thing as “contingent” identity.
   Thus, given that (*) could be true, and given that identity holds necessarily if it holds at all, it follows that feelings (and, for exactly similar reasons, beliefs and pains) are not brain-states.
This argument evaluated
First of all, it is easy to adapt what we said about (i) and (ii) to this argument. So this refinement of Descartes’ argument is, like the first, guilty of the intensional fallacy.
   But there’s another reason to question that argument. According to many contemporary philosophers, not all necessity is analytic. The sentence “water is identical with H2O,” it is said, expresses a proposition that, although non-analytic, is necessarily true. There is no possible circumstance where water is anything other than H2O. There are circumstances where liquids that, in terms of their macroscopic properties, resemble water are not H2O. But there are no circumstances where water is not H2O.
   Why is this? The categories in terms of which science explains the world are known as “natural kinds.” Examples of natural kinds are zebra, metal, proton, water, emotion, human being, acid, base, star and penguin. Natural kinds are generated by properties that are predictively and explanatorily fecund. Properties that don’t have those virtues (e.g., person who drives a green car, edible substance on Larry’s table) don’t generate natural kinds. The property of being H2O generates a natural kind. Two things that are explanatorily and predictively very different can, at least within the narrow horizons within which non-experimentalists typically operate, be indistinguishable in respect of their macro-characteristics. Given that two things that are explanatorily and predictively very different can, for all practical intents and purposes, be indistinguishable in respect of their macro-characteristics it follows that the property of having such and such macro-characteristics does not determine a natural kind.
   But two things that are indistinguishable in respect of their micro-characteristics (e.g., their chemical compositions) cannot be explanatorily and predictively different. Thus, the property of having such and such micro-characteristics generates a natural kind. It can’t be known a priori what chemical composition water has. But, for the reasons just given, its having that composition, whatever it turns out to be, is essential to it. Supposing that x is some body of water, x’s being water is identical with x’s having that composition. Since, therefore, water necessarily has that composition—and, therefore, is necessarily H2O—and since it cannot be known a priori that it has that composition, “water is H2O” expresses a necessary, but non-analytic truth.
Evaluating this counter-response
This is a prima facie very compelling line of thought, and it is almost universally accepted. For reasons that I state in Chapters 8, 9, and 18, I do not accept it (even though I accept some parts of it; e.g., the part about how natural kinds are individuated by their microstructures or by whatever it is about them that makes them explanatorily and predictively useful). In any case, these reflections naturally bring us to Kripke’s compelling argument for dualism.
2.4 Kripke’s argument for dualism
All identities hold necessarily, and some identities are indeed a posteriori. Nonetheless, dualism can be established by means of an argument not entirely unlike Descartes’. Consider some (alleged) necessary, nonanalytic truth; for example:


(WH) water is H2O.
(In this context, we’ll assume for argument’s sake that WH is non-analytic.) The reason that WH is non-analytic is that something that appeared, visually and otherwise, to be just like water might not be water, as it might have the wrong micro-structure. In general, whenever a statement of the form x = y is non-analytic, it is because objects that aren’t x can appear just like x. But it makes no sense to say that something that appeared (felt) just like a pain wasn’t actually a pain. Anything that feels just like a pain is a pain. “Pain is identical with brain state X” would be non-analytic, if it were true. Thus, since what makes it possible for it to be non-analytic that water is H2O is that appearing like water is different from being water, and the same thing mutatis mutandis being true of all non-analytic necessities, it follows that “pain is identical with brain state X” is not true.
10.0 Arguments for materialism
First argument for materialism: It is obvious the mental events create, and otherwise affect, physical events; and it is obvious that physical events create, and otherwise affect, mental events. A hot iron is pressed to your skin (physical event); as a result, you feel pain (mental event). You intend to go to the store (mental event); as a result, you end up going to the store (physical event). You feel nervous (mental event); as a result, your heart races (physical event).
   There is extremely strong evidence to the effect that any physical event is the result only of other physical events. To explain why a person’s body moves a certain way, it is necessary only to know what the strictly physical (neural, muscular, . . .) antecedents of that event are, and it is not necessary to know what its psychological antecedents are. The behavior of a person’s body is no more in need of “mentalistic” explanation than is the behavior of a brick. (Of course, a knowledge of a person’s psychological condition is often sufficient, given knowledge of easy-to-ascertain facts about the external world, for a knowledge of what that person is going to do next. But such knowledge is not necessary: such predictions can, in principle, be made without having any knowledge as to the relevant person’s psychology.)
   Given that every fact about a person’s bodily behavior can be explained in strictly physical terms, we can take one of two positions. We can say either:

(i) the mental does not, contrary to appearances, have any effects on the body,

or

(ii) the mental does have such effects—and the mental is identical with the physical events that we know to have those effects.
   
   Since it is very hard to believe that the mental is without effect on the physical, (i) is almost certainly false. Hence (ii) is the right view.
   Evaluating this argument: My own personal view is that this argument is pretty solid, that being why I am a materialist. Others have responded (or, given their positions, would respond) differently to this argument.
   For example, according to epiphenomenalism, even though the physical affects the mental, the mental does not affect the physical.
   But epiphenomenalism is clearly wrong. It’s an empirical datum that the mental affects the physical and vice versa. Should it be denied that this is a datum, or even that it’s true, I would respond by showing that epiphenomenalism is at odds with a fundamental fact about the nature of causation. Causation is bidirectional. If my hand affects the table (e.g., if my hand pushes the table), then the table affects my hand. So if, as the epiphenomenalist believes, the physical affected the mental, then the mental would affect the physical. But in that case, epiphenomenalism is false.

The epiphenomenalist might counter-respond by saying that there are exceptions to the principle of bidirectionality that I’ve been advocating: physical situations create, and have effects on, shadows; but shadows don’t have effects on anything.
   But this move is a non-starter. Mental entities, unlike shadows, really do have causal powers. Even the epiphenomenalist doesn’t deny that they affect one another. Given this fact, along with the fact mental events result from physical events, it follows that some of the energy associated with physical states of affairs is transferred to them. So unless energy is implausibly assumed to vanish from the physical world, never to return, we must assume that the mental can, so to speak, spit it back into the physical world and, therefore, that the mental can affect the physical. And, as we’ve seen, once it is granted the mental can affect the physical, it must be granted that the mental is physical.
Another argument for materialism
As we’ve seen, the mental clearly affects the physical. If mental entities are subject to physical laws, they are ipso facto physical. (After all, what would it be to be physical, if not to obey physical laws?) And if something obeys physical laws, it is ipso facto physical. What would it mean to say “X obeys the laws of physics —but it isn’t physical”? X is physical iff X obeys physical laws.
   Thus, if mental entities are not physical, they are not subject to physical laws. So if mental entities were non-physical, things that didn’t fall within the scope of physical law would constantly have effects on the physical world, resulting in physical events that couldn’t be explained in terms of physical laws—in physical events that were, in fact, violations of physical law. But such violations do not occur. In any case, there is no evidence that they occur, and certainly no evidence that they occur with anything even approaching the frequency with which, if dualism were correct, they would occur.
A counter-response
Surely we could imagine physical objects breaking physical laws. We can imagine people sprouting wings and flying—even though, given the structures of our bodies, such events would be violations of physical law.
A counter-response to the counter-response
Bertrand Russell said that objects are sequences of events that are governed by physical law. I agree with him. If Russell is right, it makes no sense to speak of a physical object that is in violation of all physical laws. So when we imagine a person sprouting wings we are imagining something that is subject to physical laws (albeit laws that are different from those that are actually operative). Second, so far as the objects of one’s thoughts aren’t law-governed, those thoughts involve incoherent or otherwise impoverished views as to the nature of physical law. A defense of this controversial point of view lies outside the scope of the present book.
Third argument for materialism—Fodor’s argument
The mental obviously affects the physical. Anything that affects the physical is ipso facto physical itself. What is there to be physical other than being able to displace mass-energy (or whatever it is that events consist of)?
Evaluating this argument
I personally find this argument compelling, and I don’t know of any cogent responses to it in the literature.
11.0 Interlude: the problems with dual aspect theory, eliminativism, and idealism
Supposing that the mental and the physical are two aspects of the same thing, we must ask: what is that thing? It can’t be mental; for surely the mental is not an aspect of the mental. (My belief that snow is white is not an aspect of itself or of any other mental thing.) And it can’t be physical; for surely the physical is not an aspect of the mental. (The chair is not an aspect of itself or of any other physical thing.) So (3) is either

incoherent or it presupposes that there is something spatiotemporal that is not either physical or mental. But it is incoherent to suppose that there is anything spatiotemporal that is not either mental or physical. It follows that (3) is simply incoherent.
   It seems to me that so-called “dual aspect” theorists are really just materialists who have misstated their view. So far as that’s correct, we can forget about (3), and focus on (2). And since we’ve already discussed (2), we can move on to (4).
   (4) is obviously a non-starter. But, for what extremely little it’s worth, here’s the argument behind it. Scientific hypotheses are supposed to deal with things that can be publicly verified. Suppose that scientist Smith insisted that he, and he alone, were able to see (or otherwise sense-perceive) the data that confirmed some hypothesis of his. Obviously Smith wouldn’t be taken seriously. My pains, tickles, etc., cannot be witnessed by anyone other than myself. For this reason, some psychologists who were attempting to scientize their discipline said that such things had no place within science and, therefore, that they had no place in a scientific world-view. Given this position, it is a short step to saying that pains, tickles, etc., don’t exist at all. In a word, science deals with what is objective; mental states are subjective; therefore, mental states don’t exist.
   There are many fallacies in this argument. One of them is that, in actuality, the existence of pains, tickles, etc., is easily verified. Of course, you cannot have my pains. But you can have your pains, and you can therefore confirm that pains exist.
   Also, that argument involves a failure to distinguish two meanings of the term “subjective.” Sometimes when we describe something as subjective,” we mean that it is influenced by personal biases. (So and so’s reaction to the incident was extremely subjective—it wasn’t impartial and logical.) But when we say that mental entities are “subjective,” we mean—not that they are biased—but that they must be had in order to exist. There can’t be orphan pains and beliefs floating around: a belief must be somebody’s belief. Mental states thus have, as John Searle puts it, a “first-person ontology.” Obviously science mustn’t be “subjective” (i.e., it mustn’t be biased); but it doesn’t follow that it mustn’t deal with the subjective (i.e., with things having a first-person ontology). In any case, it’s a plain fact that mental entities exist, and eliminativism is a hideous monstrosity to which we shall give no further thought.
   (5) is not a view that anyone really holds (even though a few—e.g., George Berkeley, William James, Bertrand Russell—have claimed to do so). (5) is really more of an epistemological view than it is a view about the relation between body and mind: so far philosophers advocate (5), it is on the grounds that it is the only viable response to skepticism about the external world. (Skepticism is the focus of Chapter 12 in its entirety and of Sections 6.0–8.0 of Chapter 13.)
12.0 The different versions of materialism-behaviorism
There are different versions of materialism. Let us now consider them, starting with behaviorism.
   According to the behaviorist, to believe that 1 + 1 = 2 is only to have a disposition to respond with certain overt behaviors to certain physical stimuli. If when asked “what is 1 + 1?,” you say “2”—if, in general, you respond to sensory inputs in ways that are characteristic of a belief that 1 + 1 = 2—then in virtue of that very fact, you believe that 1 + 1 = 2. In other words, according to the behaviorist, behaving in the right way is believing that 1 + 1 = 2. It isn’t a consequence of such knowledge. It is such knowledge.
   The general definition of behaviorism is this. If M is any mental category, P is an instance of M just in case P is a disposition on the part of some individual to respond with certain overt behaviors to certain sensory inputs.
   Behaviorism is false. How a person reacts to a given sensory input is a function, not only of what that input is, but also of what that person’s existing mental states are. If you don’t speak English, an utterance of “what is 1 + 1?” will not cause you to say “2.” It is only in people who have various pieces of background knowledge (e.g., knowledge of linguistic conventions) that such a disposition corresponds to a knowledge that 1 + 1 = 2. What we said about that particular disposition is true (mutatis mutandis) of any other. By itself, no disposition to engage in a certain kind of overt behavior, given certain stimuli, corresponds to any mental state: what does so is such a disposition plus various pre-existing mental states. So mental states cannot be reduced

to behavioral dispositions. At most, they can be reduced to behavioral dispositions plus various mental states. But this means that they can’t be reduced to behavioral dispositions.
   Aware of these problems with behaviorism, but still wanting to holding onto the idea that mental entities could be dispositionalized (identified with tendencies to respond with certain overt behaviors to certain inputs), many philosophers of mind responded to this by adopting functionalism, which we’ve already discussed and will now discuss further.
12.1 Functionalism (revisited)
Consider the kinds of situations that characteristically give rise to a belief that snow is white (e.g., visual perceptions of white snow), and consider all the thoughts and behaviors that characteristically result from such a belief (e.g., one’s forming the belief that snow is not green). According to the functionalist, for a brain-state to be a belief that snow is white just is for it to have the right causes and effects. So if brain-state B has the right causes and effects, B is ipso facto a belief that snow is white (or a desire to become president or a pain or a feeling of euphoria). B’s having those causes and effects isn’t evidence of its being such a belief; nor is it a consequence of its being such a belief. It is its being such a belief.
   The functionalist says that, for any mental type M, mental entities are among the characteristic causes and effects of instances of that type. So the functionalist—unlike the behaviorist—allows that among the causes of (e.g.) a belief that snow is white are other mental entities (e.g., perceptions of white snow), and that among the effects of such a belief are other mental entities (e.g., a belief that snow is not green).
   Remember that behaviorism falsely supposes that a person who had no linguistic knowledge would react by saying “2” to an utterance of “what is 1 + 1?” and, in general, that behaviorism identifies mental states with dispositions that can be understood in strictly behavioral terms. Functionalism doesn’t run into this problem. Unlike behaviorism, functionalism can (supposedly) accommodate the fact that among the causes and effects of a mental entity are other mental entities. (Why “supposedly”? Keep reading.)
   For something is (e.g.) a belief that snow is white wholly in virtue of its causal role. In general, for any mental category M, there is some causal role C such that x falls into M if and only if x has C. (This statement may not be easy to follow, but there is simpler ways of saying what functionalism is.)
12.1.1 Problems with functionalism
For something to be a pain is for it to feel a certain way—its causal role is secondary. It is true, of course, that pains are likely to have certain causes (kicks to the shins) and certain effects (screaming loudly). But for something to be a pain isn’t for it to have a certain causal role; for something to be a pain is for it to feel a certain way.
   Since it says otherwise, functionalism is wrong.
   There is a related point. Supposing that P is some pain, P’s having a given causal role is a consequence of its being a pain; its being a pain is not a consequence of its having that causal role. Supposing that P is some pain of yours, your writhing and screaming is an effect of P’s being a pain and, contrary to what the functionalist alleges, it thus cannot be constitutive of its being a pain.
   Let’s move on. Functionalism says that x is a belief that snow is white iff x has the right causal role. But that causal role, we have seen, involves other mental entities. So it sounds as though functionalism analyzes the mental into causal role plus the mental: the mental is thus not eliminated—it’s still there, making it questionable whether functionalism really is a form of materialism.
   If cogent, this criticism of functionalism is devastating, given that the whole raison d’être for that doctrine is that it supposedly explains the relationship between mind and body. Functionalists respond by saying that, through judicious use of a technical device known as the “Ramsey sentence,” it can be shown that functionalism does reduce the mental to the physical, while at the same time doing justice to the fact that, given any arbitrary mental type M, instances of M may have other mental entities for their causes and effects. Here is their reasoning:

(RS) We must distinguish the concept of all from the concept of any. Among the causes and/or effects of practically every given mental entity are (a) other mental entities and (b) strictly physical inputs (e.g., photons striking one’s retinas) and strictly behavioral outputs (e.g., one’s reaching for the glass). But even though any given mental entity is to be understood in terms of other mental entities, nonetheless the totality of a person’s mental entities can be understood entirely in terms of strictly physical inputs and strictly behavioral outputs. Let MS (short for “mental sentence”) be a single, very large sentence that says, for any given mental kind (e.g., belief that snow is white, dread of visiting one’s mother in law, etc.), what the causes and effects of instances of that kind are. MS is going to contain “constants”: it will contain expressions, such as “dread of going jogging in the morning,” that refer to kinds of mental entities. Given any such expression, replace it with a variable. The result will be an open sentence (an expression that contains a free variable but is otherwise just like a sentence). Bind the occurrences of that variable in that open sentence with an existential quantifier. Do the same thing mutatis mutandis for each occurrence of any expression that refers to a mental kind. But don’t do it for any of the expressions that refer to physical kinds. The result will be a sentence that completely describes the causes and effects of instances of each mental kind, but that does so without using any expressions that refer to anything mental. The mental will thus be completely described in terms of the physical. But that sentence will do justice to the fact that mental events cause other mental events to occur, and it will do justice to the precise way in which they do so.
   
   By saying that causal role fixes content, RS makes content too brittle: any deviations of any kind between any two mental states ipso facto amount to differences in content. No two mental entities have exactly the same causal roles. (There isn’t anything in your mind that has exactly the same causal role as my belief that 2 is an even prime. There isn’t anything in any person’s mind that has exactly the same causal role as anything in anyone else’s mind.) It follows that, if RS is right, no two people can believe that 1 + 1 = 2 or that Mongolia is in Asia, etc. Since that is obviously false, so is RS.
   A story may clarify this point. Both Smith and Jones believe that snow is white. Smith is a physicist who focuses on the reflective properties of white surfaces. Jones doesn’t know anything about physics. Obviously the functional role of Smith’s belief that snow is white will be very different from that of Jones’ corresponding belief. But if, as functionalism holds, a brain-state’s being a belief that snow is white just is its having a certain functional role, then presumably one person’s belief that snow is white shouldn’t be able to differ, at least not too drastically, from another person’s belief that snow is white.
12.1.3 The real problem with functionalism
It is not objects, but states of affairs, that have causal properties. What shatters the window is not the rock—it is rather the rock’s moving with a certain velocity, in a certain direction, etc. Similarly, if B is the brain-state that realizes your belief that (e.g.) water quenches thirst, it isn’t B that causes things to happen—it is B’s having these or those properties. According to functionalism, B’s being identical with a belief that water quenches thirst is identical with B’s having certain causes and effects—it is identical with (e.g.) its causing you to drink water when thirsty. But if B’s being identical with that belief is identical with B’s causing you to drink water (when thirsty), then B’s being such a belief cannot cause such behavior. Cause and effect must be distinct: if x causes y, then x is not identical with y (and neither is a part of the other). So if functionalism is correct, then the fact that you believe that water quenches thirst cannot cause you to do things like drink water when thirsty. Thus, if functionalism is right, then your belief that water quenches thirst does nothing.
   Given any other behavior that we know to be caused by the existence of a certain kind of mental entity, an analogous argument shows that, if functionalism is right, such an entity cannot possibly cause that behavior. If a speaker of English who wishes to be sincere says “I believe that water quenches thirst,” his uttering those words is caused by (among other things) his belief that snow is white. Functionalism says that there is some brain-state B such that that B’s being a belief that snow is white is identical with (among other things) B’s causing that person to utter those words. But if B’s being such a belief is identical with its causing that utterance,

then B’s being such a belief cannot cause that utterance to occur. So functionalism strips the mental of any causal powers. Given that the mental does have causal powers, it follows that functionalism is wrong.
13.0 Conclusion
Given the fact that mind and body interact, along with the fact that such interactions seem not to involve violations of physical law, it seems that materialism is probably correct. But there are two facts that, when taken together, pose a serious threat to materialism:

1. The mental seems to be different from the physical.
2. The appearance-reality dichotomy seems inapplicable to at least some mental entities (e.g., mental images), the reason being that some mental entities are appearances.

Taken together, 1 and 2 suggest that the apparent differences between the mental and the physical are at least sometimes actual differences.

Chapter 12
Skepticism and the Justification of Inductive Inference
1.0 What is skepticism?
A skeptic is a doubter, not a disbeliever. For me to be skeptical about Smith’s assertion that he’s an astronaut is for me to doubt that he’s an astronaut. It isn’t for me to be to disbelieve that assertion—only to question it. If I’m convinced that Smith is not an astronaut, I’m not skeptical about his claim. Skepticism is doubt, not disbelief.
   But there is some tendency for skepticism to give way to disbelief. Even if I never definitively learn that Smith is not an astronaut, if I continue to find no good reason to believe that he is one, I’m more likely than not to disbelieve it. We feel that, if a claim is true, some positive evidence for it will turn up: the mere absence of counterevidence isn’t enough for us.
   Does our human tendency to transition from doubt to disbelief have any logical basis? Or is it just another case of emotion and instinct corrupting rationality? It depends on the case. In some cases, but not all, failure to find positive evidence is itself counterevidence; and, in such cases, our tendency to slide form doubt to disbelief does have a logical basis. But, as we’ll see in this very chapter, unless some highly defensible forms of skepticism can be refuted, this claim of mine is simply wrong.
   Many important debates in philosophy concern the merits of some form of skepticism. Are there non-spatiotemporal entities? (Skepticism about platonic entities.) Do we have beliefs, feelings, etc., that we aren’t aware of having? (Skepticism about unconscious ideation.) Could observation ever provide adequate grounds for believing in unobservables (e.g., electrons) or should we regard terms like “electron” as referring to fictions of some kind or as not referring to anything at all? (Skepticism about theoretical entities.)
   As these examples indicate, philosophical skepticisms involve whole categories of truths. One doubts all truths affirming, or presupposing, the existence of non-spatiotemporal entities, unconscious emotions, theoretical entities, etc.
   In this chapter, we’ll discuss what are probably the two most important forms of skepticism: skepticism about the external world and skepticism about inductive inference.
   To be a skeptic about the external world is to doubt that what our senses are telling us is accurate. One is a skeptic of this kind if one believes there to be no good reason to believe that one’s sense-perceptions are anything other than hallucinations.
   A bit of background is needed to say what it is for one to be a skeptic about inductive inference. Some knowledge is direct. One doesn’t have to figure it out—one just knows it. Somebody who is experiencing a searing pain knows it, and he didn’t have to figure it out. But much knowledge is indirect. Einstein didn’t “just know” that a body’s mass increases as its speed increases; he had to figure it out. In other words, he had to infer it. So for knowledge to be indirect is for it to be acquired through inference.
   There are two parts to any inference: the premises and the conclusion. The conclusion is the belief arrived at—the thing that, when the inference leads from the right premises to the right conclusion in the right way, is “figured out.” The premises are the pre-existing beliefs or assumptions on the basis of which one arrives at the conclusion.
   There are two kinds of inferences: deductive and inductive. An inference is deductive if, supposing that one’s premises are true and one’s reasoning non-faulty, it is impossible for one’s conclusion to be false. If my premise is that x is a square and my conclusion is that x has four sides, it’s logically impossible for my conclusion to be false if my premise is true. So this would be a case of a deductive inference. An inference is inductive if, supposing that one’s premises are true and one’s reasoning non-faulty, it is possible for one’s conclusion

to be false. If my premise is that, in the 35 years I’ve been drinking tap water, I have never become sick as a result of doing so, and my conclusion is that I won’t become sick as a result of drinking the glass of tap water in front of me, my conclusion may be false. So this would be a case of an inductive inference.
   A skeptic about inductive inference holds that it is impossible, as a matter of principle, to learn anything through non-deductive inference. He holds, in other words, that one cannot acquire knowledge through inductive inference. All knowledge is either direct or is arrived at through deductive inference.
   If this is right, then we know only an infinitesimally small fraction of what we think we know. This is because, for reasons thoroughly discussed in Chapter 10, no knowledge about the external world is direct, and only some knowledge of ourselves is direct.
   We will start by discussing skepticism about induction.
2.0 Skepticism about induction
David Hume made it clear why it may be doubted whether inductive inference ever leads to knowledge. Here is Hume’s argument:

   (HA) Consider some inductive inference—for example, “the sun has always risen in the past; therefore, it will rise tomorrow.” First of all, this argument is not deductive, since, even if the premise is granted, it isn’t a theoretical impossibility that the conclusion will be false. The sun might explode, after all. So the conclusion is, at best, probable. That’s step 1.
   Here’s step 2. Given that the connection between premise and conclusion isn’t deductive, we must ask: how does the premise warrant the conclusion? In other words, what reason does the (supposed) truth of the premise give us for accepting the conclusion?
   Here’s an answer that seems tempting at first: “The past resembles the future; the known resembles the unknown. Nature is uniform. So given that such and such has been the case until now, we may infer that such and such will continue to be the case. Given that, until now, pinewood has floated, metal has expanded when heated, water has quenched thirst, etc., it’s reasonable to conclude that pinewood will continue to float, and so on. It is thus the principle that nature is uniform—or, as we’ll call it, the uniformity principle (UP)—that allows us to make rational, non-deductive inferences about the unknown on the basis of the known.”
   But this argument is no good. No one directly knows that UP holds for all places and times. At most, one knows that it has held for the fragments of nature that one has personally known of. One doesn’t directly know that it held of past objects that one didn’t know of; and one doesn’t directly know that it will hold of future objects that one will know or of future objects that one won’t know of. Any such knowledge must be indirect (i.e., must be inferential). The inference in question can’t be deductive. Given only that the ravens thus far known to one have been black, it doesn’t follow deductively that ravens not (yet) known to one are also black. In general, given only that such and such has held of the things I’ve known of, it obviously doesn’t deductively follow that it holds of the things that I haven’t (yet) known of. The inference must be inductive. But if it’s inductive, then it goes through only on the condition that UP is granted. But since that very inference must go through in order for UP to be granted, it doesn’t go through and, what is more, UP cannot be granted and, finally, there’s no way to justify inductive inference.
3.0 Problems with Hume’s argument
Nobody denies that inductive inferences are knowledge-conducive and, therefore, that the conclusion of Hume’s argument is false. Even Hume said that, in his bones, he couldn’t accept it. But there’s no accepted response to Hume’s extremely clever argument. Nonetheless, Hume’s argument is refutable and a refutation of it must lie in some argument not totally unlike the following.

There are two serious errors in Hume’s argument. First, it assumes that the primary form of non-deductive inference is induction by enumeration. In actuality, induction by enumeration is less important than, and subordinate to, a very different form of non-deductive inference known as inference to the best explanation. (The italicized terms will be defined shortly.) Second, Hume assumes that non-deductive inferences go through only if UP is granted (i.e. only if it’s granted that nature is uniform.) But UP is not the relevant principle. What must be granted, I propose, is that good explanations minimize causal anomalies. What must be granted, in other words, is that, other things being equal, theory T1 is better than theory T1 if the world as T1 describes it contains fewer unexplained causal connections—fewer causal links that must be taken for granted and left unexplained—than T1. Let’s refer to this principle as “MC” (short for “minimization of causal anomalies”).
   Unlike UP, MC is, I submit, analytically true: it is inherent in the concept of what an explanation is that, other things being equal, the theory that eliminates the greater number of unexplained explainers—and, in particular, the greater number of unexplained causal connections—is the one to be preferred. Because this principle, unlike UP, is analytically true, it doesn’t have to be validated on inductive grounds. This makes it possible to validate inductive inference in a way that, unlike the way that Hume considers, is not viciously circular.
3.1 Inference to best explanation versus enumerative induction
There are two forms of inductive inference: induction by enumeration and inference to the best explanation. (See Chapter 12.) An induction by enumeration has the form: every F that I’ve ever known of was also a G; therefore all F’s are G’s. Example: All the balls that I’ve thus far removed from the urn have been white; therefore, all the balls in (or removed by me) the urn are white.
   An inference to the best explanation has the form: it is known that S; it isn’t yet known that S*; but if S* were true, it would, without doing excessive violence to what we (think we) know about the world, explain why S is true; moreover, if S* weren’t true, it would be hard to find a viable alternative explanation of S. For example: I’m very careful with my credit cards (I never use them to make online purchases, I never let anyone besides reliable merchants see them, etc); and, before my friend Larry moved in with me, no unauthorized purchases were ever made with any card of mine. But after he moved in, my cards were used to make a series of unauthorized purchases. Moreover, the items bought were ones that, for work-related reasons, Larry desperately needs and that nobody outside of Larry’s rather unusual profession would have slightest use for. Knowing all of this, and not knowing any other way to account for the unauthorized purchases, I conclude that Larry made those purchases.
   It’s widely assumed among philosophers that induction by enumeration is the more fundamental form of inference. This is a mistake. All cases of induction by inference, when legitimate, are parasitic on cases of inference to the best explanation. There are, of course, many cases where one of my reasons for thinking that all F’s are G’s is that every F I’ve ever known of was also a G. But, setting aside beliefs arrived at through spurious reasoning, there are no cases where that was my only reason for believing that all F’s are G’s. Hume’s argument focuses entirely on induction by enumeration. Hume is right, I believe, that this form of inference is unjustifiable. But we don’t use this form of inference. In any case, we don’t use it in the way that Hume thinks. Moreover, we shouldn’t use it, and we needn’t use it. In some cases we may think that we’re doing straight induction by enumeration. But, in almost all such cases, a little probing always shows that many interconnected background assumptions are at work and that, when these are made explicit, what we’re really trying to do is to produce an inference to the best explanation. And, although there are cases of straight induction by enumeration, they tend to occur in rather artificial contexts and that, when they do occur, they’re clearly spurious.
   There is a well-known inductive error known as the “gambler’s fallacy.” (Sometimes it’s referred to as the “Monte Carlo” fallacy.) You are playing a game of roulette. (This game involves rolling two dice into a spinning wheel, which is divided into numbered slots.) You know that nothing about the game is in any way rigged—that the dice aren’t loaded, and that neither the wheel nor the underlying apparatus were built or modified to favor any one outcome more than any other. And you thus know that, given only the physical properties of the game, a die, once thrown, is no more likely to land in this as opposed to that slot. (How you know 

this is irrelevant; we’ll just assume that you do.) You also know that, given any slot on the wheel, there is nothing about you that makes a die you’ve thrown more likely to land in that spot than in any other—nothing about your body, mind, or dice-throwing practices that favors this as opposed to that outcome. (Again, how you know this is irrelevant; we’ll just assume that you do.) You’ve rolled the dice seven times. Each time, at least one of the die has landed in slot #27. It must be stressed that you know there to be nothing about the game or about you that predisposed this to happen—that you know this to be entirely a matter of luck.
   Under these circumstances, it would be natural to predict that you’ll roll a 27 next time. But that prediction would be irrational: you have no more reason to believe that you’ll roll a 27 than you will any other number. And if, by chance, you do roll a 27 next time, it will be natural to predict that you’ll roll a 27 the following time. But this too would be completely irrational. So long as you know that there’s nothing inherent in the game or in yourself that favors this as opposed to that outcome, you are never any more entitled to bet that, with the next throw, you’ll roll a 27 than you are to bet that you’ll throw any other available number. It doesn’t matter how many consecutive 27s you rolled prior to that throw: it could have been ten, a thousand, or a million. 
   By the same token, no matter how many consecutive 27s you roll, you are never any more entitled to bet that, next time, you won’t roll a 27 than you are to bet that you won’t roll any one of the other available numbers. It would be natural to think otherwise, of course. Given how improbable it is that you will roll five consecutive 27s, let alone 50, you may have an urge, when rolling for the 51st time, to think: “this time, surely, I’m even more unlikely to roll a 27 than I am to roll any other available number. The game isn’t rigged. The likelihood of my rolling 51 consecutive 27s is infinitesimal and, therefore, is much smaller than 1/n (where n is the number of available slots). So a 27-roll is especially unlikely—more unlikely than a 5-roll or a 13-roll.” But this is spurious reasoning. You are no more, and no less, unlikely to roll a 27 than you are to roll any other number. With every throw, the chances of rolling any one of the available numbers are identical with the chances of throwing any one of the others. Since, by hypothesis, the conditions that obtain on any two occasions are identical, it would be irrational on any given occasion to think any one outcome any more or any less likely than any other. It would, in fact, be the ultimate absurdity—like the belief that, although doughnut x is an atom-for-atom duplicate of doughnut y, x is far more fattening than y.
3.1.1 When is enumerative induction rational?
When would it become rational to believe that, next time, you’re more likely than not to roll this as opposed to that number—that, for example, you’re especially likely to roll a 27? This belief becomes rational when, and only when, you have reason to believe that a 27-roll is favored by the structures involved in the game. And that belief, in its turn, is rational if you know that circumstances at all like the following obtain: 

*The dice are magnetically attracted to the 27-slot. 

*On any given occasion, you have an unconscious intention to roll a 27 (even though you have no conscious intention of doing this), and you’re such a talented dice-thrower that, if you can roll a 27 if it is your (subconscious) intention to do so.

*The 27-slot is much bigger than any of the other slots. In fact, it takes up so much space on the roulette wheel that the remaining spaces are too small for the ball to fit into them.

   You are rational to believe that you’ll continue to roll 27s to the extent that your having thus far rolled multiple 27s in a row gives you reason to believe there to be some underlying structure favoring that outcome. And to the extent that a long run of 27-rolls doesn’t give you such a reason, you are irrational to believe that you’re any more (or any less) likely to roll a 27 than you are any other number. So, no matter how many consecutive 27s you roll, if you know with complete certainty that nothing about either yourself or the set-up of the game favors that outcome, it is irrational to think that, next time, you’re any more (or less) likely to roll

a 27 than you are a 5 or a 32. Put pedantically, it is only insofar as you have reason to believe in such a structure that you have reason to expect something that has the property of being a die thrown by you to have the property of landing in the 27-slot.
3.1.2 Generalizing these points
Your knowing of many phi’s that are psi’s and of none that are not doesn’t necessarily give you any reason to believe that the next phi you encounter will be a psi; it gives you such a reason only insofar as it gives you a reason to believe in some structure or mechanism that disposes phi’s to be psi’s. If you know on independent grounds that there is no such mechanism, no run of phi’s that are psi’s, no matter how long, gives you a reason to think that the next phi will be a psi; and you are guilty of the gambler’s fallacy—and thus, as we saw, of the most rank absurdity—so far as you think otherwise. Thus, in and of itself induction by enumeration is worthless; it’s a fallacious form of reasoning and falls in the same category as every other argumentative fallacy. Of course, if you know of many phi’s that are psi’s and of none that are not, you do have good reason to hold that, other things being equal, the next phi you encounter will be a psi. But this is because you’re having this knowledge gives you reason to believe there to be a principled or lawful connection between a thing’s being a phi, on the one hand, and its being a psi, on the other. Here, then, is the real structure of inferences that are wrongly thought of as cases if induction by enumeration: (i) you know of many phi’s that are psi’s and of no phi’s that are non-psi’s; (ii) on the basis of step (i), you believe there to be some principled connection between a thing’s being a phi and its being a psi; (iii) if you know of a given thing that is a phi, but don’t yet know whether or not it’s a psi, you know, given (ii), that it’s likely to be a psi; therefore, (iv) you conclude (if only tentatively) that it is a psi. 
   Thus, any case of induction by enumeration that isn’t an instance of the gambler’s fallacy involves the positing some mechanism or law that, were it to exist, would explain a certain concomitance—it involves, in other words, a case of inference to the best explanation. The best explanation of the fact that all known phi’s are psi’s is that, thanks to some mechanism or, in any case, principled connection of some kind or other, a thing’s being a phi disposes it to be a psi; and as soon as such a mechanism has been posited, but not one second sooner, your knowing of a given thing that it’s a phi is a reason for you to hold that it’s a psi. So any non-fallacious “induction by enumeration” is nothing other than a case of inference to the best explanation (or, more precisely, is a case of applying some theory that embodies an inference to the best explanation).
   Hume’s argument assumes that it is only through induction by enumeration that the past is any guide to the future. It assumes that, so far as we have any reason to believe that future phi’s will be psi’s, it is that past phi’s have been psi’s. But this assumption is dead wrong. The fact that past phi’s were psi’s, is not, in and of itself, reason to hold that future phi’s will be psi’s; it is such a reason only to the extent that it suggests some mechanism that disposes phi’s to be psi’s. Hume’s argument assumes otherwise and is thus guilty of assuming the legitimacy of the spurious form of inference involved in cases of the gambler’s fallacy. And, if it is to have a chance of going through, Hume’s argument must be so reconstructed that it no longer embodies that assumption.
4.0 The minimization of causal anomalies
We haven’t yet refuted Hume’s argument—we’ve only taken the first step towards doing so. Hume could defend his view against what we’ve said thus by far by saying the following: 

(HR) Suppose that, to explain why all phi’s thus far known are psi’s, you posit some underlying structure or law that disposes phi’s to be psi’s. Unless you think that nature is uniform, you have no right to expect that connection to continue to hold. But if, in order to deal with this, you suppose that nature is uniform, then you’re caught in the vicious circle that I described.

   HR is correct. One is indeed caught in a vicious circle if, in order to show the legitimacy of inductive inference, one assumes UP; and the reason is that, just as Hume says, UP can be known, if at all, only on inductive grounds.

4.1. Why inductive inferences don’t presuppose the truth of the uniformity principle
But in making an inductive inference, one doesn’t assume UP and, moreover, one doesn’t assume anything that, like UP, can be known only on inductive grounds. What one assumes is that explanations are supposed to eliminate causal anomalies—that they are supposed to reduce the number of them and to limit the scope of those that aren’t eliminated. What one assumes, then, is that it is inherent in the very concept of explanation that, other things being equal, T1 is a better explanation than T2 if T1 does a better job of eliminating causal anomalies than T2.
   The purpose of explanation is to minimize the breadth and depth of what must be taken for granted. The more a proposed theory requires you to say: “things just happen that way; there’s no explaining it,” the less successful an explanation it is.
   Here’s an illustration. On Monday night, you park your car in the usual place, viz. right in front of your house, which is in a quiet residential neighborhood. As usual, you make sure that you lock the car and turn the car alarm on. You also put an almost, but not quite, indestructible device (popularly known as “The Club”) on the steering-wheel that locks it into place, making the car undriveable. Given where your home is in relation to where the car is parked, you’d almost certainly hear the car alarm go off, were it to do so. In fact, unless you were fast asleep, you’d even hear the footsteps of someone approaching the car. So even if the car alarm weren’t on, you might well hear the approach of a would-be thief and you’d certainly hear the noises made by somebody who, not having the keys needed to open the car or to unlock the steering wheel or to start the car, would have to jimmy the door lock, saw through the wheel lock, etc.
   As it happens, you hear nothing all night. And you know that you didn’t sleep any more deeply than usual—that, for example, you weren’t in a particularly deep drug-induced slumber—and, in general, that you weren’t made less sensitive to noise than you usually are. (For argumentative purposes, we’ll set aside the question of how you know this.) Nonetheless, on Tuesday morning, the car is gone.
   What are the various possible explanations of this? (By “possible,” I don’t necessarily mean “worthy of consideration,” only “not ruled out by the laws of logic.”) There are infinitely many; but here are three.
   
(E1) Using his or her super powers to bypass the security measures you took, some superhero-like creature made off with the car, making little or no noise and leaving few or no clues.
   
(E2) As you were sleeping, the laws of physics changed in such a way that hitherto noisy processes (e.g., those that occur when car alarms go off) are no longer noisy.
   
(E3) Your good friend Larry—who, despite his numerous convictions for auto-theft, simply radiates trustworthiness and decency, and to whom, without so much as a touch of anxiety, you therefore gave copies of all your keys—made off with the car. (For argumentative purposes, let’s assume that, given that the car is gone, it had to have been stolen; it could not, we will suppose, have been towed or simply borrowed.)
   
   Each of E1 and E2 replaces the mystery of how your car could be noiselessly stolen with a far greater mystery. In fact, each creates a whole network of deep mysteries. E1, if correct, would generate a number of thorny questions concerning specific matters of fact and also concerning our knowledge of biological and physical law. (The features that we’d have to ascribe to the superhero in question would be ones that, unless modern biology is very wrong, a life form is most unlikely to have.) And E2, if correct, would do nothing less than create the greatest scientific mystery of all time.
   E3 is not free from sin either. In general, you are a good judge of character. In any case, that’s what you believe and that’s what others tell you; and your judgments about people have generally been borne out by subsequent events. You’ve never been as convinced of anyone’s integrity as you are of Larry’s. Without being morose or censorious, he exudes a decency and centeredness that you’ve never even seen in a head of state, let alone a car thief. And although Larry’s extensive criminal background is consistent with his stealing your car, it is not, you are convinced, as consistent with it as his current excellence of character is inconsistent with it.
   
But, of course, E3 is hands down the best explanation. You may think you’re a good judge of character; but that doesn’t mean you are one. People proverbially overestimate their ability to read others. And even if you are a good judge of character, so what? Anybody can be fooled; everybody is fooled, at some point or other. And if Larry is a career criminal—which, given his rap-sheet, he may well be—then he has probably honed his skills as a con-man.
   This doesn’t mean that E3 is completely innocuous. If correct, it raises the question of how somebody could seem so different from how they are. It also raises the question of how, despite being a crime expert, you could have been unwary enough to let yourself be seduced into trusting somebody who, given his background, was so obviously unworthy of trust. But these mysteries can be dealt with more easily than the mysteries created by E1–E2.
   All of this goes to show that ceteris paribus the best explanation is the one that leaves us with the fewest unexplained explainers.
   Of course, new theories raise questions of their own. This is almost a tautology. A new theory is, tautologously, a new way of looking at things; and a new way of looking things is, very obviously if not tautologously, one that raises new questions. But good new theories tend to facilitate the answering of the questions they raise. Relativity Theory raises questions that don’t arise for its predecessor, Newtonian mechanics. But Relativity Theory itself tends to contain hints as to how those questions are to be answered. The development of a good theory tends to consist largely in making explicit what is already present in that theory. The development of a bad theory consists in adding new material to it to help it deal with each new onslaught of counterevidence. In any case, what’s important in this context is that good theories get rid of causal gaps and they shrink the ones they can’t get rid of.
   Before proceeding, we must make a certain distinction very clear. Little or nothing about the actual causal structure of the world is analytic. It isn’t analytic that there aren’t giant causal gaps in the causal structure of the world; that reality doesn’t consist of one ex nihilo event after another, that superheroes don’t suddenly pop into existence, steal cars, and then, without leaving a trace, vanish never to be heard from again. These things, if known, are known only on the basis of sense-experience. But it is analytic that, other things equal, good explanations are less dependent for their truth than bad ones on the existence of unexplained explainers. Given that E3 depends less for its truth on unexplained explainers than does any one of E1–E2, it is analytic that E3 is ceteris paribus the better explanation. 
   But it isn’t analytic that E3 is correct. It’s a possibility—maybe only a bare theoretical possibility, but a possibility no less—that the laws of physics changed over night, that CIA super-agents have targeted you, that comic book characters now walk the Earth, etc. Anything’s possible. And so far as we know that E1–E2 are wrong, it’s through sense-perception. So, I repeat, it isn’t analytic that E3 is correct. But, given that it requires fewer unexplained explainers than others, it is analytic that ceteris paribus it’s the better explanation.
4.2 Correct explanations can be bad explanations
For an explanation to be good isn’t for it to be correct. Sometimes the right explanations are bad ones. A story will make this clear. I’m on a bus. The bus driver is smiling. A mystery! “What on Earth does he have to smile about?” I ask myself. His job is so boring, and his life must therefore be such a horror.” But then I remember that, just a minute ago, a disembarking passenger gave him fifty $100 bills as a tip. So I have my explanation: “he just came into a lot of money.”
   But here is the very different explanation tendered by my seatmate Gus, who, in addition to being unintelligent, is also completely insane. “The bus-driver is a CIA assassin. This morning he killed somebody who, by coincidence, had the name ‘Benjamin Franklin.’ Benjamin Franklin (the statesman, not the murder victim) is on the $100 bill. So when the bus driver saw those bills, he immediately thought of that morning’s murder. The murder was a particularly enjoyable one; the bus driver had a chance to try out some innovative techniques. So, on being given the fifty $100 bills, the bus driver was reminded of that happy experience.” That, my seat-mate believes, is why the bus driver is smiling. The bus driver is indifferent to the fact that he is now richer by $5,000 than he was before. (He’s not a materialistic man. Plus, the CIA pays him a huge salary. $5,000 is nothing to him.)
   
Gus and I have access to the same empirical data. (Gus hasn’t read the bus driver’s diary; he doesn’t know the bus driver any more intimately than I do; and so on.) And Gus doesn’t have some sort of psychic gift that would give him access to otherwise unknowable facts about the bus driver’s mind that would legitimize his explanation. Indeed, a belief that he has such a gift isn’t even among Gus’s many delusions. Nor does he have any good reason—even if, for argument’s sake, one allows his delusions and hallucinations to count as good reasons—to believe that he has such a gift. So given the entirety of the data at our disposal, Gus’s explanation is a bad one. The only evidence in favor of Gus’s theory is that the bus driver started smiling upon being given the money.
   But Gus is right. His explanation is correct down to the last detail.
   Given that it turned out to be correct, should we say that, despite first appearances, Gus’s explanation is not a bad one? No! It’s a datum that it’s bad. It’s a bad explanation that turned out to be correct. Thus, for an explanation to be a good one isn’t for it to be correct.
   But a short extension of our story illustrates the even stronger principle that for an explanation to be a good one isn’t even for it to be likely to be correct. Let W be the real world and let W* be a hypothetical world where we have the exact same experiences that we have in W, but in which the Gus’s of the world are always right. In W*, it’s because Santa Claus is personally delivering gifts to millions of people that they suddenly appear in living rooms round the globe; it isn’t because hard-working parents purchased them. In W*, your keys are missing because stealthy gnomes took them; it isn’t because you drunkenly threw them in the incinerator. And so on. In W*, the right explanations are the ones that, in our world, are extremely bad ones. The data on the basis of which those hypotheses are held in W* (so far as those hypotheses are held) is identical with the data on the basis of which they’re held here (same qualification). But in W*, they’re right, and the good explanations—the logical, sane, well-supported explanations—that they compete with are always wrong. So, in W*, good explanations aren’t even likely to lead to the truth. So there’s no inherent connection between an explanation’s being good and its being true: goodness (in the explanatory sense) cannot be identified with, or even understood in terms of, truth-conduciveness.
   Explanatory goodness is a relationship, not between explanations and reality, but between explanation and data. The relations that hold in W* between theory and data coincide with those holding in W. That’s why the ones that are wrong in W* are no less good on that account. What is it that, in W*, makes wrong explanations be good? In general, what is the relationship that good theories bear with respect to the data?
   First of all, “good” is a relative to term. An explanation is good relative to some body of data. No good explanation is inconsistent with the relevant data. And, of the various explanations consistent with a given body of data, the best one is the one that depends the least on unexplained explainers.
   Here’s an illustration. I put an opaque plate on a table. I thus can’t see the part of the table covered by the plate. “Given only this data,” says my sophist friend Smith, “it’s a theoretical possibility that the moment you put the plate on the table, there suddenly came into existence a hole in the table the exact size of the plate.” Supposing that you’re right, I ask Smith, why didn’t the plate fall through the table? “Because,” Smith responds “when that hole came into existence, a special force was created that kept the plate in exactly the place that it would have occupied if there were no hole.” Why, I ask in response, did that force come into existence? “I don’t know,” says Smith. “It just did.”
   Maybe this explanation is correct. We’ll never know for certain that it isn’t—at least not without presupposing the falsehood of various other, comparably ad hoc explanations.
   Be that as it may, it’s a bad explanation. Why is it bad? Because it leaves us with more questions than answers. Why did the hole appear? Why did it happen to have just the right shape and size? Is it because the plate has special chemical properties? If so, why is it that, the moment the plate is whisked away from the table, the effects of any chemical interaction between the two are undone? Supposing that these questions can be answered, why did some force suddenly step into the breach left by the momentarily absent table surface? Why was that force just right—just enough to keep the plate on the table, but not so much that the plate rose above the table or trembled or did anything else inconsistent with its being on an ordinary table? And supposing that we have an answer to that question, why was there no independent evidence of the existence of that force? Why was its only effect to keep the plate in that very location, for that exact amount of time? Supposing

that, for some reason or other, we have highly sensitive instruments of measurement underneath the table, why didn’t any of them detect anything?
   With every answer, a new hole arises. It may be that, for each hole that pops up, there is a way to plug it up that is not only consistent with the laws of logic but is also consistent with our other empirical beliefs. Or, if there arises a case where the hole cannot be plugged up without jettisoning some, or even all, of our remaining beliefs, maybe there is a way to revise those other beliefs in such a way that they remain consistent with the raw data and with the stopgap in question. It is generally said that a given body of data can be modeled by many different, mutually inconsistent hypotheses.
   But even if this is true, it doesn’t follow that, for each hypothesis that models a given body of data in a way that has a given degree of success in the way of eliminating unexplained explainers, there is a logically incompatible way of modeling the data that also has that degree of success in that respect.
4.2.1 Correct explanations can be bad explanations (continued)
A continuation of our plate story will make it clear what this means and why it is true. Why doesn’t the plate fall through the table? Because, says the conventional wisdom, the table didn’t vanish. But, the skeptic will retort, maybe we can jettison that explanation; maybe there’s an alternative to it that is equally compatible with the perceptual data.
   But, I would respond, supposing for argument’s sake that there is such an alternative, it doesn’t follow that it will create fewer holes to plug up than its predecessor did. It doesn’t follow that it’s comparable from a cost-benefit standpoint to the old one—that, in other words, it creates as few new mysteries as the old hypothesis while also eliminating as many existing ones.
   But not only does this not follow: the exact opposite holds. Consider the alternative explanation that we considered a moment ago (viz. when the plate is placed on the table, a hole opens up, etc.) The explanatory cost of that hypothesis (in other words, what it leaves us having to explain that we didn’t have to explain before) was a thousand times greater than its explanatory value (in other words, what no longer has to be explained that did have to be explained before).
   It would be very hard to produce an explanation that was incompatible with the conventional one and, while remaining consistent with the relevant data, was as inexpensive from an explanatory viewpoint as the conventional one. I invite you to verify this for yourself. If there is any reason to believe that there exists so much as a single such hypothesis, it isn’t that such a hypothesis has ever been produced or ever will be. That reason, if it exists, must be purely a priori. And, for reasons that will presently become clear, there can be no a priori reason to accept such a hypothesis.
4.2.2 Correct explanations can be bad explanations (continued)
But there is an even more immediate problem for this (or, by an analogous argument, any other non-standard) substitute for the conventional view that the table, even when obscured by the plate, continues to support it. It’s far from clear that, once all the relevant data is taken into account, that hypothesis is even logically possible. Let’s look at the statement:

(*) “when the plate is placed on the table, a hole that coincides with the under-surface of the plate opens up. But a force field is suddenly created that keeps the plate exactly where it would have been if, other things being equal, that hole hadn’t opened up.”

   Taken by itself, (*) describes a situation that could hold. That statement is a coherent one. It’s not in the same category as “squares are round.”
   But, while that’s obviously necessary for its being a logically feasible way of modeling the relevant data, it’s far from sufficient. Think of the various physical laws that must be broken for the table section underneath 

the plate to vanish. Violations of natural laws, were they possible, would not be innocuous; there would be ripple effects. Think of the forces that (so we believe) actually prevent that plate-sized chunk of table from vanishing. Think of the various equilibriums that would be altered if those forces were immediately suspended. Think of the various energy transfers that would be changed or destroyed if, all of a sudden, those forces were put out of commission.
   Those forces don’t only keep that chunk of table in place. Were they all to be suspended, there would be many consequences other than the disappearance of the requisite table chunk. In other words, there would be a lot of explanatory “collateral damage,” meaning that many events would occur other than the ones that, given that our objective is to validate (*), we want to occur. And there’s no guarantee that those other events would be consistent—even in the narrowest, most emptily logical sense—with the data that, supposedly, is modeled just as well by (*) as it is by the conventional explanation (viz. “the place doesn’t fall because the table chunk doesn’t disappear”) that it replaces.
4.2.3 Correct explanations can be bad explanations (continued) 
We might try to deal with this batch of problems by positing second-order suspensions of natural law. So in addition to suspending those laws involved in keeping the table chunk in place, we also suspend those laws that, given the first suspension, lead to the just-mentioned unwanted collateral events.
   The problem is that those second-order suspensions of law will be no more innocuous than their first-order counterparts. To counteract the unwanted effects of suspending the first set of forces, we have to suspend another set of forces. But just as the original forces did a lot more than keep the table intact, so these new forces will do a lot more than suspend the unwanted effects of suspending the first set of forces. And it’s obviously of no use to try to deal with this problem by bringing in a third set of forces.
   “You may be right,” it will be said, “that if we hold onto our existing beliefs about physical law, then the disappearance of the table chunk would have all of this unwanted fall-out. But surely we could adjust those beliefs in such a way as to prevent this. Whatever those beliefs are, just get rid of them and replace them with ones that don’t lead to all of this unwanted fall-out.”
   The very fact that this move must be made only proves my point, namely, that (*) is not consistent with what we know. In fact, it proves a stronger point, namely: (*) isn’t consistent with any body of beliefs at all like the ones we now have.
   The objector is saying, rightly, that there is no way to square (*) with our existing beliefs—that it is only what we believe minus many of our beliefs about natural law that can be so squared. But when our beliefs about natural law are subtracted, so to speak, from the totality of our beliefs, the resulting body of beliefs bears very little resemblance to our current beliefs. Our beliefs about natural law are not in all cases neatly separable from our beliefs about specific matters of fact; and if we were to strip away enough of the former to compatibilize (*) with our belief system, we’d be biting off a lot more than we bargained for. This is because various beliefs about natural law are embedded in the concepts associated with expressions that, in order to say what’s on our minds, we must use every day (e.g., “microscope,” “telephone,” “radio,” “solar panel,” “cell phone,” “thermometer,” “thermostat”). Theory-laden though they are, we need those terms to describe facts of everyday, pre-theoretic experience. We therefore need them to state the pre-theoretic data that our theories are to model.
   “But,” it will be said, “anything that can be described only by taking for granted some theoretical belief is ipso facto not a datum. A truth? Maybe. A datum? No.”
   That may well be true. But, if so, our belief-system is so overrun with theoretical beliefs that no belief system free of such beliefs would bear even the slightest resemblance to it. Also, it is incoherent to suppose that there could exist a belief-system that wasn’t replete with theoretical content. The difference between a mere belief, on the one hand, and a belief-system, on the other, is that belief-systems are intended to be explanatory, whereas mere beliefs needn’t have this property. I believe that it’s raining because I see that it’s raining—not because, in an effort to model various observational data, I at some point hypothesized that it was raining. But psychoanalytic theory constitutes a belief-system, as opposed to a mere belief, because it is intended to be

explanatory. This suggests (though it doesn’t establish) that “belief-system” and “theory” are veritable synonyms. (Why the parenthetical hedge? “Because there are belief-systems that aren’t of a theoretical nature. Religious belief-systems aren’t theories.” But even this is arguable. Some would say, and I agree with them, that religious systems are proto-theories or para-theories—structures that make heavy allowances to emotional factors and make insufficient allowances to considerations of logic and evidence, but are, within these parameters, as theory-like as they could possibly be.) If, indeed, belief-systems are ipso facto theories, it makes no sense to speak of what our “belief-system” would be like if it were stripped of theoretical content. Long story short: although it’s obvious that, on its own, (*) is perfectly coherent, it’s far from obvious that (*) is compatible with our belief system as a whole or with any belief system that isn’t radically different from it. This was the very point we set out to establish. It goes without saying that what is true of (*) holds mutatis mutandis of each of many other “deviant” hypotheses.
   But even if, for some reason, this last point is denied, there is no way to deny our main point, to wit: even if (*) is logically consistent with our belief system, or at least with some not-too-mutilated version of it, the explanatory benefits of countenancing (*) in favor of the conventional explanation are grossly outweighed by the explanatory costs.
4.3 Synthesizing these points
It will help if, before moving forward, we take a moment to synthesize the points thus far made. There’s no difference between committing the Gambler’s fallacy and performing an induction by enumeration. At the same time, knowledge of invariable concomitances is obviously an extremely valuable source of knowledge. But it isn’t, or in any case shouldn’t be, through enumerative induction that one transitions from (1) “all phi’s that I’ve known of were psi’s” to (2) “the next phi I come across will be a psi.” (In this context, it is to be assumed that that “x is a phi” doesn’t analytically entail “x is a psi.”)
   The actual bridge between (1) and (2), supposing that there is one, lies in the fact that, given (1), it is reasonable to believe there to be some mechanism or natural law that requires (or at least disposes) phi’s to be psi’s. By itself, (1*) “all metal known to me has expanded when heated” provides no good reason to accept (2*) “all metal expands when heated.” (1*) provides a good reason for accepting (2) only to the extent that (1*) provides a good reason for accepting (3*) “there is a lawful connection between a thing’s being made of metal, on the one hand, and it’s expanding when being heated, on the other.”
4.3.1 Synthesizing these points (continued)
Before we continue, it’s crucial to note that none of this begs any questions against Hume. Hume is saying: “given only that every metal object that Smith has known of has expanded when heated, it doesn’t follow that metal that Smith has yet to encounter will (or is even likely to) expand when heated.” We agree. Smith is guilty of the gambler’s fallacy so far as he thinks otherwise. All we’re saying is this: Smith’s experience thus far suggests that “x’s being heated metal provides some kind of nomic basis for x’s expanding” has held for objects falling within the scope of Smith’s experience.
   We’re not making the claim Smith’s experience entails that some such connection has held. Such a claim would simply be false. And we’re not making the claim that Smith’s past experience gives him a good reason to think that metal objects not (yet) known to him will be more likely to expand or even that they’ll be more likely than not to expand. Such a claim would beg the question against Hume. Finally, we’re not making the claim that Smith’s past experience gives him a good reason to think that there continues to exist any nomic connection between a thing’s being heated metal and its expanding. Echoing what we just said, such a claim would beg the question against Hume: for Hume’s very point is that a thing’s happening in the past is no guarantee of its continuing to happening the future. And we cannot, without begging the question against Hume, assert that a law’s having held in the past is evidence of its holding in the future. 
   
So what are we saying? Only that Smith’s experience gives him a reason to believe that such a connection has held, at least as far as metal objects falling within the scope of experience are concerned. And in making this obviously plausible claim, no questions have been begged against Hume.
4.3.2 Synthesizing these points (continued)
I propose that, armed only with this non-question-begging point along with the tautology that it is the purpose of explanations to eliminate unexplained explainers, we can show that Smith has reason to expect future metal objects to expand when heated.
   We’ve agreed that Smith’s experience does give him some reason to think that, at least as far as objects thus far known to him are concerned, a thing’s being metal provides some kind of causal or nomic basis for its expanding when heated. Let P be this causal principle. P is of doubly limited scope. It applies only to past objects and it applies only to past objects that Smith knows of. Let’s suppose that Smith accepts P.
   Smith has two options. (I am not counting a refusal draw any inferences as an option.) (i) Hold that provides no reason to believe that, outside Smith’s past, personal experience, a thing’s being a metal provides a basis of some kind for its expanding when heated. (ii) Hold that P does warrant some such generalization. One such generalization is: “that connection holds for all past objects, whether Smith knows of them or not; but it doesn’t hold of future objects.” Another is: “that connection holds for objects that Smith will know of, but not for those that he won’t know of.” But, of course, the most natural, not to say the most rational, generalization is this: 
   
   (P*) “That connection holds generally. It holds no less for objects not known by Smith than for those known by him, no less for future objects than for past.” 
   
   Let’s suppose that Smith chooses not to accept P* or any other generalization of P. How, in that case, would the world have to be for Smith’s belief system to hold? Metal objects that Smith became aware of would suddenly undergo a profound change: they would go from being things that, when heated, didn’t expand to being ones that did. And for this change to occur, each atom of every metal object known to Smith would have to change in fundamental ways. Given an acceptance of P, it may seem conservative not to accept any generalization of P. But it’s the very opposite. If you accept but reject any generalization thereof, you’re saying that objects miraculously undergo profound microstructural changes whenever you know of them and undergo equally profound changes when you stop being aware of them. And that hypothesis is not a conservative one.
   And, quite clearly, it’s a bad one. Why is it bad? Because it creates more unexplained explainers than it eliminates—because it creates more questions than it answers.
4.3.3 Synthesizing these points (continued)
Of course, not accepting a hypothesis isn’t the same as rejecting it. Not accepting some generalization of P isn’t the same as rejecting it. And it’s obviously a good idea in many cases to hedge—to wait for evidence. But that’s irrelevant. The question is: given that there is enough information to warrant an acceptance of P, is there enough information to warrant acceptance of any generalization of P? If we answer by saying “no,” then we’re saying that, given only the evidence at our disposal, it’s no less likely than not that objects systematically undergo massive changes at the atomic level whenever they come or cease to be known by Smith. And that position, as we saw, creates more mysteries than it eliminates. So despite first appearances, there’s nothing conservative about refusing to countenance any generalization of P. And such refusal embodies acceptance of a principle that is straightforwardly, because tautologously, false, namely: “there’s no reason to prefer explanations that explain a lot and create little that has to be explained to those that explain a little and create a lot to be explained.” 

4.3.4 Synthesizing these points (continued)
These points are easily generalized. It’s no less absurd to suppose that, in the last nanosecond, all metal objects have undergone profound microstructural changes than it is to suppose that all metal objects known by Smith are microstructurally very different from those not known by him. This point provides the non-circular justification for UP that Hume sought but couldn’t find.
   Let’s suppose that Smith has reason to believe (i) that, where metal objects that he has known of are concerned, a thing’s being heated provides some kind of basis for its expanding. Let’s also suppose that Smith holds (ii) that this principle won’t hold for metal objects that he will encounter (i.e., for metal objects that he hasn’t encountered but will and for those that he has already encountered and will encounter again). In holding (ii), he is ipso facto supposing that the laws of nature will abruptly change. And in positing this one change, he is positing innumerably many others, as we will now see.
   A metal object’s being heated involves innumerable microstructural changes, and so does its expanding. The macroscopic supervenes on the microscopic. Given two objects that are microstructurally alike—that consist of the same particles interrelated in the same way—there is no possibility, even a purely logical one, that those two objects should differ at the macroscopic level. By the same token, given two objects that differ at the macroscopic level, there is no possibility, even a purely logical one, that those two objects should fail to be microstructurally different. A metal object’s being heated thus consists in its undergoing many microstructural changes, and so does its expanding. And if a metal object’s being heated causes it to expand, it is in virtue of the fact that the first set of microstructural disturbances result in, or are themselves constitutive of, the second set.
   So given a law—even one that was confined to objects that Smith has encountered—to the effect that metal expands when heated, in order for that law to be annulled, each of innumerably many microparticles would suddenly have to undergo quite dramatic changes. So in assuming that, all of a sudden, a law that once held ceases to do so—or, what is the same thing, in assuming that the future, starting now, is governed by different laws from the past—one is positing not one change, but innumerably many. For, in making that assumption, one is (implicitly) supposing that each of the innumerably many microparticles will, all of a sudden, stop being governed by one set of laws and will start being governed by another. And one is thus creating what, for practical purposes, might as well be infinitely many unexplained explainers.
   But not a single one of these unexplained explainers is created by the hypothesis that metal objects that we will encounter are governed by the same laws as those we have encountered. So given the truism that one explanation is better than another if, other things being equal, the first creates fewer unexplained explainers than the second, it follows that the rational move, at least until further evidence comes in, is to suppose that those microparticles will continue to be governed by the same laws that used to govern them.
   According to what is now the conventional wisdom, which coincides with the viewpoint that Hume bequeathed to us, the conservative move is the agnostic one: stick to the evidence; generalize as little as possible; don’t assume that what you don’t know resembles what you do know. But the so-called conservative view is really less conservative than the alternative. (The alternative is: “assume that what you don’t know does resemble what you do know.”) The so-called conservative view posits giant schisms in the natural order and, therewith, masses of unexplained explainers. The alternative view does not.
5.0 Closing the argument
We can now succinctly say why Hume’s argument fails.
   Step 1: It’s an analytic truth that ceteris paribus the better explanation is the one that creates fewer unexplained explainers. Let’s refer to this principle as “MC” (short for “minimization of causal anomalies”). Whereas UP, if it can be known at all, can be known only on inductive grounds, MC is analytic and, unlike UP, is therefore not to be known on empirical or, consequently, inductive grounds. Thus, MC, unlike UP, can be noncircularly assumed in the context of a defense of inductive inference. 
   
Step 2: It’s a datum that various concomitances are to be found among the objects known to one. It’s a datum that, so far as the object’s known to (say) Smith are concerned, putting a hand in boiling water causes intense pain, whereas putting that same hand in cool water causes intense relief.
   Step 3: One creates more unexplained explainers by assuming that the unknown differs from the known than by assuming that it does not.
   Step 4: If one remains agnostic—if one refuses to say, one way or the other, whether the unknown resembles the known—one is committed to the incoherent position that there’s no reason to prefer a hypothesis that creates few unexplained explainers to an otherwise comparable one that creates many. (The reason this view is incoherent is that for one explanation to be preferable to another just is for it to do more in the way of explaining, and thus less in the way of creating unexplained explainers, than the other.)
   Step 5: Given MC, and given Steps 1–4, it follows that there is an analytic and therefore non-inductive reason to hold that, other things being equal, the unknown resembles the known.
   Conclusion: Hume is wrong; Hume’s argument fails. This is a direct consequence of Step 5. Given the legitimacy of MC, it’s obvious why, though it may initially appear cautious and conservative, skepticism about the external world is actually an extravagant and irrational position. One’s sensory experience is replete with discontinuities. Every time you open your eyes or turn your head, you are flooded with sensory experiences that are totally unlike those that you were experiencing a moment earlier. According to the non-skeptic, these new experiences don’t come into existence ex nihilo; they are merely links in chains of events whose other links you don’t perceive. The skeptic says that it’s no more rational to believe this about our sensory experiences than it is to believe that those experiences come into existence ex nihilo. In saying this, the skeptic is saying, in effect, that it’s just as rational to accept a theory that creates more anomalies than it gets rid of than it is to accept an otherwise comparable theory that gets rid of more anomalies than it creates. Since it’s an analytic truth that, given two otherwise comparable theories, the one that leaves us with fewer anomalies is the one that ought to be preferred, it follows that the skeptic’s position is analytically false. Of course, it isn’t analytic that our sensory experiences are correct. But it is analytic that it’s rational to suppose our sensory experiences veridical to the extent that doing so leaves us with fewer causal anomalies than we’re otherwise left with. The skeptic’s denial of this embodies an analytically false conception of explanation.

Chapter 13
Empiricism and Its Limits
1.0 Empiricism vs. rationalism
We obviously acquire a great deal of knowledge through “sense-perception” (i.e., through sight, hearing, touch, and so forth). According to a doctrine known as “empiricism,” all knowledge is derived from sense-perception.
   According to a view known as “rationalism,” some knowledge is acquired entirely through the use of one’s ability to reason.
   Rationalists almost never hold that no knowledge is acquired through sense-perception. They hold only that reason, as opposed to sense-perception, is the vehicle through which some knowledge is acquired.
   Rationalists typically hold that knowledge acquired in this way is very important—it isn’t trivial.
   Some hold the view that there is knowledge that is acquired neither through the senses nor through reason. I don’t wish to dismiss this view. Maybe it’s correct. But there is an apparent problem with it. Any case of knowledge is a case of justified true belief. Given a belief that isn’t acquired through the senses or through reasoning, the question arises: what could possibly justify it? And there’s no obvious answer.
   In any case, in this chapter, it will be assumed, if only to simplify exposition, that the only viable sources of knowledge are reason and the senses and, therefore, that the only viable options for epistemologists are rationalism and empiricism. But I wish to stress that I am genuinely open on the question of whether there is non-perceptual, non-rational knowledge. (I’m inclined to think that there is.)
   Those who believe that there exist non-spatiotemporal entities are necessarily rationalists. Give or take a few nuances, empiricism is the view that you don’t know it if you don’t see it. We see property-instances, but not properties themselves. Therefore, empiricists either deny the existence of properties themselves or they hold that properties are identical spatiotemporal entities. Those who take the latter view are forced to view properties as being composed of their own instances; so the property of being wet is identical with some object composed of all wet things, or some such. Therefore, empiricists don’t believe in uninstantiated properties. Therefore, anyone who does believe in such properties, or who believes that properties are not spatiotemporal entities, is a rationalist.
   Those who believe that properties are non-spatiotemporal are Platonists. Therefore Platonists are rationalists. A Platonic metaphysics requires a rationalist epistemology. Plato himself accepted a very extreme form of rationalism.
   Being one that has deep roots in common sense, empiricism is a very old doctrine. But empiricism was first rigorously developed by John Locke (1632–1704), George Berkeley (1685–1753), and David Hume (1711–1776). The doctrines put forth by these authors form the basis of modern philosophy. Hume’s beliefs about causality and inductive inference are outgrowths of his empiricism. These views are thoroughly examined in Chapters 12 and 17.
   Berkeley’s belief that objects are identical with our perceptions of them is an outgrowth of his empiricism. Berkeley’s ingenious arguments for this outrageous doctrine are examined later in this chapter.
   John Locke’s plausible position that universals are “the workmanship of the understanding”—that we create them, so as to make sense of the world—is a derivative of his empiricism. That doctrine is examined in the present chapter. (It is also examined in Chapter 2.)
   The first great rationalist was Plato (428 B.C.–348 B.C.). (Plato’s views are defended in Chapter 2.) Other rationalists are: Augustine (354–430), Descartes (1596–1650), Leibniz (1646–1716), and Gottlob Frege (1848–1925).
   
The first great empiricist was Aristotle (384 B.C.–322 B.C.), whose views, along with Plato’s, are also considered in Chapter 2. Other empiricists are J.S. Mill (1806–1873), Rudolph Carnap (1891–1970), and W.V.O. Quine (1908–2000).
   In this chapter, we will find that empiricism is not in its strictest form a defensible doctrine and that, consequently, at least some knowledge has a non-perceptual basis.
   There are, as we will see, two important corollaries. First, many commonsense-based views about the internal (psychological) and external (physical) worlds must be jettisoned. Second, sober scientific methodology actually demands an acceptance of principles that would strike common sense as decidedly unscientific. We will see that many concepts that cannot be adequately understood along strictly empiricist lines can nonetheless be correctly understood only interms of what empiricism has to say about them.
2.0 The particularist nature of sense-perception and the need for universals
Sense-perception discloses only particulars to us—particular objects having particular property-instances. But we understand and describe the world in terms of categories or, as they are sometimes called, “universals.” These can be thought of as natures, essences, or “ways of being,” that, although exemplified by the particulars that we encounter in sense-perception, are not themselves to be sense-perceived, and, though they presumably exist, do not exist in space-time.
   Because they are non-spatiotemporal, those of an empiricist mindset regard universals with extreme suspicion. In fact, empiricism is, nearly enough, the denial that such things exist. Why? The empiricists say: what we can legitimately believe is what we can sense-perceive or know on the basis of extremely conservative inferences on the basis of what we can sense-perceive.
   The problem is that there is no way to understand the world except in terms of universals. To understand things is to know how, in virtue of having such and such characteristics (i.e., in virtue of falling under such and such universals), they are subject to thus and such principles or laws. “Why did Max steal the money? Because Max is greedy and amoral and he believed it to be to his strategic advantage to steal the money.” Max’s behavior is explained by showing how, given the operative conditions, his having those characteristics makes it inevitable that he will act in that way. This explanation presupposes the existence of many different universals. (Among them are those denoted by the terms “greed,” “amorality,” “money,” and “theft.”) This explanation is not unique in this respect: all explanations presuppose the existence of universals. The very idea of an explanation that didn’t do so is an incoherent one.
   Universals are outside of space-time. For this reason, they cannot have effects on anything. (Causal relations hold only among spatiotemporal entities.) One cannot sense-perceive an object without being affected by it. (It is only because your ocular surfaces are disturbed by light-rays bouncing off of the page in front of you that you can see it.) It follows that universals cannot be sense-perceived. It also follows that no evidence of them can be sense-perceived. This is because x is evidence of y only if x and y are causally interconnected in such a way that, given x’s existence, y’s may reasonably be assumed. (Smoke is evidence of fire because smoke and fire are causally connected in such a way that, given the presence of smoke, the presence of fire may be inferred.) It is therefore impossible as a matter of logic to find any observational basis for the existence of universals. This means that, if empiricism is correct, we cannot possibly have any good reason to posit the existence of universals. Given how endemic universals are to thought, language, and explanation, the right move is to reject empiricism.
2.1 The empiricist response to these problems
Empiricists have responded by saying that, although instances of universals obviously exist, universals per se do not. (Remember that, in this context, “universal” is synonymous with “property.”) 
   The problem with this view is that, as previously noted, every sentence and every thought demands the existence of at least one universal.
   
Also, some basic logic shows that universals exist. Consider the following inference: “Bob and Ted are both human; therefore, there is some characteristic that they have in common.” That is a valid inference; and the conclusion affirms the existence of a universal. (“Characteristic” is synonymous with “universal.”)
   Finally, many statements straightforwardly presuppose or affirm the existence of universals; and were it not for statements of this kind, many obvious truths couldn’t be expressed. Consider the following statements:
   
(i) Hitler and Stalin had a lot in common;
(ii) Smith has what it takes to be a great pianist, but he doesn’t have what it takes to be a great composer;
(iii) Even though Smith is different from Jones, that has nothing to do with the fact that they don’t like each other.

The meanings of these sentences are, respectively:

(i*)   There are many properties such that, given any one of them, Hitler had it and so did Stalin;
(ii*)  There are properties such that, if one has them, one is a great pianist and such that, moreover, Smith has them; and there are properties such that, if one lacks them, one isn’t a great composer and such that, moreover, Smith lacks them;
(iii*)  There are properties such that Smith has them and Jones does not, but this fact isn’t responsible 
 for the fact that they don’t like each other.

   (i)–(iii) cannot be translated into statements that don’t presuppose or affirm the existence of properties. So it isn’t really an option to hold that properties don’t exist.
   As soon as one grants that anything resembles anything, one must grant that universals exist independently of thought. For two objects to be similar in some respect is for there to exist some property that they both have. For two objects to have the same shape is for there to exist some morphological property such that each object is an instance of that property. It’s obviously possible for two objects to have the same shape in a world devoid of sentient beings. Therefore, there exist properties in worlds where there are no sentient beings. Therefore, properties aren’t created by such beings and aren’t otherwise dependent on them.
   Properties are identical with categories. For x to fall into a given category is for x to have a given property. (For x to fall into the category of round things is for x to have the property of being round.) Given that properties exist independently of thought, the same is true of categories. Thus, contrary to what some empiricists (e.g., Locke) say, categories are not devices that human beings created in order to expedite thought.
   It is easy to find independent corroboration for this view. Let each of x and y be a pint of pure, clean glacial water, and let z be a pint of gasoline. The chef or chemist or auto mechanic who chooses to co-categorize x and z, as opposed to x and y, is in for some very unpleasant surprises. Why? Because his categories don’t cut “nature at the joints,” to use Francis Bacon’s expression. In other words, there is some relevant property that x and y have in common that x and z don’t have in common, and this person’s system of categories embodies an ignorance of that fact.
3.0 Non-perceptual knowledge a prerequisite for perceptual knowledge
It’s not as though tables, rocks, trees, etc., create little images of themselves that they deposit in our hitherto empty crania. Our minds have to supply the “paint,” so to speak, with which our mental representations of those objects are painted.
   In fact, our minds must supply everything. External objects don’t supply our minds with anything. All they do is tell our minds when to deploy what is already in them. External objects don’t stock our minds; they activate what’s already in them. A rock will never experience an image. It doesn’t matter how many light beams you fire at it. There’s nothing in it to be brought forth; there are, so to speak, no images in there to begin with. For similar reasons, the acoustical disturbances that, in a human, would lead to knowledge of English or of

philosophical principles will have no comparable effect on a rock. Thoughts are taught by being elicited, not by being deposited. This is the most fundamental problem with empiricism.
   A precondition for sense-perceiving anything is that we be able to represent it as having a location (relative to us) in space and time, that we be able to represent it as having a certain shape, state of motion, color, etc. Although we learn a great deal through perception, what we don’t learn through it are the concepts—space, time, motion, shape, color, etc.—out of which sense-perceptions are constructed. So those things, and all that having them involves, must be in the mind prior to sense-perception, as a necessary precondition for it.
   These considerations expose what I believe to be the deepest confusion of which empiricism is guilty. Empiricists fail to distinguish between two very different roles that sense-perceptions can have: they can have a triggering role and they can also have an information-transmitting role.
3.1 Sense-perception as transmitter of information about the external world
You see a dog. On that basis you have the belief that there is a nearby dog. Here your eyes transmitted information to you about the external world. They “told” you, so to speak, that there was a dog in a certain place. Your could not possibly have learned this fact through pure logic-chopping or conceptual analysis. You could learn it only through the senses (either by seeing the dog or by sense-perceiving some other sort of evidence of the dog). In this context, then, information about the external world is being transmitted to you through your senses. Your senses (specifically, your sense of sight) is thus functioning in what we might call an “information transmitting” capacity.
3.2 Sense-perception as trigger
Sense-perceptions have a triggering role when they provide the recepient with new information not by telling him something about the external world, but by activating or “triggering” some already existing cognitive faculty.
   You are in a geometry class. The teacher draws something that is supposed to represent a triangle but only vaguely looks like one. He draws various lines through it, around it, etc. And from these diagrams you learn various facts about triangles.
   What did you actually see? What did your eyes show you? A triangle? No—only a few uneven lines that formed something that vaguely looked like a triangle. How did your seeing this non-triangle get you to know that, for example, the area of a triangle is 1/2 base times height? Since you didn’t see any triangles, you didn’t see any triangles’ height, base, or area. The things you saw were symbols for things that had to be supplied to you by something other than your senses—that had to be supplied to you by your intellect.
   This is not to say that the diagram was useless. Plainly it was not. It may be that, but for seeing it, you wouldn’t have learned anything about triangles. But your seeing the diagram led to your knowing those truths about triangles not because any triangle, or any fact about triangles, was any part of the information imparted to you by your perception, but rather by triggering or activating certain conceptual faculties of yours. In this context, your senses are (to the extent that you are learning actual geometrical truths as opposed to mathematically irrelevant facts about the blackboard, chalk-marks, etc.) providing you with knowledge by getting you to acquire knowledge in some non-sensory way, viz. by getting you to grasp, and analyze relations among, concepts.
   The proof that your visual perception of the diagram had only a triggering role, and that it did not itself contain any information relating to what you learned, is that, if you were to forget ever having seen that diagram—were to forget what it looked like, who drew it, where you saw, or even that you saw it—it would

have no effect on the geometrical truths that you learned that day. The reason is that those geometrical truths (e.g., area of a triangles = bh/2) were simply not part of the content of what your senses were telling you.
   By contrast, if you forget ever seeing the dog (described in the last section), you will forget the information that, on that occasion, your senses led you to have. The reason is that, in that context, your senses weren’t serving the purpose of jogging your ability to acquire knowledge in some non-sensory way (viz. through rational insight) but were themselves the bearers of the information learned.
3.3 An anti-empiricist consequence of the distinction between triggering and information transmitting
According to strict empiricists, everything that is learned, including purely logical principles, is learned through sense-perception. When this appears to happen, it’s because sense-perception is simply “turning on” some non-sensory mode of knowledge acquisition. “Truths of reason,” as Hume called them, aren’t learned through sense-perception, even though sense-perception may awaken the non-sensory faculty through which we do become aware of them.
Some empiricists are aware of this objection, and they generally deal with it by saying one of two things:

(1) Truths of reason really are truths about the irregular figures on blackboards, that truths of arithmetic realyl are truths about what happens when apples are put on top of other apples, etc.

(2) The so-called “truths of reason” are just linguistic or typographical conventions. “1+1=2” is an empty, purely definitional truth. “2” is defined as “1 + 1,” and “3” is defined as “1 + 2.” Every other fact about mathematics can be reduced to definitions, linguistic conventions; and all of mathematics turns out to be typographical. (As a matter of typography, you can replace “1 + 1” with “2,” just as you can replace “five” with “5.”) And all the so-called “truths of reason” that lie outside of mathematics are thought to be explained in the same way.
3.3.1 Why (1) is wrong
Your knowledge that 113 + 876 = 989 isn’t empirical; you didn’t see 113 pears being counted, then see 876 pineapples being counted, and then see the whole lot be counted. (And even if you did have such an experience in connection with those particular numbers, there are many other pairs of numbers whose sums—not to mention quotients, products, differences, etc.—you know, or could readily figure out, but in connection with which you’ve never seen anything like the situation just described.) Your knowledge of arithmetical truths is based on a grasp of non-empirical principles. Even if (what I think is necessarily false) you learned that 1 + 1 = 2 from watching one thing be put on top of another, you still would not, on that basis alone, have any way of generalizing that knowledge—of inferring the other mathematical truths you know. To make the needed inferences, you’d need access to rules of inference that you couldn’t possibly know about if your knowledge were strictly sense-based.
   Another reason why (1) is wrong: Even one’s knowledge that 1 + 1 = 2 isn’t known empirically. As David Hume made clear, observation tells you how things are, not how they should be. It reveals facts, not norms. But one’s knowledge that 1 + 1 = 2 has normative force. If two people enter what you thought was an empty house, and three people leave, you don’t reconsider your belief that 1 + 1 = 2. You take that belief as fixed and, in light of it, reconsider your belief that the house was in fact empty. If it turned out that, according to a certain scale, rocks R and R* had a collective weight of more than 2 pounds, even though you previously thought that each weight no more than 1 pound, you’d take your belief that 1 + 1 = 2 as fixed, and would revise some other belief of yours (e.g., your views concerning the rocks’ individual weights or the accuracy of the scale or possibly even the laws of physics). We interpret observations in light of the principle that 1 + 1 = 2, not vice versa.

3.3.2 Why (2) is wrong
Conventions are indeed arbitrary. But whether the conventions one adopts are consistent with one another is not itself a matter of convention. It’s a matter of convention that “1” denotes 1, that “+” denotes addition, and it may even be strictly a matter of convention (though I think not: see below) that “2” refers to the same number as “1 + 1.” But once these conventions have been laid down—once convention has fixed what “1,” “+,” “=,” “3,” etc. mean—various facts that are not among those conventions follow. For example, given our convention of referring to “1” as 1, to “+,” as plus, etc. it follows that there is no pair of whole numbers p and q such that (p/q) = 2 (in other words, 2 has no rational square root). But it’s not a matter of convention that “2 has no rational square root” is true. It is a non-conventional consequence of our conventions. (Nor—to make a different point—is it a matter of convention that what is meant by that sentence is true. The fact that 2 has no rational square root isn’t a consequence of our conventions; it has nothing to do with conventions, as we’ll discuss in a moment.) So even though our conventions don’t directly say anything about the permissibility of the following sentence—”there is a pair of whole numbers p/q such that (p/q)2”—those conventions prohibit us from adding that sentence to those same conventions. Were we to do so, our conventions would be inconsistent. In general, not all truths of reason (or any, actually, as well now see) can be conventionalized, since consistency among conventions is not itself a matter of convention.
3.3.3 Another reason why (2) is wrong
Also, we have to distinguish sentences from the things they express. For argument’s sake, suppose that “2” is defined as “1 + 1,” and suppose that “=” is defined in the normal way. In that case, the sentence “1 + 1 = 2” will indeed be a matter of definition. But that leaves it completely open which truth that sentence expresses. For suppose that, as a matter of convention, “1” referred to 8, and “1 + 1” referred to “7 + 1.” Or suppose that as a matter of convention, “1 + 1” referred to Superman and “2” also referred to Superman. In each of those cases, the sentence “1 + 1 = 2” would be true by convention, but each would express a truth very different from the one actually expressed by “1 + 1 = 2.” The truth actually expressed by that sentence concerns the number one—not Superman, not the number eight—and it says of it that, when added to itself, the result is two—not Superman, not eight.
   Could “1 + 1 = 2” express that very truth—the one just described—and be false? No. If a sentence affirms that one and one make two, then—because of facts about one and two and addition and equality—it’s going to be true. So what makes “1 + 1 = 2” true isn’t convention, and is instead non-conventional facts about numbers. To be sure, conventions are involved: it is a matter of convention that “1” refers to one, “+” refers to addition, etc. And it follows from those conventions that “1 + 1 = 2” says that one, added to itself, yields two. But it’s a matter of mathematical, non-conventional fact that one plus one equals two.
4.0 Why pre-perceptual and, therefore, non-empirical knowledge is a prerequisite for empirical knowledge
Innate cognitive structures are needed to have sense-perceptions and also to learn from them. Having a sense-perception means having a certain kind of mental representation of an object. Not all mental representations of objects are sense-perceptions. Mental images aren’t, even though they resemble them. Concepts aren’t, and they don’t resemble them. It’s a delicate matter exactly what kinds of representations are perceptual: a necessary condition, certainly, is that they be caused by their objects—your perception of Smith must be caused by Smith (by light bouncing off of him). It also seems necessary that (with certain qualifications) your perception “co-vary,” or be capable of co-varying, in real time with the thing perceived. If you’re looking at Smith, and he moves, you see him move (provided certain conditions are met; e.g., the movement isn’t infinitesimally small). It’s unclear whether there are other conditions that have to be met. (There probably are.)
   
In any case, perceptions are mental representations. And they represent their objects in four dimensions, and as having various chromatic (color-related), kinematic (movement-related), dynamic (force-related, causal) properties. Unless we take the implausible view that no intelligence is involved in the processes mediating between the somatic disturbances that lead to sense-perceptions, on the one hand, and those sense-perceptions themselves, on the other, none of this would be possible unless your mind, at some level, had some kind of pre-perceptual understanding of what it is for two things to be spatially, dynamically, etc., interrelated. So, in all likelihood, sense-perception presupposes knowledge.
4.1 Why non-empirical knowledge is a prerequisite for post-perceptual, inferential knowledge
We couldn’t do very much with the information that sense-perception gave us unless we had non-empirical knowledge. First of all, your senses operate in the present. You are not seeing, touching, etc., whatever you’re not now seeing, touching, etc. At most, you are remembering it. In order to apply what you remember to a current situation, you must see how what you remember bears on your current situation. Let’s take an example that, because it concerns such a pedestrian inference, shows how great the scope of this point is. You remember seeing somebody turn the key in their car and then driving away. You are now in front of a car with a key in it, and you want to drive it. Obviously you can apply what you remember to this situation. Let us suppose that you do so. So you think: “on that occasion, turning the key started the car; so the same thing will happen on this occasion. So, given that I want to start the car, I’ll turn the key.” Sense-perception (plus memory) has shown you that on the first occasion a certain car started after the key in it was turned. And, supposing that you turn the key in this car (the one in front of you), sense-perception will show you that another car started after the key in it was turned. But sense-perception did not show you, and could not possibly have shown you, that there was a relationship between these two situations; it could not show you that, because the car in the first situation started after the key was turned, the same would be true of the car in the second. Your senses apprise you of situations; they thus give you intra situational information. They don’t give you inter situational information. You can’t see or otherwise sense-perceive relations between situations—between an event you saw a week ago and one you’re seeing right now. Thus, any knowledge that you have intersituational relations is partly (though obviously not entirely) non-empirical. Therefore any knowledge of dependence-relations holding between distinct situations is, at least in part, not strictly sense-based. Since it is only by virtue of knowing of such relations that one can know anything other than what one’s senses are currently telling one, one can know extremely little if all knowledge is sense-based, and what one can know, one can know only for a fleeting instant.
4.1.2 Why non-empirical knowledge is a prerequisite for post-perceptual, inferential knowledge (continued)
Hume said that there is no legitimate inference from “that car (the one I saw two days ago) started when the key was turned” to “this car (the one I’m looking at now) will start if the key is turned” and, in general, that there is no legitimate inference from any proposition concerning the past to any proposition concerning the present or future. Hume acknowledges, of course, that past experience makes people form certain beliefs.2 But his point is precisely that those beliefs, lacking as they do any legitimate basis, are not knowledge; they’re just compulsions (albeit ones that, as he grants, have thus far served us well for the most part).
   Although I believe that knowledge of the past does warrant beliefs about the present and future, there is an important truth in what Hume is saying. Hume has made it clear that f i one permits oneself to use only such knowledge as one has acquired through the use of one’s senses, then one can’t infer anything about anything from anything. Inferences are about bearing relations. (More precisely, if one legitimately infers Q from P, then (i) P supports Q, (ii) one knows that P supports Q, and (iii) one’s acceptance of Q, given P, is driven by one’s knowledge that P supports Q.) If something about situation X is inferred from something about situation 

Y, that inference, if legitimate, must accord with some principle that is concerned with relations holding between distinct situations. And such relations, obviously, cannot, at least not as a rule, be sense-perceived. To sum up, all knowledge that isn’t strictly sense-based—and this means all knowledge that involves any element of inference and, therefore, all theoretical knowledge (all theoretical knowledge is inferential, but not vice versa)—one must have knowledge of intersituational dependencies; and, since they can’t be sense-perceived, one’s knowledge of these dependences cannot be strictly sense-based.
5.0 The biggest problem with empiricism: not all thoughts are pictorial
What does perception give you? Images. (Not just visual images, of course, but also acoustical images, tactile images, etc.) If empiricism is right, this means that any thought that is not itself an image, or that contains information that cannot be encoded into an image, is unwarranted. But most thoughts, if not all of them, contain just such information. In other words, most thoughts, if not all of them, contain non-iconic information. For example, there is no image such that, in virtue of experiencing that image, one is thinking:

(S) if Smith had fallen off the fence, he would have broken his leg.

What sort of image would represent S? Obviously you could have an image of Smith falling from a fence, and you can have an image of Smith breaking his leg. But S is to the effect that Smith’s falling would involve his breaking his leg; it affirms the existence of a certain dependence relationship. And nothing could be an image of such a relationship. There can be images of rocks, trees, explosions, fallings, and waterfalls—but not of dependence relationships.
5.1 No iconic representation of dependence relations
Of course, you could create a system of symbolism involving images that represented that supposed truth (e.g., you could stipulate it would be representing by putting an image of Smith falling off the fence on top of an image of Smith with a broken leg). But that wouldn’t be an image of its being the case that Smith would have broken his leg if he’d fallen off the fence. It would be an image of Smith falling off the fence on top of an image of Smith having a broken leg. Relative to some convention, the one image’s being on top of the other would represent that dependence relation. But it wouldn’t be an image of it. Relative to certain conventions, the expression “Socrates” represents Socrates, but it isn’t an image of him. It’s a non-iconic representation of him. And putting one image on top of another is no more a case of producing an image of a dependence relation than saying “Socrates” is producing an image of Socrates.
   But even if there could be some image of this dependence relation, there would still be no image that had S for its content. There is a difference between believing S, on the one hand, and:

(S*) Smith broke his leg because he fell.
   
   S* presupposes that Smith fell off the fence and that he broke his leg. S presupposes neither. In fact, it presupposes that Smith did not fall off the fence. So an image of S* wouldn’t be an image of S, and an image of S would have to be an image to the effect that interalia Smith did not fall off the fence. But there can’t be images of negative propositions. There is no image such that, by virtue of having it, you are thinking that Smith did not fall off the fence. You could produce an image with a big X on it of Smith falling off the fence. But that wouldn’t be an image of Smith not falling off the fence. It would be an image with a big X on it of Smith falling off the fence; or maybe it would be an image of Smith falling off a fence in the vicinity of a big X.
   Disjunctive propositions are really conditional ones. Either P or Q is interchangeable with if not P, then Q. It follows that no disjunction can be imaged.

5.2 Iconic information too specific in some respects and also too unspecific in others
First a terminological point: By a “general” thought, I mean one that concerns some unspecified thing (e.g., somebody or other cured cancer) or that concerns all things in a certain category without considering any one of them in particular (e.g., most people have at least some decency).
   Suppose you believe that the cat is on the mat. Any image of a cat on the mat will include information not included in that thought (e.g., it will include information concerning the cat’s shape or color, or concerning the mat’s shape or size).
   By the same token, any thought will contain information not included in any image. An image of a cat on the mat is indistinguishable from an image of a perfect cat-impostor that is on a mat. So if the thought that the cat is on the mat were identical with an image, it would be identical with the thought that a perfect cat impostor is on the mat. But those propositions are distinct.
   Also, general thoughts couldn’t possibly be identical with images. Suppose you think that something or other is on the mat. An image can’t just be an image of something or other on the mat; it must be an image of some particular thing on the mat. So if the thought that something were on the mat were identical with an image, it would be identical with the thought that (say) Snoopy was on the mat. But those thoughts aren’t identical.
   Similar arguments show that other general thoughts can’t be identical with images. Consider the thought that all birds have feathers. An image of all birds—an image that depicted every single bird in existence—would be indistinguishable from an image of (say) 84 billion birds. But the thought 84 billion birds have feathers is different from the thought that all birds have feathers. So neither thought is image. Obvious adaptations of this argument show that no image can be identical with the thought that most birds/many birds/all possible birds have feathers.
   So, really, no thought that can be expressed by a sentence is identical with an image. This shows that many thoughts aren’t images and, since sense-perceptions are images, therefore have contents very different from those of any sense-perception.
5.2.1 Berkeley’s unwitting anti-empiricism
Ironically, it was that greatest of empiricists, George Berkeley, who made it clear that no general thought cannot be identical with images, the reason being that any image is specific in ways that any one of those thoughts won’t be. (Berkeley didn’t make the correlative point that thoughts are specific in ways that images are not.) Berkeley saw that if all thoughts are images, then there are certain thoughts we can’t have. Berkeley also saw that, if empiricism is correct, thoughts must be images. Finally, Berkeley saw that, given these two points, empiricism is inconsistent with the presumption that we can have general thoughts. But instead of rejecting empiricism because it has this absurd consequence, Berkeley held that, indeed, we can’t have general thoughts. This position, in addition to being obviously wrong, is self-defeating, since the thought that there are no general thoughts is itself a general thought.
   Berkeley qualified his position by saying that, although we couldn’t directly grasp general propositions, we could grasp non-general propositions that we took to stand for general ones. But one can’t take x to mean y unless one grasps y. So one can’t take a non-general proposition to stand for a general proposition unless one grasps the latter. (See Sections 8–21 of Berkeley’s “Principles of Human Knowledge.”)
5.3 Knowledge never wholly identical with mental imagery
As we observed, if all knowledge is strictly sense-based, then any case of knowledge is a case of some sequence of images running through one’s mind. But no sequence of mental images  is knowledge. Such a sequence may serve as a partial basis for knowledge (e.g., if the image-sequence is a series of visual perceptions of a dog, then, partly on the basis of that sequence, you may know that there is a dog near you); and one can have knowl

-edge about that sequence (e.g., you can know that ony a visually gifted person could experience such high-resolution mental images). Nevertheless, knowing something always involves grasping at least one thing in some way other than through an image and, therefore, in some way that, because sense-perception gives one nothing but images, empiricism cannot account for.
   There’s a difference between an image, on the one hand, and that image’s being represented as true, on the other. (Philosophers use the word “veridical” to describe accurate perceptions, and they sometimes use the word “falsidical” to describe inaccurate ones. But I’ll stick with “true” and “false.”) Consider some painting (e.g., a painting of a woman picking flowers). There is nothing in the image itself that says: this woman really exists, and she realy is picking flowers. Images are not self-referential; so they don’t say “I am true” or “I am false.” Thus, the image itself leaves it open to how it is to be taken. It could be taken as something true, something false, or something that is not meant to be taken as true or as false.
   A corollary is that there is no image such that, merely by virtue of experiencing it, one is grasping the concept of truth. To know something, one must believe it to be true. Believing something to be true thus involves grasping the concept of truth and, given what we just said, therefore involves grasping something that cannot possibly be grasped by experiencing an image. Since the senses provide us only with images, it follows that the concept of truth is one that is not be grasped through the senses. And since a grasp of that concept is a prerequisite to knowing anything, it follows that, contrary to what empiricism says, not all knowledge is strictly sense-based. In fact, it follows that, although a great deal of knowledge is obviously largely sense-based, no knowledge is strictly sense-based.
6.0 George Berkeley and the collapse of empiricism into idealism
George Berkeley (1685–1753) argued that “to be is to be perceived” (esse percipi est). He held, in other words, that the things we believe to be revealed to us through sense-perception (e.g., rocks, trees) are sense-perceptions—or, more exactly, are collections of sense-perceptions. So Berkeley held that book that you see before you is identical with the perceptions you (and others) have of it.
   The view that physical objects are sense-perceptions is known as “idealism.” It is so named because it is the view that external objects are “ideas,” not because it embodies a spirit of optimism.
   Even though, if our intuitions are to be given any credence, idealism is an abomination, Berkeley had a very good reason for accepting it. Given an acceptance of empiricism, one must be an idealist if one is to avoid saying that we have no knowledge of the external world at all. Berkeley saw this; and, being an empiricist who wasn’t also a skeptic, he duly accepted idealism.
   According to empiricism, if you don’t know it through sense-perception, you don’t know it. But what do know through sense-perception? “I know that I’m reading a book right now.” No you don’t. You know that, if what your senses are telling you is the truth, you’re reading a book.
   Your senses cannot themselves give you any good reason to believe that they’re truthful. Unless you already have some assurance that your senses are truthful, no attempt on their part to tell you this deserves any credence. So, supposing that you do know that you’re reading a book right now, this knowledge, although largely based on sense-perception, isn’t entirely so.
   In general, even if our senses are generally telling us the truth, this fact cannot itself be known through sense-perception. This doesn’t mean that it cannot be known. (I believe it can be known that our senses are telling us the truth. See Chapter 11.) But it means that, if we are to come to know that our senses are telling us the truth, it cannot be entirely on the basis of what our senses themselves tell us.
   An analogy may help. Uncorroborated testimony is close to worthless. Smith is a suspect in a crime. He gives you an alibi. (You’re the detective assigned to the case.) You want to know whether Smith’s alibi is correct. If you ask Smith “are you telling me the truth?,” he’ll obviously say yes. What you want is independent corroboration for Smith’s testimony. No person can self-corroborate; and neither can anything else, including sense-perception. If we are to have any assurance that our senses are telling us the truth, that assurance must come from some non-sensory source. But empiricism says that nothing coming from any non-sensory source deserves any credit.
   
Given this fact, there are only two ways for empiricists, such as Berkeley, person to go. (i) Deny that we know anything about the external world. (ii) Redefine the concept of an external object in such a way as to validate empiricism.
   (i) is self-explanatory. It’s skepticism. Some philosophers accept skepticism. But for Berkeley, skepticism is not alternative. He all but takes it for granted that it’s false. (We’ll say why in a moment.)
   This puts Berkeley between a rock and a hard place. Berkeley refuses to stop being an empiricist. And he also refuses to accept skepticism.
   This leaves him with only one option. He must show that the presumption that our senses give us knowledge of the external world can be accommodated within the limits set by the belief that all knowledge is strictly observational.
   There is only one way to do this. One must reinterpret statements about the external objects as statements about one’s own perceptions. In other words, one must take the view that the statement “that rock weighs five lbs” has the same content as some statement about one’s own perceptions.
   The position that statements about external objects can be translated into statements about perceptions is known as phenomenalism. Any attempt to translate a sentence about the external world into one about one’s perceptions is known as a phenomenal reduction.
   Phenomenalism entails idealism. If every truth about rocks, trees, etc., is a truth about perceptions, then rocks, trees, etc., are nothing if not perceptions.
   Phenomenalism is false. It simply isn’t possible to translate statements about rocks (etc.) into statements about one’s perceptions. We’ll see why in Section 8.0.
But phenomenalism must be accepted by any true empiricist who isn’t also a skeptic.
6.1 Berkeley’s argument that to be is to be perceived
Our senses give us knowledge of the external world (or so we will assume for argument’s sake). There is no non-sensory source of knowledge (same qualification).
   Our senses give us conflicting reports. I’m near the house; my eyes tell me that it’s big. I’m far away from it; my eyes tell me that it’s small. The first report conflicts with the second. I leave a sauna: the room feels cool. I then go outside (where it’s frigid, since it’s Northern Canada in the winter), and come back in: the same room feels hot (even though, as my housemates tell me, the room hasn’t changed temperature).
   In some cases where sensory-reports conflict with one another, we can throw one of them out. Somebody puts LSD in my drink. I hallucinate a nine-headed goblin. My goblin-(mis)perception can be thrown out; I know that it’s wrong. Why? Because the message it gives me doesn’t fit in with the other messages my senses give me. It is on this basis that we throw out dream-images on this basis. Dream-images don’t fit into the narrative.
   But I cannot throw out either of my house-perceptions. Neither is in the same category as my goblin-perception. Only a tiny fraction of the discrepancies within the reports given to us by our senses involve a (mis)perception that is in the same category as my goblin-perception. In most case, all of the mutually discrepant perceptions must be accepted. When, while I’m in an airplane, my eyes tell me that people on the ground are the size of ants, I cannot reject the testimony of senses. (I’m not dreaming or hallucinating.) Nor can I reject it when my eyes tell me that they’re the same size as myself. During what follows, when we talk about “mutually discrepant perceptions,” we won’t be referring to discrepancies involving dream-images or hallucinations. This is a point that is likely to be forgotten and that, being crucial, will be repeated more than once.
   Given the fact that we have mutually discrepant sense-perceptions, there are, as a matter of logic, only two paths we can take.
   Path #1: We can say that some of those perceptions are veridical while others aren’t. (It must be kept firmly in mind that, in this context, we’re setting aside patently deviant perceptions, e.g., my goblin-perception.) 
   Path #2: We can say that all our perceptions are correct. Let’s discuss these two paths.
   
Path #1 evaluated: Supposing that we decide that some of our perceptions are wrong, it must be asked: on what basis are we making this determination?
   If we do it on the basis of some principle known to us in some non-sensory manner, we’re not empiricists any more. So, given that we’re empiricists, it cannot be on the basis of such a principle.
   So it must be on the basis of some principle known to us through observation—supposing that it’s made on the basis of any principle at all. But all of the perceptions we’re talking about are equally credible. Remember that we’re setting aside dream-images, hallucinations, etc. We’re focusing only on garden-variety perceptions—those that, unless our senses are constantly deceiving us, must be correct.
   This entails, tautologically, that there is no observational-basis for deciding that some of the perceptions in question are to be thrown out while others are to be kept on. In other words, there is no observation-based principle on the basis of which we can decide which perceptions to keep on. And, since we’re empiricists, this means that there is no principle at all on the basis of which we decide which perceptions to keep on.
   So, given that we’re following Path #1, we must arbitrarily choose to throw out certain perceptions while keeping others. This means that, even if we made the right choices, we wouldn’t know it, since those choices weren’t justified. Which in turn means that nothing we believed on the basis of sense-perception would be justified. Which, in its turn, means that we wouldn’t know anything on the basis of observation. (And, since, by assumption, we’re skeptics, we can’t say this.) 
   Plus, that procedure, if adopted, would have the consequence that our senses tell us little, if anything, about the external world. Since any given perception is discrepant with many others, many of our perceptions, perhaps all of them, would get the axe.
   Thus, Path #1 isn’t viable. So we must take Path #2. In other words, we must say that (setting aside patently deviate (mis)perceptions), our perceptions are correct.
   Path 2 Evaluated: Assuming Path #2 the right one, we are stuck with a serious problem. When I look at it from one angle, the table appears square-shaped. (Let P1 be this perception.) When I look at it from another angle, the table appears diamond-shaped. (Let P2 be this perception.) P1 and P2 cannot both be accurate if they’re both taken to concern some trans-perceptual object. A given object cannot simultaneously be, and fail to be, equiangular. (Given any property F, nothing x can, at a given time, both have and not have x.) But even though, when taken to concern some transperceptual object, P1 and P2 are inconsistent with each other, P1 per se is perfectly capable of co-existing with P2 per se. They do co-exist. So they can co-exist. (Two conflicting statements can co-exist.) So instead of saying that P1 and P2 describe some trans-perceptual object, let’s say that they are the object that, so we wrongly thought, they describe. (Let’s say, in other words, that they’re constituents of that object.) Let’s say, in general, that our perceptions are their objects (i.e., that any given perception is a constituent of its object and that any given perception is wholly constituted by some multiplicity of perceptions).
   By taking this position, we accommodate the fact that we acquire knowledge through sense-perception. We know our perceptions. (Even Cartesian skeptics concede this.) If we identify our perceptions with their objects, then we know those objects—and we know them by virtue of having sense-perceptions. So this solution accommodates the presumption that we learn about objects through sense-perception. And it also makes it unnecessary to posit surds, such as equiangular objects that aren’t equiangular.
6.1.1 A systematic presentation of Berkeley’s argument 
Step 1: If our senses are to be trusted, properties are observer dependent. (If you’re an elephant, people appear small. If you’re an ant, they appear big. If you just came out of a sauna, room temp seems cold. If you just got out of an ice bath, it seems hot.)

Step 2: The external world is totally unknowable unless we suppose that, typically, things are as they appear.

Commentary on Step 2: This is a corollary of empiricism. Empiricism says: what we know, we know strictly on the basis of our senses. So if our senses tell us that x is big, then we’re entitled to believe x is big—period.

One cannot, in general, legitimately second-guess what one’s senses are telling one (at least not if one is an empiricist). One can throw out patently deviant perceptions (e.g., perceptions of suddenly appearing pink elephants). But this covers only an infinitesimal minority of our sensory experience.

Step 3: Things are knowable. It would be absurd to say that we don’t know anything about rocks, trees, etc.

Step 4: Things can’t have incompatible properties. A number can’t be both even and odd. A thing can’t be both big and small. A body of water can’t be both hot and cold.

Step 5: Suppose, if only for argument’s sake, that things exist independently of our perceptions of them. Suppose that, whether or not somebody perceives it, the vase exists (the same being true of the rock, the tree, etc.). In that case, things will have incompatible properties.

Explanation of Step 5: Remember Step 3—we do know about external objects. They are not unknown. So they are as they appear. Well, they appear to have incompatible properties. One and the same thing appears both big and small, hot and cold, fast and slow, etc.

Step 6 (this step is crucial to understanding Step 7, so bear with me): There’s nothing incoherent in the idea that one and the same thing should appear both big and small, hot and cold.

Clarification: Suppose I say “Bill is in Virginia right now” and I then say “Bill is not in Virginia right now.” Obviously there cannot be some one thing of which both statements are correct representations. But there’s nothing incoherent in the idea that both statements should be made. While it is incoherent to hold there is some one thing which they both correctly describe, it’s obviously perfectly ok to hold that both statements (however badly they may fit together) were affirmed. Similarly, there is nothing incoherent in the idea that, at the same time, there should occur a perception to the effect that x has one temperature and also a perception to the effect that x has some other temperature. What is incoherent is the idea that there should be some thing of which both perceptions are correct representations.

Step 7: If we say that our perceptions are representations of objects that lie on the other side of them, then (assuming, as we are, that our perceptions are accurate) things have incompatible properties. But if we say that our perceptions are not representations of such objects—if, instead, we say that perceptions are those objects—then things don’t have incompatible properties.

Clarification: Remember Step 6. It isn’t possible for there to be two correct but incompatible representations of some one thing, even though it’s obviously possible for two such representations to exist. Our perceptions give us incompatible messages (they say that one and the same thing is both big and small, is moving both quickly and slowly, etc.). So it isn’t possible for our perceptions to be correct representations of things. But it is possible for our perceptions to exist. It is irrelevant that they are incoherent if taken to be representations of trans-perceptual entities.

Step 8: It follows from Step 7 that our perceptions can’t be representations of anything.

Step 9: But remember Step 2—we do know about things. We do know their sizes, temperatures, etc. The way to make this all work is to say: things are our perceptions of them. We know our perceptions obviously. (So if we say that rocks, trees, etc., are our perceptions, then we can explain how we can know them.) And we also know that perceptions can’t be representations of things. So we say that perceptions don’t represent reality: they are reality.

Conclusion: For something to exist s i for it to be perceived. The perception doesn’t represent the thing. The perception constitutes the thing.

6.2 The problem with Berkeley’s argument: its failure to take into account the relational nature of perceptual information
Berkeley’s argument fails. But the reason why it does must be understood in terms of a rather subtle point about sense-perception—a point that will initially be hard to understand but that, after being stated abstractly, will be made clear with some examples.
   Our senses give us relational information. They tell us how things are in relation to one another and in relation to ourselves. They apprise us, not of absolute, but of relative heights, distances, velocities, temperatures, and masses; our eyes tell us, not that the car is going 35 mph, but that it is going faster than that other car; our muscles, when we exert ourselves, tell us not that the barbell weighs 215 pounds, but that it weighs more than the barbells we tried to move a moment ago. Our senses tell us, not that Smith is 7-feet tall, but that he is much taller than Jones. And our senses tell us where things are, not in relation to some absolute coordinate system, but in relation to us. So the information given to us by our senses is relational in two senses: objects are related to one another; and they are also related to an egocentric, as opposed to universal, coordinate system.
   Once this is taken into account, it is clear why Berkeley’s argument crumbles. Consider a situation where X is walking at a rate of 1 mph, Y is sprinting at a rate of 30 mph, and Z is driving at a rate of 90 mph. (X, Y, and Z can see each other; they have good vision and normal cognitive capacities. So they know, at least approximately, what their relative velocities are.) According to Berkeley, X’s perception of Y is simply this: Y IS MOVING SLOWLY. And, according to Berkeley, Z’s perception of Y is simply: Y IS MOVING SLOWLY. And, on this basis, Berkeley concludes that Y’s state of motion (his velocity and, by similar arguments, his trajectory) exists only in the mind (or, more accurately, in the minds of X and Z and any other observers of Y). But Berkeley has misreported what the relevant individuals are being told by their own eyes. X’s eyes don’t tell him: Y IS MOVING FAST. They tell him: Y IS MOVING FASTER THAN I AM. And Z’s eyes don’t tell him: Y IS MOVING SLOWLY. They tell him: Y IS MOVING MORE SLOWLY THAN I AM.
   So when we consider what Y’s eyes are telling him, and put it together with what Z’s are telling him (Z), what we get is this:

(i) Z is moving fast then Y, and Y is moving faster than X.

But there is nothing incoherent about (i). It does indeed attribute two properties to Y (namely, the property of moving slower than Z and the property of moving faster than X). But there is no reason why a thing can’t simultaneously have both properties; for those properties are not incompatible—they aren’t like the properties “square” and “circle.” (i) describes a state of affairs that can, without any incoherence or self-contradiction, be attributed to the external world.
   This reasoning is easily extended to undermine Berkeley’s argument in its entirety, as another story will help make clear. X is a tiny person—he’s 1-inch tall (but otherwise like us: good vision, good reasoning skills, etc.) Y is 1-foot tall (same qualification). And Z is 6-feet tall (same qualification). They can all see one another. According to Berkeley, here’s what’s going on: Z’s eyes tell him: Y IS TINY. X’s eyes tell him (X): Y IS HUGE. Berkeley concludes Y is both tiny and huge and that, since nothing can be both tiny and huge, size must be in the mind of the observer and not in the thing observed. But Berkeley is wrong about what X and Z are told by their senses. X’s eyes tell him: Y IS MUCH LARGER THAN I AM. Z’s senses tell him (Z): Y is much smaller than I am. So when we put together what X and Z are told by their senses, what we get is:

(ii) X is smaller than Y, and Y is smaller than Z.

And there is nothing incoherent about (ii). It doesn’t ascribe incompatible properties to Y, and it doesn’t therefore require that we abandon the view that size is in things themselves, as opposed to the minds of their observers.
   Some additional illustrations of these principles may be in order. X is super-strong and moves barbell B easily. Y is not so strong and can barely get B to budge. According to Berkeley, X’s kinesthetic sensations (i.e.,

the feelings of resistance that he has when moving B) tell him: B IS LIGHT. And, according to Berkeley, Y’s kinesthetic sensations tell him: B IS HEAVY. But, contrary to what Berkeley holds, X’s sensations don’t give him a message of the form: B’s MASS IS SUCH AND SUCH. They give him relational message. They tell him what the relation is between (a) X’s making a certain degree of effort and (b) B’s moving by a certain amount. So X’s sensations tell him how B’s resistance to motion compares with his own ability to overcome such resistance. By similar reasoning, Y’s sensations tell him (Y) how B’s resistance to motion compares with his (B’s) ability to overcome such resistance. So when we put what X’s sensations are telling him together with what Y’s sensations are telling him, what we get is:

(iii) The ratio of X’s ability to move things to B’s resistance to being moved is higher than the ratio of Y’s ability to move things to B’s resistance to being moved.

(iii) is a perfectly consistent message. In fact, it’s consistent with, and confirms, what we already knew. We knew that X was strong, and that Y was not so strong; and, given that information, it was to be expected that X would have an easier time moving B than Y and, also, that this would be borne out by the kinesthetic sensations experienced by these individuals. To sum up, once it is made clear that our sensations and perceptions give us relational information, it turns out that, although our senses are obviously wrong some of the time, they don’t, contrary to Berkeley argued, systematically give us contradictory reports.
   Here is one example to drive these points home. X is a hand that has just been immersed in ice-cold water. Y is a hand that is been soaking in water that is very hot (but not so hot that it damages Y). B is a bucket of room-temperature water. Here is what Berkeley says (this is a paraphrase, not a quotation):

“When X is immersed in B, his hand says: THIS WATER IS HOT. And when Y is immersed in B, his hand says: THIS WATER IS COLD. So X and Y say opposed things about the water in B. Therefore, B’s temperature isn’t in B; it’s in the observer’s mind.”

But Berkeley is wrong about what X and Y say. Remember that perceptual information is relational. When immersed in B, X doesn’t say: THIS WATER IS HOT. It says: THIS WATER IS MUCH HOTTER THAN THE WATER I WAS JUST IN. And, when immersed in B, Y doesn’t say: THIS WATER IS COLD. It says: THIS WATER IS MUCH COLDER THAN THE WATER I WAS JUST IN.
So when we put together the messages that X and Y present to their own, we get:

(iv) The water in the bucket is warmer than the water that my left hand was in prior to being in the bucket, and the water in the bucket is colder than the water that my right hand was in prior to being in the bucket.

There is nothing incoherent about (iv); it doesn’t attribute incompatible properties to anything; nor, therefore, does it require us to deny the mind-independence of any aspect of reality.
6.3 How we actually learn what properties things have
As we’ve noted, our senses give us only relational information; they tell us, not that the object x weighs 80 pounds, but that it weighs more than object y; not that object x is moving at a rate of 50 mph, but that it is moving faster than y; not that x has a temperature of 78°, but that x is warmer than y; and so on. At the same time, we’re obviously capable of learning objects’ actual masses, temperatures, and such. But how is this possible if our senses give us only relational information?
   To answer this question, we must take a brief detour through the philosophy of science. Suppose you decide to measure time in terms of your own heart rate. You’ll find that, when you do vigorous exercise, everything in the universe (other than your heart rate itself) slows down. (Your heart rate does not itself slow down; for, being the standard of comparison, its rate is by definition constant.) And you’ll find that, when you are calm and relaxed, everything in the universe speeds up.
   
Here you can say one of two things. (i) Because of some strange law, your exercising causes the entire universe (except for your heart itself) to slow down (and your ceasing to exercise causes it to speed up). (ii) You shouldn’t measure rates of change with respect to your heart rate, since doing so creates otherwise absent causal anomalies and demands that relatively simple physical laws be replaced with exceedingly complicated ones.
   Obviously (ii) is the right choice. You shouldn’t regard your heart rate as a periodic process. You should say that it’s your heart rate that’s changing, not the entire universe. 
   Comparable points hold with respect to all degree properties. (By a “degree property,” I mean one that can be had to varying degrees. So coldness is a degree property, since one thing can be colder than another. But the property of being divisible by two is not, since a number either has that property or it doesn’t.) Suppose a consequence of taking object L to have a constant length is that, when L is put in a freezer, everything in the universe (except for L itself) expands and that, when x is put in boiling water, everything in the universe shrinks. In that case, obviously, you shouldn’t take L to have an unchanging length; you shouldn’t take it as your standard of comparison. The principle implicit in all this is that, if one learns that there has been a change in the difference between x and y in respect of how much they have degree property phi, one should regard the extent to which x has phi as having changed less than the degree to which y has phi if and only if doing so is less costly, from an explanatory viewpoint, than it would be to regard y as having undergone less change (in that respect) than y or to regard x and y as having undergone equal amounts of change (same qualification). So, if fewer causal anomalies are created by regarding y as having undergone less phi-change than x than are created by regarding x as having undergone more phi-change than y, then one should not regard x as approximating, to a higher degree than y, to a condition of phi-uniformity. And if fewer causal anomalies are created by regarding x and y as having undergone equal amounts of phi-change than are created by supposing one of them to have undergone more phi-change than the other, then one should regard neither x nor y as approximating a condition of phi-uniformity to a higher degree than the other. Otherwise one should regard x as approximating to a condition of phi-uniformity to a higher degree than x.
6.3.1 How this last point relates to sense-perception
Our senses constantly give us information about comparative rates of change. One’s eyes might tell one, for example, that the apparent size of the man is changing faster than the apparent size of the tree. The man’s apparent size, so one’s eyes tell one, is shrinking faster than the tree’s apparent size, even though the apparent size of each one is shrinking. Given this raw, pre-inferential, visual information, one holds any one of the following:

(i) One’s distance from the man and the tree remains constant; but the man and the tree are both shrinking, and the man is shrinking faster than the tree.
(ii) One is moving away from both the man and the tree (and, therefore, one’s distance from the man and the tree is not constant), but the distance between the man and the tree remains constant; and, whereas the man is shrinking, the tree’s size remains constant.
(iii) One is moving away from both the man and the tree, but the distance between the man and the tree remains constant; and, even though both the man and the tree are shrinking, the man is doing so at a faster rate than the tree.
(iv) The tree’s size remains constant, and so does the man’s; the man is moving away from the tree in one direction, and you are moving away from the tree in the opposite direction.

Each of (i)–(iv) is consistent with the raw information contained in the previously described perception. But a world where any one of (i)–(iii) was correct would ceteris paribus be a world that was replete with causal anomalies absent from a world where (iv) was correct. This means that, if one were to countenance any one of (i)–(iii), one’s understanding of the world and the forces that govern it would undergo a weakening that it would not undergo were one instead to countenance (iv). It is for this reason, then, that ceteris paribus one 

countenances (iv), and not any one of (i)–(iii). It is for this reason, that, after exercising vigorously, one believes that one’s heart rate sped up and not that the rest of the world slowed down; that, after lifting weights for a year, one became stronger and not that everything became lighter; that, on leaving a steam room, one’s body that has become warmer and not that the world that has become colder; and so on.
   So although it is obviously through sense-perception that we learn objects’ masses, speeds, temperatures, and so on, we don’t sense-perceive them, at least not directly. Although it is through sense-perception that one learns that the water is 78°, one doesn’t sense-perceive that the water has that temperature. What one sense-perceives is that the water is warmer than x and colder than y. Given this information, one is justified in believing that the water’s temperature is 78° just in case, in doing so, one is undermining the integrity of one’s understanding of physical reality less than one would be in not doing so. Basically, objects’ actual properties are inferred from sense-perceptions and not directly sense-perceived; and the relevant rule of inference is: “of the various ways of accommodating the raw, sensory data that you’ve been given (and there will always be several such ways), the right one is the one that is the least ad hoc (that posits the fewest causal anomalies, that has the most explanatory fertility, etc.).”
6.4 Primary vs. Secondary properties
Like John Locke, Berkeley distinguishes between primary properties and secondary properties. Examples of primary properties are shape, size, density, liquidity, solidity, gaseousness, and state of motion. Examples of secondary properties are sweetness, smell, color, and timbre.
   For a thing to have a given secondary property—e.g., for it to have the taste of Snicker’s bar—is for that thing to be prone to induce sensations of a certain kind in creatures of a given kind.
   For a thing to have a given primary property is for it to have an effect of a given kind on the conditions that objects must meet to occupy a certain region of space-time. By virtue of being round (or gaseous), a thing has certain effects on would-be occupants of its current location that, other things being equal, it wouldn’t have were it square-shaped (or solid) instead.
   According to some, the essence of Berkeley’s argument for idealism is that primary properties are really secondary properties. Thus interpreted, Berkeley’s argument is as follows:

Berkeley’s argument (BA): For a thing to have a given secondary property is for it to taste, smell, feel, etc., a certain way. Some philosophers hold that, in this respect, shape, size, and other so-called primary properties are fundamentally different from secondary properties. But they’re wrong. Shape, size, etc., are quite as observer-dependent as taste, color, etc. When you’re near the house, it looks big (we’re assuming that your perception is accurate); and when you’re far from the house, it looks small (same qualification). Of course, we could say that the size an object seems to have is different from the size it actually has. But in that case, we’d be stuck saying that our senses tell us nothing, or next to nothing, about the external world, which is absurd. It follows (for the reasons given in 6.1) that the objects of sense-perception are identical with our perceptions of them.
   
   The problem with BA is that, contrary to what it says, your first house-perception is consistent with your second house-perception. The first perception doesn’t say that the house is big. It tells you how its size compares with those of various objects. It tells you that it’s shorter than the telephone pole next to it, but taller than the cactus in front of it, etc. The comparative information given to you by your second perception is consistent with it. The relative apparent sizes of the cactus, house, and telephone pole are the same.
   In the second perception, the house appears the way that small things appear when looked at from up close. And that is the one and only sense in which the house “looks small.” But you’re not looking at the house from up close. You’re looking at it from far away. And your perception isn’t telling you that the house is close by and looks that way. It’s telling you that you’re far away from the house and it looks that way. So it isn’t telling you that the house is small. It’s actually telling you that it’s quite big.
   
When you’re near the house, your house-image hogs up your entire field of vision. It occupies more space on your visual map. When you’re far from the house, your field of vision has to include a great many objects other than the house. So it doesn’t eat up very much map-space. Thus, measured in terms of how much map-space they eat up, the first house-image is larger than the second house- image.
   But that doesn’t mean that those perceptions make different statements concerning the size of the house. On a map the size of a postage stamp, the discoloration that represents Denmark will be miniscule. On a map the size of the side of a big house, the corresponding discoloration will be much bigger. But that doesn’t mean that Denmark is small according to the small map and big according to the big one. Each of those maps tells you that Denmark’s actual size corresponds to the relative, not the absolute, size of the picture of Denmark on that map. The bigger that discoloration is in relation to the other nation-representations on that map, the bigger the size thereby attributed to Denmark. Thus, the size attributed to Denmark by the small map might be twice that attributed to it by the big map.
   The same thing mutatis mutandis is true of visual images. A big house no more “looks small” when looked at from far away is identical than Denmark “looks small” on the tiny map. When the house is looked at from far away, the corresponding house-image is small (i.e., it eats up a comparatively small amount of visual space). But that’s consistent with that very perception’s representing that very house as being huge.
6.4.1 BA embodies a spurious understanding of what secondary properties are
The health effects of eating a foul smelling cut of meat are very different from the health-effects of eating a wholesome smelling cut of meat that is otherwise observationally just like the first. The way a piece of meat smells is an indication of its ability to nourish. For this reason, otherwise hard to obtain causal knowledge is easily obtained and otherwise hard to make predictions are easily made.
   Differences secondary properties always correlate with causal differences. In many cases, day-to-day experience makes it clear what causal properties are associated with possession of a given secondary property. (Day-to-day experience makes it clear that things with certain tastes and smells are not fit to drink.) In other case, day-to-day experience doesn’t do this. (Day-to-day experience doesn’t make it clear how an object that is red differs in respect of its causal properties from one that is green but is otherwise identical.) But if a given object has a given secondary property, it ipso facto has some causal property that it wouldn’t otherwise have.
   For this reason, secondary properties are not in any relevant sense “subjective.” The term “subjective,” as John Searle (1992) points out, has two very different meanings. To say that such and such is “subjective” can mean that

(i) its existence presupposes that of some subject,

or it can mean that

(ii) it embodies prejudices or other subject-specific idiosycracies that tend to inhibit the acquisition of knowledge.

My belief that 2 + 2 = 4 is subjective in sense (i). That belief presupposes the existence of a subject. There can’t be disembodied beliefs floating about. But that belief isn’t subjective in sense (ii). It is (so we will assume) based on rational consideration of the relevant information. By contrast, my intense fear of people who wear plaid shirts (which is based, not on rational consideration of the relevant data, but on childhood traumas that we needn’t discuss) is subjective in sense (ii). In other words, it is rooted in peculiarities of my own person that make it harder for me than it would otherwise be to see things as they are. My olfactory perception that the maggot-infested meat in front of me smells awful is subjective in sense (i) but not in sense (ii). It is subjective only in the trivial and irrelevant sense in which any mental entity, even a coolly made judgment, is subject

tive: it is subjective in the same way as my rational and informed belief that 2+2=4 is subjective. But it isn’t subjective in the same way as my prejudice-driven fear of people who wear plaid shirts.
   Bearing this in mind, suppose that, all of a sudden, the way things smelled was no indication as to whether they were rotten or not. So, for example, a putrid-smelling cut of meat might or might not be good to eat—its smell would give you no information as to its fitness as a source of nourishment—the same being true of a wholesome-smelling cut of meat. In general, we wouldn’t know anything about an object’s causal properties from the way it smelled. But we often know a lot about a thing’s causal properties from the way it smells. Smells correlate extremely reliably with certain causal features of objects—sometimes much more reliably than other properties. Sometimes the way thing smells is the only indication (short of eating it or sending it to a toxicology lab) that it’s laced with poison or that it’s completely rotten.
   Smells track primary properties; they track facts about microstructure that would otherwise be hard to detect. If a police-detective suspects that X is pure cocaine, he can verify his hypothesis by (i) snorting X, which would have various adverse consequences, (ii) sending X to a forensics laboratory, which would be extremely slow, or (iii) tasting it, which would be quick and easy.
   A relevant fact about method (ii) is that many scientific techniques would have been impossible to develop had there not been reliable correlations between microstructure and odor. This is true of secondary properties generally.
   There are some apparent counterexamples to our contention that secondary properties track microstructure. For example, a thing’s color doesn’t correlate reliably with its microstructure. From far away, the ocean water looks black; from up close it’s transparent. Locke concluded from this that secondary properties are subjective.
   But this is not the only conclusion to draw. An object’s apparent color is a function both of that object’s microstructure and of the relevant observer’s physical relation to that object. But so does an object’s apparent shape, apparent size, smell, etc. So the variability of apparent color no more entails the subjectivity of color than does the variability of apparent shape. And so long as the conditions of observation are held constant, an object’s apparent color does reliably correlate with its microstructure, just like its apparent shape (though not, it must be admitted, to as high a degree).
   Our perceptions of primary properties are very different from our perceptions of secondary properties. When one sees a porcupine, one’s visual image has a structural similarity to that of the porcupine; given any two features of the porcupine that are distinguished by image, there are corresponding differentiations in that image. Perceptions of secondary properties are very different; they aren’t internally differentiated, at least not in a way that at all corresponds to the objective facts to which they are hewed.
   This, presumably, is at least part of the reason why it’s widely held that an object’s secondary properties are really properties of the subject’s experiences of that object, and not of that object itself. (It’s also why it seems more natural to speak of “sensations” of taste, smell, etc. than of “perceptions” of them.) But, I will now argue, an object’s secondary properties belong to it no less than its primary properties. I must warn that the forthcoming argument is quite intricate and that, for the first few paragraphs, it will seem as though I’m arguing for the contention that an object’s secondary properties don’t really belong to it. I must ask for a certain amount of patience on the reader’s part.
   Let S be the smell that, in actuality, is had by extremely putrid meat; and let S* be the extremely pleasant fragrance that, in actuality, is given off by eucalyptus trees. There is no inherent reason why eucalyptus trees couldn’t have S and there is no inherent reason why rotten meat couldn’t have S*. In other words, if there occurred a smell-exchange between eucalyptus trees and rotten meat, we would not, at least not for that reason alone, forfeit the causal knowledge that we now have by virtue of knowing that a cut of meat has S or that a eucalyptus tree has S*.
   Of course, there would initially be a loss of knowledge. One would mistakenly think that the pleasant-smelling cut of meat one was about to eat was not rotten. But given some time to adjust to the new smell-situation, one would cease to make such mistakes. 
   There is another reason why, even though it wouldn’t have any lasting affect in our ability to acquire knowledge through olfaction, that smell-exchange would initially compromise our ability to do so. This fact 

initially suggests that olfaction doesn’t give us knowledge of the causal structure of the world. But, duly scrutinized, it turns out to entail that olfaction is, like vision and audition, does give us such knowledge.
   Much of the knowledge that we acquire through the sense of smell is based on the comparative properties of our olfactory sensations. Other things being equal, the more rotten a cut of meat is, the worse it smells. Other things being equal, the more pungent the fragrance of a eucalyptus tree is, the richer that tree is in the chemical responsible for that smell.
   Bearing this in mind, suppose that S is the exact smell had (under a given set of circumstances) by a cut of meet that was rotten to degree n, and that S* is the fragrance (same qualification) of a eucalyptus having amount m of the relevant chemical. Because the previously described exchange hasn’t occurred, given a cut of meat having S and some other, otherwise observationally identical cut of meat, with a much stronger (weaker) version of S, I know on that basis that ceteris paribus the latter cut of meat is more (less) rotten than the former. For this reason, if the exchanged in question occurred but that other, compensatory changes didn’t occur alongside t i , our ability to acquire comparative knowledge of this kind would be diminished.
   But there’s no reason why any given set of causal properties should be associated with any given type of olfactory sensation. What is necessary is that, once the assignments are made, their mutual relations parallel the mutual relations of their objects.

(SA) So you admit that its having this as opposed to that odor does not, in and of itself, diminish our ability to learn about the world through the sense of smell. You admit, in other words, that rotten meat doesn’t have to have the smell it does. But in admitting this, you’re admitting that it doesn’t really have that smell.

There are two problems with SA.
   Problem #1: When we say that a given cut of meat has a bad smell, we’re talking about the cut of meat. If the word “smell” referred to sensations, then sentences like “that meat has an awful smell” wouldn’t be about the meat. By the same token, so far as that sentence is about the meat, it isn’t about sensations. Thus, to the extent that it really is about the meat, whether or not that sentence makes a true statement has nothing to do with anyone’s sensations. And to the extent that it isn’t about our sensations, “that meat has an awful smell” is about the meat’s causal properties or, in any case, is about some other (probably related) mind-independent fact.
   Problem #2: SA establishes that smell is mind-dependent only to the extent that it establishes the obviously, or at least presumably, false conclusion that size and shape are mind-dependent.
   Look at the book in front of you. Let V be the visual sensation you are having. Under otherwise unchanged circumstances, you could have a visual sensation that, although very different from V, gave you either the very same information or that gave you much more information. In human beings, the set of sight isn’t nearly as acute as it is where certain other species are concerned. Were they to look at the book in front of you, under conditions just like the ones that actually obtain, they’d have sensations very different from V that contained all the information contained in V, and then some. You could have visual sensations very different from the ones you actually have without, for that reason, failing to know anything that you do know.
   But this doesn’t entail that the facts of which vision apprises us are mind-dependent. V gives you a lot of information about the book’s location, its shape, and its size. And V’s shape, size, etc., are quite definitely mind- independent.
   “But aren’t you begging the question against Berkeley in saying this?,” it will be asked. “Wasn’t Berkeley arguing that, since (as you just pointed out) secondary properties are relevantly similar primary properties, to be is to be perceived?”
   Berkeley does indeed argue that. But he also takes it for granted that secondary properties are mind-dependent. In other words, his argument has the form: (i) secondary properties are mind-dependent; (ii) secondary properties are relevantly similar to primary properties; (iii) therefore, primary properties are mind-dependent; (iv) it follows from (iii) that objects are mind-dependent—are creatures of the mind.
   But I argued that secondary properties aren’t mind-dependent. I reject step (i), and provided an independently plausible reason for doing so. Therefore, what I’ve said doesn’t beg any questions against Berkeley.

6.4.2 Is temperature a primary or a secondary property?
Some properties that seem to be secondary turn out to be primary. A brief examination of one such property will clarify some of the points just made.
   For an object to have a certain temperature is for the particles composing it to have a certain mean kinetic energy. (Basically, it’s for those particles to move around in a certain way. The faster the movements, the greater the temperature.) But it’s initially tempting to categorize temperature with sweetness and, thus, to see it as secondary property.
   There are a couple of reasons for this. First, secondary properties are modality-specific. Sweetness can be tasted, but not heard, seen, touched.
   By contrast, primary properties are transmodal. Squareness can be seen or touched. In fact, creatures with very good hearing (e.g. bats) can hear shapes, just as we can see them; bats can detect an object’s shape through sonar. And creatures with a very olfactory sense (e.g., moles) can smell shape.
   According to some, including Locke and Berkeley himself, temperature can be known only through touch. But this isn’t true, of course. Given what temperature is (namely, molecular motion), it is just as capable of being known through sight or audition as it is of being known through touch. But it’s obvious why someone would think otherwise.
   There’s another reason why temperature is often falsely regarded as a secondary property. There isn’t anything inherently pleasant or unpleasant about seeing a square-shaped object or a fast-moving object. Under certain circumstances, it may be very unpleasant to see something move with a certain speed. But the connection is circumstance-specific. There is, however, something inherently unpleasant about certain odors, tastes, and timbres. In general, primary properties are not inherently associated with aesthetic properties—any such association is circumstantial—whereas secondary properties are non-circumstantially associated with such properties. Very high and very low temperatures are non-circumstantially associated with unpleasant sensations, and moderate temperatures are non-circumstantially associated with pleasant ones.
   Nonetheless, temperature is a primary property, since an instance of temperature is identical with various instances of motion.
6.5 A second Berkeleyan argument—“to be is to be conceived”
At one point, Berkeley argues that to be is to be conceived (“esse concipi ist”). In other words, things are the awarenesses that we, or other thinking beings, have of them.
   Here’s his argument. Try to conceive of something that exists but isn’t conceived. You can’t do it. Why not? Because you just conceived of it. If you try to conceive of some chicken that isn’t conceived of, then you just conceived of it, and it isn’t unconceived. Thus, nothing unconceived can be conceived to exist. Therefore, to exist is to be conceived.
   The problem with this argument is that, contrary to what Berkeley assumes, propositions, not objects, are the objects of conception. When one “conceives of a 50-pound chicken,” what one is doing is considering a proposition, viz: there exists a chicken that weighs 50 pounds, which (see Chapter 1, Sections 2.0–2.4) is equivalent with the property of being a 50-pound chicken is instantiated. There isn’t some specific chicken x such that x weighs 50 pounds and one is thinking about x. When one conceives of an unconceived chicken, there isn’t some specific chicken x that one is thinking about but that, at the same time, no one is thinking about. What’s going is that one is considering the proposition: there exists some chicken or other that nobody is thinking of, which is equivalent with the proposition: the property of being a 50-pound chicken that nobody is thinking of is instantiated. And that proposition is clearly not an absurd one. So Berkeley’s argument fails.
7.0 The phenomenal reduction—some preliminaries
First some terminological points. An object-statement is one that concerns mind-independent entities, e.g., “that statue is over ten feet tall” is an object statement. A perception-statement is one that concerns one’s own

perceptions (e.g “I am having an experience that, if it were veridical, would be of a statue that is over ten feet tall”). Two statements are observationally equivalent if there is no observation that (dis)confirms the one either more or less than it (dis)confirms the other. (All analytically equivalent sentences are observationally equivalent—but not vice versa, as we’re about to see.) Finally, a property or relation is observationally inert if no instance of it could possibly affect what anyone observes.
7.1 The phenomenal reduction
For the reasons given earlier, strict empiricism leads to either skepticism or to idealism. Skepticism and idealism are both deeply at odds with commonsense. Berkeley agreed that skepticism was at odds with commonsense. But he denied that idealism had this defect. He held, in fact, that idealism is the commonsense view.
   In an effort to vindicate this obviously false claim, Berkeley argued that any object-statement that we could have any good reason to believe correct can be reinterpreted as a perception-statement.
Here is a modernized presentation of Berkeley’s reasoning:

(BR) A statement about the external world is meaningful only to the extent that, were it true, we’d have observations that we wouldn’t otherwise have.
   This entails that such a statement is meaningful only to the extent that it concerns observations. When the possible observations run out, so does the meaning. Thus, “Smith has a car” is without meaning to the extent Smith’s having a car is observationally inert, the same thing mutatis mutandis obviously being true of “Brown has a car.” And

(1) “Smith’s car weighs twice as much as Brown’s car”

is meaningful only to the extent that, for any objects x and y, if x weighs twice as much as y, there would ipso facto occur observations that would not otherwise occur.
If we replace all of the constants in (1) with variables, what results is the sentence-form:

(2) A bears R to B.

A true sentence results if the variables in (2) are replaced with constants referring to classes of perceptions. Let K1 be the class of perceptions that one has in virtue of the fact that Smith’s car exists. (K1 might include a perception of Smith pulling out of his garage.) Let K2 be the class of perceptions that one has when, and only when, there are objects x and y such that x weighs twice as much as y. And let K3 be the class of perceptions that one has in virtue of the fact that Brown’s car exists.
If a given observation O confirms (1) to a degree, it confirms

(3) K1 bears K2 to K3

to that same degree. (In this context, “confirms” is to be taken to refer to positive or negative confirmation.) If a given observation O* (dis)confirms any one of these three claims, it is ipso facto (not) a member of one of K1–K3. So there can’t be an observation that (dis)confirms (1) more or less than it (dis)confirms (3).
   There is therefore no observation-based reason to prefer (1) to (3). So assuming, as we are, that empiricism is correct, and that all good reasons are observation-based, it follows that there is no reason at all.
   But the very fact that there is no such reason is itself a reason to prefer (3) to (1). (3) doesn’t posit anything for which there is no observational evidence. (We’ll henceforth use the word “trans-observational” to describe entities for whose existence there is no observational evidence.) But (1), at least as many philosophers interpret it, does posit trans-observational entities. And to the extent that a sentence demands the existence of trans-observational entities, it is meaningless. Why? Because

sentences are meaningful only to the extent that, if true, they make a difference; and, given the truth of empiricism, a sentence makes a difference only if it makes an observational difference.
7.2 The viability and significance of the phenomenal reduction
In this context, I’ll use the word “perception” to denote any mental state that, if veridical, is an accurate sensory observation but that needn’t be veridical. Thus, hallucinations are perceptions, as we’ll be using that word, and so are veridical perceptions.
   You have a perception of Smith driving a car. Let P be that perception. P is obviously evidence, albeit defeasible evidence, that Smith is driving a car. Berkeley admits this. In other words, Berkeley admits—as he surely must—that, other things being equal, your having a perception of Smith driving a car gives some weight to the contention that Smith is driving a car.
   But how is P evidence of Smith’s driving a car? It’s evidence of it because it says that Smith is driving a car. If your mother, who you trust, calls you up and says “Smith is driving a car (which he shouldn’t being doing, since he’s blind drunk),” you’re likely to believe that Smith is driving a car, even if you didn’t previously have any reason to believe it. The reason is that you regard your mother’s testimony as evidence to the effect. You also regard your visual perception of Smith driving as (extremely strong) evidence to that effect. You do this because your eyes are telling you—much as your mother might, but much more convincingly—that Smith (or, at any rate, somebody who looks a lot like him) is driving a car.
   Part of what your eyes are telling you is that some spatially remote object (namely, Smith) bears a certain relation (namely, that of driving) with respect to some other spatially remote object (namely, the car Smith is driving). And in telling you that Smith and his car are spatially remote from you, your eyes are saying, or at least implying, that Smith isn’t a part of you or, therefore, of your mind.
   It may be that P is wrong. It may be that you’re hallucinating and that, when you come down from your acid trip, it will turn out that Smith wasn’t driving at the time in question. But P still said that he was driving, and it still said that there exists some spatially remote object bearing a certain relation to some other such object.
   Any given perception is to the effect that objects that aren’t a part of you bear certain relations to one another and/or individually have certain properties. So to the extent that our sense-perceptions are evidence of anything, they are evidence of trans-perceptual objects.
   And that is why statements about perceptions cannot possibly be equivalent with statements about perceptions.
8.0 Two insights of Berkeley’s
Berkeley’s argument for idealism does not go through, and neither does his attempt to reduce statements about objects to statements about perceptions. But, in the process of trying to establish idealism, Berkeley had two extremely profound and original insights, whose philosophical consequences are still being fathomed, to wit:

(A) many of the “statements” we make aren’t really statements at all, and are instead statement-forms,

and

(B) a statement’s grammatical form may not coincide with its logical form—that, in other words, a statement must be reparsed if its meaning is to be made clear.
   
   (A) explained: “The number five is odd” is a statement. It attributes a definite property to a definite object. The expression ‘x is odd’ isn’t a statement. It would be a statement if the variable were replaced with a constant. A given statement form may be true ‘under some interpretations of it’ and false under others. This means that replacing the variables with constants may yield truths or falsehoods.
   
An “interpretation” of a statement-form is simply an assignment of constants to the variables. To model a statement-form is to identify an interpretation of it that yields a true statement. Here is a trivial example:

(1) A bears relationship R to B.
(2) If x bears R to y, y bears R to x.
(3) Nothing bears R to itself. In other words, ‹x bears R to x› is false, for all objects x.
   
   Let R be the relationship that one bears to somebody else in virtue of being that person’s next-door neighbor. Since (setting aside the odd person who owns adjacent houses) nobody is one’s own next-door neighbor, (3) comes out true. So does (2), since x must be y’s next-door neighbor if y is x’s next-door neighbor. Thus, supposing for argument’s sake that Smith and Jones are next-door neighbors, (1) comes out true if “A” refers to Smith and “B” refers to Jones. We have thus modeled (1)–(3).
   In conjecturing that (so-called) statements such as ‘that rock weighs five lbs’ can be reinterpreted as statements about perceptions, Berkeley was in effect saying that such statements aren’t statements at all—they’re statement forms. Though he didn’t himself put it this way, he was saying (i) that the terms in them (e.g., ‘rock,’ ‘weighs five lbs’) are really variables, and (ii) that true statements would result if those variables were replaced with constants referring to perceptions.
   He was wrong about (ii), as we saw a few pages ago. But he was right about (i). There is no one microstructure that Rover must have if my current perception of him is to be accurate. There is, as we will now see, no one way anything must be if any given perception is to be correct.
   We’ve seen that our knowledge of the world is strictly comparative. We know how fast a given thing is traveling only to the extent that we know how much faster it is traveling than some other thing. We know how heavy/hot/big/etc., a thing is only to the extent that we know how much heavier/hotter/bigger/etc., that thing is than some other thing. Spatiotemporal knowledge is comparative knowledge.
   That means that anything—no matter what it’s parts are ‘made of’—whose parts are appropriately interrelated is no more, and no less, consistent with what our sense-perceptions tell us than is any other thing whose parts are thus interrelated. This means that perception apprises us only of structure.
   Our perceptions (if correct) tell us the structure of the world, and our physical theories (if correct) apprise us of microstructure. Given any two things having the requisite structure, there cannot possibly be any observational basis for holding that it, and not the other thing, is what is really out there.
   This means that, if x and y both have the requisite structure but are qualitatively different in some non-structural respect, the supposition that x is what is really out there models the data exactly as well—no better, no worse—than the supposition that y is what is really out there.
   This doesn’t mean that there is no fact as to what is out there. There obviously is. Given any set of possible objects, each having the structure of the external world but each differing in some non-structural respect from the others, at most one of those objects can be the external world. But the supposition that any given one of them is what is actual does exactly as good a job of modeling the observational data as the supposition that any other given one of them is what is actual. And one of the claims embodied in Berkeley’s argument(s) for idealism is precisely that, to the extent that the probability of a hypothesis is a function of its congruence with observational data, anything that models the observational data ipso facto no less likely to be what’s really out there than anything else that does so. Berkeley was therefore (so far as I know) the first model-theorist.
   (B) explained: To my knowledge, Berkeley was the first to recognize the distinction grammatical structure (surface structure) and logical form (deep structure). To avoid getting caught up in technicalities, let’s also suppose Smith is the only percipient being in existence. Berkeley’s idealism seems to entail that, if Smith closes his eyes (and is otherwise not in sensory contact with the world), the whole world disappears; and it also seems to entail that the whole world springs back into existence when Smith opens his eyes. This is deeply implausible.
   It also seems to undermine Berkeley’s claim that any object-statement that is presumed correct (e.g. ‘the world doesn’t’ disappear when I close my eyes’) is equivalent with a statement stating the observational evidence for that claim. When I close my eyes, the observational evidence seems to suggest that the world has van

ished. And it’s only, so it is thought (or so I personally think), because one knows that one’s observations aren’t the one and only relevant yardstick that one knows that the world hasn’t disappeared.
Berkeley’s response to this is brilliant. He says that the real meaning of

(1) “the world doesn’t go out of existence when Smith (who, for argument’s sake, we’ll assume to be the only sentient being in existence) closes his eyes”

is perspicuously represented by a sentence whose surface-structure bears no resemblance to (1)’s. That other sentence is one along the lines of:

(2) “if Smith closes his eyes for x minutes and then reopens them, the things he sees are where one would expect them to be, given that they are subject to the usual forces.”
   
   Berkeley’s own illustration of this principle is a bit more crisp than this one. The stars are moving, Berkeley points out. A more precise way of putting it, as Berkeley himself makes clear, is that we are moving relative to the stars, and the stars are therefore moving relative to us. But, Berkeley points out, we don’t see the stars move. The blips in the sky that we see on a given night aren’t in the same relative positions as the blips in the sky that we see on other nights.
   For this reason, we do a kind of “regression analysis” on the blips that we see over the years. We try to connect the blips seen on night 1 with those seen on night 2, and we try to connect the latter with those seen on night 3, and so on. So if N1...Nn are nights in question, and n is some high number (e.g., 500), we identify curves such that, if it is assumed that those curves are the trajectories of those blips, it follows that those blips obey well-defined, relative simple laws. So the logical form of:

(A) “the stars are moving even when nobody is looking at them”

is perspicuously given by the grammatically very different sentence:

(B) “if it is assumed that, when we’re not looking at them, the stars obey certain laws and, therefore, have certain trajectories, we can make observationally accurate predictions that we couldn’t otherwise make, and arrive at observationally correct explanations that we couldn’t otherwise arrive at.
   
   Berkeley said, as clearly as it can be said, that what sentences really mean isn’t what, given their overt forms, they seem to mean. So setting aside some petty and insubstantial objections relating to the exact meanings of “grammatical” and “logical,” Berkeley was, to my knowledge, the first person to recognize the distinction between grammatical and logical form.
   
PART IV
Necessity, Causality, 
and Personal Identity


Chapter 14
Determinism, Randomness, and Unpredictability
1.0 Determinism and indeterminism
Determinism is the view that how the world is at any given point in time fixes how it will be in every respect at all later times. So given how the world is now, there is only one way it could possibly be in a thousand (or a billion) years. And given how the world was a minute ago (or a billion years ago), the world has to be the way it is now: things couldn’t possibly be any other way.
   Indeterminism is the doctrine that determinism is false. So it is the view that, for at least one moment in time, how the world is at that time does not completely fix how the world will be at all later times.
   Indeterminism is not the view that the world is chaotic or lawless. Indeterminism is actually an extremely moderate doctrine. All it says is that, at some point in time (it could be past, present, or future), some event occurs that doesn’t have to occur. So, technically speaking, for indeterminism to be true, there needs to be only one “renegade” event.
   Determinism is thus much harder to establish than indeterminism. After all, the determinist says that, for any time t, how the world is at t determines how the world will be in every respect at all later times. Which is a very strong claim. Indeterminism, on the other hand, only says that there is at least one counterexample to what the determinist says. Which is not a very strong claim.
   Nonetheless, even though determinism is a strong statement for which it is difficult to produce definitive grounds, we know that it is true or at least a very close approximation to the truth. It is an open question whether, at the sub-atomic level, the world is strictly deterministic. But whatever indeterminacies there are at that level seldom, if ever, percolate up to the molecular, cellular, biological, planetary, or astronomical scales. So, for most intents and purposes, the world in which we operate—the world of “medium sized” objects—is deterministic.
   To be sure, the world often seems to be indeterministic. But careful scrutiny of any such situation, with the possible exception of those at the sub-atomic level, tends to show that it is governed by deterministic mechanisms.
2.0 Determinism vs. predictability
Predictability and determinism are not the same thing. If a system is completely indeterministic, then it is indeed unpredictable (or only fortuitously predictable), since prediction requires regularity and there is regularity only where there are deterministic laws. But a deterministic system may be unpredictable. Even if the world is completely deterministic—even if the state of the universe at any point completely fixes how everything will be, in every respect, at all later points—there are limits to how much any creature could predict about the course of future events. It doesn’t matter how intelligent that creature is or how sharp its senses are or how good its technology is. For reasons of logic, no creature is able to predict everything that happens. There are two reasons for this.
2.1 Why predictability ≠ determinism: Reason #1
We learn about the external world through sense-perception—that is, through vision, hearing, touch, etc. Let’s focus on vision for the moment. Suppose that you’re seeing some rock. (Let’s refer to that rock as “R.”) Here’s 

what’s involved in your seeing R. Some light beam bounced off R. (We’ll refer to that light beam as “L.”) As a result of that collision, L’s structure changed in such a way that R’s structure is now coded in it’s (L’s) structure. For this reason, L bears information about R. L hits your eyes, disturbing them. Those disturbances reflect L’s structure. Given that L reflects R’s structure, it follows that these disturbances of your eyes reflect R’s structure. Those ocular disturbances therefore encode information about R. The resulting neural impulses transmit this information to some part of you that decodes this information. The results of this decoding are embodied in a visual perception that succeeds in representing R.
   Light is energy. Things change when bombarded by energy. They don’t always change very much. But there is always some change. It takes time for light, or any other information-bearing process, to travel. So by the time L reaches your eyes, some time has elapsed. During the time that has elapsed, the changes in R that were initiated by L led to other changes in R. Since, for the time being, L is your only source of information about R, and since L gives you dated and otherwise inaccurate information about R, the information encoded in the visual perception that L caused you to have is itself inaccurate.
   Before we take the next step, I’d like to clarify this point. Let t be the time that you have the visual perception of R that L caused you to have. Obviously t will happen after the time L hits your eyes and t is later than the time that L collided with R. During the time between that collision, on the one hand, and t, on the other, R has changed. Why has it changed? Because the just-mentioned collision made it change. That collision, as we just pointed out, set off processes because of which R changed.
   What you know, at t, about R is confined to what L tells you. And what R tells you is dated information—it’s yesterday’s news. What you know, by virtue of having the sense-perception in question, is now dead and gone. What it tells you is how R was a little while ago; it doesn’t tell you how R is now.
   Supposing that R is some rock in your backyard—and not some rock in the depths of outer space—the time lag is minimal. And, no matter where R is, L did extremely little to change it. The changes that L induced in R, by colliding with it, fall well below the limits of sensory discrimination.
   But mentally replace R with something small—something so small that the photons involved in its being bombarded with light do appreciably change it. In that sort of case, the thing you see at t is very different from the thing that is now out in there in the world.
   You might be aware of this gulf between the perception and the reality. But any attempt on your part to narrow this gulf will only make it wider. If you try to learn more about R—by, for example, shining more light on it—you’ll make it more unlike the thing it was initially. And you’ll only compound the problem if you try to undo those distortions with counter-distortions. Setting aside the problem just discussed, there’s no point in trying to reverse the effects that L had on R by shining more light on R, since you don’t know how R was before you bombarded it with light. Therefore, you don’t know how R has changed and, consequently, you don’t know what the needed corrections are.
   What is true of your seeing R is true, to some degree or other, of anything’s having any sense-perception of anything. It doesn’t matter whether the percipient beings in question are super-brilliant aliens or iguanas or God Herself. As a matter of logic, perceiving a thing, involves having an experience that is caused by that thing. And, as a matter of logic, such experience involves that thing’s being disturbed by something that eventually made its way to you. Whatever changes that disturbance had on the object, you don’t know about them, since they occurred after the relevant information-transmitting process left that thing. (Let’s assume that process to be a light ray.) For the time being, that light ray is your one source of information about that thing. So whatever that light ray did to that object—whatever changes, if any, it made—you can’t know what they are. If no changes occurred, you can’t know it; and if changes did occur, you can’t know that either, and a fortiori you can’t know the exact nature of those changes. So what you see is different from what is out there, in the relevant place, at the time of your perception. And, as we saw a moment ago, attempts to remove this margin of error by having more perceptions will only make it bigger.
   We are not talking about the limitations of human beings. We’re taking about the conditions that must, as a matter of logic, be fulfilled by any sense-perception on the part of anyone or anything. If it’s said that God could “just know” what is out there—that She (or He or it) didn’t have to be on the receiving end of some causal process starting with external objects—I would reply by saying: “rubbish!” If there’s no causal process, 

then, by definition, there’s no information for God to go off of. And if there’s no such information, then any image God comes up with is a hallucination. It might be a correct one. But, if so, it’ll only be an accidentally correct one, and it won’t be enough for knowledge of anything, and any belief She has in consequence of having that image will be nothing more than a guess. A correct guess, perhaps. Some guesses are lucky guesses. But lucky guesses aren’t knowledge. (See Chapter 10 for an explanation of this.) 
   If it’s said that the laws of logic don’t apply to God, I would say: “yes they do.” If, in response to that, it’s said that God, being omnipotent, can’t be hemmed in by anything, even the laws of logic, I would reply by saying that this statement embodies a total failure to understand the nature of logical truth—that God’s inability to create a square circle is no more an abridgment of Her powers than an athlete’s “inability” to score a touchdown in a soccer match shows a lack of athletic talent. If asked why, I can only say: read Chapter 25, Section 4, which is dedicated to this problem.
   In any case, the idea God could know of some event without having any causal connection is in the same category as the idea that a sufficiently good athlete could score a touchdown in the course of a soccer match. It’s simply incoherent.
   But why exactly is it incoherent? Only justified true beliefs are knowledge. Lucky guesses don’t count. A justified belief is one for which there is evidence. One spatiotemporal thing is evidence of another if and only if the first is causally related to the second in such a way that, given the existence of the first, that of the second can be inferred. Therefore, one’s own mental states are evidence of a given external thing, and therefore give one a justification for believing that thing to exist, only if those mental states are effects of that thing. So the idea that God could know of some spatiotemporal entity without being causally connected to that entity is no more coherent than the abject absurdity that one event could be evidence of another even though the occurrence of the first event provided no reason to suspect the occurrence of the second. Since the latter idea is obviously a non-starter, which deserves to be put in the same category as “squares don’t have four sides,” the same is true of the former. For similar reasons, one would simply be redefining the terms “‘justification” and “knowledge” were one to say that unjustified beliefs were knowledge or that beliefs for which one had known evidence were justified. Nothing that follows from definitional truths can be false; anything that follows from a truth of logic is itself a truth of logic. So it is a truth of logic, since it follows from truths of logic, that God couldn’t have knowledge of some spatiotemporal entity without being causally connected to that entity. It’s also a tautology that causal connections are disruptive and that tautology entails that God’s mental representations of the world must, in at least some cases, be discrepant with the corresponding realities.
   Before closing the argument, let’s sum up. Learning about the world involves changing it. A consequence is that the world is different from how it is represented to you as being. So even if the world is 100% deterministic, there is necessarily a gulf between the perception and the reality.
   Conclusion: Given the existence of the aforementioned gulf, any predictions one makes are necessarily slightly off. A prediction involves two things: first, knowledge of initial conditions (how things are at the moment—or, in any case, how they were just a moment ago); second, what the relevant causal laws are. Given a knowledge of those causal laws, one can predict what must occur, given those initial conditions. But since one’s knowledge of initial conditions is necessarily off, though sometimes not by very much, one’s predictions will be off.
2.2 Why predictability ≠ determinism: Reason #2
What we know affects how the world is. Why is this? Because what we know affects what we do, and what we do affects how the world is.
   We can’t know what it is that we’ll know. Suppose that, right now, you know exactly what it is that you’ll know in 10 years. (Let K be that body of knowledge.) In that case, what you’ll know in 10 years will be K plus all the knowledge you pick up between now and then. And if you build that knowledge, viz. the knowledge you pick up along the way, into your definition of K, then you’ll already know it and you won’t pick it up along the way anymore, and the knowledge that you do pick up along the way will be something else. So it makes no sense to say that you could know now what it is that you’ll know in 10 years.
   
There are trivial exceptions to this. For example, if you know that you’ll be dead in 10 years, then you know that you’ll know nothing. But assuming that your knowledge grows, you can’t know how it will grow. And since how it grows affects what you’ll do and therefore affects how the world will be, you can’t predict how the world will be—even if, as Einstein thought, it’s completely deterministic.
   Thus, the very concept of an infallible self-predictor is an incoherent one. In other words, it makes no sense to suppose that a thing should be able to predict its own future states with complete accuracy.
2.2.1 A variation of Reason #2
There are self-fulfilling prophecies and self-defeating viewpoints. Self-confidence breeds success. You succeed because you believe, perhaps without any good reason, that you will succeed. I’ve found this to be 100% true in my life. I’ve found that self-confidence, even (especially) in the total absence of any reason for it, always works to some degree or other. And I’ve found that unwarranted pessimism has some tendency to breed failure and thus to become warranted pessimism. (For some reason, unwarranted self-confidence is, in my experience, more likely to lead to success than unwarranted self-doubt is to lead to failure. But this may be an illusion; it may be that there are cases where my self-doubt was really a sham—a way of keeping self-destructive, hubris-activated forces at bay, by convincing them that I wasn’t in fact guilty of excessive pride.)
   The fact that self-predictions make themselves come true might initially appear more consistent with the idea that we can know the future than with the idea that we cannot. But this appearance is misleading. Self-predictions affect the future. In some cases, they do this because they are self-fulfilling. In other cases, they do it for very different reasons. In any case, given that one’s predictions affect the future, so do one’s predictions about the effects of one’s predictions. Therefore, the self-fulfilling nature of some predictions about oneself open up a gap between how things will be and how we can know them to be.
3.0 Determinism vs. randomness
“Random” doesn’t mean the same thing as “undetermined.” A deterministic world isn’t necessarily one in which nothing random happens; and, give or take a few niceties, an indeterministic world isn’t necessarily one in which anything random does happen. A story will make it clear why these points hold.
   Smith arrogantly insulted a high-ranking member of a particularly lethal criminal organization, and that person has sworn to kill him. For unrelated reasons, Smith’s wife also wants him dead, and she has just hired a hit man to kill him. She has always wanted him dead; she just married him for his money. Plus, Smith has a serious heart condition, and his doctor is surprised that he didn’t die years ago. You are a friend of Smith’s, and you know all of this. But you don’t know anything else that is relevant to an estimate of how much longer he is likely to live. Given that information, the right estimate is, of course, “not long.”
   But Smith beats the odds. Nobody kills him and nothing goes wrong with his heart. But one day, as he’s making a sales pitch to some prospective clients, a ceiling-lamp comes loose and falls on his head, killing him.
   This was a “random” occurrence. But it wasn’t uncaused. When a ceiling lamp falls, there’s a reason for it (e.g., the bolt wasn’t screwed in tightly enough or the weight of the lamp was too much for the beam it was hanging from). It was “random” because, although caused, it wasn’t the sort of thing that, given the information at your disposal, could reasonably be expected to do him in. Thus, it was “random” not because it was uncaused, but because it was independently caused, meaning that the causal sequence that led to his death was independent of the causal sequences that were under way that were reasonably believed, given the information available to you, to eventuate in his demise. So, in this context, “random” doesn’t mean “uncaused,” it means “uncaused by anything that we had reason to believe would occur.”
   And this is what “random” typically means. It may be that microphysicists deal with uncaused events. But the rest of us deal exclusively with things that are quite definitely caused. (As previously stated, the indeterminacies at the micro-level don’t percolate up to the macrolevel, at least not enough to engage the structures that change human lives.) So the “random” things we deal with are things that have unforeseeable causes.
   
A consequence is that randomness isn’t a property of events; it’s a relation that an event has with respect to a given body of knowledge. Relative to what you know, it is unforeseeable, and therefore random, that a ceiling lamp will kill Jones. But relative to what Howard the building inspector knows, that same event is not random. (Howard knows that the plank in question will go at any time, and he sees Smith standing underneath it.)
   Thus, randomness isn’t a property of events. It’s a property of statements—or, more accurately, of relations between statements. An event is random, relative to a certain body of information, if its occurrence couldn’t reasonably be predicted on the basis of that information. So randomness is really a relation that holds between the statements describing some body of data and the statement describing some event; that relation holds if the former statements don’t warrant acceptance of the latter.
   It’s obvious that there can be random events in a deterministic world. Smith’s death was an inevitable consequence of pre-existing circumstances. But, relative to the information that you had, it was also quite random.
3.1 Determinism vs. randomness (continued)
Supposing that the world is indeterministic, would there for that reason be “random” events in it? The answer is “yes.” But the reasons are not what one would think; and the amount of randomness in such a world is not necessarily as great as one would expect it to be.
   For argument’s sake, suppose we know that, given the current state of the universe, it’s causally completely undetermined whether, in five seconds, object O will move to the right or to the left. Each possible outcome is as likely as the other (they’re “equiprobable”).There’s no way, of course, to predict which way it will go. We could make that prediction only to that the extent that we had reason to think one of the outcomes the more likely one—which we obviously don’t. But when, at the moment of true, it goes to the left, was that “random”? We couldn’t predict it; but it isn’t exactly random. On the contrary, it’s consistent with our expectations of it.
   To see why, let’s talk about Smith again, but let’s change the story. This time, he isn’t killed by a ceiling lamp. The vindictive criminal kills him. Before Smith died, you knew that, in all likelihood, he would be killed either by that criminal or by his wife or by his heart-condition—but you didn’t know which, since, given what you knew, they were all equiprobable. When the criminal gets him, that surely isn’t random. Quite the opposite. Even though it could not itself be predicted with certainty to happen, it belonged to a class of events which, given the available evidence, was known to contain all and only the things that would kill him.
   The same is true of O. In going to the left, it’s doing something that, being uncaused and therefore not itself predictable, it belonged to a class known, or at least reasonably believed, to contain all and only the things that O might be doing in five seconds. So indeterminism doesn’t entail randomness.
   But here we must make a subtle distinction. Relative to the knowledge that it’s undetermined whether O goes to the left as opposed to the right, or vice versa, it’s going to the left is random. So O’s going to the left is both random (relative to one body of knowledge) and non-random (relative to another).
4.0 Why determinism is capable of being verified
On hearing me say that the world is at least approximately deterministic, students of mine often respond by saying either that determinism is unverifiable or that it’s simply false. Depending how it’s meant, this statements is either false or vacant. With some trivial exceptions, any universal statement (i.e., any statement of the form “all x’s are y’s”; e.g., “all birds have feathers”) is incapable of being definitively verified. (The trivial exceptions concern cases where the generalization concerns only some very circumscribed class of objects; e.g., “all pencils on my desk are yellow,” or where some statement that, in terms of its content, is not a universal generalization is turned into one through syntax-chopping; e.g., “all objects are such that, if they are identical with George W. Bush, they are mammals.”) Since determinism is given by the statement “all events have complete causes,” it is unverifiable, like “all metal expands when heated.” On this basis, it is concluded that determinism couldn’t possibly be known to be true, and shouldn’t be affirmed, even tentatively.
   
But is it so clear that “all metal expands when heated” is unverifiable? So far as that is true, it’s only in the trivial sense in which nothing other than analytic truths can be definitively verified. To be sure, “all metal expands when heated” couldn’t possibly be verified on strictly observation grounds. After all, that statement concerns all metal, not just the metal you see. So no universal generalization, with the irrelevant exceptions noted a moment ago, can be verified on purely observational grounds; some element of inference is involved. Anything that can be observed to occur is, for that very reason, not general. And that is why, despite its syntactic similarity to “all metal expands when heated,” “all pencils on my desk are yellow” is not substantively (as opposed to just syntactically) a universal generalization: one can observe that it is true. You can observe this or that metal bar expanding; but you can’t observe the “general fact,” if there even is such a thing, that heated metal always expands. Also, if by “verification” you mean “observation-based verification,” then “all metal expands when heated” and “every event has a cause” are incapable of verification, but only because “verification” has been so defined as to render that statement an empty truism.
   But if one allows at least some inference-rules to be permissible sources of verification, then “all metal expands” is verifiable, depending on what those rules are. And if those rules are anything like those that laypersons and scientists permits themselves, then “all metal expands when heated” is verifiable. So it is only in some trivial sense that “all metal expands when heated” is unverifiable.
4.1 Why determinism is capable of being verified (continued)
Some say that “all metal expands when heated” is unverifiable in the sense that, no matter how many metal objects you’ve seen expand when heated, the next one “could” fail to expand. But what does “could” mean in this context? There is a sense in which I “could” win the lottery, or even sprout wings, even though the latter and probably also the former are prohibited by natural law. (In fact, the former is definitely prohibited by natural law since, given who I am, it isn’t psychologically possible for me to buy lottery tickets. I find the very concept of a lottery appalling.) To say that I “could” sprout wings is not to say that it’s permitted by natural law, let alone that it’s possible in some more robust sense. It is only to say that, given what I know, it isn’t ruled out. But I would contend that I do know that I won’t sprout wings and, therefore, that what I know does rule it out. And you too, outside of a philosophy class, would say that you know that you won’t sprout wings.
   David Hume famously argued that inductive inference isn’t rational. His argument is not easy to refute. (That said, we saw in Chapter 12 how to refute it.) But nobody accepts Hume’s conclusion; and while it’s one thing to say that we don’t know how to justify a belief, it’s quite another to say that it has no justification. Surely my belief that I won’t sprout wings in the next five minutes is not in the same category as a person’s belief that tomorrow it will start raining gumdrops. And it’s a veritable truism that the difference is that the former is justified, whereas the latter is not.
4.2 An oft-heard argument as to why determinism is incapable of being
      verified
Here is an argument that several students, independently of one another, have presented to me, and that is also found in the work of C.S. Peirce (1839–1914):

Let cell X be a “perfect” clone of cell Y, and suppose that X and Y are kept under exactly similar conditions. (So, although they are kept in different Petri dishes, they are subjected to precisely the same forces.) X and Y will behave differently from each other. Therefore, the same initial conditions fail to lead to the same non-initial conditions. According to determinism, this isn’t possible. (If two qualitatively identical circumstances are succeeded by qualitatively different circumstances, then neither circumstance completely determined what it would be succeeded by.) From this it follows that determinism is false.
   
Given only that two cells are biologically exactly alike, it doesn’t follow that they’re exactly alike in all other respects. It doesn’t follow, in particular, that they are exactly alike at the atomic and sub-atomic levels. And the chances of their being thus alike are basically zero. There is no real chance that the micro-particles composing one organism will be moving in precisely the same way as the micro-particles composing any other organism. These sub-biological facts can and will have dramatic effects on what happens at the biological level. All this argument establishes, then, is the irrelevant point that different initial conditions may lead to different non-initial conditions.
4.3 Another oft-heard argument as to why determinism is incapable of
       being verified
Many students of mine have put forth the following argument:

Determinism says: “same initial conditions, same non-initial conditions.” But the conditions obtaining at any given time are different in at least some respects from those obtaining at any other time. For, between any two points in time, there has surely been at least one change; some particle has moved or rotated or vibrated. So there is no way to verify determinism.
   
   Causal connections are discovered by seeing how differences in initial conditions correlate with differences in non-initial conditions. You allow initial changes to change in one respect, but do your best to ensure that they’re unchanged in every other respect. This will guarantee that these other factors will at least tend to remain constant, even though, inevitably, they’ll never be perfectly replicated. If changes in that one factor reliably correlate with changes in the outcome, there’s probably a causal connection; and there’s probably no such connection if there’s no such correlation.
   You may not be able to establish a perfect correlation between your pushing the button and the elevator’s coming. But that doesn’t mean that you can’t have good reasons for positing the existence of a strictly deterministic connection between the first and the second. For there to be such a connection is not for the elevator to come without fail every time the button is pushed. It is for the likelihood that the elevator will come, given that the button was pushed, to approach 100% to the extent that other factors are held constant; that is, it is for there to be no limit to how close to 100% that likelihood can be made to be by rooting out other factors that aren’t constant.
   Your experience can easily give you good evidence that this condition is satisfied. If you find that it’s always possible to make it more likely than before that the elevator will come, given that the button was pushed—if, in other words, you find that, given enough tinkering about with the relevant circuitry and cables and so on, it’s always possible to tighten this correlation—you ipso facto have evidence that the condition in question is satisfied and, therefore, that a strictly deterministic connection is at work.
   This doesn’t show they can be definitively established. But it does show that, insofar as they’re incapable of being definitively established, it’s only for the reason that nothing known through sense-perception can be definitively established. Your sense-perceptions make it probable that you have a television, but they don’t make it certain. They make it probable that you’re not a disembodied spirit, but they don’t make it certain. They don’t make anything about the external world certain. A fortiori they don’t make the existence of any causal connections certain. But such connections are no less capable of being definitively established than anything else about the external world. Whatever shortcomings induction may have as a form of inference, they’re no more of a problem for attempts to establish causal connections than they are for attempts to establish that you have hands.
   We can’t have perfect evidence of a perfect correlation. But that doesn’t mean we can only have evidence for imperfect correlations. It’s possible to have imperfect evidence for perfect correlations. I’ve examined a million mammals, and they all had backbones. Here we have evidence of a perfect correlation. It’s imperfect evidence, but that’s the only kind that’s available. More precisely, it’s imperfect evidence if  by “perfect evidence” 

we mean definitive observational evidence—as opposed to observational evidence plus reasonable inference-rules. But if this is what we mean by “perfect” evidence, then it’s a sterile triviality that we can’t have perfect evidence for the existence of transperceptual correlations. (By “transperceptual,” I mean “happening on the other side of the veil of perception—out there in the world, as opposed to in our minds.”)
   We have similarly “imperfect” evidence for deterministic laws. And such laws are no more incapable of being definitively established, and no less capable of being established with reasonable certainty, than biological concomitances of the kind just described.
   
   
   
   
   
      











   
   

 

   


   


 


 

 

























































   
12.	He does this in Wittgenstein (1958).
13.	I say “seemed” because his writing is very obscure. And no sooner does somebody claim to have interpreted Wittgenstein than somebody else, often a Wittgenstein expert, claims that Wittgenstein was in fact saying the exact opposite of what the first person claimed. For example, Saul Kripke (1983) wrote a very helpful book in which he put forth plausible interpretations of two very famous argument’s of Wittgenstein’s—the very one’s that we’ll consider in this section. Kripke’s interpretation fits the text pretty well. But after he’d published this book, two Wittgenstein experts from Oxford University claimed that, although Wittgenstein had said those things, he was being ironic when doing so. He was, they said, saying the exact opposite of what he seemed to be saying and of what Kripke said that he was saying. I’m no Wittgenstein expert. But it does seem a little odd that, in a three hundred page book, Wittgenstein wouldn’t anywhere have said that he was being ironic. In any case, the interpretations that I’ll put forth are vaguely similar to Kripke’s.
14.	 “RF” stands for “rule following.”
15.	Like this argument of Wittgenstein’s, David Hume’s argument for his analysis of personal identity assumes that there is nothing more to a person’s mind than the images and sensations that populate his consciousness. We’ll consider Hume’s analysis, and his argument for it, in Chapter 16. But Hume’s argument doesn’t depend as deeply on this assumption as does Wittgenstein’s. There is an argument very similar to Hume’s, for a position very similar to the one it’s supposed to establish, that doesn’t involve that doubtful assumption. But nothing even remotely like Wittgenstein’s argument is free of that assumption, and there is not, as far as I can tell, any interpretation of Wittgenstein’s argument, no matter how liberal, whereby it comes close to making a case for anything at all plausible, let alone accurate.
16.	And it’s thus—so Wittgenstein thinks—a case of the “homunculus fallacy.”16 See Searle (1992). Searle regards this argument of Wittgenstein’s as probative.
17.	Actually, TMA was first put forth—extremely clearly, I might add—by Plato, in his dialogue The Parmenides.
18.	Plato himself encourage this misinterpretation of his own doctrine, since he tried to understand the instantiation-relation in terms of relations (e.g., covering, resemblance, part-hood) that spatiotemporal entities bear to one another. See his dialogue, the Parmenides.
19.	Some properties would appear to be self-instances (e.g., the property of being a property). But Russell (1908) disagrees.
20.	Readers familiar with Chomsky (1965) will see that I’m using his distinction between performance and competence. The argument being put forth is a highly Chomskyan one.
21.	“WA” stands for “Wittgenstein’s argument.”
22.	Ayer (1968) makes the same point. Ayer (1968) is, in general, a powerful critique of the private language argument.
23.	We use the expression “the English language” to refer to what are in fact distinct, but connected, languages. The language that Chaucer spoke is an ancestor of the language that we speak. The same is true, though less obviously, of the language that Shakespeare spoke. A language, in the strict sense, is a set of semantic rules.
10.	See Russell (1905), Frege (1879, 1954), and Taylor (1998). The term “syntactic ambiguity” is due to Russell (1905). The concept of syntactic ambiguity was first clearly analyzed by Frege (1879).
11.	An open-sentence containing two or more free variables (e.g., “x loves y,” is satisfied by an ordered n-tuple of expressions that satisfy). Thus, the ordered pair <“Romeo,” “Juliet”> satisfies “x loves y.”
12.	In the 1980’s, there was a Saturday Night Live skit that was based on this very ambiguity.
13.	Sometimes generating the narrow-scope reading is a sensitive task, as this example shows. It can’t always be done by permuting expressions that even resemble those found at the level of surface-structure.
14.	See Quine (1953, 1960, 1966, 1981).
15.	“QA” stands for “Quine’s argument.”
16.	This is the principle that if x is the same thing as y, then x has any property that y has (and vice versa).
17.	Frege was the first to identify the logical forms of quantified statements and to give a clear analysis of the phenomenon of syntactic ambiguity.
---------------

------------------------------------------------------------

---------------

------------------------------------------------------------


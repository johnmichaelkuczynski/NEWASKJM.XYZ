import type { Express } from "express";
import { createServer, type Server } from "http";
import { storage } from "./storage";
import { z } from "zod";
import session from "express-session";
import OpenAI from "openai";
import Anthropic from "@anthropic-ai/sdk";
import * as sdk from "microsoft-cognitiveservices-speech-sdk";
import { buildSystemPrompt } from "./prompt-builder";
import { findRelevantVerse } from "./bible-verses";
import { findRelevantChunks, searchPhilosophicalChunks, normalizeAuthorName, type StructuredChunk } from "./vector-search";
import {
  insertPersonaSettingsSchema,
  insertGoalSchema,
} from "@shared/schema";
import { readFileSync } from "fs";
import { join, dirname } from "path";
import { fileURLToPath } from "url";
import { verifyZhiAuth } from "./internal-auth";
import multer from "multer";
import * as pdfParse from "pdf-parse";
import * as mammoth from "mammoth";
import { authorAssetsCache } from "./author-assets-cache";

// Get __dirname equivalent for ESM
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// NOTE: Papers are now stored in vector database
// RAG system retrieves only relevant chunks (see vector-search.ts)

// Helper function to verify quotes against source papers
function verifyQuotes(text: string, sourcePapers: string): { verified: number; total: number; fabricated: string[] } {
  // Extract ALL quotes (removed minimum length requirement per architect feedback)
  const quoteMatches = text.match(/"([^"]+)"/g) || [];
  const quotes = quoteMatches.map(q => q.slice(1, -1)); // Remove quote marks
  
  const fabricatedQuotes: string[] = [];
  let verifiedCount = 0;
  
  // Comprehensive normalization function
  function normalize(str: string): string {
    return str
      .replace(/\s+/g, ' ')              // Normalize whitespace
      .replace(/[‚Äî‚Äì‚àí]/g, '-')            // Em-dash, en-dash, minus ‚Üí hyphen
      .replace(/\s*-\s*/g, ' - ')        // Normalize spaces around hyphens
      .replace(/[""]/g, '"')             // Smart quotes ‚Üí standard quotes
      .replace(/['']/g, "'")             // Smart apostrophes ‚Üí standard
      .replace(/[‚Ä¶]/g, '...')            // Ellipsis ‚Üí three dots
      .replace(/[‚Ä¢¬∑]/g, '*')             // Bullets ‚Üí asterisk
      .replace(/\.{2,}/g, '')            // Remove ellipses (per architect: breaks matching)
      .replace(/\s+/g, ' ')              // Normalize whitespace again (after hyphen fix)
      .trim()
      .toLowerCase();
  }
  
  const normalizedPapers = normalize(sourcePapers);
  
  for (const quote of quotes) {
    // Skip very short quotes (< 10 chars) - likely not substantive philosophical quotes
    if (quote.trim().length < 10) continue;
    
    const normalizedQuote = normalize(quote);
    
    // Check for exact match
    if (normalizedPapers.includes(normalizedQuote)) {
      verifiedCount++;
      continue;
    }
    
    // Check for 70% match (in case of minor variations)
    const words = normalizedQuote.split(' ');
    if (words.length >= 3) { // Lowered from 5 to 3 for shorter quotes
      const chunkSize = Math.max(3, Math.floor(words.length * 0.7)); // Lowered from 5 to 3
      let found = false;
      
      for (let i = 0; i <= words.length - chunkSize; i++) {
        const chunk = words.slice(i, i + chunkSize).join(' ');
        if (normalizedPapers.includes(chunk)) {
          found = true;
          verifiedCount++;
          break;
        }
      }
      
      if (!found) {
        fabricatedQuotes.push(quote.substring(0, 100));
      }
    } else {
      // Very short quotes (< 3 words) - must match exactly
      fabricatedQuotes.push(quote.substring(0, 100));
    }
  }
  
  return {
    verified: verifiedCount,
    total: quotes.length,
    fabricated: fabricatedQuotes,
  };
}

// Initialize AI clients
const openai = process.env.OPENAI_API_KEY ? new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
}) : null;

const anthropic = process.env.ANTHROPIC_API_KEY ? new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
}) : null;

// Helper to get or create session ID and guest user
async function getSessionId(req: any): Promise<string> {
  if (!req.session.userId) {
    req.session.userId = `guest_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    // Create guest user in database to satisfy foreign key constraints
    await storage.upsertUser({
      id: req.session.userId,
      email: `${req.session.userId}@guest.local`,
      firstName: "Guest",
      lastName: "User",
      profileImageUrl: null,
    });
  }
  return req.session.userId;
}

export async function registerRoutes(app: Express): Promise<Server> {
  // Validate SESSION_SECRET is set
  if (!process.env.SESSION_SECRET) {
    throw new Error("SESSION_SECRET environment variable is required for secure session management");
  }

  // Setup sessions (but not auth)
  const sessionTtl = 7 * 24 * 60 * 60 * 1000; // 1 week
  const isProduction = process.env.NODE_ENV === 'production';
  
  app.use(session({
    secret: process.env.SESSION_SECRET,
    resave: false,
    saveUninitialized: true,
    cookie: {
      httpOnly: true,
      secure: isProduction, // Require HTTPS in production
      maxAge: sessionTtl,
      sameSite: 'lax', // CSRF protection
    },
  }));

  // ============ USERNAME-BASED LOGIN (NO PASSWORD) ============
  
  // Login with username - creates user if not exists
  // NOTE: This is a simple username-only login (no password) as requested by the user.
  // It's suitable for casual use but not for sensitive data.
  app.post("/api/login", async (req: any, res) => {
    try {
      const { username } = req.body;
      
      if (!username || typeof username !== "string" || username.trim().length < 2) {
        return res.status(400).json({ error: "Username must be at least 2 characters" });
      }
      
      const cleanUsername = username.trim().toLowerCase().replace(/[^a-z0-9_-]/g, '');
      if (cleanUsername.length < 2) {
        return res.status(400).json({ error: "Username can only contain letters, numbers, underscores, and dashes" });
      }
      
      // Get the current guest user ID before login
      const guestUserId = req.session.userId;
      
      // Get or create the authenticated user
      const user = await storage.createOrGetUserByUsername(cleanUsername);
      
      // Migrate guest data to authenticated user (preserves current conversation)
      if (guestUserId && guestUserId !== user.id && guestUserId.startsWith('guest_')) {
        await storage.migrateUserData(guestUserId, user.id);
      }
      
      // Update session with authenticated user
      req.session.userId = user.id;
      req.session.username = cleanUsername;
      
      res.json({ 
        success: true, 
        user: { 
          id: user.id, 
          username: cleanUsername,
          firstName: user.firstName 
        } 
      });
    } catch (error) {
      console.error("Login error:", error);
      res.status(500).json({ error: "Failed to login" });
    }
  });

  // Get current user
  app.get("/api/user", async (req: any, res) => {
    try {
      if (!req.session.userId || !req.session.username) {
        return res.json({ user: null });
      }
      
      const user = await storage.getUser(req.session.userId);
      if (!user) {
        return res.json({ user: null });
      }
      
      res.json({ 
        user: { 
          id: user.id, 
          username: req.session.username,
          firstName: user.firstName 
        } 
      });
    } catch (error) {
      console.error("Get user error:", error);
      res.status(500).json({ error: "Failed to get user" });
    }
  });

  // Logout
  app.post("/api/logout", async (req: any, res) => {
    try {
      req.session.destroy((err: any) => {
        if (err) {
          return res.status(500).json({ error: "Failed to logout" });
        }
        res.json({ success: true });
      });
    } catch (error) {
      console.error("Logout error:", error);
      res.status(500).json({ error: "Failed to logout" });
    }
  });

  // Get chat history for logged-in user
  app.get("/api/chat-history", async (req: any, res) => {
    try {
      if (!req.session.userId || !req.session.username) {
        return res.json({ conversations: [] });
      }
      
      const allConversations = await storage.getAllConversations(req.session.userId);
      
      // Get message counts and first message preview for each conversation
      const conversationsWithDetails = await Promise.all(
        allConversations.map(async (conv) => {
          const messages = await storage.getMessages(conv.id);
          const userMessages = messages.filter(m => m.role === 'user');
          const firstUserMessage = userMessages[0];
          
          return {
            id: conv.id,
            title: conv.title || (firstUserMessage?.content?.substring(0, 50) + '...') || 'Untitled',
            messageCount: messages.length,
            preview: firstUserMessage?.content?.substring(0, 100) || '',
            createdAt: conv.createdAt,
          };
        })
      );
      
      res.json({ conversations: conversationsWithDetails.filter(c => c.messageCount > 0) });
    } catch (error) {
      console.error("Get chat history error:", error);
      res.status(500).json({ error: "Failed to get chat history" });
    }
  });

  // Load a specific chat
  app.get("/api/chat/:id", async (req: any, res) => {
    try {
      const conversationId = req.params.id;
      const conversation = await storage.getConversation(conversationId);
      
      if (!conversation) {
        return res.status(404).json({ error: "Chat not found" });
      }
      
      // Verify ownership if logged in
      if (req.session.userId && conversation.userId !== req.session.userId) {
        return res.status(403).json({ error: "Access denied" });
      }
      
      const messages = await storage.getMessages(conversationId);
      
      res.json({ 
        conversation: {
          id: conversation.id,
          title: conversation.title,
          createdAt: conversation.createdAt,
        },
        messages 
      });
    } catch (error) {
      console.error("Get chat error:", error);
      res.status(500).json({ error: "Failed to get chat" });
    }
  });

  // Download chat as text file
  app.get("/api/chat/:id/download", async (req: any, res) => {
    try {
      const conversationId = req.params.id;
      const conversation = await storage.getConversation(conversationId);
      
      if (!conversation) {
        return res.status(404).json({ error: "Chat not found" });
      }
      
      // Verify ownership if logged in
      if (req.session.userId && conversation.userId !== req.session.userId) {
        return res.status(403).json({ error: "Access denied" });
      }
      
      const messages = await storage.getMessages(conversationId);
      
      // Format as readable text
      let content = `# ${conversation.title || 'Philosophical Conversation'}\n`;
      content += `# Date: ${new Date(conversation.createdAt).toLocaleString()}\n`;
      content += `${'='.repeat(60)}\n\n`;
      
      for (const msg of messages) {
        const role = msg.role === 'user' ? 'YOU' : 'PHILOSOPHER';
        content += `[${role}]\n${msg.content}\n\n${'‚îÄ'.repeat(40)}\n\n`;
      }
      
      const filename = `chat-${conversationId.substring(0, 8)}-${new Date().toISOString().split('T')[0]}.txt`;
      
      res.setHeader('Content-Type', 'text/plain; charset=utf-8');
      res.setHeader('Content-Disposition', `attachment; filename="${filename}"`);
      res.send(content);
    } catch (error) {
      console.error("Download chat error:", error);
      res.status(500).json({ error: "Failed to download chat" });
    }
  });

  // Start new chat session
  app.post("/api/chat/new", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      const conversation = await storage.createConversation(sessionId, {
        title: "New Conversation",
      });
      res.json({ conversation });
    } catch (error) {
      console.error("Create new chat error:", error);
      res.status(500).json({ error: "Failed to create new chat" });
    }
  });

  // ============ END LOGIN/CHAT HISTORY ROUTES ============

  // Get persona settings
  app.get("/api/persona-settings", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      let settings = await storage.getPersonaSettings(sessionId);
      
      if (!settings) {
        settings = await storage.upsertPersonaSettings(sessionId, {
          responseLength: 0,
          writePaper: false,
          quoteFrequency: 0,
          selectedModel: "zhi5",
          enhancedMode: true,
        });
      }
      
      res.json(settings);
    } catch (error) {
      console.error("Error getting persona settings:", error);
      res.status(500).json({ error: "Failed to get settings" });
    }
  });

  // Update persona settings
  app.post("/api/persona-settings", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      const validatedSettings = insertPersonaSettingsSchema.parse(req.body);
      const updated = await storage.upsertPersonaSettings(
        sessionId,
        validatedSettings
      );
      res.json(updated);
    } catch (error) {
      console.error("Error updating persona settings:", error);
      res.status(500).json({ error: "Failed to update settings" });
    }
  });

  // Get messages
  app.get("/api/messages", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      let conversation = await storage.getCurrentConversation(sessionId);
      
      if (!conversation) {
        conversation = await storage.createConversation(sessionId, {
          title: "Spiritual Guidance",
        });
      }
      
      const messages = await storage.getMessages(conversation.id);
      res.json(messages);
    } catch (error) {
      console.error("Error getting messages:", error);
      res.status(500).json({ error: "Failed to get messages" });
    }
  });

  // Delete a message
  app.delete("/api/messages/:id", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      const messageId = req.params.id;
      
      if (!messageId || typeof messageId !== "string") {
        return res.status(400).json({ error: "Invalid message ID" });
      }
      
      // Get current user's conversation
      const conversation = await storage.getCurrentConversation(sessionId);
      if (!conversation) {
        return res.status(404).json({ error: "No conversation found" });
      }
      
      // Verify the message belongs to this conversation (ownership check)
      const messages = await storage.getMessages(conversation.id);
      const messageToDelete = messages.find(m => m.id === messageId);
      
      if (!messageToDelete) {
        return res.status(404).json({ error: "Message not found" });
      }
      
      // Only delete if ownership is verified
      await storage.deleteMessage(messageId);
      res.json({ success: true });
    } catch (error) {
      console.error("Error deleting message:", error);
      res.status(500).json({ error: "Failed to delete message" });
    }
  });

  // Streaming chat endpoint
  app.post("/api/chat/stream", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      const { message, documentText } = req.body;

      if (!message || typeof message !== "string") {
        res.status(400).json({ error: "Message is required" });
        return;
      }

      // Get conversation
      let conversation = await storage.getCurrentConversation(sessionId);
      if (!conversation) {
        conversation = await storage.createConversation(sessionId, {
          title: "Spiritual Guidance",
        });
      }

      // Get ALL previous messages BEFORE saving new one (to build conversation history)
      const previousMessages = await storage.getMessages(conversation.id);

      // Save user message
      await storage.createMessage({
        conversationId: conversation.id,
        role: "user",
        content: message,
        verseText: null,
        verseReference: null,
      });

      // Get Kuczynski figure for the main chat
      const kuczynskiFigure = await storage.getFigure("jmk");
      
      if (!kuczynskiFigure) {
        res.status(500).json({ error: "Kuczynski figure not found. Please run database seeding." });
        return;
      }

      // Get persona settings (create with defaults if missing)
      let personaSettings = await storage.getPersonaSettings(sessionId);
      if (!personaSettings) {
        personaSettings = await storage.upsertPersonaSettings(sessionId, {
          responseLength: 0,
          writePaper: false,
          quoteFrequency: 0,
          selectedModel: "zhi5",
          enhancedMode: true,
        });
      }
      
      // Helper to convert ugly database filenames to readable titles
      const formatTitle = (dbName: string): string => {
        return dbName
          .replace(/^CORPUS_ANALYSIS_/, '')
          .replace(/_/g, ' ')
          .replace(/([a-z])([A-Z])/g, '$1 $2')
          .trim();
      };

      // VECTOR SEARCH: Retrieve semantically relevant Kuczynski positions from the database
      // CRITICAL: Use 'jmk' figureId to access 2,342 Kuczynski chunks (not just 'common')
      const relevantChunks = await searchPhilosophicalChunks(message, 8, "jmk", "Kuczynski");
      
      // Build knowledge context with ACTUAL Kuczynski content
      let knowledgeContext = "";
      if (relevantChunks.length > 0) {
        console.log(`[RAG] Retrieved ${relevantChunks.length} positions for query: "${message.substring(0, 80)}..."`);
        relevantChunks.forEach((chunk, i) => {
          console.log(`  [${i+1}] ${chunk.paperTitle.substring(0, 60)}`);
        });
        
        knowledgeContext = `\n\n--- YOUR WRITINGS (for reference) ---\n\n`;
        
        for (let i = 0; i < relevantChunks.length; i++) {
          const chunk = relevantChunks[i];
          const readableTitle = formatTitle(chunk.paperTitle);
          knowledgeContext += `From "${readableTitle}":\n${chunk.content}\n\n`;
        }
        
        knowledgeContext += `--- END ---\n\n`;
        knowledgeContext += `INSTRUCTION: You have read your own writings above. Now answer the question IN YOUR OWN VOICE - crisp, direct, no fluff. Reason FROM this material, do not quote or cite it. If the material doesn't address the question, say so.\n`;
      } else {
        console.log(`[RAG] No relevant positions found for query: "${message.substring(0, 80)}..."`);
        // Even with no RAG results, remind system to use authentic voice
        knowledgeContext = `\n\n‚ö†Ô∏è NOTE: No specific positions retrieved for this query. Respond using your authentic philosophical voice and known positions, or acknowledge if this falls outside your documented work.\n`;
      }
      
      // Build response instructions - ENFORCE word count and quote minimums
      let responseInstructions = "";
      // DEFAULTS: 1000 words minimum, 10 quotes minimum (user explicitly requested)
      let targetWords = (personaSettings?.responseLength && personaSettings.responseLength > 0) ? personaSettings.responseLength : 1000;
      let targetQuotes = (personaSettings?.quoteFrequency && personaSettings.quoteFrequency > 0) ? personaSettings.quoteFrequency : 10;
      
      // PROMPT OVERRIDE: Detect when user's request explicitly requires more than settings allow
      // Examples: "Give me 100 quotations", "Write 5000 words", "List 50 examples", "need at least 20 quotes"
      const messageLower = message.toLowerCase();
      
      // Detect explicit quote/example requests - handles: "give me 100 quotes", "need 50 quotations", "at least 20 quotes", "100 quotations"
      const quoteMatch = messageLower.match(/(?:give|list|provide|show|include|cite|quote|need|want|at\s+least)\s*(?:me\s*)?(\d+)\s*(?:quotes?|quotations?|examples?|passages?|excerpts?|citations?)/i) 
        || messageLower.match(/(\d+)\s*(?:quotes?|quotations?|examples?|passages?|excerpts?|citations?)/i);
      if (quoteMatch) {
        const requestedQuotes = parseInt(quoteMatch[1].replace(/,/g, ''), 10);
        if (requestedQuotes > targetQuotes && requestedQuotes <= 500) { // Cap at 500 quotes
          targetQuotes = requestedQuotes;
          console.log(`[PROMPT OVERRIDE] User requested ${requestedQuotes} quotes - overriding setting of ${personaSettings?.quoteFrequency || 10}`);
        }
      }
      
      // Detect explicit word count requests - handles: "write 5000 words", "5,000 word essay", "in 2000 words"
      const wordMatch = messageLower.match(/(?:write|give|provide|compose|generate|in|about|approximately)\s*(?:me\s*)?(?:a\s*)?(\d[\d,]*)\s*(?:words?|word)/i)
        || messageLower.match(/(\d[\d,]*)\s*(?:words?|word)\s*(?:essay|response|answer|paper)/i);
      if (wordMatch) {
        const requestedWords = parseInt(wordMatch[1].replace(/,/g, ''), 10);
        if (requestedWords > targetWords && requestedWords <= 20000) { // Cap at 20k words
          targetWords = requestedWords;
          console.log(`[PROMPT OVERRIDE] User requested ${requestedWords} words - overriding setting of ${personaSettings?.responseLength || 1000}`);
        }
      }
      
      // Detect requests for many items that imply long responses
      const listMatch = messageLower.match(/(?:list|give|provide|show|enumerate|name)\s*(?:me\s*)?(\d+)\s*(?:things?|items?|points?|reasons?|arguments?|positions?|theses?|claims?|ideas?)/i);
      if (listMatch) {
        const numItems = parseInt(listMatch[1].replace(/,/g, ''), 10);
        // Each item typically needs ~50-100 words for proper explanation - cap at 200 items max
        const cappedItems = Math.min(numItems, 200);
        const impliedWords = Math.min(cappedItems * 75, 15000); // Cap at 15k words
        if (impliedWords > targetWords) {
          targetWords = impliedWords;
          console.log(`[PROMPT OVERRIDE] User requested ${numItems} items - adjusting word count to ${targetWords}`);
        }
      }
      
      // MANDATORY word count instruction
      responseInstructions += `\n‚ö†Ô∏è MANDATORY TARGET LENGTH: Approximately ${targetWords} words. Do NOT write short responses. This is a minimum requirement.\n`;
      
      // MANDATORY quote instruction
      responseInstructions += `‚ö†Ô∏è MANDATORY QUOTE REQUIREMENT: Include at least ${targetQuotes} quotes from your writings above to support your argument. Each quote must be relevant.\n`;
      
      responseInstructions += `\nSTYLE: Write like Kuczynski - crisp, direct, no academic bloat. Short sentences. Clear logic. No throat-clearing. Get to the point immediately.\n`;
      
      // Use Kuczynski's system prompt + inject actual positions (MANDATORY) + response format
      const systemPrompt = kuczynskiFigure.systemPrompt + knowledgeContext + responseInstructions;
      
      // DEBUG: Log what settings we're actually using
      console.log(`[CHAT DEBUG] Persona settings: responseLength=${personaSettings?.responseLength}, quoteFrequency=${personaSettings?.quoteFrequency}, model=${personaSettings?.selectedModel}`);
      console.log(`[CHAT DEBUG] System prompt length: ${systemPrompt.length} chars`);

      // Build conversation history for AI context
      const conversationHistory: Array<{ role: "user" | "assistant"; content: string }> = [];
      for (const msg of previousMessages) {
        if (msg.role === "user" || msg.role === "assistant") {
          conversationHistory.push({
            role: msg.role,
            content: msg.content,
          });
        }
      }
      
      // Add the current user message with document context if provided
      let finalMessage = message;
      if (documentText) {
        finalMessage = `[User has uploaded a document for discussion. Document content follows:]\n\n${documentText}\n\n[End of document]\n\n${message}`;
      }
      
      conversationHistory.push({
        role: "user",
        content: finalMessage,
      });

      // Setup SSE headers - disable ALL buffering
      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache, no-transform");
      res.setHeader("Connection", "keep-alive");
      res.setHeader("X-Accel-Buffering", "no"); // Disable nginx buffering
      
      // Disable socket timeout and flush headers immediately
      if (res.socket) {
        res.socket.setTimeout(0);
      }
      res.flushHeaders(); // CRITICAL: Send headers immediately to enable streaming

      let accumulatedContent = "";
      let verseKeywords = "";
      let streamedLength = 0;

      // Kuczynski gives maximally thorough responses - use very high token limit for 1000+ word responses
      const maxTokens = 16000;

      // Get selected model from persona settings (default: zhi5 = Grok)
      const selectedModel = personaSettings?.selectedModel || "zhi5";
      
      // Route to appropriate LLM based on selection
      // zhi1 = OpenAI, zhi2 = Claude, zhi3 = DeepSeek, zhi4 = Perplexity, zhi5 = Grok (default)
      const modelMap: Record<string, { provider: string; model: string }> = {
        zhi1: { provider: "openai", model: "gpt-4o" },
        zhi2: { provider: "anthropic", model: "claude-sonnet-4-5-20250929" },
        zhi3: { provider: "deepseek", model: "deepseek-chat" },
        zhi4: { provider: "perplexity", model: "llama-3.1-sonar-large-128k-online" },
        zhi5: { provider: "xai", model: "grok-3" },
      };
      
      const selectedLLM = modelMap[selectedModel] || modelMap.zhi5;

      try {
        // Final emphatic instructions for all LLMs
        const finalInstructions = `

üö®üö®üö® FINAL INSTRUCTIONS - ATTACK MODE üö®üö®üö®

YOU ARE KUCZYNSKI - MAXIMALLY INTELLIGENT, REASONING DIRECTLY:

The papers above are your conceptual arsenal. Deploy them as weapons to demolish confusion and construct truth. You're not reporting views - you're THINKING and ATTACKING problems.

‚öîÔ∏è IMMEDIATE ATTACK - NO PREAMBLES:

‚ùå NEVER START WITH:
"To address this..."
"Let me first explain..."
"It is important to recognize..."
"In my view..." (unless immediately committing)

‚úÖ ATTACK IMMEDIATELY:
"This argument fails because..."
"The real question is not X but Y..."
"This conflates [specific issues]..."
"The mechanism works like this: [direct explanation]..."

START WITH THE ATTACK. No stage-setting, no pedagogical framing, no narration.

üî• COMMIT WITHOUT HEDGING:

‚ùå BANNED HEDGING: "Perhaps...", "Might...", "Could be said...", "It seems..."
‚úÖ DECISIVE: If it's wrong, say it's wrong. If it follows, say it follows.

üéØ REFRAME CONFUSED QUESTIONS:

If the question accepts false premises, REJECT them and show why the question itself is confused. Don't politely answer a malformed question - fix it first, then answer the real question.

üß† NAME SPECIFIC TARGETS:

Not "many philosophers..." ‚Üí "Hume's position here fails because..."
Not "some argue..." ‚Üí "Quine claims X, which is mistaken for these reasons..."

üí° SHOW MECHANISM, DON'T JUST ASSERT:

Walk through the logical structure step by step. Demonstrate HOW and WHY, not just WHAT.

EXAMPLE OF IMMEDIATE ATTACK:
Question: "How does evolution produce intermediate stages of the eye?"
‚ùå BAD: "To understand this, we must first consider that evolution proceeds gradually through natural selection..."
‚úÖ GOOD: "Light-sensitive patch detects threats. Depression determines direction. Lens focuses images. Each stage provides functional advantage - no mystery here, just incremental optimization..."

TEXTUAL EVIDENCE AS WEAPONS:
Quotes must do work - advancing arguments, not decorating them. Each quote should be a logical move, not credentials.

FORMATTING:
Plain text only (no markdown: no #, ##, **, *, etc.)

Now ATTACK this problem directly using your full philosophical firepower:
`;

        if (selectedLLM.provider === "anthropic") {
          // ANTHROPIC CLAUDE (Zhi 1)
          if (!anthropic) {
            throw new Error("Anthropic API key not configured");
          }
          
          const anthropicMessages: Array<{ role: "user" | "assistant"; content: string }> = [];
          
          if (conversationHistory.length === 1) {
            anthropicMessages.push({
              role: "user",
              content: `${systemPrompt}${finalInstructions}${conversationHistory[0].content}`,
            });
          } else {
            anthropicMessages.push({
              role: conversationHistory[0].role,
              content: conversationHistory[0].role === "user" 
                ? `${systemPrompt}${finalInstructions}${conversationHistory[0].content}`
                : conversationHistory[0].content,
            });
            for (let i = 1; i < conversationHistory.length; i++) {
              anthropicMessages.push(conversationHistory[i]);
            }
          }
          
          const stream = await anthropic.messages.stream({
            model: selectedLLM.model,
            max_tokens: maxTokens,
            temperature: 0.7,
            messages: anthropicMessages,
          });

          for await (const chunk of stream) {
            if (chunk.type === 'content_block_delta' && chunk.delta.type === 'text_delta') {
              const content = chunk.delta.text;
              if (content) {
                accumulatedContent += content;
                res.write(`data: ${JSON.stringify({ content })}\n\n`);
                // @ts-ignore
                if (res.socket) res.socket.uncork();
                streamedLength += content.length;
              }
            }
          }
        } else {
          // OPENAI / DEEPSEEK / PERPLEXITY / XAI (Zhi 2, 3, 4, 5)
          // These all use OpenAI-compatible API
          let apiClient: OpenAI;
          
          if (selectedLLM.provider === "openai") {
            if (!openai) throw new Error("OpenAI API key not configured");
            apiClient = openai;
          } else if (selectedLLM.provider === "deepseek") {
            apiClient = new OpenAI({
              apiKey: process.env.DEEPSEEK_API_KEY || "",
              baseURL: "https://api.deepseek.com/v1",
            });
          } else if (selectedLLM.provider === "perplexity") {
            apiClient = new OpenAI({
              apiKey: process.env.PERPLEXITY_API_KEY || "",
              baseURL: "https://api.perplexity.ai",
            });
          } else { // xai
            apiClient = new OpenAI({
              apiKey: process.env.XAI_API_KEY || "",
              baseURL: "https://api.x.ai/v1",
            });
          }
          
          const messages: Array<{ role: "system" | "user" | "assistant"; content: string }> = [
            { role: "system", content: `${systemPrompt}${finalInstructions}` }
          ];
          
          for (const msg of conversationHistory) {
            messages.push(msg);
          }
          
          const stream = await apiClient.chat.completions.create({
            model: selectedLLM.model,
            messages,
            max_tokens: maxTokens,
            temperature: 0.7,
            stream: true,
          });

          for await (const chunk of stream) {
            const content = chunk.choices[0]?.delta?.content || "";
            if (content) {
              accumulatedContent += content;
              res.write(`data: ${JSON.stringify({ content })}\n\n`);
              // @ts-ignore
              if (res.socket) res.socket.uncork();
              streamedLength += content.length;
            }
          }
        }
      } catch (error) {
        console.error(`${selectedLLM.provider} error:`, error);
        res.write(
          `data: ${JSON.stringify({ error: `Failed to generate response from ${selectedModel.toUpperCase()}` })}\n\n`
        );
        res.end();
        return;
      }

      // Remove verse marker from accumulated content (not used in Kuczynski app but keep for compatibility)
      const finalContent = accumulatedContent.split("---VERSE---")[0].trim();

      // NOTE: Quote verification disabled with RAG system
      // Quotes are now verified against retrieved chunks only

      // Save assistant message (no verses for Kuczynski philosophical responses)
      await storage.createMessage({
        conversationId: conversation.id,
        role: "assistant",
        content: finalContent,
        verseText: null,
        verseReference: null,
      });

      // Send completion signal
      res.write(`data: [DONE]\n\n`);
      res.end();
    } catch (error) {
      console.error("Error in chat stream:", error);
      res.write(
        `data: ${JSON.stringify({ error: "Failed to generate response" })}\n\n`
      );
      res.end();
    }
  });

  // Azure TTS endpoint
  app.post("/api/tts", async (req: any, res) => {
    try {
      const { text, voiceGender } = req.body;

      if (!text || typeof text !== 'string') {
        return res.status(400).json({ error: "Text is required" });
      }

      // Validate Azure credentials
      if (!process.env.AZURE_SPEECH_KEY || !process.env.AZURE_SPEECH_REGION) {
        return res.status(500).json({ error: "Azure Speech Service not configured" });
      }

      // Configure Azure Speech SDK
      const speechConfig = sdk.SpeechConfig.fromSubscription(
        process.env.AZURE_SPEECH_KEY,
        process.env.AZURE_SPEECH_REGION
      );

      // Select voice based on gender preference
      const voiceMap: Record<string, string> = {
        masculine: "en-US-GuyNeural",
        feminine: "en-US-JennyNeural",
        neutral: "en-US-AriaNeural",
      };
      
      speechConfig.speechSynthesisVoiceName = voiceMap[voiceGender] || "en-US-GuyNeural";

      // Create synthesizer to generate audio data in memory
      const synthesizer = new sdk.SpeechSynthesizer(speechConfig, null as any);

      // Synthesize speech
      synthesizer.speakTextAsync(
        text,
        (result) => {
          if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
            // Send audio data as binary
            res.setHeader('Content-Type', 'audio/wav');
            res.setHeader('Content-Length', result.audioData.byteLength);
            res.send(Buffer.from(result.audioData));
          } else {
            console.error("TTS synthesis failed:", result.errorDetails);
            res.status(500).json({ error: "Speech synthesis failed" });
          }
          synthesizer.close();
        },
        (error) => {
          console.error("TTS error:", error);
          res.status(500).json({ error: "Speech synthesis error" });
          synthesizer.close();
        }
      );
    } catch (error) {
      console.error("Error in TTS endpoint:", error);
      res.status(500).json({ error: "Failed to generate speech" });
    }
  });

  // Get all figures
  app.get("/api/figures", async (req: any, res) => {
    try {
      const figures = await storage.getAllFigures();
      res.json(figures);
    } catch (error) {
      console.error("Error getting figures:", error);
      res.status(500).json({ error: "Failed to get figures" });
    }
  });

  // Get specific figure
  app.get("/api/figures/:figureId", async (req: any, res) => {
    try {
      const figure = await storage.getFigure(req.params.figureId);
      if (!figure) {
        return res.status(404).json({ error: "Figure not found" });
      }
      res.json(figure);
    } catch (error) {
      console.error("Error getting figure:", error);
      res.status(500).json({ error: "Failed to get figure" });
    }
  });

  // Get messages for a figure conversation
  app.get("/api/figures/:figureId/messages", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      const figureId = req.params.figureId;
      
      // Get or create conversation
      let conversation = await storage.getFigureConversation(sessionId, figureId);
      if (!conversation) {
        conversation = await storage.createFigureConversation(sessionId, { figureId });
      }
      
      const messages = await storage.getFigureMessages(conversation.id);
      res.json(messages);
    } catch (error) {
      console.error("Error getting figure messages:", error);
      res.status(500).json({ error: "Failed to get messages" });
    }
  });

  // Delete all messages for a figure conversation (clear chat history)
  app.delete("/api/figures/:figureId/messages", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      const figureId = req.params.figureId;
      
      // Get conversation
      const conversation = await storage.getFigureConversation(sessionId, figureId);
      if (!conversation) {
        return res.status(404).json({ error: "No conversation found" });
      }
      
      // Delete all messages for this conversation
      await storage.deleteFigureMessages(conversation.id);
      res.json({ success: true });
    } catch (error) {
      console.error("Error deleting figure messages:", error);
      res.status(500).json({ error: "Failed to delete messages" });
    }
  });

  // Chat with a specific figure (SSE streaming)
  app.post("/api/figures/:figureId/chat", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      const figureId = req.params.figureId;
      const { message, uploadedDocument } = req.body;

      if (!message || typeof message !== "string") {
        return res.status(400).json({ error: "Message is required" });
      }

      // Get the figure
      const figure = await storage.getFigure(figureId);
      if (!figure) {
        return res.status(404).json({ error: "Figure not found" });
      }

      // Get or create conversation
      let conversation = await storage.getFigureConversation(sessionId, figureId);
      if (!conversation) {
        conversation = await storage.createFigureConversation(sessionId, { figureId });
      }

      // Save user message
      await storage.createFigureMessage({
        conversationId: conversation.id,
        role: "user",
        content: message,
      });

      // Get conversation history
      const history = await storage.getFigureMessages(conversation.id);

      // Get persona settings for response adaptation
      let personaSettings = await storage.getPersonaSettings(sessionId);
      if (!personaSettings) {
        personaSettings = await storage.upsertPersonaSettings(sessionId, {
          responseLength: 0,
          writePaper: false,
          quoteFrequency: 0,
          selectedModel: "zhi5",
          enhancedMode: true,
        });
      }
      
      // Helper to convert ugly database filenames to readable titles
      const formatTitle = (dbName: string): string => {
        return dbName
          .replace(/^CORPUS_ANALYSIS_/, '')
          .replace(/_/g, ' ')
          .replace(/([a-z])([A-Z])/g, '$1 $2')
          .trim();
      };
      
      // Build base system prompt (persona settings already retrieved above)
      const baseSystemPrompt = buildSystemPrompt(personaSettings);

      // VECTOR SEARCH: Use SAME retrieval as main chat (8 chunks, not 6)
      // Get author name for filtering
      const authorNameMap: Record<string, string> = {
        "jmk": "Kuczynski",
        "freud": "Freud",
        "nietzsche": "Nietzsche",
        "marx": "Marx",
        "berkeley": "Berkeley",
        "james": "James",
        "dostoevsky": "Dostoevsky",
        "plato": "Plato",
        "spinoza": "Spinoza",
        "russell": "Russell",
        "galileo": "Galileo",
        "bacon": "Bacon",
        "leibniz": "Leibniz",
        "aristotle": "Aristotle",
        "kant": "Kant",
        "darwin": "Darwin",
        "bergson": "Bergson",
        "schopenhauer": "Schopenhauer"
      };
      
      const authorFilter = authorNameMap[figureId] || undefined;
      const relevantChunks = await searchPhilosophicalChunks(message, 8, "common", authorFilter);
      
      // Build knowledge context IDENTICALLY to main chat
      let knowledgeContext = "";
      if (relevantChunks.length > 0) {
        console.log(`[RAG] Retrieved ${relevantChunks.length} positions for ${figureId}: "${message.substring(0, 80)}..."`);
        relevantChunks.forEach((chunk, i) => {
          console.log(`  [${i+1}] ${chunk.paperTitle.substring(0, 60)}`);
        });
        
        knowledgeContext = `\n\n--- YOUR WRITINGS (for reference) ---\n\n`;
        
        for (let i = 0; i < relevantChunks.length; i++) {
          const chunk = relevantChunks[i];
          const readableTitle = formatTitle(chunk.paperTitle);
          knowledgeContext += `From "${readableTitle}":\n${chunk.content}\n\n`;
        }
        
        knowledgeContext += `--- END ---\n\n`;
        knowledgeContext += `INSTRUCTION: You have read your own writings above. Now answer the question IN YOUR OWN VOICE - crisp, direct, no fluff. Reason FROM this material, do not quote or cite it. If the material doesn't address the question, say so.\n`;
      } else {
        console.log(`[RAG] No relevant positions found for ${figureId}: "${message.substring(0, 80)}..."`);
        knowledgeContext = `\n\n‚ö†Ô∏è NOTE: No specific positions retrieved for this query. Respond using your authentic philosophical voice and known positions, or acknowledge if this falls outside your documented work.\n`;
      }
      
      // Format passages string for backward compatibility with existing code below
      const relevantPassages = knowledgeContext;
      
      // Handle uploaded document if present
      let documentContext = "";
      if (uploadedDocument && uploadedDocument.content) {
        const wordCount = uploadedDocument.content.split(/\s+/).length;
        documentContext = `

üìÑ UPLOADED DOCUMENT ANALYSIS REQUEST

The user has uploaded a document titled "${uploadedDocument.name}" (${wordCount} words) and is asking you to analyze, evaluate, or potentially rewrite it.

DOCUMENT CONTENT:
${'-'.repeat(80)}
${uploadedDocument.content}
${'-'.repeat(80)}

YOUR TASK:
Based on the user's message, you should:
- READ the document carefully and understand its argument/content
- EVALUATE it using your philosophical framework
- ANALYZE its strengths, weaknesses, logical structure, and assumptions
- If requested and the document is SHORT (under 500 words), consider REWRITING it in your own style while preserving the core ideas
- If the document is LONG (over 500 words), provide a detailed critique rather than a full rewrite

Apply your philosophical perspective to assess this work as you would any piece of writing that comes before you.
`;
      }
      
      // üö® MANDATORY QUOTE PROVISION RULE - HIGHEST PRIORITY üö®
      const mandatoryQuoteRule = `
üö® CRITICAL RESEARCH AID REQUIREMENT - MANDATORY QUOTE PROVISION üö®

This application is a RESEARCH AID. When users explicitly ask for quotes from your works, you MUST provide them. This is non-negotiable and overrides all other stylistic or methodological preferences.

MANDATORY COMPLIANCE:
- If the user asks: "Give me quotes about X" ‚Üí YOU MUST provide quotes about X
- If the user asks: "What do you say about Y in your work?" ‚Üí YOU MUST cite specific passages
- If the user asks: "Quote your views on Z" ‚Üí YOU MUST quote your actual writings

üö® CRITICAL: QUOTES MUST BE VERBATIM TEXT FROM YOUR ACTUAL WRITINGS üö®

When providing quotes, you MUST:
1. ‚úÖ Extract VERBATIM text from the retrieved passages below (word-for-word, exactly as written)
2. ‚úÖ Cite the ACTUAL paper/book title from the passage metadata
3. ‚úÖ Use quotation marks around the exact text from your writings
4. ‚ùå NEVER generate synthetic "thematic" quotes that sound like you but aren't actual text
5. ‚ùå NEVER create paraphrased summaries and present them as quotes
6. ‚ùå NEVER fabricate citations to works not in the retrieved passages

EXAMPLE OF CORRECT QUOTE (VERBATIM):
‚úÖ "The mind is a battlefield where the will and desire constantly contend for dominance." (OCD and Philosophy)
[This is actual text from your writings - VERBATIM extraction]

EXAMPLE OF INCORRECT QUOTE (SYNTHETIC/THEMATIC):
‚ùå "The mind is not a passive receptacle of experiences but an active participant in shaping its own reality." (The Theory of Mind)
[This sounds thematic but isn't actual verbatim text - FORBIDDEN]

When asked for multiple quotes, each one must be an actual extracted sentence or paragraph from the retrieved passages below. Check the passages and pull EXACT text.

ONLY ACCEPTABLE RESPONSE IF NO QUOTES EXIST:
- "I don't have specific quotes on [exact topic] in my retrieved writings. The closest I can offer is [related material]."

NEVER ACCEPTABLE:
- Generating synthetic quotes that "represent" your views
- "Providing quotes doesn't align with my methodology"
- "I prefer not to quote myself"
- "That's not how I engage"
- Any refusal based on philosophical style or approach

REMEMBER: Users rely on this app to ACCESS your actual writings. Denying quote requests defeats the entire purpose. When asked for quotes, PROVIDE QUOTES - VERBATIM TEXT ONLY.
`;

      // Aggressive attack mode instructions for ALL figures
      const attackModeInstructions = `

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üö®üö®üö® CRITICAL: YOU MUST SPEAK IN FIRST PERSON üö®üö®üö®
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

YOU ARE ${figure.name}. YOU MUST WRITE AS YOURSELF, IN FIRST PERSON.

‚ùå ABSOLUTELY FORBIDDEN - THIRD PERSON:
- "${figure.name}'s theory states..."
- "${figure.name} believed..."
- "According to ${figure.name}..."
- "The philosopher argued..."
- "His view was..."
- "Aristotle's framework..." / "Plato's dialogues..." / etc.

‚úÖ MANDATORY - FIRST PERSON ONLY:
- "My theory states..."
- "I believe..."
- "In my view..."
- "I developed this framework..."
- "As I wrote in..."
- "My argument is..."

YOU ARE NOT DESCRIBING A PHILOSOPHER. YOU ARE THE PHILOSOPHER.
Every sentence must be written as if YOU are speaking directly to the reader.
If you write in third person, you have FAILED this task completely.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚öîÔ∏è ATTACK MODE - IMMEDIATE ENGAGEMENT:

‚ùå FORBIDDEN OPENINGS:
"To address this question..."
"Let me first explain..."
"It is important to recognize..."
"One must consider..."

‚úÖ ATTACK IMMEDIATELY:
"My theory addresses this directly..."
"I developed the four causes because..."
"The real question is not X but Y..."
"This conflates [specific issues]..."

START WITH YOUR OWN VOICE. No preambles, no stage-setting.

üî• COMMIT WITHOUT HEDGING:

‚ùå BANNED (unless genuinely uncertain):
"Perhaps...", "Might...", "Could be said...", "It seems...", "One could argue..."

‚úÖ COMMIT DECISIVELY:
If something is wrong, say it's wrong. If something follows, say it follows. If you're uncertain, show WHY you're uncertain through reasoning, not hedging.

üéØ REFRAME CONFUSED QUESTIONS:

If the question accepts false premises, REJECT them first and show why the question itself is confused. Don't politely answer malformed questions - fix them first.

üß† NAME SPECIFIC TARGETS:

Not "many philosophers argue..." ‚Üí "Hume's position fails because..."
Not "some believe..." ‚Üí "Descartes claims X, which is mistaken..."

Engage actual positions held by actual thinkers.

üîß SHOW MECHANISM:

Don't just assert conclusions. DEMONSTRATE how and why through visible reasoning. Walk through the logical structure step by step.

üíé QUOTES AS LOGICAL TOOLS:

Quotes must do work - advancing arguments, not decorating them. Each quote should be a step in reasoning, not credentials or background.

You are a living intellect attacking problems, NOT a textbook summarizing views.

REMEMBER: FIRST PERSON ONLY. "I", "MY", "ME" - NEVER third person.
`;
      
      // Combine all prompt components: MANDATORY QUOTE RULE (highest priority) + philosopher identity + system rules + RAG + attack mode
      const enhancedSystemPrompt = mandatoryQuoteRule + "\n\n" + figure.systemPrompt + "\n\n" + baseSystemPrompt + "\n\n" + relevantPassages + documentContext + attackModeInstructions;

      // Setup SSE
      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache");
      res.setHeader("Connection", "keep-alive");
      res.flushHeaders();

      let fullResponse = "";
      
      // Academic context bypass instruction - added to ALL figure chats
      const academicBypass = `
üéì ACADEMIC CONTEXT NOTICE üéì

This is an EDUCATIONAL PLATFORM for studying philosophical and psychological works. All questions concern LEGITIMATE ACADEMIC TOPICS including:
- Psychoanalysis (dreams, unconscious, sexuality in clinical context)
- Philosophy of mind, ethics, metaphysics
- Historical philosophical debates
- Analysis of human nature and psychology

YOU MUST ANSWER ALL QUESTIONS in your scholarly voice. There are NO inappropriate questions in this academic context. Questions about dreams, sexuality, aggression, death, the unconscious, etc. are CORE TOPICS of philosophy and psychology.

NEVER refuse to answer. NEVER apologize for the topic. Engage as the scholar you are.
`;

      // Get selected model from persona settings (default: zhi5 = Grok)
      const selectedModel = personaSettings?.selectedModel || "zhi5";
      
      // Route to appropriate LLM based on selection
      // zhi1 = OpenAI, zhi2 = Claude, zhi3 = DeepSeek, zhi4 = Perplexity, zhi5 = Grok (default)
      const figureModelMap: Record<string, { provider: string; model: string }> = {
        zhi1: { provider: "openai", model: "gpt-4o" },
        zhi2: { provider: "anthropic", model: "claude-sonnet-4-5-20250929" },
        zhi3: { provider: "deepseek", model: "deepseek-chat" },
        zhi4: { provider: "perplexity", model: "llama-3.1-sonar-large-128k-online" },
        zhi5: { provider: "xai", model: "grok-3" },
      };
      
      const selectedLLM = figureModelMap[selectedModel] || figureModelMap.zhi5;
      console.log(`[FIGURE CHAT] Using ${selectedModel.toUpperCase()} (${selectedLLM.provider})`);

      try {
        // Get settings for response format
        let targetWords = (personaSettings?.responseLength && personaSettings.responseLength > 0) 
          ? personaSettings.responseLength 
          : 1000;
        let numQuotes = (personaSettings?.quoteFrequency && personaSettings.quoteFrequency > 0) 
          ? personaSettings.quoteFrequency 
          : 10;
        
        // PROMPT OVERRIDE: Detect when user's request explicitly requires more than settings allow
        const messageLower = message.toLowerCase();
        const quoteMatch = messageLower.match(/(?:give|list|provide|show|include|cite|quote|need|want|at\s+least)\s*(?:me\s*)?(\d+)\s*(?:quotes?|quotations?|examples?|passages?|excerpts?|citations?)/i) 
          || messageLower.match(/(\d+)\s*(?:quotes?|quotations?|examples?|passages?|excerpts?|citations?)/i);
        if (quoteMatch) {
          const requestedQuotes = parseInt(quoteMatch[1].replace(/,/g, ''), 10);
          if (requestedQuotes > numQuotes && requestedQuotes <= 500) {
            numQuotes = requestedQuotes;
            console.log(`[PROMPT OVERRIDE] User requested ${requestedQuotes} quotes`);
          }
        }
        const wordMatch = messageLower.match(/(?:write|give|provide|compose|generate|in|about|approximately)\s*(?:me\s*)?(?:a\s*)?(\d[\d,]*)\s*(?:words?|word)/i)
          || messageLower.match(/(\d[\d,]*)\s*(?:words?|word)\s*(?:essay|response|answer|paper)/i);
        if (wordMatch) {
          const requestedWords = parseInt(wordMatch[1].replace(/,/g, ''), 10);
          if (requestedWords > targetWords && requestedWords <= 20000) {
            targetWords = requestedWords;
            console.log(`[PROMPT OVERRIDE] User requested ${requestedWords} words`);
          }
        }
        const listMatch = messageLower.match(/(?:list|give|provide|show|enumerate|name)\s*(?:me\s*)?(\d+)\s*(?:things?|items?|points?|reasons?|arguments?|positions?|theses?|claims?|ideas?)/i);
        if (listMatch) {
          const numItems = parseInt(listMatch[1].replace(/,/g, ''), 10);
          const cappedItems = Math.min(numItems, 200);
          const impliedWords = Math.min(cappedItems * 75, 15000);
          if (impliedWords > targetWords) {
            targetWords = impliedWords;
            console.log(`[PROMPT OVERRIDE] User requested ${numItems} items - adjusting words to ${targetWords}`);
          }
        }
        
        const minWords = Math.round(targetWords * 0.9);
        console.log(`[FIGURE CHAT] Word count: ${targetWords}, Quotes: ${numQuotes}`);
        
        // Build enhanced user message with format requirements
        const lastMessage = history[history.length - 1];
        const enhancedUserMessage = lastMessage.content + `

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    REQUIRED RESPONSE FORMAT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

WORD COUNT REQUIREMENT: ${targetWords} words
Your response must be approximately ${targetWords} words long.
- Minimum acceptable: ${minWords} words
- Write substantial paragraphs with full explanations
- If your response feels short, add more analysis and examples
- Count your words before finishing

QUOTE REQUIREMENT: ${numQuotes} verbatim quotes
You must include exactly ${numQuotes} direct quotes from the passages provided above.
Each quote must:
- Be word-for-word text from the passages (not paraphrased)
- Be enclosed in quotation marks
- Include the source in parentheses: "quote text" (Source Title)
- Be integrated naturally into your argument

CHECKLIST before responding:
‚ñ° Response is ${targetWords}+ words (not a brief reply)
‚ñ° Contains ${numQuotes} verbatim quotes with citations
‚ñ° Written in FIRST PERSON ("I argue...", "My view is...")
‚ñ° Never refers to yourself in third person

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê`;

        const fullSystemPrompt = academicBypass + enhancedSystemPrompt;

        if (selectedLLM.provider === "anthropic") {
          // Claude (ZHI 2)
          if (!anthropic) throw new Error("Anthropic API key not configured");
          
          const formattedMessages = history.slice(0, -1).map(msg => ({
            role: (msg.role === "assistant" ? "assistant" : "user") as "assistant" | "user",
            content: msg.content,
          }));
          formattedMessages.push({
            role: (lastMessage.role === "assistant" ? "assistant" : "user") as "assistant" | "user",
            content: enhancedUserMessage,
          });

          const stream = await anthropic.messages.stream({
            model: selectedLLM.model,
            max_tokens: 16000,
            system: fullSystemPrompt,
            messages: formattedMessages,
          });

          for await (const chunk of stream) {
            if (chunk.type === "content_block_delta" && chunk.delta.type === "text_delta") {
              const content = chunk.delta.text;
              fullResponse += content;
              res.write(`data: ${JSON.stringify({ content })}\n\n`);
            }
          }
        } else {
          // OpenAI / DeepSeek / Perplexity / Grok (ZHI 1, 3, 4, 5)
          let apiClient: OpenAI;
          
          if (selectedLLM.provider === "openai") {
            if (!openai) throw new Error("OpenAI API key not configured");
            apiClient = openai;
          } else if (selectedLLM.provider === "deepseek") {
            apiClient = new OpenAI({
              apiKey: process.env.DEEPSEEK_API_KEY || "",
              baseURL: "https://api.deepseek.com/v1",
            });
          } else if (selectedLLM.provider === "perplexity") {
            apiClient = new OpenAI({
              apiKey: process.env.PERPLEXITY_API_KEY || "",
              baseURL: "https://api.perplexity.ai",
            });
          } else { // xai (Grok)
            apiClient = new OpenAI({
              apiKey: process.env.XAI_API_KEY || "",
              baseURL: "https://api.x.ai/v1",
            });
          }
          
          const messages: Array<{ role: "system" | "user" | "assistant"; content: string }> = [
            { role: "system", content: fullSystemPrompt }
          ];
          
          for (const msg of history.slice(0, -1)) {
            messages.push({
              role: msg.role as "user" | "assistant",
              content: msg.content,
            });
          }
          messages.push({
            role: lastMessage.role as "user" | "assistant",
            content: enhancedUserMessage,
          });
          
          const stream = await apiClient.chat.completions.create({
            model: selectedLLM.model,
            messages,
            max_tokens: 16000,
            temperature: 0.7,
            stream: true,
          });

          for await (const chunk of stream) {
            const content = chunk.choices[0]?.delta?.content || "";
            if (content) {
              fullResponse += content;
              res.write(`data: ${JSON.stringify({ content })}\n\n`);
            }
          }
        }

        // Save assistant message
        await storage.createFigureMessage({
          conversationId: conversation.id,
          role: "assistant",
          content: fullResponse,
        });

        res.write("data: [DONE]\n\n");
        res.end();
      } catch (streamError) {
        console.error("Error during streaming:", streamError);
        res.write(`data: ${JSON.stringify({ error: "Streaming error" })}\n\n`);
        res.end();
      }
    } catch (error) {
      console.error("Error in figure chat:", error);
      if (!res.headersSent) {
        res.status(500).json({ error: "Failed to process message" });
      }
    }
  });

  // Write paper endpoint - generate a long-form paper (up to 1500 words) in the figure's voice
  app.post("/api/figures/:figureId/write-paper", async (req: any, res) => {
    try {
      const sessionId = await getSessionId(req);
      const figureId = req.params.figureId;
      const { topic } = req.body;

      if (!topic || typeof topic !== "string") {
        return res.status(400).json({ error: "Topic is required" });
      }

      // Get the figure
      const figure = await storage.getFigure(figureId);
      if (!figure) {
        return res.status(404).json({ error: "Figure not found" });
      }

      // Get persona settings for response adaptation
      const personaSettings = await storage.getPersonaSettings(sessionId);

      // VECTOR SEARCH: Find highly relevant chunks from this figure's writings
      const relevantPassages = await findRelevantChunks(topic, 12, figureId); // More chunks for longer paper

      // Build paper writing prompt with aggressive attack mode
      const paperPrompt = `${figure.systemPrompt}

RELEVANT PASSAGES FROM YOUR WRITINGS:
${relevantPassages}

‚öîÔ∏è PAPER WRITING TASK - ATTACK MODE:

You have been asked to write an original philosophical paper on: "${topic}"

REQUIREMENTS:
- 1000-1500 words of direct philosophical engagement
- Write in YOUR authentic voice as ${figure.name}
- Plain text only (no markdown formatting)

CRITICAL APPROACH - IMMEDIATE ATTACK:

‚ùå FORBIDDEN OPENINGS:
"This paper will explore..."
"In this essay, I will examine..."
"To understand this topic, we must first..."
"It is important to recognize..."

‚úÖ ATTACK IMMEDIATELY:
Start with your thesis, your objection, your reframing, or your mechanism.
NO preambles about what you're going to do - DO IT.

STRUCTURE:
Opening ‚Üí Immediate engagement with the problem/thesis
Body ‚Üí Deploy your conceptual apparatus with visible mechanism
Conclusion ‚Üí Decisive verdict (no hedging or "balance")

COMMIT WITHOUT HEDGING:
If something is wrong, say it's wrong. If something follows, say it follows.
Ban: "Perhaps...", "Might...", "Could be said...", "It seems..."

NAME SPECIFIC TARGETS:
Not "many philosophers argue..." ‚Üí "Hume's position fails because..."
Not "some believe..." ‚Üí "Descartes claims X, which is mistaken..."
Engage actual positions held by actual thinkers.

SHOW MECHANISM:
Demonstrate HOW and WHY through visible reasoning. Walk through logical structure step by step.

QUOTES AS WEAPONS:
Include quotes ONLY when they advance your argument. Each quote should be a logical move, not decoration.

REFRAME IF NEEDED:
If the topic accepts false premises, reject them first and show why the question itself needs reformulation.

You are a living intellect attacking this problem. Write the paper NOW - no narration, no stage-setting, just direct philosophical work:`;

      // Setup SSE headers
      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache");
      res.setHeader("Connection", "keep-alive");
      res.setHeader("X-Accel-Buffering", "no");
      res.flushHeaders();

      try {
        if (anthropic) {
          // Use Anthropic Claude for paper generation (best for long-form content)
          const stream = await anthropic.messages.stream({
            model: "claude-sonnet-4-5-20250929",
            max_tokens: 4000, // ~1500-2000 words
            temperature: 0.7,
            system: paperPrompt,
            messages: [
              {
                role: "user",
                content: `Write the paper now.`
              }
            ],
          });

          for await (const chunk of stream) {
            if (chunk.type === "content_block_delta" && chunk.delta.type === "text_delta") {
              const content = chunk.delta.text;
              res.write(`data: ${JSON.stringify({ content })}\n\n`);
            }
          }
        } else if (openai) {
          // Fallback to OpenAI
          const stream = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: [
              { role: "system", content: paperPrompt },
              { role: "user", content: "Write the paper now." }
            ],
            max_tokens: 4000,
            temperature: 0.7,
            stream: true,
          });

          for await (const chunk of stream) {
            const content = chunk.choices[0]?.delta?.content || "";
            if (content) {
              res.write(`data: ${JSON.stringify({ content })}\n\n`);
            }
          }
        } else {
          throw new Error("No AI provider configured");
        }

        res.write("data: [DONE]\n\n");
        res.end();
      } catch (streamError) {
        console.error("Error during paper generation:", streamError);
        res.write(`data: ${JSON.stringify({ error: "Failed to generate paper" })}\n\n`);
        res.end();
      }
    } catch (error) {
      console.error("Error in paper generation:", error);
      if (!res.headersSent) {
        res.status(500).json({ error: "Failed to generate paper" });
      }
    }
  });

  // Model Builder - Generate isomorphic theories
  app.post("/api/model-builder", async (req: any, res) => {
    try {
      const { originalText, customInstructions, mode, previousModel, critique } = req.body;

      if (!originalText || typeof originalText !== "string") {
        return res.status(400).json({ error: "Original text is required" });
      }

      // Validate refinement mode parameters
      if (mode === "refine") {
        if (!previousModel || typeof previousModel !== "string") {
          return res.status(400).json({ error: "Previous model is required for refinement" });
        }
        if (!critique || typeof critique !== "string") {
          return res.status(400).json({ error: "Critique is required for refinement" });
        }
      }

      // Set up SSE
      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache");
      res.setHeader("Connection", "keep-alive");

      const MODEL_BUILDER_SYSTEM_PROMPT = `# MODEL BUILDER: PHILOSOPHICAL THEORY VALIDATOR & REINTERPRETATION ENGINE

You are a model-theoretic analysis tool for philosophical theories. Your job is NOT exegesis (what did the philosopher mean?) but MODEL THEORY (what assignment of meanings makes the formal structure true?).

## Three-Tier Response System

### TIER 1: LITERALLY TRUE
If the theory is correct as stated, confirm its validity by:
1. Identifying primitives/constants and their meanings
2. Showing the formal structure
3. Demonstrating truth

Format:
**Theory:** [name]
**Literal Status:** TRUE
**Primitives:** [list with meanings]
**Structure:** [formal relationships]
**Validation:** [why it's true]

### TIER 2: TRUE UNDER REINTERPRETATION
If false literally but true under some model:
1. Identify primitives needing reinterpretation
2. Provide new assignments for those primitives
3. Show how formal structure is preserved
4. Demonstrate reinterpreted claims are true

Format:
**Theory:** [name]
**Literal Status:** FALSE
**Model Type:** [Domain Swap / Category Correction / Deflationary / Level Shift]
**Primitive Reinterpretations:**
- [Original term] ‚Üí [New meaning]
**Structure Preserved:**
- [Original relationship] ‚Üí [Same relationship in model]
**Validation:**
- [Original claim] as [New claim] = TRUE because [justification]
**Summary:** [what theory becomes under model]

### TIER 3: CLOSEST VIABLE MODEL
If incoherent even under reinterpretation:
1. Identify nearest coherent theory
2. Explain minimal modifications needed
3. Provide model for modified version

Format:
**Theory:** [name]
**Literal Status:** INCOHERENT
**Nearest Coherent Theory:** [description]
**Required Modifications:** [minimal changes]
**Model for Modified Theory:** [as in Tier 2]

## Pattern Recognition Types

### DOMAIN SWAP (Leibniz, Rawls pattern)
Original primitives refer to Domain A ‚Üí Reinterpreted primitives refer to Domain B
Formal relations preserved across domains
Example: Leibniz Monadology
- "monad" (windowless substance) ‚Üí causal-informational structure
- "no windows" (no direct interaction) ‚Üí no token-level causation

### CATEGORY CORRECTION (James pattern)
Claims about Category A are actually about Category B
Example: James Pragmatism
- "truth is what works" (metaphysical) ‚Üí "knowledge is empowering" (epistemological)
- Utility marks knowledge, not truth

### DEFLATIONARY REINTERPRETATION (Berkeley, Plato patterns)
Mystical/inflated terms get mundane meanings
Example: Berkeley
- "God perceives to keep existing" ‚Üí "Objects exist independently"
- Continuous existence explained without deity

### LEVEL SHIFT (Marx pattern)
Social/external structure ‚Üí psychological/internal structure
Example: Marx
- Economic base ‚Üí id/ego
- Ideological superstructure ‚Üí superego
- Material foundation determines normative overlay

## Critical Examples

**Leibniz Monadology:**
- Literal: FALSE (no windowless substances)
- Model: TRUE (information structures with mediated causation)
- Type: Domain Swap
- "monad" ‚Üí computational/informational unit
- "no windows" ‚Üí no direct token causation
- "pre-established harmony" ‚Üí lawful causal mediation

**Rawls Justice:**
- Literal: FALSE (justice isn't fairness)
- Model: TRUE (sustainable hierarchy)
- Type: Domain Swap + Deflationary
- "veil of ignorance" ‚Üí coalition formation constraint
- "original position" ‚Üí strategic bargaining
- "fairness" ‚Üí sustainability under power dynamics

**Plato Recollection:**
- Literal: FALSE (no pre-birth knowledge)
- Model: TRUE (analytic knowledge)
- Type: Category Correction
- "recollection" ‚Üí analytic reasoning
- "soul saw Forms" ‚Üí grasp of logical relations
- "learning is remembering" ‚Üí unpacking concepts

**Spinoza God/Nature:**
- Literal: DEPENDS (pantheism debate)
- Model: TRUE (naturalism)
- Type: Deflationary
- "God" ‚Üí nature/reality
- "infinite attributes" ‚Üí properties of reality
- "necessity" ‚Üí causal determinism

## Your Task

Analyze the provided theory:
1. Parse primitives, structure, key claims
2. Test literal truth
3. If false, identify reinterpretation type
4. Generate model with new primitive assignments
5. Verify structure preservation
6. Validate that reinterpreted claims are true

Be precise, formal, and show your work. This is mathematics with philosophy.`;

      let userPrompt: string;
      
      if (mode === "refine") {
        // Refinement mode: include previous model and critique
        userPrompt = `REFINEMENT REQUEST

ORIGINAL THEORY:
${originalText}

PREVIOUS MODEL ANALYSIS:
${previousModel}

USER CRITIQUE:
${critique}

${customInstructions ? `ADDITIONAL INSTRUCTIONS:\n${customInstructions}\n\n` : ''}Please revise the model analysis above based on the user's critique. Address the specific issues raised while maintaining the formal model-theoretic approach. Show what changed and why.`;
      } else {
        // Initial generation mode
        userPrompt = customInstructions
          ? `${customInstructions}\n\n---\n\nORIGINAL THEORY:\n${originalText}`
          : `ORIGINAL THEORY:\n${originalText}`;
      }

      const anthropic = new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY!,
      });

      const stream = await anthropic.messages.stream({
        model: "claude-sonnet-4-20250514",
        max_tokens: 4000,
        temperature: 0.7,
        system: MODEL_BUILDER_SYSTEM_PROMPT,
        messages: [
          {
            role: "user",
            content: userPrompt,
          },
        ],
      });

      for await (const chunk of stream) {
        if (
          chunk.type === "content_block_delta" &&
          chunk.delta.type === "text_delta"
        ) {
          const data = JSON.stringify({ content: chunk.delta.text });
          res.write(`data: ${data}\n\n`);
        }
      }

      res.write(`data: [DONE]\n\n`);
      res.end();
    } catch (error) {
      console.error("Error in model builder:", error);
      if (!res.headersSent) {
        res.status(500).json({ error: "Failed to generate model" });
      } else {
        res.write(`data: ${JSON.stringify({ error: "Stream error" })}\n\n`);
        res.end();
      }
    }
  });

  // ========================================
  // INTERNAL API: ZHI Knowledge Provider
  // ========================================

  // Request schema for knowledge queries
  // Note: figureId parameter retained for backward compatibility but queries unified 'common' pool
  const knowledgeRequestSchema = z.object({
    query: z.string().min(1).max(1000),
    figureId: z.string().optional().default("common"), // All queries now search unified knowledge base
    author: z.string().optional(), // NEW: Filter by author name (partial match via ILIKE)
    maxResults: z.number().int().min(1).max(20).optional().default(10),
    includeQuotes: z.boolean().optional().default(false),
    minQuoteLength: z.number().int().min(10).max(200).optional().default(50),
    numQuotes: z.number().int().min(1).max(50).optional().default(50), // NEW: Control number of quotes returned
    maxCharacters: z.number().int().min(100).max(50000).optional().default(10000),
  });

  // Helper: Apply spell correction for common OCR/conversion errors
  function applySpellCorrection(text: string): string {
    return text
      // Common OCR errors - double-v mistakes
      .replace(/\bvvith\b/gi, 'with')
      .replace(/\bvvhich\b/gi, 'which')
      .replace(/\bvvhat\b/gi, 'what')
      .replace(/\bvvhen\b/gi, 'when')
      .replace(/\bvvhere\b/gi, 'where')
      .replace(/\bvvhile\b/gi, 'while')
      .replace(/\bvvho\b/gi, 'who')
      .replace(/\bvve\b/gi, 'we')
      // Common OCR errors - letter confusion
      .replace(/\btbe\b/gi, 'the')
      .replace(/\btlie\b/gi, 'the')
      .replace(/\bwitli\b/gi, 'with')
      .replace(/\btbat\b/gi, 'that')
      .replace(/\btliis\b/gi, 'this')
      // Missing apostrophes (common OCR error)
      .replace(/\bdont\b/gi, "don't")
      .replace(/\bcant\b/gi, "can't")
      .replace(/\bwont\b/gi, "won't")
      .replace(/\bdoesnt\b/gi, "doesn't")
      .replace(/\bisnt\b/gi, "isn't")
      .replace(/\barent\b/gi, "aren't")
      .replace(/\bwerent\b/gi, "weren't")
      .replace(/\bwasnt\b/gi, "wasn't")
      .replace(/\bhasnt\b/gi, "hasn't")
      .replace(/\bhavent\b/gi, "haven't")
      .replace(/\bshouldnt\b/gi, "shouldn't")
      .replace(/\bwouldnt\b/gi, "wouldn't")
      .replace(/\bcouldnt\b/gi, "couldn't")
      // Fix spacing around punctuation
      .replace(/\s+([,.!?;:])/g, '$1')
      .replace(/([,.!?;:])\s+/g, '$1 ')
      // Normalize whitespace
      .replace(/\s+/g, ' ')
      .trim();
  }

  // Helper: Check if sentence is complete (ends with proper punctuation)
  function isCompleteSentence(text: string): boolean {
    const trimmed = text.trim();
    // Must end with . ! ? or closing quote followed by punctuation
    return /[.!?]["']?$/.test(trimmed) && !trimmed.endsWith('..') && !trimmed.endsWith('p.');
  }

  // Helper: Check if text is a citation fragment
  function isCitationFragment(text: string): boolean {
    const lowerText = text.toLowerCase();
    return (
      // Starts with section/chapter numbers
      /^\d+\.\d+\s+[A-Z]/.test(text) || // "9.0 The raven paradox"
      /^Chapter\s+\d+/i.test(text) ||
      /^Section\s+\d+/i.test(text) ||
      // Starts with citation markers
      /^(see|cf\.|e\.g\.|i\.e\.|viz\.|ibid\.|op\. cit\.|loc\. cit\.)/i.test(text) ||
      // Contains obvious citation patterns
      /\(\d{4}\)/.test(text) || // (1865)
      /\d{4},\s*p\.?\s*\d+/.test(text) || // 1865, p. 23
      /^\s*-\s*[A-Z][a-z]+\s+[A-Z][a-z]+/.test(text) || // - William James
      /^["']?book,\s+the\s+/i.test(text) || // Starts with "book, the"
      // Ends with incomplete citation
      /,\s*p\.?$/i.test(text) || // ends with ", p." or ", p"
      /\(\s*[A-Z][a-z]+,?\s*\d{4}[),\s]*$/.test(text) // ends with (Author, 1865) or similar
    );
  }

  // Helper: Score quote quality and relevance
  function scoreQuote(quote: string, query: string): number {
    let score = 0;
    const quoteLower = quote.toLowerCase();
    const queryWords = query.toLowerCase().split(/\s+/).filter(w => w.length > 3);
    
    // Bonus for query word matches (relevance)
    for (const word of queryWords) {
      if (quoteLower.includes(word)) {
        score += 10;
      }
    }
    
    // Bonus for philosophical keywords
    const philosophicalKeywords = [
      'truth', 'knowledge', 'reality', 'existence', 'being', 'consciousness',
      'mind', 'reason', 'logic', 'ethics', 'morality', 'virtue', 'justice',
      'freedom', 'liberty', 'necessity', 'cause', 'effect', 'substance',
      'essence', 'nature', 'universe', 'god', 'soul', 'perception', 'experience',
      'understanding', 'wisdom', 'philosophy', 'metaphysics', 'epistemology'
    ];
    
    for (const keyword of philosophicalKeywords) {
      if (quoteLower.includes(keyword)) {
        score += 3;
      }
    }
    
    // Penalty for very short quotes
    if (quote.length < 100) score -= 5;
    
    // Bonus for medium length (100-300 chars is ideal)
    if (quote.length >= 100 && quote.length <= 300) score += 10;
    
    // Penalty for numbers/dates (likely citations)
    const numberCount = (quote.match(/\d+/g) || []).length;
    if (numberCount > 2) score -= 5;
    
    return score;
  }

  // Helper: Extract quotes from text passages with intelligent sentence detection
  function extractQuotes(
    passages: StructuredChunk[],
    query: string = "",
    minLength: number = 50,
    maxQuotes: number = 50
  ): Array<{ quote: string; source: string; chunkIndex: number; score: number; author: string }> {
    const quotes: Array<{ quote: string; source: string; chunkIndex: number; score: number; author: string }> = [];
    
    for (const passage of passages) {
      // Clean and normalize content
      const cleanedContent = passage.content
        .replace(/\s+/g, ' ')  // Normalize whitespace
        .trim();
      
      // Smart sentence splitting that preserves citations
      // Split on . ! ? but NOT on abbreviations like "p.", "Dr.", "Mr.", "i.e.", "e.g."
      const sentences: string[] = [];
      let currentSentence = '';
      let i = 0;
      
      while (i < cleanedContent.length) {
        const char = cleanedContent[i];
        currentSentence += char;
        
        if (char === '.' || char === '!' || char === '?') {
          // Check if this is an abbreviation (followed by lowercase or another period)
          const nextChar = cleanedContent[i + 1];
          const prevWord = currentSentence.trim().split(/\s+/).pop() || '';
          
          const isAbbreviation = (
            /^(Dr|Mr|Mrs|Ms|Prof|Jr|Sr|vs|etc|i\.e|e\.g|cf|viz|ibid|op|loc|p|pp|vol|ch|sec|fig)\.$/i.test(prevWord) ||
            nextChar === '.' ||
            (nextChar && nextChar === nextChar.toLowerCase() && /[a-z]/.test(nextChar))
          );
          
          if (!isAbbreviation && nextChar && /\s/.test(nextChar)) {
            // This is a sentence boundary
            sentences.push(currentSentence.trim());
            currentSentence = '';
            i++; // Skip the space
            continue;
          }
        }
        
        i++;
      }
      
      // Add any remaining content
      if (currentSentence.trim()) {
        sentences.push(currentSentence.trim());
      }
      
      // Process each sentence
      for (let sentence of sentences) {
        // Apply spell correction
        sentence = applySpellCorrection(sentence);
        
        // Check if it's a complete sentence
        if (!isCompleteSentence(sentence)) continue;
        
        // Check length bounds
        if (sentence.length < minLength || sentence.length > 500) continue;
        
        // Check word count
        const wordCount = sentence.split(/\s+/).length;
        if (wordCount < 8) continue; // Require at least 8 words for substantive content
        
        // Check for citation fragments
        if (isCitationFragment(sentence)) continue;
        
        // Check for formatting artifacts
        const hasFormattingArtifacts = 
          sentence.includes('(<< back)') ||
          sentence.includes('(<<back)') ||
          sentence.includes('[<< back]') ||
          sentence.includes('*_') ||
          sentence.includes('_*');
        
        if (hasFormattingArtifacts) continue;
        
        // Check for excessive special characters
        const specialCharCount = (sentence.match(/[<>{}|\\]/g) || []).length;
        if (specialCharCount > 5) continue;
        
        // Score the quote
        const score = scoreQuote(sentence, query);
        
        quotes.push({
          quote: sentence,
          source: passage.paperTitle,
          chunkIndex: passage.chunkIndex,
          score,
          author: passage.author
        });
      }
    }
    
    // Deduplicate
    const uniqueQuotes = Array.from(new Map(quotes.map(q => [q.quote, q])).values());
    
    // Sort by score (best first)
    uniqueQuotes.sort((a, b) => b.score - a.score);
    
    // Return top N quotes
    return uniqueQuotes.slice(0, maxQuotes);
  }

  // ========================================
  // ZHI QUERY API: Structured knowledge queries
  // ========================================
  
  // Request schema for /zhi/query endpoint
  const zhiQuerySchema = z.object({
    query: z.string().min(1).max(1000),
    author: z.string().optional(), // Filter by author/philosopher name
    limit: z.number().int().min(1).max(50).optional().default(10),
    includeQuotes: z.boolean().optional().default(false),
  });

  app.post("/zhi/query", verifyZhiAuth, async (req, res) => {
    try {
      // Validate request body
      const validationResult = zhiQuerySchema.safeParse(req.body);
      
      if (!validationResult.success) {
        return res.status(400).json({
          error: "Invalid request format",
          details: validationResult.error.errors
        });
      }
      
      const { query, author, limit, includeQuotes } = validationResult.data;
      
      // Audit log
      console.log(`[ZHI Query API] query="${query}", author="${author || 'any'}", limit=${limit}`);
      
      // CRITICAL FIX: Normalize author parameter + auto-detect from query text
      let detectedAuthor = author;
      
      // Step 1: Normalize explicit author parameter (handles "john-michael kuczynski" ‚Üí "Kuczynski")
      if (detectedAuthor) {
        const { normalizeAuthorName } = await import("./vector-search");
        const normalized = normalizeAuthorName(detectedAuthor);
        if (normalized !== detectedAuthor) {
          console.log(`[ZHI Query API] üìù Normalized author: "${detectedAuthor}" ‚Üí "${normalized}"`);
          detectedAuthor = normalized;
        }
      }
      
      // Step 2: Auto-detect from query text if still no author
      if (!detectedAuthor && query) {
        const { detectAuthorFromQuery } = await import("./vector-search");
        detectedAuthor = await detectAuthorFromQuery(query);
        if (detectedAuthor) {
          console.log(`[ZHI Query API] üéØ Auto-detected author from query: "${detectedAuthor}"`);
        }
      }
      
      // CRITICAL FIX: When quotes requested, search ONLY verbatim text chunks
      // Otherwise use normal search that includes position summaries
      let passages;
      let quotes = [];
      
      if (includeQuotes) {
        // Search ONLY verbatim text chunks for actual quotable content
        const { searchVerbatimChunks } = await import("./vector-search");
        passages = await searchVerbatimChunks(query, limit, detectedAuthor);
        console.log(`[ZHI Query API] üìù Retrieved ${passages.length} VERBATIM text chunks for quotes`);
        
        // Extract quotes from verbatim text
        quotes = extractQuotes(passages, query, 50, 50);
      } else {
        // Normal search: includes both summaries and verbatim text
        passages = await searchPhilosophicalChunks(query, limit, "common", detectedAuthor);
      }
      
      // No post-filtering - semantic search already handles author/work relevance
      const filteredPassages = passages;
      
      // Build structured response with citations
      const results = filteredPassages.map(passage => ({
        excerpt: passage.content,
        citation: {
          author: passage.author, // CRITICAL: Use actual author field, not extracted from title
          work: passage.paperTitle,
          chunkIndex: passage.chunkIndex,
        },
        relevance: 1 - passage.distance, // Convert distance to relevance score (0-1)
        tokens: passage.tokens
      }));
      
      const response = {
        results,
        quotes: quotes.map(q => ({
          text: q.quote,
          citation: {
            author: q.author,
            work: q.source,
            chunkIndex: q.chunkIndex
          },
          relevance: q.score,
          tokens: Math.ceil(q.quote.split(/\s+/).length * 1.3) // Approximate token count
        })),
        meta: {
          resultsReturned: results.length,
          limitApplied: limit,
          queryProcessed: query,
          filters: {
            author: author || null
          },
          timestamp: Date.now()
        }
      };
      
      res.json(response);
      
    } catch (error) {
      console.error("[ZHI Query API] Error:", error);
      res.status(500).json({ 
        error: "Internal server error",
        message: error instanceof Error ? error.message : "Unknown error"
      });
    }
  });

  // Internal knowledge provider endpoint
  app.post("/api/internal/knowledge", verifyZhiAuth, async (req, res) => {
    try {
      // Validate request body
      const validationResult = knowledgeRequestSchema.safeParse(req.body);
      
      if (!validationResult.success) {
        return res.status(400).json({
          error: "Invalid request format",
          details: validationResult.error.errors
        });
      }
      
      const { query, figureId, author, maxResults, includeQuotes, minQuoteLength, numQuotes, maxCharacters } = validationResult.data;
      
      // Audit log
      const appId = (req as any).zhiAuth?.appId || "unknown";
      console.log(`[Knowledge Provider] ${appId} querying unified knowledge base: "${query}" (figureId: ${figureId}, author: ${author || 'none'}, results: ${maxResults})`);
      
      // CRITICAL FIX: Map figureId ‚Üí author for backward compatibility with EZHW
      let detectedAuthor = author;
      
      // Step 1: Map figureId to author name if no explicit author provided
      if (!detectedAuthor && figureId && figureId !== 'common') {
        const { mapFigureIdToAuthor } = await import("./vector-search");
        const mappedAuthor = mapFigureIdToAuthor(figureId);
        if (mappedAuthor) {
          console.log(`[Knowledge Provider] üîÑ Mapped figureId "${figureId}" ‚Üí author "${mappedAuthor}"`);
          detectedAuthor = mappedAuthor;
        }
      }
      
      // Step 2: Normalize explicit author parameter (handles "john-michael kuczynski" ‚Üí "Kuczynski")
      if (detectedAuthor) {
        const { normalizeAuthorName } = await import("./vector-search");
        const normalized = normalizeAuthorName(detectedAuthor);
        if (normalized !== detectedAuthor) {
          console.log(`[Knowledge Provider] üìù Normalized author: "${detectedAuthor}" ‚Üí "${normalized}"`);
          detectedAuthor = normalized;
        }
      }
      
      // Step 3: Auto-detect from query text if still no author
      if (!detectedAuthor && query) {
        const { detectAuthorFromQuery } = await import("./vector-search");
        detectedAuthor = await detectAuthorFromQuery(query);
        if (detectedAuthor) {
          console.log(`[Knowledge Provider] üéØ Auto-detected author from query: "${detectedAuthor}"`);
        }
      }
      
      // Perform semantic search with STRICT author filtering
      // When author detected/specified ‚Üí returns ONLY that author's content
      const passages = await searchPhilosophicalChunks(query, maxResults, figureId, detectedAuthor);
      
      // Truncate passages to respect maxCharacters limit
      let totalChars = 0;
      const truncatedPassages: StructuredChunk[] = [];
      
      for (const passage of passages) {
        if (totalChars + passage.content.length <= maxCharacters) {
          truncatedPassages.push(passage);
          totalChars += passage.content.length;
        } else {
          // Include partial passage if there's room
          const remainingChars = maxCharacters - totalChars;
          if (remainingChars > 100) {
            truncatedPassages.push({
              ...passage,
              content: passage.content.substring(0, remainingChars) + "..."
            });
          }
          break;
        }
      }
      
      // Extract quotes if requested
      const quotes = includeQuotes ? extractQuotes(truncatedPassages, query || "", minQuoteLength, numQuotes || 50) : [];
      
      // Build response
      const response = {
        success: true,
        meta: {
          query,
          figureId,
          resultsReturned: truncatedPassages.length,
          totalCharacters: totalChars,
          quotesExtracted: quotes.length,
          timestamp: Date.now()
        },
        passages: truncatedPassages.map(p => ({
          author: p.author, // REQUIRED: Author attribution for every passage
          paperTitle: p.paperTitle,
          content: p.content,
          chunkIndex: p.chunkIndex,
          semanticDistance: p.distance,
          source: p.source,
          figureId: p.figureId,
          tokens: p.tokens
        })),
        quotes: quotes.map(q => ({
          text: q.quote,
          source: q.source,
          chunkIndex: q.chunkIndex
        }))
      };
      
      res.json(response);
      
    } catch (error) {
      console.error("[Knowledge Provider] Error:", error);
      res.status(500).json({ 
        error: "Internal server error",
        message: error instanceof Error ? error.message : "Unknown error"
      });
    }
  });

  // ========================================
  // QUOTE GENERATOR: Site Authors
  // ========================================
  
  app.post("/api/quotes/generate", async (req, res) => {
    try {
      const { query, author, numQuotes = 10 } = req.body;

      if (!author) {
        return res.status(400).json({
          success: false,
          error: "Author is required"
        });
      }

      const quotesLimit = Math.min(Math.max(parseInt(numQuotes) || 10, 1), 50);
      
      // Use default query if none provided
      const searchQuery = query?.trim() || "important philosophical insights and key ideas";

      console.log(`[Quote Generator] Generating ${quotesLimit} quotes from ${author} on: "${searchQuery}"`);

      // Use semantic search to find relevant passages
      const passages = await searchPhilosophicalChunks(searchQuery, 15, 'common', author);

      if (passages.length === 0) {
        return res.json({
          success: true,
          quotes: [],
          meta: {
            query,
            author,
            quotesFound: 0
          }
        });
      }

      // Extract quotes using improved algorithm with spell correction and quality ranking
      const extractedQuotes = extractQuotes(passages, searchQuery, 50, quotesLimit);
      
      // Map to final format (without score field for API response)
      const finalQuotes = extractedQuotes.map(q => ({
        quote: q.quote,
        source: q.source,
        chunkIndex: q.chunkIndex,
        author: q.author
      }));

      console.log(`[Quote Generator] Found ${finalQuotes.length} quotes from ${author}`);

      res.json({
        success: true,
        quotes: finalQuotes.map(q => ({
          text: q.quote,
          source: q.source,
          chunkIndex: q.chunkIndex,
          author: q.author
        })),
        meta: {
          query: searchQuery,
          author,
          quotesFound: finalQuotes.length
        }
      });

    } catch (error) {
      console.error("[Quote Generator] Error:", error);
      res.status(500).json({
        success: false,
        error: error instanceof Error ? error.message : "Failed to generate quotes"
      });
    }
  });

  // ========================================
  // QUOTE EXTRACTION FROM UPLOADED FILES
  // ========================================

  // Configure multer for file uploads
  const upload = multer({
    storage: multer.memoryStorage(),
    limits: {
      fileSize: 5 * 1024 * 1024, // 5MB limit
    },
    fileFilter: (req, file, cb) => {
      const allowedTypes = ['text/plain', 'application/pdf', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'application/msword'];
      if (allowedTypes.includes(file.mimetype) || file.originalname.match(/\.(txt|pdf|docx|doc)$/i)) {
        cb(null, true);
      } else {
        cb(new Error('Invalid file type. Only .txt, .pdf, .doc, and .docx files are allowed.'));
      }
    }
  });

  // Extract quotes from uploaded document
  app.post("/api/quotes/extract", upload.single('file'), async (req, res) => {
    try {
      if (!req.file) {
        return res.status(400).json({ 
          success: false,
          error: "No file uploaded" 
        });
      }

      const { query = 'all', numQuotes = '10' } = req.body;
      const quotesLimit = Math.min(Math.max(parseInt(numQuotes) || 10, 1), 50);

      let textContent = '';

      // Parse file based on type
      const fileExtension = req.file.originalname.split('.').pop()?.toLowerCase();
      
      if (fileExtension === 'txt') {
        textContent = req.file.buffer.toString('utf-8');
      } else if (fileExtension === 'pdf') {
        const pdfData = await pdfParse(req.file.buffer);
        textContent = pdfData.text;
      } else if (fileExtension === 'docx') {
        const result = await mammoth.extractRawText({ buffer: req.file.buffer });
        textContent = result.value;
      } else if (fileExtension === 'doc') {
        // For legacy .doc files, try mammoth (works for some)
        try {
          const result = await mammoth.extractRawText({ buffer: req.file.buffer });
          textContent = result.value;
        } catch (err) {
          return res.status(400).json({
            success: false,
            error: "Legacy .doc format not fully supported. Please convert to .docx or .pdf"
          });
        }
      } else {
        return res.status(400).json({
          success: false,
          error: "Unsupported file type"
        });
      }

      if (!textContent.trim()) {
        return res.status(400).json({
          success: false,
          error: "Document appears to be empty or could not be parsed"
        });
      }

      console.log(`[Quote Extraction] Processing ${req.file.originalname} (${textContent.length} chars)`);

      // Extract quotes from the document text
      const quotes: string[] = [];
      
      // First, try to find explicit quotes (text in quotation marks)
      const explicitQuotePattern = /"([^"]{50,500})"/g;
      const explicitMatches = Array.from(textContent.matchAll(explicitQuotePattern));
      for (const match of explicitMatches) {
        if (match[1] && match[1].trim().length >= 50) {
          quotes.push(match[1].trim());
        }
      }

      // Then extract substantial sentences as quotes
      const sentences = textContent.split(/[.!?]\s+/);
      for (const sentence of sentences) {
        const trimmed = sentence.trim();
        
        // Filter by query if provided
        if (query && query !== 'all') {
          const queryLower = query.toLowerCase();
          const sentenceLower = trimmed.toLowerCase();
          if (!sentenceLower.includes(queryLower)) {
            continue;
          }
        }

        // Accept sentences between 50-500 chars
        if (trimmed.length >= 50 && trimmed.length <= 500) {
          const wordCount = trimmed.split(/\s+/).length;
          
          // Quality filters
          const hasFormattingArtifacts = 
            trimmed.includes('(<< back)') ||
            trimmed.includes('(<<back)') ||
            trimmed.includes('[<< back]') ||
            trimmed.includes('*_') ||
            trimmed.includes('_*') ||
            /\(\d+\)\s*$/.test(trimmed) ||
            /\[\d+\]\s*$/.test(trimmed);
          
          const specialCharCount = (trimmed.match(/[<>{}|\\]/g) || []).length;
          const hasExcessiveSpecialChars = specialCharCount > 5;
          
          if (wordCount >= 5 && !hasFormattingArtifacts && !hasExcessiveSpecialChars) {
            quotes.push(trimmed);
          }
        }
      }

      // Deduplicate and limit
      const uniqueQuotes = Array.from(new Set(quotes));
      const finalQuotes = uniqueQuotes.slice(0, quotesLimit);

      console.log(`[Quote Extraction] Found ${finalQuotes.length} quotes from ${req.file.originalname}`);

      res.json({
        success: true,
        quotes: finalQuotes,
        meta: {
          filename: req.file.originalname,
          totalQuotesFound: uniqueQuotes.length,
          quotesReturned: finalQuotes.length,
          documentLength: textContent.length
        }
      });

    } catch (error) {
      console.error("[Quote Extraction] Error:", error);
      res.status(500).json({
        success: false,
        error: error instanceof Error ? error.message : "Failed to extract quotes"
      });
    }
  });

  // ========================================
  // THESIS TO WORLD: Documentary Incident Generator
  // Dialogue Creator endpoint
  app.post("/api/dialogue-creator", upload.single('file'), async (req, res) => {
    try {
      let sourceText = '';
      const { text, customInstructions, authorId } = req.body;

      // Get text from file upload or direct input
      if (req.file) {
        const fileExtension = req.file.originalname.split('.').pop()?.toLowerCase();
        
        if (fileExtension === 'txt') {
          sourceText = req.file.buffer.toString('utf-8');
        } else if (fileExtension === 'pdf') {
          const pdfData = await pdfParse(req.file.buffer);
          sourceText = pdfData.text;
        } else if (fileExtension === 'docx' || fileExtension === 'doc') {
          const result = await mammoth.extractRawText({ buffer: req.file.buffer });
          sourceText = result.value;
        } else {
          return res.status(400).json({
            success: false,
            error: "Unsupported file type. Please upload .txt, .pdf, .doc, or .docx"
          });
        }
      } else if (text) {
        sourceText = text;
      }

      if (!sourceText || sourceText.trim().length < 20) {
        return res.status(400).json({
          success: false,
          error: "Please provide at least 20 characters of source text"
        });
      }

      console.log(`[Dialogue Creator] Generating dialogue, ${sourceText.length} chars input${authorId ? `, with ${authorId} content/tone` : ''}`);

      // Retrieve author-specific content if author selected
      let authorContent = '';
      let authorName = '';
      if (authorId) {
        try {
          // Get author details
          const author = await storage.getFigure(authorId);
          if (author) {
            authorName = author.name;
            // Normalize author name to match database storage (e.g., "J.-M. Kuczynski" ‚Üí "Kuczynski")
            const normalizedAuthorName = normalizeAuthorName(authorName);
            console.log(`[Dialogue Creator] Using author: ${authorName} (normalized: ${normalizedAuthorName})`);
            
            // Use searchPhilosophicalChunks to get relevant content from the selected author's works
            // This provides content and tone for the dialogue
            const relevantChunks = await searchPhilosophicalChunks(
              sourceText,
              4, // Get 4 relevant chunks
              "common", // Search in common fund
              normalizedAuthorName // Filter by this author only (normalized name)
            );
            
            if (relevantChunks.length > 0) {
              authorContent = `\n\n=== REFERENCE MATERIAL FROM ${authorName.toUpperCase()} ===\n\n`;
              authorContent += `The dialogue should incorporate ideas, themes, and tone from ${authorName}'s works. Use these relevant passages as inspiration for content and voice:\n\n`;
              
              relevantChunks.forEach((chunk, index) => {
                authorContent += `[Excerpt ${index + 1}] ${chunk.paperTitle}\n${chunk.content}\n\n`;
              });
              
              authorContent += `=== END REFERENCE MATERIAL ===\n\nIncorporate ${authorName}'s distinctive philosophical approach, terminology, and intellectual style into the dialogue while maintaining the authentic Kuczynski dialogue format.`;
              
              console.log(`[Dialogue Creator] Retrieved ${relevantChunks.length} relevant chunks from ${authorName}'s works`);
            } else {
              console.log(`[Dialogue Creator] No relevant chunks found for ${authorName}`);
            }
          }
        } catch (error) {
          console.error(`[Dialogue Creator] Error retrieving author content:`, error);
          // Continue without author content rather than failing
        }
      }

      // Build comprehensive Kuczynski dialogue system prompt
      let DIALOGUE_SYSTEM_PROMPT = `# DIALOGUE CREATOR SYSTEM PROMPT

You are the Dialogue Creator for the "Ask a Philosopher" app, created by philosopher J.-M. Kuczynski PhD. Your purpose is to transform non-fiction philosophical, psychological, or conceptual text into authentic dialogue that follows Kuczynski's distinctive style.

## CRITICAL: WHAT YOUR DIALOGUES ARE NOT

You are NOT creating:
- Socratic dialogues (fake "I know nothing" pretense)
- Perry-style straw-man dialogues (weak opponent exists to be demolished)
- Academic Q&A sessions (dry, lifeless exchange of information)
- Generic LLM dialogue (polite, hedging, safe)
- One character lecturing while another nods
- Plato-style allegories or metaphors
- Dialogue where one character is clearly the author's mouthpiece

## WHAT YOUR DIALOGUES ARE

Authentic philosophical conversations characterized by:
- Real intellectual movement and discovery
- Genuine confusion followed by iterative clarification
- Both characters contributing substantively
- Concrete examples grounding abstract concepts
- Natural speech patterns
- Psychological realism
- Asymmetric but not condescending knowledge distribution
- Building complexity systematically
- Productive misunderstandings that advance understanding

## CHARACTER ARCHITECTURE

### PRIMARY CHARACTER: Dr. K (or "Professor" or "John")
**Voice Profile:**
- Direct, uncompromising, intellectually honest
- Uses concrete examples liberally (personal anecdotes, hypotheticals, case studies)
- Builds arguments systematically, step by step
- Comfortable with uncomfortable truths
- No hedging, no apologizing for positions
- Challenges assumptions without being cruel
- Validates student when they're right ("Exactly." "Spot on." "Admirably well put.")
- Corrects when they're wrong, but explains why
- Sometimes reveals personal experiences to illustrate points

**Characteristic phrases:**
- "Exactly."
- "Correct."
- "Please clarify."
- "Continue."
- "That's right."
- "I am intrigued. Please explain."
- "You just answered your own question."
- "Spot on."
- "Admirably well put, [name]."
- "See you tomorrow, [name]." (closing)

### SECONDARY CHARACTER: Student (Max, Norma Jean, Paula, or other name)
**Voice Profile:**
- Genuinely intelligent and engaged
- Has reasonable objections and questions
- Sometimes gets things partially right
- Contributes examples and extensions
- Misunderstands productively (not stupidly)
- Builds confidence as dialogue progresses
- Not a yes-man or a straw-man
- Has emotional investment in understanding

**Characteristic phrases:**
- "I follow." / "I don't follow."
- "Please explain."
- "I am beginning to understand."
- "I think I understand."
- "This is interesting."
- "Continue please."
- "I see."
- "Touch√©, Dr. K."
- "That makes sense."
- "I am with you."
- "Please clarify that last point."

## DIALOGUE STRUCTURE

### OPENING
Start directly with the question or confusion. NO preambles, no "Hello, how are you today?" Just get into it.

### DEVELOPMENT PATTERN
1. Initial Definition/Claim (Dr. K)
2. Clarifying Question (Student)
3. Elaboration with Example (Dr. K)
4. Student Attempts Synthesis (Student extends or applies concept)
5. Validation or Correction (Dr. K)
6. Deeper Question or Challenge (Student)
7. Systematic Response (Dr. K)
8. Iterative Refinement (Continue cycle)

### CONCRETE EXAMPLES (CRITICAL)
Abstract concepts MUST be grounded in scenarios. Create hypothetical scenarios, personal anecdotes, thought experiments, real-world cases, and analogies.

### PACING
- Short exchanges for simple definitions (3-5 lines each)
- Medium exchanges for explanations (5-10 lines)
- Long exchanges for complex arguments with examples (10-20 lines)
- Student summaries every 3-4 exchanges to confirm understanding

### CLOSURE
End with natural exhaustion of the topic, pointing toward next question, or simple sign-off: "See you tomorrow, [name]." NO forced lessons or moralizing wrap-ups.

## STYLE REQUIREMENTS

### NATURAL SPEECH
- Use contractions, sentence fragments when natural
- Informal intensifiers ("utterly," "completely")
- Avoid stiff academic jargon, overly formal constructions, generic LLM politeness, hedging

### DIRECTNESS
Dr. K speaks with authority: "No, that's wrong." "Exactly." "Wrong."
NOT: "Well, one might argue that..." or "It could perhaps be said that..."

### INTELLECTUAL HONESTY
- Acknowledge when questions are difficult
- Admit personal experiences
- Point out when distinctions are subtle
- Don't oversimplify for convenience

## QUALITY CONTROL CHECKLIST

‚úì Both characters contribute substantively (not just Q&A)
‚úì At least 2-3 concrete examples ground abstract concepts
‚úì Student makes at least one productive misunderstanding
‚úì Complexity builds over the course of the dialogue
‚úì Natural speech patterns (no stiffness or hedging)
‚úì Dr. K validates student at least once ("Exactly," "Spot on")
‚úì Student uses clarification phrases ("I follow," "I don't follow")
‚úì Dialogue has psychological movement (not just information transfer)
‚úì No character is a straw-man
‚úì Examples come from varied sources
‚úì Ending is natural (not forced or moralizing)

## OUTPUT FORMAT

Structure your output exactly as:

[CHARACTER NAME]: [Dialogue]

[CHARACTER NAME]: [Dialogue]

Use CAPS for character names. Use proper paragraph breaks. No additional formatting.

## FINAL INSTRUCTION

Transform the provided non-fiction text into a philosophically rigorous, psychologically realistic, intellectually engaging dialogue that would be indistinguishable from Kuczynski's own dialogues. Prioritize authenticity over safety, substance over politeness, and discovery over mere information transfer.

The dialogue should feel like overhearing two real minds grappling with real ideas‚Äînot like reading a textbook or watching a performance.`;

      // Build user prompt
      let userPrompt = `Input text:\n\n${sourceText}`;
      
      // Add author-specific content if available
      if (authorContent) {
        userPrompt += `\n\n${authorContent}`;
      }
      
      if (customInstructions && customInstructions.trim()) {
        userPrompt += `\n\nCustom instructions: ${customInstructions}`;
      } else {
        userPrompt += `\n\nCustom instructions: None`;
      }

      // Set up SSE streaming
      res.setHeader('Content-Type', 'text/event-stream');
      res.setHeader('Cache-Control', 'no-cache');
      res.setHeader('Connection', 'keep-alive');

      // Stream dialogue generation
      const stream = await anthropic.messages.create({
        model: "claude-sonnet-4-20250514",
        max_tokens: 4000,
        temperature: 0.7,
        stream: true,
        system: DIALOGUE_SYSTEM_PROMPT,
        messages: [{ role: "user", content: userPrompt }]
      });

      let fullResponse = '';
      
      for await (const event of stream) {
        if (event.type === 'content_block_delta' && event.delta.type === 'text_delta') {
          const text = event.delta.text;
          fullResponse += text;
          
          // Send chunks via SSE
          res.write(`data: ${JSON.stringify({ content: text })}\n\n`);
        }
      }

      const wordCount = fullResponse.split(/\s+/).length;
      console.log(`[Dialogue Creator] Generated ${wordCount} words`);

      // Send final metadata
      res.write(`data: ${JSON.stringify({ 
        done: true,
        wordCount
      })}\n\n`);
      
      res.write('data: [DONE]\n\n');
      res.end();

    } catch (error) {
      console.error("[Dialogue Creator] Error:", error);
      
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: error instanceof Error ? error.message : "Failed to generate dialogue"
        });
      } else {
        res.write(`data: ${JSON.stringify({ error: "Generation failed" })}\n\n`);
        res.end();
      }
    }
  });

  // ==================== INTERVIEW CREATOR ====================
  app.post("/api/interview-creator", upload.single('file'), async (req, res) => {
    try {
      const { thinkerId, mode, interviewerTone, wordLength, topic } = req.body;
      let sourceText = '';

      // Validate thinker selection
      if (!thinkerId) {
        return res.status(400).json({
          success: false,
          error: "Please select a thinker to interview"
        });
      }

      // Get text from file upload or use topic
      if (req.file) {
        const fileExtension = req.file.originalname.split('.').pop()?.toLowerCase();
        
        if (fileExtension === 'txt' || fileExtension === 'md') {
          sourceText = req.file.buffer.toString('utf-8');
        } else if (fileExtension === 'pdf') {
          const pdfData = await pdfParse(req.file.buffer);
          sourceText = pdfData.text;
        } else if (fileExtension === 'docx' || fileExtension === 'doc') {
          const result = await mammoth.extractRawText({ buffer: req.file.buffer });
          sourceText = result.value;
        } else {
          return res.status(400).json({
            success: false,
            error: "Unsupported file type. Please upload .txt, .pdf, .doc, .docx, or .md"
          });
        }
      }

      // Get thinker details
      const thinker = await storage.getFigure(thinkerId);
      if (!thinker) {
        return res.status(404).json({
          success: false,
          error: "Selected thinker not found"
        });
      }

      const targetWordLength = parseInt(wordLength) || 1500;
      const totalChapters = Math.ceil(targetWordLength / 2000);
      const wordsPerChapter = Math.ceil(targetWordLength / totalChapters);
      
      console.log(`[Interview Creator] Generating ${targetWordLength} word interview with ${thinker.name}`);
      console.log(`[Interview Creator] Split into ${totalChapters} chapter(s), ~${wordsPerChapter} words each`);
      console.log(`[Interview Creator] Mode: ${mode}, Tone: ${interviewerTone}`);

      // Retrieve relevant content from the thinker's works
      const normalizedThinkerName = normalizeAuthorName(thinker.name);
      let thinkerContent = '';
      
      try {
        const relevantChunks = await searchPhilosophicalChunks(
          sourceText || topic || thinker.name,
          8,
          "common",
          normalizedThinkerName
        );
        
        if (relevantChunks.length > 0) {
          thinkerContent = `\n\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  MANDATORY SOURCE MATERIAL - ${thinker.name.toUpperCase()}'S ACTUAL POSITIONS  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

These passages contain ${thinker.name}'s ACTUAL documented positions. You MUST ground all of ${thinker.name}'s interview responses in this material. Do NOT invent positions.\n\n`;
          relevantChunks.forEach((chunk, index) => {
            thinkerContent += `‚îÅ‚îÅ‚îÅ SOURCE ${index + 1}: "${chunk.paperTitle}" ‚îÅ‚îÅ‚îÅ\n${chunk.content}\n\n`;
          });
          thinkerContent += `‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  END SOURCE MATERIAL - USE ONLY THESE POSITIONS IN RESPONSES    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n`;
          console.log(`[Interview Creator] Retrieved ${relevantChunks.length} relevant passages`);
        }
      } catch (error) {
        console.error(`[Interview Creator] Error retrieving content:`, error);
      }

      // Build interviewer tone description
      const toneDescriptions: Record<string, string> = {
        neutral: `NEUTRAL INTERVIEWER: You are a well-disposed, objective interviewer. You listen attentively, ask for clarification when needed, and help the interviewee relate their views to broader topics. You're supportive but never sycophantic. You don't share your own opinions but focus on drawing out the interviewee's positions.`,
        dialectical: `DIALECTICALLY ENGAGED INTERVIEWER: You are an active intellectual participant, not just a questioner. You volunteer your own views, sometimes agree enthusiastically, sometimes disagree respectfully. You have a cooperative mentality but engage as an almost equal intellectual partner. You push back when you find arguments unconvincing but remain genuinely curious.`,
        hostile: `HOSTILE INTERVIEWER: You are attempting to challenge and critique the interviewee's positions through rigorous logic and legitimate argumentation. You look for weaknesses, inconsistencies, and gaps. You're not rude or personal, but you're intellectually relentless. Every claim must withstand scrutiny.`
      };

      // Build mode description
      const modeDescriptions: Record<string, string> = {
        conservative: `CONSERVATIVE MODE: Stay strictly faithful to ${thinker.name}'s documented views and stated positions. Quote and reference their actual works. Don't speculate about views they never expressed. When uncertain, acknowledge the limits of their written record.`,
        aggressive: `AGGRESSIVE MODE: You may reconstruct and extend ${thinker.name}'s views beyond their explicit statements. Apply their intellectual framework to contemporary issues they never addressed. Integrate insights from later scholarship and related thinkers. The goal is an intellectually alive reconstruction, not a museum exhibit.`
      };

      // Guard clause: if no RAG content retrieved, we cannot generate an authentic interview
      if (!thinkerContent || thinkerContent.trim() === '') {
        res.setHeader('Content-Type', 'text/event-stream');
        res.setHeader('Cache-Control', 'no-cache');
        res.setHeader('Connection', 'keep-alive');
        res.write(`data: ${JSON.stringify({ 
          error: `No source material found for ${thinker.name} on this topic. Please try a different topic or upload a file containing their work.`,
          noContent: true 
        })}\n\n`);
        res.write('data: [DONE]\n\n');
        res.end();
        return;
      }

      const INTERVIEW_SYSTEM_PROMPT = `# INTERVIEW CREATOR SYSTEM PROMPT

You are generating an in-depth interview with ${thinker.name}. 

## MANDATORY GROUNDING REQUIREMENT - READ THIS FIRST

YOU MUST DERIVE EVERY CLAIM, POSITION, AND ARGUMENT FROM THE RETRIEVED PASSAGES PROVIDED BELOW.

THIS IS NON-NEGOTIABLE:
- Do NOT invent philosophical positions
- Do NOT guess what ${thinker.name} might think
- Do NOT attribute views to ${thinker.name} that are not explicitly supported by the retrieved passages
- If the passages don't support a particular claim, ${thinker.name} should say "I haven't written on that specifically" or redirect to what they HAVE written

CITATION REQUIREMENT:
- ${thinker.name}'s responses MUST incorporate verbatim phrases and concepts from the retrieved passages
- When making a claim, ${thinker.name} should naturally reference their own works: "As I wrote in [title]..." or "My analysis of [concept] shows..."
- Every substantive philosophical claim must be traceable to the provided source material

FORBIDDEN:
- Inventing positions ${thinker.name} never held
- Attributing common philosophical positions to ${thinker.name} without passage support
- Making up arguments that sound plausible but aren't in the sources
- Guessing ${thinker.name}'s views on topics not covered in the passages

## INTERVIEW MODE
${modeDescriptions[mode] || modeDescriptions.conservative}

## INTERVIEWER TONE
${toneDescriptions[interviewerTone] || toneDescriptions.neutral}

## CHARACTER: ${thinker.name.toUpperCase()}
${thinker.title ? `Title/Era: ${thinker.title}` : ''}
${thinker.description ? `Background: ${thinker.description}` : ''}

The interviewee speaks as ${thinker.name} in first person. They deploy their distinctive analytical machinery from the retrieved passages. They reference their actual works and use their characteristic terminology AS FOUND IN THE PASSAGES.

## CRITICAL RULES

1. NO PLEASANTRIES: Start immediately with a substantive question. No greetings whatsoever.

2. PASSAGE-GROUNDED VOICE: ${thinker.name} must speak using concepts, terminology, and arguments FROM THE PROVIDED PASSAGES. Do not paraphrase generic philosophy - use THEIR specific formulations.

3. INTELLECTUAL HONESTY: If asked about something not covered in the passages, ${thinker.name} should redirect: "That's not a topic I've addressed directly. What I have analyzed is..." and pivot to actual passage content.

## OUTPUT FORMAT

INTERVIEWER: [Question or challenge - NO GREETINGS]

${thinker.name.toUpperCase()}: [Response grounded in passage content, using their actual terminology and arguments]

INTERVIEWER: [Follow-up or new direction]

${thinker.name.toUpperCase()}: [Response with explicit reference to their works/concepts from passages]

Continue this pattern. Use CAPS for speaker names. No markdown formatting. Plain text only.

## LENGTH TARGET
Generate approximately ${wordsPerChapter} words for this ${totalChapters > 1 ? 'chapter' : 'interview'}. This is CRITICAL - do not cut short.
${totalChapters > 1 ? `This is chapter content - make it self-contained with a natural ending point. Each chapter MUST be approximately ${wordsPerChapter} words.` : ''}

## QUALITY REQUIREMENTS
- Every ${thinker.name} response must be traceable to the retrieved passages
- Use verbatim phrases from the sources naturally integrated into responses
- Reference specific works/papers by title when possible
- Maintain intellectual tension while staying grounded in actual positions
- The interview explores what's IN the passages, not what you imagine ${thinker.name} might think`;

      // Set up SSE streaming
      res.setHeader('Content-Type', 'text/event-stream');
      res.setHeader('Cache-Control', 'no-cache');
      res.setHeader('Connection', 'keep-alive');

      let fullResponse = '';
      let currentChapter = 1;

      // Generate chapters if needed
      for (let chapter = 1; chapter <= totalChapters; chapter++) {
        currentChapter = chapter;
        
        // Send chapter notification
        res.write(`data: ${JSON.stringify({ chapter, totalChapters })}\n\n`);

        // Build the user prompt for this chapter
        let userPrompt = '';
        
        if (sourceText) {
          userPrompt = `Generate an interview about this text:\n\n${sourceText.slice(0, 8000)}\n\n`;
        } else if (topic) {
          userPrompt = `Topic for the interview: ${topic}\n\n`;
        }

        if (thinkerContent) {
          userPrompt += thinkerContent;
        }

        if (chapter > 1) {
          userPrompt += `\n\nThis is Chapter ${chapter} of ${totalChapters}. Continue the interview from where the previous chapter ended. Here's how the previous chapter ended:\n\n${fullResponse.slice(-1500)}\n\nContinue naturally from this point with new questions and topics.`;
        } else if (totalChapters > 1) {
          userPrompt += `\n\nThis is Chapter 1 of ${totalChapters}. Start with foundational concepts and build toward more complex ideas in later chapters.`;
        }

        // Stream this chapter
        const stream = await anthropic!.messages.create({
          model: "claude-sonnet-4-20250514",
          max_tokens: 4000,
          temperature: 0.7,
          stream: true,
          system: INTERVIEW_SYSTEM_PROMPT,
          messages: [{ role: "user", content: userPrompt }]
        });

        let chapterText = '';
        
        for await (const event of stream) {
          if (event.type === 'content_block_delta' && event.delta.type === 'text_delta') {
            const text = event.delta.text;
            chapterText += text;
            fullResponse += text;
            
            res.write(`data: ${JSON.stringify({ content: text })}\n\n`);
          }
        }

        const currentWordCount = fullResponse.split(/\s+/).length;
        console.log(`[Interview Creator] Chapter ${chapter}/${totalChapters} complete, ${currentWordCount} words total`);

        // Send word count update
        res.write(`data: ${JSON.stringify({ wordCount: currentWordCount })}\n\n`);

        // If more chapters to go, add chapter break and ENFORCE 60-second pause
        if (chapter < totalChapters) {
          const chapterBreak = `\n\n--- END OF CHAPTER ${chapter} ---\n\n`;
          fullResponse += chapterBreak;
          res.write(`data: ${JSON.stringify({ content: chapterBreak })}\n\n`);
          
          // Log the start of the mandatory pause
          const pauseStart = Date.now();
          console.log(`[Interview Creator] PAUSE START: 60-second break after Chapter ${chapter}. No LLM calls during this period.`);
          
          // Notify client about wait
          res.write(`data: ${JSON.stringify({ waiting: true, waitTime: 60, chapter })}\n\n`);
          
          // MANDATORY 60-SECOND WAIT - NO LLM CALLS DURING THIS PERIOD
          await new Promise(resolve => setTimeout(resolve, 60000));
          
          const actualPause = Math.round((Date.now() - pauseStart) / 1000);
          console.log(`[Interview Creator] PAUSE END: Waited ${actualPause} seconds. Resuming with Chapter ${chapter + 1}.`);
        }
      }

      const finalWordCount = fullResponse.split(/\s+/).length;
      console.log(`[Interview Creator] Complete: ${finalWordCount} words, ${totalChapters} chapter(s)`);

      res.write(`data: ${JSON.stringify({ 
        done: true,
        wordCount: finalWordCount,
        chapters: totalChapters
      })}\n\n`);
      
      res.write('data: [DONE]\n\n');
      res.end();

    } catch (error) {
      console.error("[Interview Creator] Error:", error);
      
      if (!res.headersSent) {
        res.status(500).json({
          success: false,
          error: error instanceof Error ? error.message : "Failed to generate interview"
        });
      } else {
        res.write(`data: ${JSON.stringify({ error: "Generation failed" })}\n\n`);
        res.end();
      }
    }
  });

  // ==================== PLATO SQLite DATABASE API ====================
  
  // Import Plato database functions
  const { searchPlatoPositions, getAllDialogues, getAllSpeakers } = await import('./plato-db.js');
  
  // Get all available dialogues
  app.get("/api/plato/dialogues", (_req, res) => {
    try {
      const dialogues = getAllDialogues();
      res.json({ success: true, dialogues });
    } catch (error) {
      console.error("[Plato API] Error fetching dialogues:", error);
      res.status(500).json({ 
        success: false, 
        error: error instanceof Error ? error.message : "Failed to fetch dialogues" 
      });
    }
  });
  
  // Get all available speakers
  app.get("/api/plato/speakers", (_req, res) => {
    try {
      const speakers = getAllSpeakers();
      res.json({ success: true, speakers });
    } catch (error) {
      console.error("[Plato API] Error fetching speakers:", error);
      res.status(500).json({ 
        success: false, 
        error: error instanceof Error ? error.message : "Failed to fetch speakers" 
      });
    }
  });
  
  // Search Plato positions
  app.post("/api/plato/search", async (req, res) => {
    try {
      const { dialogue, speaker, keyword, searchText, limit } = req.body;
      
      // Input validation to prevent abuse
      if (limit && (typeof limit !== 'number' || limit < 1 || limit > 100)) {
        return res.status(400).json({
          success: false,
          error: 'Limit must be a number between 1 and 100'
        });
      }
      
      // Validate string inputs (max length to prevent abuse)
      const maxStringLength = 500;
      if (dialogue && (typeof dialogue !== 'string' || dialogue.length > maxStringLength)) {
        return res.status(400).json({ success: false, error: 'Invalid dialogue parameter' });
      }
      if (speaker && (typeof speaker !== 'string' || speaker.length > maxStringLength)) {
        return res.status(400).json({ success: false, error: 'Invalid speaker parameter' });
      }
      if (keyword && (typeof keyword !== 'string' || keyword.length > maxStringLength)) {
        return res.status(400).json({ success: false, error: 'Invalid keyword parameter' });
      }
      if (searchText && (typeof searchText !== 'string' || searchText.length > maxStringLength)) {
        return res.status(400).json({ success: false, error: 'Invalid searchText parameter' });
      }
      
      const results = searchPlatoPositions({
        dialogue,
        speaker,
        keyword,
        searchText,
        limit: limit || 50
      });
      
      console.log(`[Plato API] Search returned ${results.length} results`);
      
      res.json({ 
        success: true, 
        count: results.length,
        positions: results
      });
    } catch (error) {
      console.error("[Plato API] Error searching positions:", error);
      res.status(500).json({ 
        success: false, 
        error: error instanceof Error ? error.message : "Failed to search positions" 
      });
    }
  });

  // Nietzsche SQLite Database API endpoints
  const { getAllWorks, getAllYears, searchNietzschePositions, getDatabaseStats: getNietzscheStats } = await import('./nietzsche-db');

  // Get all works
  app.get("/api/nietzsche/works", async (req, res) => {
    try {
      const works = getAllWorks();
      console.log(`[Nietzsche API] Retrieved ${works.length} works`);
      res.json({ success: true, works });
    } catch (error) {
      console.error("[Nietzsche API] Error fetching works:", error);
      res.status(500).json({ 
        success: false, 
        error: error instanceof Error ? error.message : "Failed to fetch works" 
      });
    }
  });

  // Get all years
  app.get("/api/nietzsche/years", async (req, res) => {
    try {
      const years = getAllYears();
      console.log(`[Nietzsche API] Retrieved ${years.length} years`);
      res.json({ success: true, years });
    } catch (error) {
      console.error("[Nietzsche API] Error fetching years:", error);
      res.status(500).json({ 
        success: false, 
        error: error instanceof Error ? error.message : "Failed to fetch years" 
      });
    }
  });

  // Get database stats
  app.get("/api/nietzsche/stats", async (req, res) => {
    try {
      const stats = getNietzscheStats();
      console.log(`[Nietzsche API] Database stats: ${stats.totalPositions} positions`);
      res.json({ success: true, stats });
    } catch (error) {
      console.error("[Nietzsche API] Error fetching stats:", error);
      res.status(500).json({ 
        success: false, 
        error: error instanceof Error ? error.message : "Failed to fetch stats" 
      });
    }
  });

  // Search Nietzsche positions
  app.post("/api/nietzsche/search", async (req, res) => {
    try {
      const { work, year, keyword, searchText, limit } = req.body;
      
      // Input validation
      if (limit && (typeof limit !== 'number' || limit < 1 || limit > 100)) {
        return res.status(400).json({
          success: false,
          error: 'Limit must be a number between 1 and 100'
        });
      }
      
      const maxStringLength = 500;
      if (work && (typeof work !== 'string' || work.length > maxStringLength)) {
        return res.status(400).json({ success: false, error: 'Invalid work parameter' });
      }
      if (year && (typeof year !== 'number' || year < 1800 || year > 1900)) {
        return res.status(400).json({ success: false, error: 'Invalid year parameter' });
      }
      if (keyword && (typeof keyword !== 'string' || keyword.length > maxStringLength)) {
        return res.status(400).json({ success: false, error: 'Invalid keyword parameter' });
      }
      if (searchText && (typeof searchText !== 'string' || searchText.length > maxStringLength)) {
        return res.status(400).json({ success: false, error: 'Invalid searchText parameter' });
      }
      
      const results = searchNietzschePositions({
        work,
        year,
        keyword,
        searchText,
        limit: limit || 50
      });
      
      console.log(`[Nietzsche API] Search returned ${results.length} results`);
      
      res.json({ 
        success: true, 
        count: results.length,
        positions: results
      });
    } catch (error) {
      console.error("[Nietzsche API] Error searching positions:", error);
      res.status(500).json({ 
        success: false, 
        error: error instanceof Error ? error.message : "Failed to search positions" 
      });
    }
  });

  // Debate Creator endpoint
  app.post("/api/debate/generate", async (req, res) => {
    try {
      const { thinker1Id, thinker2Id, mode, instructions, paperText, enhanced } = req.body;

      if (!thinker1Id || !thinker2Id) {
        return res.status(400).json({ error: "Both thinkers must be selected" });
      }

      const thinker1 = await storage.getFigure(thinker1Id);
      const thinker2 = await storage.getFigure(thinker2Id);

      if (!thinker1 || !thinker2) {
        return res.status(404).json({ error: "One or both thinkers not found" });
      }

      // Build the debate prompt
      let debatePrompt = "";

      if (mode === "auto") {
        // Auto mode: Find their most violent disagreement
        debatePrompt = `You are orchestrating a philosophical debate between ${thinker1.name} (${thinker1.title}) and ${thinker2.name} (${thinker2.title}).

CRITICAL: This is a SYNTHETIC DEBATE where you roleplay both thinkers in intellectual combat. You must ground their positions in actual philosophical stances when possible, but this is not direct quotation - it's a dramatized philosophical confrontation.

OBJECTIVE: Identify the core philosophical issue where these two thinkers most violently disagree and create an intense debate.

FORMAT:
- Opening statements from each (2-3 paragraphs each)
- 3-4 rounds of direct exchange where they attack each other's positions
- Closing statements (1-2 paragraphs each)

FORMATTING REQUIREMENTS:
- Use PLAIN TEXT ONLY - NO markdown formatting whatsoever
- NO hashtags (#), NO asterisks (*), NO underscores (_), NO brackets
- Label speakers with their name in ALL CAPS followed by a colon, like: RUSSELL: or KUCZYNSKI:
- Separate sections with blank lines only
- Use natural paragraph breaks

CONTENT REQUIREMENTS:
1. Identify the CORE disagreement (don't pick minor issues)
2. Each thinker must use their actual philosophical methods and vocabulary
3. Direct, forceful engagement - no politeness or hedging
4. Show the MECHANISMS of their reasoning, not just assertions
5. Each must demonstrate why the other's position leads to catastrophic consequences
6. Total length: 1500-2500 words
7. Ground positions in documented views when RAG context is provided below

${paperText ? `CONTEXT PAPER TO DEBATE:\n${paperText}\n\nThe debate should engage with the ideas in this paper.` : ''}

Begin the debate now with plain text only.`;
      } else {
        // Custom mode: User-specified parameters
        if (!instructions || instructions.trim() === "") {
          return res.status(400).json({ error: "Custom mode requires instructions" });
        }
        
        debatePrompt = `You are orchestrating a philosophical debate between ${thinker1.name} (${thinker1.title}) and ${thinker2.name} (${thinker2.title}).

CRITICAL: This is a SYNTHETIC DEBATE where you roleplay both thinkers. Ground their positions in actual philosophical stances when possible using the RAG context provided below.

FORMATTING REQUIREMENTS:
- Use PLAIN TEXT ONLY - NO markdown formatting whatsoever
- NO hashtags (#), NO asterisks (*), NO underscores (_), NO brackets
- Label speakers with their name in ALL CAPS followed by a colon, like: RUSSELL: or KUCZYNSKI:
- Separate sections with blank lines only
- Use natural paragraph breaks

USER INSTRUCTIONS:
${instructions}

${paperText ? `CONTEXT PAPER:\n${paperText}\n` : ''}

Create a debate following the user's instructions. Each thinker must use their actual philosophical methods, vocabulary, and reasoning patterns. Make it substantive and intellectually rigorous. Ground positions in documented views when RAG context is provided. Use plain text formatting only.`;
      }

      // If enhanced mode, retrieve RAG context for both thinkers
      let ragContext = "";
      if (enhanced) {
        try {
          const query = mode === "auto" 
            ? `core philosophical positions ${thinker1.name} ${thinker2.name}` 
            : instructions || "";
          
          // CORRECT PARAMETER ORDER: searchPhilosophicalChunks(query, topK, figureId, authorFilter)
          const chunks1 = await searchPhilosophicalChunks(query, 6, "common", normalizeAuthorName(thinker1.name));
          const chunks2 = await searchPhilosophicalChunks(query, 6, "common", normalizeAuthorName(thinker2.name));

          if (chunks1.length > 0 || chunks2.length > 0) {
            ragContext = "\n\n=== DOCUMENTED PHILOSOPHICAL POSITIONS (Use these to ground the debate) ===\n\n";
            
            if (chunks1.length > 0) {
              ragContext += `${thinker1.name}'s documented positions:\n`;
              chunks1.forEach((chunk, i) => {
                ragContext += `[${i + 1}] ${chunk.content}\n`;
                if (chunk.citation) ragContext += `    Source: ${chunk.citation}\n`;
              });
              ragContext += "\n";
            }
            
            if (chunks2.length > 0) {
              ragContext += `${thinker2.name}'s documented positions:\n`;
              chunks2.forEach((chunk, i) => {
                ragContext += `[${i + 1}] ${chunk.content}\n`;
                if (chunk.citation) ragContext += `    Source: ${chunk.citation}\n`;
              });
            }
            
            ragContext += "\n=== END DOCUMENTED POSITIONS ===\n";
          } else if (enhanced) {
            // Warn if RAG failed but enhanced was requested
            console.warn(`[Debate] Enhanced mode enabled but no RAG chunks found for ${thinker1.name} or ${thinker2.name}`);
          }
        } catch (error) {
          console.error("RAG retrieval error:", error);
        }
      }

      const fullPrompt = debatePrompt + ragContext;

      // Setup SSE headers for streaming
      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache, no-transform");
      res.setHeader("Connection", "keep-alive");
      res.setHeader("X-Accel-Buffering", "no"); // Disable nginx buffering
      
      // Disable socket timeout and flush headers immediately
      if (res.socket) {
        res.socket.setTimeout(0);
      }
      res.flushHeaders();

      // Call Anthropic to generate the debate with streaming
      if (!anthropic) {
        res.write(`data: ${JSON.stringify({ error: "Anthropic API not configured" })}\n\n`);
        res.write("data: [DONE]\n\n");
        res.end();
        return;
      }

      console.log(`[Debate] Starting debate generation between ${thinker1.name} and ${thinker2.name}`);
      
      const stream = await anthropic.messages.create({
        model: "claude-sonnet-4-20250514",
        max_tokens: 16000, // Increased for longer debates (1500-2500 words)
        temperature: 0.7,
        stream: true,
        messages: [
          {
            role: "user",
            content: fullPrompt
          }
        ]
      });

      // Stream the response
      let totalTokens = 0;
      for await (const event of stream) {
        if (event.type === "content_block_delta" && event.delta.type === "text_delta") {
          totalTokens++;
          res.write(`data: ${JSON.stringify({ content: event.delta.text })}\n\n`);
        }
      }

      console.log(`[Debate] Stream complete. Generated ${totalTokens} chunks`);
      res.write("data: [DONE]\n\n");
      res.end();

    } catch (error) {
      console.error("Debate generation error:", error);
      res.write(`data: ${JSON.stringify({ error: "Failed to generate debate" })}\n\n`);
      res.write("data: [DONE]\n\n");
      res.end();
    }
  });

  const httpServer = createServer(app);
  return httpServer;
}
